year,title,body,clean_body,sentiment_label,sentiment_score,tone,ethical_issues,ethical_principles,recommendations,technologies,issue_count,principle_count,recommendation_count,technology_count
2024,Unknown Title,"Body
2024 DEC 26 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators discuss new findings in artificial intelligence. According to news originating from Surrey, United Kingdom, by NewsRx correspondents, research stated, ""This article explores how the work of ethical assurance is understood by those involved in artificial intelligence development and deployment, and uses the findings to consider how ethical reflection might be better supported."" 
 Funders for this research include Apex Award Scheme; Medical Research Council, Alzheimer's Society And Alzheimer's Research Uk. 
 The news correspondents obtained a quote from the research from University of Surrey: ""The article presents a case study of a multi-disciplinary project developing a care support system that used machine learning in remote monitoring of people living at home with dementia. In this project engineering and clinical perspectives come together through a fractionated interdisciplinary trading zone to address goals such as remote detection of urinary infections. Ethics is done, according to project participants, in formal ethical review processes and through a shared understanding of common goals, but also in discipline-specific practices that sit outside of the trading zone."" 
 According to the news reporters, the research concluded: ""A key role is played by team members who translate concerns between discipline-based research groups and who act as proxies for the ultimate users of the systems not directly present within the trading zone. These insights into cross-disciplinary ethical work in relation to smart care lead us to recommend that infrastructural support for imaginative and transparent ethical reflection needs to be woven through the collaborations that create artificial intelligence, both across disciplines and throughout the lifetime of a project."" 
 For more information on this research see: Ethics and Artificial Intelligence in the Interdisciplinary Collaborations of Smart Care. Science, Technology, & Human Values, 2024. The publisher for Science, Technology, & Human Values is SAGE Publications. 
 A free version of this journal article is available at https://doi.org/10.1177/01622439241302519. 
 Our news editors report that more information may be obtained by contacting Christine Hine, Department of Sociology, University of Surrey, Guildford, Surrey, United Kingdom. Additional authors for this research include Payam Barnaghi.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Christine Hine (orcid.org/0000-0002-1172-0252). 
 Keywords for this news article include: University of Surrey, Surrey, United Kingdom, Europe, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); INDUSTRIAL AUTOMATION (90%); INVESTIGATIONS (90%); MEDICAL RESEARCH (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); SMART TECHNOLOGY (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); TECHNOLOGY (79%); JOURNALISM (78%); CASE STUDIES (77%); ENGINEERING (77%); SOCIOLOGY (77%); ALZHEIMER'S DISEASE (75%); EMERGING TECHNOLOGY (74%); SOCIAL SCIENCE EDUCATION (73%); DEMENTIA (70%); MEDICINE & HEALTH (70%); UROGENITAL DISORDERS & INJURIES (52%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Organization: ALZHEIMER'S SOCIETY (83%)
Industry: MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INDUSTRIAL AUTOMATION (90%); ROBOTICS (90%); SMART TECHNOLOGY (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); ENGINEERING (77%)
Geographic: UNITED KINGDOM (90%); EUROPE (58%)
Load-Date: December 27, 2024","2024 DEC 26 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators discuss new findings in artificial intelligence. According to news originating from Surrey, United Kingdom, by NewsRx correspondents, research stated, ""This article explores how the work of ethical assurance is understood by those involved in artificial intelligence development and deployment, and uses the findings to consider how ethical reflection might be better supported."" 
 Funders for this research include Apex Award Scheme; Medical Research Council, Alzheimer's Society And Alzheimer's Research Uk. 
 The news correspondents obtained a quote from the research from University of Surrey: ""The article presents a case study of a multi-disciplinary project developing a care support system that used machine learning in remote monitoring of people living at home with dementia. In this project engineering and clinical perspectives come together through a fractionated interdisciplinary trading zone to address goals such as remote detection of urinary infections. Ethics is done, according to project participants, in formal ethical review processes and through a shared understanding of common goals, but also in discipline-specific practices that sit outside of the trading zone."" 
 According to the news reporters, the research concluded: ""A key role is played by team members who translate concerns between discipline-based research groups and who act as proxies for the ultimate users of the systems not directly present within the trading zone. These insights into cross-disciplinary ethical work in relation to smart care lead us to recommend that infrastructural support for imaginative and transparent ethical reflection needs to be woven through the collaborations that create artificial intelligence, both across disciplines and throughout the lifetime of a project."" 
 For more information on this research see: Ethics and Artificial Intelligence in the Interdisciplinary Collaborations of Smart Care. Science, Technology, & Human Values, 2024. The publisher for Science, Technology, & Human Values is SAGE Publications. 
 A free version of this journal article is available at https://doi.org/10.1177/01622439241302519. 
 Our news editors report that more information may be obtained by contacting Christine Hine, Department of Sociology, University of Surrey, Guildford, Surrey, United Kingdom. Additional authors for this research include Payam Barnaghi.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Christine Hine (orcid.org/0000-0002-1172-0252). 
 Keywords for this news article include: University of Surrey, Surrey, United Kingdom, Europe, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); INDUSTRIAL AUTOMATION (90%); INVESTIGATIONS (90%); MEDICAL RESEARCH (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); SMART TECHNOLOGY (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); TECHNOLOGY (79%); JOURNALISM (78%); CASE STUDIES (77%); ENGINEERING (77%); SOCIOLOGY (77%); ALZHEIMER'S DISEASE (75%); EMERGING TECHNOLOGY (74%); SOCIAL SCIENCE EDUCATION (73%); DEMENTIA (70%); MEDICINE & HEALTH (70%); UROGENITAL DISORDERS & INJURIES (52%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Organization: ALZHEIMER'S SOCIETY (83%)
Industry: MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INDUSTRIAL AUTOMATION (90%); ROBOTICS (90%); SMART TECHNOLOGY (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); ENGINEERING (77%)
Geographic: UNITED KINGDOM (90%); EUROPE (58%)
Load-Date: December 27, 2024",neutral,0.9145776629447937,balanced/neutral,[],[],['recommend'],"['machine learning', 'robotics']",0,0,1,2
2024,Unknown Title,"Byline: Nilesh Hirapra
Body
Abstract
In an era defined by rapid technological advancement, artificial intelligence (AI) and data science are reshaping industries, economies, and societal norms at an unprecedented pace. The digital transformation spurred by AI-driven innovations introduces transformative potential and profound ethical implications. This article explores the multi-faceted dimensions of AI and data ethics in the context of digital transformation, discussing ethical frameworks, regulatory requirements, societal implications, and the crucial role of corporate governance. Drawing on a range of interdisciplinary perspectives, we outline the complex ethical considerations arising from AI applications and emphasise the need for a collaborative approach to ensure responsible, fair, and transparent AI deployment.
Introduction
The integration of AI technologies into modern organisations is integral to digital transformation, improving decision-making, optimising processes, and enhancing consumer experiences. However, the powerful capabilities of AI bring a host of ethical dilemmas, especially concerning data privacy, algorithmic bias, accountability, transparency, and long-term societal impact. In this landscape, AI and data ethics are essential to address emerging ethical issues and align technological progress with human-centered values.
Foundations of AI and Data Ethics
AI ethics is grounded in interdisciplinary concepts, blending principles from philosophy, law, data science, and social sciences. Core ethical frameworks relevant to AI include:
* Consequentialism: Evaluating the ethicality of AI based on its outcomes, emphasising the benefits and harms.
* Deontology: Focusing on rules and duties, suggesting that AI must operate within pre-set ethical guidelines regardless of outcomes.
* Virtue Ethics: Focusing on the moral character of those developing and deploying AI systems.
* Human Rights: Asserting that AI should align with human rights, especially in areas like privacy, autonomy, and equity.
Data ethics, in tandem, concerns the responsible collection, processing, and analysis of data. Key data ethical principles involve transparency, consent, data security, and minimisation of harm.
Ethical Challenges in AI and Data-Driven Transformation
The application of AI technologies and the handling of vast data volumes raise several ethical concerns:
3.1 Data Privacy and Consent
Data privacy is foundational in AI ethics, with GDPR and CCPA as prominent regulations setting the global standards. However, data collection often involves complexities such as informed consent, data anonymisation, and secondary data usage. Challenges arise in balancing the utility of data with respect to user privacy, especially as companies leverage AI for personalised experiences.
3.2 Algorithmic Bias and Fairness
Algorithmic bias, often a byproduct of biased datasets or training processes, can lead to discriminatory outcomes in AI applications. This is particularly critical in areas like hiring, credit scoring, and law enforcement, where bias can reinforce existing inequalities. Addressing bias requires an approach that prioritises fairness in data sourcing, algorithm design, and continual auditing.
3.3 Accountability and Transparency
The ""black box"" nature of many AI systems creates a gap in understanding how algorithms reach specific decisions, complicating accountability. As AI decisions impact human lives, transparency becomes essential to build trust, and ensure that outcomes are justifiable and explainable. Interpretability methods, such as explainable AI (XAI), are crucial to address these issues.
3.4 Autonomous Decision-Making
The ethical implications of AI-driven decision-making, especially in sensitive sectors such as healthcare, finance, and autonomous driving, are profound. Autonomous decision-making poses risks of unintended consequences, raising the need for well-defined ethical guidelines that ensure AI systems are safe, reliable, and aligned with societal values.
3.5 Surveillance and Social Manipulation
AI-powered surveillance technologies, particularly facial recognition and behavioral analysis, have raised concerns around personal freedom and autonomy. Surveillance presents an ethical paradox between ensuring security and maintaining privacy. Additionally, AI can be exploited for manipulation, as seen in algorithmic amplification of disinformation on social media platforms, impacting democratic processes and public opinion.
3.6 Long-Term Societal Impact
Beyond immediate ethical issues, the long-term societal impact of AI-driven transformation includes questions about employment displacement, economic inequality, and the influence on social structures. Policies are needed to ensure that digital transformation enhances societal welfare and does not exacerbate socio-economic divides.
Ethical Governance and Regulatory Approaches
Given the potential for AI to disrupt societal norms and regulations, ethical governance frameworks are increasingly recognised as essential for responsible AI. Key approaches include:
4.1 Regulatory Frameworks
Countries globally are implementing regulatory frameworks to manage AI ethics. For instance, the European Union's Artificial Intelligence Act classifies AI applications into risk categories, mandating specific regulations for high-risk systems. Other initiatives like the OECD AI Principles and UNESCO's Recommendation on AI Ethics establish broad guidelines emphasising fairness, accountability, and transparency.
4.2 Corporate Responsibility and Governance
Organisations are increasingly adopting ethical AI governance frameworks. AI ethics boards and external audits are becoming standard practice to ensure AI systems are compliant with ethical standards. Corporate governance structures should include accountability mechanisms, transparency requirements, and bias mitigation processes.
4.3 Human-Centric AI and Ethical Design
Ethical design principles focus on creating AI systems that prioritise human welfare, emphasising values like respect for privacy, inclusivity, and transparency. Design strategies like privacy-by-design and explainability-by-design encourage the development of AI systems that inherently respect ethical principles, fostering user trust.
4.4 Multi-Stakeholder Collaboration
Addressing AI ethics requires collaboration among government entities, private companies, academia, and civil society organisations. Public-private partnerships, ethical AI research initiatives, and open-source AI ethics platforms enable knowledge sharing and collective problem-solving, advancing ethical standards in AI development.
Case Studies: Navigating Ethical Dilemmas
Case Study 1: Healthcare and Predictive Analytics
In healthcare, predictive AI models are used to forecast patient outcomes, optimise treatments, and reduce operational inefficiencies. However, data sensitivity in healthcare demands robust ethical safeguards. Ethical challenges include data privacy, potential biases, and issues of accountability if AI misdiagnoses or makes incorrect predictions. Transparent, accountable systems that emphasise patient consent and data security are essential.
Case Study 2: Hiring Algorithms and Bias
AI in hiring has become common, with tools that analyse candidate profiles to predict job performance. However, these algorithms risk perpetuating biases based on gender, ethnicity, or socioeconomic background. A high-profile example is Amazon's hiring tool, which was found to favor male candidates due to historical bias in training data. Fairness-focused interventions and diverse training datasets are essential for ethical AI in hiring.
Case Study 3: Autonomous Vehicles and Responsibility
Autonomous vehicles present a profound ethical challenge as they transition decision-making from humans to machines. In situations like unavoidable accidents, ethical dilemmas emerge regarding whom the system should prioritise. Addressing these concerns involves ethical programming, regulatory oversight, and establishing accountability standards.
The Future of Ethical AI and Digital Transformation
AI and data ethics will evolve as AI technologies advance and societies adapt to digital transformation. Key considerations for the future include:
* Adaptive Regulatory Models: Regulations must evolve to match the pace of technological change, incorporating new insights and methodologies to address emerging ethical concerns.
* AI Ethics Education and Literacy: Promoting AI ethics literacy among developers, business leaders, and the public is crucial to build a culture of ethical AI use and understanding.
* Ethical AI Tools and Frameworks: Continuous development of tools, such as fairness audits, explainability modules, and bias detection systems, can support organisations in implementing ethical AI.
* Emphasis on Human-Values Alignment: Future AI systems should prioritise alignment with human-centered values, emphasising respect, equity, and empowerment for all societal members.
Implications of AI and Data Ethics on Industry Sectors
AI's applications span multiple sectors, each of which faces unique ethical challenges due to the specific contexts and impacts of digital transformation. We explore the implications for three key industries:
8.1 Financial Services
AI has revolutionised financial services, automating credit scoring, risk assessment, and fraud detection. However, ethical considerations are critical, particularly concerning:
* Bias in Lending and Credit Scoring: Algorithms used in credit scoring can unfairly disadvantage groups based on socio-economic, racial, or demographic biases within the data. Ensuring that models undergo fairness assessments and have representative training data is essential.
* Transparency in Automated Decision-Making: Financial decisions affect lives significantly, and opaque models can lead to mistrust. Financial firms are implementing explainable AI techniques, such as interpretable machine learning models, to provide stakeholders with insights into decision-making processes.
* Privacy in Data Utilisation: Financial institutions handle sensitive data, requiring high levels of security. Compliance with regulations such as GDPR and the Financial Industry Regulatory Authority (FINRA) is essential to maintain ethical data practices.
8.2 Healthcare
Healthcare is another area where AI's potential to improve diagnostics, patient outcomes, and operational efficiencies is tempered by ethical concerns:
* Patient Privacy and Data Consent: Patient data is highly sensitive. Ethical AI in healthcare emphasises privacy-preserving data techniques, like federated learning and differential privacy, to ensure patients' data security.
* Bias in Diagnostic Algorithms: Datasets used in training healthcare AI systems may lack diversity, leading to bias in diagnostic outputs. Regular validation and testing with diverse datasets help reduce these biases.
* Ethical AI in Treatment Planning: Algorithms that assist in treatment planning must consider ethical questions about resource allocation and medical prioritisation to ensure fair patient treatment.
8.3 Retail and Marketing
AI's role in retail and marketing has enhanced customer targeting and personalisation, but not without ethical concerns:
* Privacy in Consumer Data Collection: AI-driven personalisation often relies on extensive consumer data collection, raising questions about user consent and data handling. Ethical AI in retail requires transparent data usage policies and adherence to regulations such as CCPA and GDPR.
* Algorithmic Influence on Consumer Choices: AI algorithms often shape consumer behavior through recommendation engines. Ethical AI in retail promotes fairness by avoiding manipulative tactics and ensuring customers have an unbiased selection.
* Equity in Price Discrimination: Dynamic pricing, where prices change based on perceived customer data, can lead to unethical practices if it disproportionately affects vulnerable populations. Ethical retail AI should adopt fair pricing models to prevent exploitative tactics.
Ethical Tools and Techniques for AI
To support organisations in navigating AI ethics, various tools and techniques have emerged to assist in ethical decision-making:
9.1 Fairness Audits and Bias Detection
Fairness audits assess AI systems for bias, examining data, algorithms, and outputs. Common techniques include:
* Preprocessing Techniques: Modify data before training to reduce bias, such as rebalancing data classes or equalising opportunity scores.
* In-Processing Techniques: Integrate fairness constraints within the algorithm training process to improve unbiased predictions.
* Post-Processing Techniques: Adjust outputs to align with fairness metrics after model training, such as threshold adjustments or re-ranking.
9.2 Explainability and Transparency Tools
Explainable AI (XAI) tools help demystify the ""black box"" nature of AI, allowing developers and stakeholders to understand model decision-making. Some widely used XAI techniques include:
* LIME (Local Interpretable Model-agnostic Explanations): LIME approximates complex models with simpler interpretable models to help explain individual predictions.
* SHAP (SHapley Additive exPlanations): SHAP values provide insights into each feature's contribution to the output, based on cooperative game theory.
* Model Interpretability Layers: Integrate interpretability directly into model design, such as using decision trees or linear models within complex algorithms.
9.3 Privacy-Enhancing Technologies (PETs)
Privacy-Enhancing Technologies (PETs) enable ethical data usage by minimising risks related to data exposure. Key PETs include:
* Federated Learning: Allows model training across decentralised devices without centralising data, preserving user privacy.
* Differential Privacy: Adds statistical noise to data, making it challenging to identify individuals while allowing aggregate insights.
* Secure Multi-Party Computation: Allows multiple parties to compute a function over their inputs without revealing them, ensuring secure data collaboration.
The Ethical AI Development Lifecycle
Creating ethical AI systems requires a structured approach throughout the AI development lifecycle, emphasising ethics at every stage:
1. Define Ethical Goals: Establish ethics-focused objectives, such as privacy preservation or bias minimisation, based on the project context and societal values.
2. Data Collection and Preprocessing: Collect representative data, ensuring diversity and consent. Address potential biases by conducting audits during the data preprocessing stage.
3. Algorithm Design and Training: Incorporate fairness constraints and transparency requirements in model design. Utilise in-processing techniques to minimise bias within training processes.
4. Evaluation and Testing: Evaluate AI systems using ethics metrics, such as fairness, accountability, and explainability. Conduct external audits where applicable.
6. Deployment and Monitoring: Monitor AI systems post-deployment to track ethical performance and maintain accountability. Regularly update models to incorporate new ethical standards.
7. User and Stakeholder Engagement: Communicate AI systems' ethical implications to users and stakeholders, enabling informed decisions and feedback loops for continuous improvement.
Conclusion
AI and data ethics are critical in ensuring that digital transformation benefits society equitably and responsibly. Organisations adopting AI must navigate complex ethical challenges, such as ensuring data privacy, minimising bias, and upholding accountability. Ethical AI frameworks, tools, and techniques-coupled with robust governance and regulatory compliance-form a strong foundation for responsible AI practices.
As digital transformation accelerates, a collaborative approach among governments, corporations, researchers, and civil society will be vital to guide ethical AI development. By aligning AI systems with human-centered values, society can harness AI's potential to drive progress while safeguarding fundamental rights and social equity.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (97%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SCIENCE (90%); HUMANITIES & SOCIAL SCIENCE (78%); NEGATIVE SOCIETAL NEWS (78%); SOCIAL SCIENCES (78%); CORPORATE GOVERNANCE (76%); ENERGY & UTILITY LAW (76%); REGULATORY ACTIONS (76%); HUMAN SUBJECTS (69%); LAW ENFORCEMENT (66%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SCIENCE (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (90%); INFORMATION SECURITY & PRIVACY (89%); ENERGY & UTILITY LAW (76%); DATA SECURITY (73%); CREDIT RATINGS (50%)
Load-Date: November 13, 2024","Abstract
In an era defined by rapid technological advancement, artificial intelligence (AI) and data science are reshaping industries, economies, and societal norms at an unprecedented pace. The digital transformation spurred by AI-driven innovations introduces transformative potential and profound ethical implications. This article explores the multi-faceted dimensions of AI and data ethics in the context of digital transformation, discussing ethical frameworks, regulatory requirements, societal implications, and the crucial role of corporate governance. Drawing on a range of interdisciplinary perspectives, we outline the complex ethical considerations arising from AI applications and emphasise the need for a collaborative approach to ensure responsible, fair, and transparent AI deployment.
Introduction
The integration of AI technologies into modern organisations is integral to digital transformation, improving decision-making, optimising processes, and enhancing consumer experiences. However, the powerful capabilities of AI bring a host of ethical dilemmas, especially concerning data privacy, algorithmic bias, accountability, transparency, and long-term societal impact. In this landscape, AI and data ethics are essential to address emerging ethical issues and align technological progress with human-centered values.
Foundations of AI and Data Ethics
AI ethics is grounded in interdisciplinary concepts, blending principles from philosophy, law, data science, and social sciences. Core ethical frameworks relevant to AI include:
* Consequentialism: Evaluating the ethicality of AI based on its outcomes, emphasising the benefits and harms.
* Deontology: Focusing on rules and duties, suggesting that AI must operate within pre-set ethical guidelines regardless of outcomes.
* Virtue Ethics: Focusing on the moral character of those developing and deploying AI systems.
* Human Rights: Asserting that AI should align with human rights, especially in areas like privacy, autonomy, and equity.
Data ethics, in tandem, concerns the responsible collection, processing, and analysis of data. Key data ethical principles involve transparency, consent, data security, and minimisation of harm.
Ethical Challenges in AI and Data-Driven Transformation
The application of AI technologies and the handling of vast data volumes raise several ethical concerns:
3.1 Data Privacy and Consent
Data privacy is foundational in AI ethics, with GDPR and CCPA as prominent regulations setting the global standards. However, data collection often involves complexities such as informed consent, data anonymisation, and secondary data usage. Challenges arise in balancing the utility of data with respect to user privacy, especially as companies leverage AI for personalised experiences.
3.2 Algorithmic Bias and Fairness
Algorithmic bias, often a byproduct of biased datasets or training processes, can lead to discriminatory outcomes in AI applications. This is particularly critical in areas like hiring, credit scoring, and law enforcement, where bias can reinforce existing inequalities. Addressing bias requires an approach that prioritises fairness in data sourcing, algorithm design, and continual auditing.
3.3 Accountability and Transparency
The ""black box"" nature of many AI systems creates a gap in understanding how algorithms reach specific decisions, complicating accountability. As AI decisions impact human lives, transparency becomes essential to build trust, and ensure that outcomes are justifiable and explainable. Interpretability methods, such as explainable AI (XAI), are crucial to address these issues.
3.4 Autonomous Decision-Making
The ethical implications of AI-driven decision-making, especially in sensitive sectors such as healthcare, finance, and autonomous driving, are profound. Autonomous decision-making poses risks of unintended consequences, raising the need for well-defined ethical guidelines that ensure AI systems are safe, reliable, and aligned with societal values.
3.5 Surveillance and Social Manipulation
AI-powered surveillance technologies, particularly facial recognition and behavioral analysis, have raised concerns around personal freedom and autonomy. Surveillance presents an ethical paradox between ensuring security and maintaining privacy. Additionally, AI can be exploited for manipulation, as seen in algorithmic amplification of disinformation on social media platforms, impacting democratic processes and public opinion.
3.6 Long-Term Societal Impact
Beyond immediate ethical issues, the long-term societal impact of AI-driven transformation includes questions about employment displacement, economic inequality, and the influence on social structures. Policies are needed to ensure that digital transformation enhances societal welfare and does not exacerbate socio-economic divides.
Ethical Governance and Regulatory Approaches
Given the potential for AI to disrupt societal norms and regulations, ethical governance frameworks are increasingly recognised as essential for responsible AI. Key approaches include:
4.1 Regulatory Frameworks
Countries globally are implementing regulatory frameworks to manage AI ethics. For instance, the European Union's Artificial Intelligence Act classifies AI applications into risk categories, mandating specific regulations for high-risk systems. Other initiatives like the OECD AI Principles and UNESCO's Recommendation on AI Ethics establish broad guidelines emphasising fairness, accountability, and transparency.
4.2 Corporate Responsibility and Governance
Organisations are increasingly adopting ethical AI governance frameworks. AI ethics boards and external audits are becoming standard practice to ensure AI systems are compliant with ethical standards. Corporate governance structures should include accountability mechanisms, transparency requirements, and bias mitigation processes.
4.3 Human-Centric AI and Ethical Design
Ethical design principles focus on creating AI systems that prioritise human welfare, emphasising values like respect for privacy, inclusivity, and transparency. Design strategies like privacy-by-design and explainability-by-design encourage the development of AI systems that inherently respect ethical principles, fostering user trust.
4.4 Multi-Stakeholder Collaboration
Addressing AI ethics requires collaboration among government entities, private companies, academia, and civil society organisations. Public-private partnerships, ethical AI research initiatives, and open-source AI ethics platforms enable knowledge sharing and collective problem-solving, advancing ethical standards in AI development.
Case Studies: Navigating Ethical Dilemmas
Case Study 1: Healthcare and Predictive Analytics
In healthcare, predictive AI models are used to forecast patient outcomes, optimise treatments, and reduce operational inefficiencies. However, data sensitivity in healthcare demands robust ethical safeguards. Ethical challenges include data privacy, potential biases, and issues of accountability if AI misdiagnoses or makes incorrect predictions. Transparent, accountable systems that emphasise patient consent and data security are essential.
Case Study 2: Hiring Algorithms and Bias
AI in hiring has become common, with tools that analyse candidate profiles to predict job performance. However, these algorithms risk perpetuating biases based on gender, ethnicity, or socioeconomic background. A high-profile example is Amazon's hiring tool, which was found to favor male candidates due to historical bias in training data. Fairness-focused interventions and diverse training datasets are essential for ethical AI in hiring.
Case Study 3: Autonomous Vehicles and Responsibility
Autonomous vehicles present a profound ethical challenge as they transition decision-making from humans to machines. In situations like unavoidable accidents, ethical dilemmas emerge regarding whom the system should prioritise. Addressing these concerns involves ethical programming, regulatory oversight, and establishing accountability standards.
The Future of Ethical AI and Digital Transformation
AI and data ethics will evolve as AI technologies advance and societies adapt to digital transformation. Key considerations for the future include:
* Adaptive Regulatory Models: Regulations must evolve to match the pace of technological change, incorporating new insights and methodologies to address emerging ethical concerns.
* AI Ethics Education and Literacy: Promoting AI ethics literacy among developers, business leaders, and the public is crucial to build a culture of ethical AI use and understanding.
* Ethical AI Tools and Frameworks: Continuous development of tools, such as fairness audits, explainability modules, and bias detection systems, can support organisations in implementing ethical AI.
* Emphasis on Human-Values Alignment: Future AI systems should prioritise alignment with human-centered values, emphasising respect, equity, and empowerment for all societal members.
Implications of AI and Data Ethics on Industry Sectors
AI's applications span multiple sectors, each of which faces unique ethical challenges due to the specific contexts and impacts of digital transformation. We explore the implications for three key industries:
8.1 Financial Services
AI has revolutionised financial services, automating credit scoring, risk assessment, and fraud detection. However, ethical considerations are critical, particularly concerning:
* Bias in Lending and Credit Scoring: Algorithms used in credit scoring can unfairly disadvantage groups based on socio-economic, racial, or demographic biases within the data. Ensuring that models undergo fairness assessments and have representative training data is essential.
* Transparency in Automated Decision-Making: Financial decisions affect lives significantly, and opaque models can lead to mistrust. Financial firms are implementing explainable AI techniques, such as interpretable machine learning models, to provide stakeholders with insights into decision-making processes.
* Privacy in Data Utilisation: Financial institutions handle sensitive data, requiring high levels of security. Compliance with regulations such as GDPR and the Financial Industry Regulatory Authority (FINRA) is essential to maintain ethical data practices.
8.2 Healthcare
Healthcare is another area where AI's potential to improve diagnostics, patient outcomes, and operational efficiencies is tempered by ethical concerns:
* Patient Privacy and Data Consent: Patient data is highly sensitive. Ethical AI in healthcare emphasises privacy-preserving data techniques, like federated learning and differential privacy, to ensure patients' data security.
* Bias in Diagnostic Algorithms: Datasets used in training healthcare AI systems may lack diversity, leading to bias in diagnostic outputs. Regular validation and testing with diverse datasets help reduce these biases.
* Ethical AI in Treatment Planning: Algorithms that assist in treatment planning must consider ethical questions about resource allocation and medical prioritisation to ensure fair patient treatment.
8.3 Retail and Marketing
AI's role in retail and marketing has enhanced customer targeting and personalisation, but not without ethical concerns:
* Privacy in Consumer Data Collection: AI-driven personalisation often relies on extensive consumer data collection, raising questions about user consent and data handling. Ethical AI in retail requires transparent data usage policies and adherence to regulations such as CCPA and GDPR.
* Algorithmic Influence on Consumer Choices: AI algorithms often shape consumer behavior through recommendation engines. Ethical AI in retail promotes fairness by avoiding manipulative tactics and ensuring customers have an unbiased selection.
* Equity in Price Discrimination: Dynamic pricing, where prices change based on perceived customer data, can lead to unethical practices if it disproportionately affects vulnerable populations. Ethical retail AI should adopt fair pricing models to prevent exploitative tactics.
Ethical Tools and Techniques for AI
To support organisations in navigating AI ethics, various tools and techniques have emerged to assist in ethical decision-making:
9.1 Fairness Audits and Bias Detection
Fairness audits assess AI systems for bias, examining data, algorithms, and outputs. Common techniques include:
* Preprocessing Techniques: Modify data before training to reduce bias, such as rebalancing data classes or equalising opportunity scores.
* In-Processing Techniques: Integrate fairness constraints within the algorithm training process to improve unbiased predictions.
* Post-Processing Techniques: Adjust outputs to align with fairness metrics after model training, such as threshold adjustments or re-ranking.
9.2 Explainability and Transparency Tools
Explainable AI (XAI) tools help demystify the ""black box"" nature of AI, allowing developers and stakeholders to understand model decision-making. Some widely used XAI techniques include:
* LIME (Local Interpretable Model-agnostic Explanations): LIME approximates complex models with simpler interpretable models to help explain individual predictions.
* SHAP (SHapley Additive exPlanations): SHAP values provide insights into each feature's contribution to the output, based on cooperative game theory.
* Model Interpretability Layers: Integrate interpretability directly into model design, such as using decision trees or linear models within complex algorithms.
9.3 Privacy-Enhancing Technologies (PETs)
Privacy-Enhancing Technologies (PETs) enable ethical data usage by minimising risks related to data exposure. Key PETs include:
* Federated Learning: Allows model training across decentralised devices without centralising data, preserving user privacy.
* Differential Privacy: Adds statistical noise to data, making it challenging to identify individuals while allowing aggregate insights.
* Secure Multi-Party Computation: Allows multiple parties to compute a function over their inputs without revealing them, ensuring secure data collaboration.
The Ethical AI Development Lifecycle
Creating ethical AI systems requires a structured approach throughout the AI development lifecycle, emphasising ethics at every stage:
1. Define Ethical Goals: Establish ethics-focused objectives, such as privacy preservation or bias minimisation, based on the project context and societal values.
2. Data Collection and Preprocessing: Collect representative data, ensuring diversity and consent. Address potential biases by conducting audits during the data preprocessing stage.
3. Algorithm Design and Training: Incorporate fairness constraints and transparency requirements in model design. Utilise in-processing techniques to minimise bias within training processes.
4. Evaluation and Testing: Evaluate AI systems using ethics metrics, such as fairness, accountability, and explainability. Conduct external audits where applicable.
6. Deployment and Monitoring: Monitor AI systems post-deployment to track ethical performance and maintain accountability. Regularly update models to incorporate new ethical standards.
7. User and Stakeholder Engagement: Communicate AI systems' ethical implications to users and stakeholders, enabling informed decisions and feedback loops for continuous improvement.
Conclusion
AI and data ethics are critical in ensuring that digital transformation benefits society equitably and responsibly. Organisations adopting AI must navigate complex ethical challenges, such as ensuring data privacy, minimising bias, and upholding accountability. Ethical AI frameworks, tools, and techniques-coupled with robust governance and regulatory compliance-form a strong foundation for responsible AI practices.
As digital transformation accelerates, a collaborative approach among governments, corporations, researchers, and civil society will be vital to guide ethical AI development. By aligning AI systems with human-centered values, society can harness AI's potential to drive progress while safeguarding fundamental rights and social equity.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (97%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SCIENCE (90%); HUMANITIES & SOCIAL SCIENCE (78%); NEGATIVE SOCIETAL NEWS (78%); SOCIAL SCIENCES (78%); CORPORATE GOVERNANCE (76%); ENERGY & UTILITY LAW (76%); REGULATORY ACTIONS (76%); HUMAN SUBJECTS (69%); LAW ENFORCEMENT (66%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SCIENCE (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (90%); INFORMATION SECURITY & PRIVACY (89%); ENERGY & UTILITY LAW (76%); DATA SECURITY (73%); CREDIT RATINGS (50%)
Load-Date: November 13, 2024",positive,0.6688525080680847,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'human rights', 'autonomy', 'consent', 'manipulation', 'disinformation', 'inclusivity', 'inequality']","['deontology', 'virtue ethics', 'character', 'fairness', 'equity', 'autonomy', 'consequentialism']","['governance', 'oversight', 'standards', 'guidelines', 'law', 'compliance', 'should', 'must']","['machine learning', 'facial recognition', 'algorithm', 'predictive analytics']",16,7,8,4
2024,Unknown Title,"Byline: Hillary
Body
November 4th, 2024 ( TechBullion  - Delivered by  Newstex )
Artificial Intelligence (AI) has become an incredibly powerful tool, reshaping everything from social media algorithms to self-driving cars and medical diagnostics. In Silicon Valley, the heart of tech innovation, AI is more than just a technology it's a driving force for shaping the future. But with this power comes a big question: how do we ensure AI is used ethically? For many, the ethics of AI isn't just about what it can do but about whether it should do certain things. This article explores the ethical dimensions of AI from a Silicon Valley perspective, looking at the challenges and potential solutions for using AI responsibly.
Understanding AI and Ethics
Ethics are the moral principles that guide our actions, helping us determine right from wrong. When it comes to AI, ethics involve considering the impact of AI systems on people and society. Silicon Valley companies like Google, Facebook, and Apple are building AI technologies that can affect millions of lives, so it's essential to understand how these technologies align with ethical principles.
In simple terms, ethical AI involves creating systems that are fair, unbiased, and safe for everyone. The idea is to make sure AI supports society positively and doesn't harm anyone in the process. But this isn't always easy AI is based on data, and data can be messy, biased, or incomplete, which makes ethical concerns a constant topic of discussion.
Why AI Ethics Matter in Silicon Valley
Silicon Valley is home to many of the world's top tech companies, which means it's also the birthplace of many AI innovations. Companies here are constantly pushing boundaries and exploring new possibilities, which makes it a hub of exciting but sometimes controversial advancements. When technology changes fast, it can be hard to keep up with the ethical considerations.
For instance, algorithms that recommend social media posts or suggest search results can unintentionally reinforce harmful stereotypes or spread misinformation. Imagine a young person seeing misleading or biased content repeatedly, possibly influencing their beliefs or opinions. This impact is one of many ethical challenges Silicon Valley companies face, and it's why they're starting to take AI ethics more seriously. In recent years, several tech companies have even established 'AI ethics boards' or hired 'ethics officers' to help guide responsible AI development.
Key Ethical Challenges in AI Development
Silicon Valley's biggest AI challenges boil down to issues like privacy, bias, accountability, and transparency. Here's a breakdown of each:
Privacy: AI relies on vast amounts of data, including personal information, to function effectively. For example, AI can predict what movies you might like by analyzing your past viewing history. But what if AI systems use personal information without consent? Privacy concerns have sparked debates on how data should be collected, stored, and used. Silicon Valley companies are now finding ways to protect privacy, such as anonymizing data (removing identifiers) before processing it.
Bias: Since AI systems learn from data, they can pick up biases present in that data. For instance, a hiring AI trained on biased data might favor certain genders or backgrounds over others. This is a big problem because bias can lead to unfair treatment. Silicon Valley tech companies are actively researching ways to reduce bias, such as testing AI systems on diverse data sets to make sure they work fairly for everyone.
Accountability: If an AI system makes a mistake, who is responsible? For example, if a self-driving car crashes, is the company, the car manufacturer, or the programmer responsible? Accountability in AI is tricky because it can be hard to trace decisions back to specific people. Silicon Valley is working on ways to ensure someone is accountable when things go wrong, which is crucial for building trust.
Transparency: Transparency means making AI processes easy to understand. Imagine trying to figure out how a complicated math problem works without seeing the steps involved. The same goes for AI if companies keep their AI 'black boxes' closed, it's hard for users to know if decisions are fair. Silicon Valley leaders are exploring ways to open up AI processes, making them easier to understand and explain.
Steps Silicon Valley is Taking for Ethical AI
Addressing AI ethics isn't just about talking; it requires real action. Many Silicon Valley companies are making meaningful changes to ensure their AI technologies align with ethical principles. Here are some of the key steps being taken:
Creating Ethical Guidelines: Companies like Google, Microsoft, and Facebook have published AI ethical guidelines that outline how their technologies should respect privacy, avoid bias, and maintain transparency. These guidelines set a standard for how AI should be used responsibly.
Building Diverse Teams: Diverse teams can help reduce bias in AI development. By hiring people from different backgrounds, companies can gain a broader perspective and create AI systems that are fairer for everyone. Many Silicon Valley companies are actively working to make their teams more diverse to avoid 'groupthink' and encourage a variety of viewpoints.
Developing Fairness Tools: Fairness tools are software solutions that help identify and reduce bias in AI systems. For example, IBM has developed tools that scan AI models for signs of bias, alerting developers when adjustments are needed. These tools are becoming more popular in Silicon Valley, making it easier to create fair AI systems.
Collaborating with Experts:  Silicon Valley companies are working closely with ethicists, sociologists, and human rights experts to better understand the ethical implications of their AI technologies. By getting input from people outside the tech world, these companies can better address the real-world impacts of their innovations.
The Role of Regulation in Ethical AI
Government regulation is another critical factor in AI ethics. In the U.S., there's currently no single set of rules governing AI use, but many argue that we need regulations to protect society from harmful AI practices. For instance, the European Union has introduced the AI Act, which sets rules to prevent risky AI applications, like facial recognition in public spaces, from being misused.
In Silicon Valley, some tech companies are open to regulation, understanding that responsible AI is necessary for building public trust. However, others worry that too many rules could slow innovation. The balance between innovation and regulation is a delicate one, and Silicon Valley is watching closely as the government develops policies for AI.
A Look to the Future: Ethical AI as a Core Value
The ethical challenges of AI are likely to grow as technology becomes even more advanced. Silicon Valley companies know that they need to embrace ethical AI as a core value, not just a 'nice-to-have.' Building trustworthy AI means ensuring that it benefits society, respects individual rights, and minimizes harm.
Youths interested in tech and AI are also essential in shaping this future. Many Silicon Valley companies offer internships, workshops, and online courses to educate the next generation on responsible AI practices. Learning about AI ethics early on can help you, as future developers, engineers, or tech influencers, contribute positively to society.
Conclusion
Ethics in AI isn't just about controlling what AI can or cannot do; it's about guiding AI in a way that benefits society as a whole.  Silicon Valley, as the birthplace of many AI innovations, holds a significant responsibility to make ethical AI a priority. While challenges like privacy, bias, accountability, and transparency remain, the steps being taken by tech companies to address them are a promising start.
As AI continues to advance, ethical considerations will become more important than ever. Youths interested in technology can play a big role in this journey by advocating for and learning about ethical practices in AI. With a collective effort from tech companies, policymakers, and the next generation, we can work toward a future where AI helps everyone ethically and responsibly.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); TECHNOLOGY (90%); SOCIAL MEDIA (89%); BLOGS & MESSAGE BOARDS (78%); BUSINESS ETHICS (78%); INTERNET SOCIAL NETWORKING (78%); MEDICAL DIAGNOSTICS, SCREENING & TESTING (77%); DISINFORMATION & MISINFORMATION (68%); PRIVACY RIGHTS (62%); Artificial intelligence (%); Technology (%); AI technologies (%); Ethics in AI (%); Silicon Valley (%)
Company:  GOOGLE LLC (58%);  META PLATFORMS INC (56%)
Ticker: META (NASDAQ) (56%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (56%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (56%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (89%); SOCIAL MEDIA (89%); BLOGS & MESSAGE BOARDS (78%); INTERNET SOCIAL NETWORKING (78%); AUTONOMOUS MOTOR VEHICLES (72%); INFORMATION SECURITY & PRIVACY (69%)
Geographic: SILICON VALLEY, CA, USA (94%)
Load-Date: November 4, 2024","November 4th, 2024 ( TechBullion  - Delivered by  Newstex )
Artificial Intelligence (AI) has become an incredibly powerful tool, reshaping everything from social media algorithms to self-driving cars and medical diagnostics. In Silicon Valley, the heart of tech innovation, AI is more than just a technology it's a driving force for shaping the future. But with this power comes a big question: how do we ensure AI is used ethically? For many, the ethics of AI isn't just about what it can do but about whether it should do certain things. This article explores the ethical dimensions of AI from a Silicon Valley perspective, looking at the challenges and potential solutions for using AI responsibly.
Understanding AI and Ethics
Ethics are the moral principles that guide our actions, helping us determine right from wrong. When it comes to AI, ethics involve considering the impact of AI systems on people and society. Silicon Valley companies like Google, Facebook, and Apple are building AI technologies that can affect millions of lives, so it's essential to understand how these technologies align with ethical principles.
In simple terms, ethical AI involves creating systems that are fair, unbiased, and safe for everyone. The idea is to make sure AI supports society positively and doesn't harm anyone in the process. But this isn't always easy AI is based on data, and data can be messy, biased, or incomplete, which makes ethical concerns a constant topic of discussion.
Why AI Ethics Matter in Silicon Valley
Silicon Valley is home to many of the world's top tech companies, which means it's also the birthplace of many AI innovations. Companies here are constantly pushing boundaries and exploring new possibilities, which makes it a hub of exciting but sometimes controversial advancements. When technology changes fast, it can be hard to keep up with the ethical considerations.
For instance, algorithms that recommend social media posts or suggest search results can unintentionally reinforce harmful stereotypes or spread misinformation. Imagine a young person seeing misleading or biased content repeatedly, possibly influencing their beliefs or opinions. This impact is one of many ethical challenges Silicon Valley companies face, and it's why they're starting to take AI ethics more seriously. In recent years, several tech companies have even established 'AI ethics boards' or hired 'ethics officers' to help guide responsible AI development.
Key Ethical Challenges in AI Development
Silicon Valley's biggest AI challenges boil down to issues like privacy, bias, accountability, and transparency. Here's a breakdown of each:
Privacy: AI relies on vast amounts of data, including personal information, to function effectively. For example, AI can predict what movies you might like by analyzing your past viewing history. But what if AI systems use personal information without consent? Privacy concerns have sparked debates on how data should be collected, stored, and used. Silicon Valley companies are now finding ways to protect privacy, such as anonymizing data (removing identifiers) before processing it.
Bias: Since AI systems learn from data, they can pick up biases present in that data. For instance, a hiring AI trained on biased data might favor certain genders or backgrounds over others. This is a big problem because bias can lead to unfair treatment. Silicon Valley tech companies are actively researching ways to reduce bias, such as testing AI systems on diverse data sets to make sure they work fairly for everyone.
Accountability: If an AI system makes a mistake, who is responsible? For example, if a self-driving car crashes, is the company, the car manufacturer, or the programmer responsible? Accountability in AI is tricky because it can be hard to trace decisions back to specific people. Silicon Valley is working on ways to ensure someone is accountable when things go wrong, which is crucial for building trust.
Transparency: Transparency means making AI processes easy to understand. Imagine trying to figure out how a complicated math problem works without seeing the steps involved. The same goes for AI if companies keep their AI 'black boxes' closed, it's hard for users to know if decisions are fair. Silicon Valley leaders are exploring ways to open up AI processes, making them easier to understand and explain.
Steps Silicon Valley is Taking for Ethical AI
Addressing AI ethics isn't just about talking; it requires real action. Many Silicon Valley companies are making meaningful changes to ensure their AI technologies align with ethical principles. Here are some of the key steps being taken:
Creating Ethical Guidelines: Companies like Google, Microsoft, and Facebook have published AI ethical guidelines that outline how their technologies should respect privacy, avoid bias, and maintain transparency. These guidelines set a standard for how AI should be used responsibly.
Building Diverse Teams: Diverse teams can help reduce bias in AI development. By hiring people from different backgrounds, companies can gain a broader perspective and create AI systems that are fairer for everyone. Many Silicon Valley companies are actively working to make their teams more diverse to avoid 'groupthink' and encourage a variety of viewpoints.
Developing Fairness Tools: Fairness tools are software solutions that help identify and reduce bias in AI systems. For example, IBM has developed tools that scan AI models for signs of bias, alerting developers when adjustments are needed. These tools are becoming more popular in Silicon Valley, making it easier to create fair AI systems.
Collaborating with Experts:  Silicon Valley companies are working closely with ethicists, sociologists, and human rights experts to better understand the ethical implications of their AI technologies. By getting input from people outside the tech world, these companies can better address the real-world impacts of their innovations.
The Role of Regulation in Ethical AI
Government regulation is another critical factor in AI ethics. In the U.S., there's currently no single set of rules governing AI use, but many argue that we need regulations to protect society from harmful AI practices. For instance, the European Union has introduced the AI Act, which sets rules to prevent risky AI applications, like facial recognition in public spaces, from being misused.
In Silicon Valley, some tech companies are open to regulation, understanding that responsible AI is necessary for building public trust. However, others worry that too many rules could slow innovation. The balance between innovation and regulation is a delicate one, and Silicon Valley is watching closely as the government develops policies for AI.
A Look to the Future: Ethical AI as a Core Value
The ethical challenges of AI are likely to grow as technology becomes even more advanced. Silicon Valley companies know that they need to embrace ethical AI as a core value, not just a 'nice-to-have.' Building trustworthy AI means ensuring that it benefits society, respects individual rights, and minimizes harm.
Youths interested in tech and AI are also essential in shaping this future. Many Silicon Valley companies offer internships, workshops, and online courses to educate the next generation on responsible AI practices. Learning about AI ethics early on can help you, as future developers, engineers, or tech influencers, contribute positively to society.
Conclusion
Ethics in AI isn't just about controlling what AI can or cannot do; it's about guiding AI in a way that benefits society as a whole.  Silicon Valley, as the birthplace of many AI innovations, holds a significant responsibility to make ethical AI a priority. While challenges like privacy, bias, accountability, and transparency remain, the steps being taken by tech companies to address them are a promising start.
As AI continues to advance, ethical considerations will become more important than ever. Youths interested in technology can play a big role in this journey by advocating for and learning about ethical practices in AI. With a collective effort from tech companies, policymakers, and the next generation, we can work toward a future where AI helps everyone ethically and responsibly.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); TECHNOLOGY (90%); SOCIAL MEDIA (89%); BLOGS & MESSAGE BOARDS (78%); BUSINESS ETHICS (78%); INTERNET SOCIAL NETWORKING (78%); MEDICAL DIAGNOSTICS, SCREENING & TESTING (77%); DISINFORMATION & MISINFORMATION (68%); PRIVACY RIGHTS (62%); Artificial intelligence (%); Technology (%); AI technologies (%); Ethics in AI (%); Silicon Valley (%)
Company:  GOOGLE LLC (58%);  META PLATFORMS INC (56%)
Ticker: META (NASDAQ) (56%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (56%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (56%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (89%); SOCIAL MEDIA (89%); BLOGS & MESSAGE BOARDS (78%); INTERNET SOCIAL NETWORKING (78%); AUTONOMOUS MOTOR VEHICLES (72%); INFORMATION SECURITY & PRIVACY (69%)
Geographic: SILICON VALLEY, CA, USA (94%)
Load-Date: November 4, 2024",neutral,0.49855080246925354,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'security', 'human rights', 'consent', 'misinformation', 'disinformation']",['fairness'],"['regulation', 'guidelines', 'should', 'need to', 'recommend', 'suggest']","['facial recognition', 'self-driving car']",10,1,6,2
2024,Unknown Title,"Body
The 2024 nursing ethics conference brought together health and social care professionals, educators, leaders, ethicists and students to share international and interdisciplinary research and scholarship.
Brunel students contributed to the success of the conference by acting as volunteers and reading citations relating to the Human Rights and Nursing Awards. Students from the University of Genoa, Italy, presented their research in parallel sessions.
This Editorial captures the perspectives of students from Brunel University of London and from the University of Genoa. Student reflections are informative and important as they illuminate issues students perceived as most interesting and engaging.
Brunel University of London Pre-registration Student Authors: Sin Hang (John) Yip, BSc, in Occupational Therapy; Miriam Isaacs, MSc, Occupational Therapy; Elena Lambrianou, MSc, Physiotherapy and Chelsey Mordue, BSc, Nursing (Adult), Department of Health Sciences, Brunel University of London, Kingston Lane, Uxbridge, Middlesex UB8 3PH.
Email: ann.gallagher@brunel.ac.uk.
University of Genoa PhD Student Authors: Lara Delbene, Martin Barbieri, Michela Calzolari, Department of Health Sciences, University of Genoa, Via A. Pastore 116132, Genoa, Italy.
Email: giuseppe.aleo@edu.unige.it
Reflections from pre-registration students at Brunel University of London
The human rights and nursing awards – celebrating success and transferable insights
The importance of celebrating success and encouraging nurses to strive for excellence through the international nursing awards provided a good contrast to hearing about the challenges that nurses faced. As a Physiotherapy student, I was not aware of the scope of nursing and hearing about ethical challenges in a multinational setting was definitely a highlight. It was clear that although this was a nursing conference, a lot of the issues raised are transferable to all Allied Health Professionals – such as not being able to get the fundamentals right, timing constraints, pressure and the practitioner’s own perspectives. Despite a large focus on being on challenges, the discussions in the breakout sessions and vignettes of the award winners gave a sense of hope. I believe it was largely beneficial to hear about all three award winners as they had very different career paths and worked in different countries, overcoming different issues. Therefore, there was potential to inspire multiple groups of people who attended the awards, especially the students.
Fundamentals of care
The two-day conference began with an excellent exposition by Professor Sarah Banks on care in a ‘crisis’-stricken world. The point that struck me most keenly was how a discourse of crisis leads to suboptimal care being accepted. A lack of trust between patient and care-giver, bullying in the workforce and moral distress are likely to flourish in these conditions. The conference facilitated an interprofessional and international dialogue as to how we move from a framework of reactive care to proactive care. One of the key takeaways was a reflection made by Fiona Timmins that we must focus on the fundamentals of care. This struck me as an important antidote to the crisis narratives. A strong foundation has the potential to build trust, highlight ineffective and unethical practices and ensure that the cornerstones of care are firmly instilled.
Education as a positive force
The significance of education as a mechanism through which real and potential workforce crises could be resolved permeated discussions throughout the conference. Perhaps unsurprisingly, conference delegates, with backgrounds in health and social care and academia, viewed education as a positive force for change in the pursuit of ethically conscious healthcare provision. As has often been the case, education was lauded by many as a conduit for changing wider healthcare values and ethics.
Yet the crises facing nurse education were recognized as barriers to better workforce outcomes more widely. The English example of nurse education evidences a flawed construction on already unstable foundations; falling number of applicants, strained funding for both HEIs and students alike and, arguably, an excessive requirement of 2300 hours of unpaid clinical practice are a few of the mounting obstacles. In the shadow of such practical challenges, engaging students on matters of morals, values and ethics becomes increasingly difficult. As many delegates recognized, resolving workforce crises through education is not merely a matter of instructing students to bear ethics in mind. Rather, we need to teach students to be curious, to engage with the world at large and to think critically about what we do and why we do it.
Ethical competence
The work of the PROMOCON Project presented by an international team of researchers at the conference might be the future of producing morally competent nurses through the engagement of students with a purposively designed Massive Open Online Course (MOOC) exploring the ethical conditions of the profession. We look forward to the 25th international conference to learn of the project’s outcomes. While a perfect strategy for achieving an ethically minded workforce may not yet exist, the passion and commitment of delegates at the conference highlights that this is not yet the time for cynicism on the matter.
Impact of technology and Artificial Intelligence (AI) on care
Wes Streeting, the Secretary of State for Health and Social Care, declared that “the NHS is broken,” and his mission is to save it. One key change he proposes is transitioning the NHS from analogue to digital, an important step as AI rapidly emerges in clinical work. The benefits of using AI in clinical settings seem obvious – automation, and more efficient data processing could help ease the stress and burnout faced by healthcare professionals. Expanding technology in healthcare seems unavoidable, yet the ethical concerns surrounding the use of AI in clinical work remain urgent. These issues must be carefully explored and addressed, with clear principles established to ensure that ethical standards are upheld.
Ramvi et al.1 identified several challenges posed by technology in healthcare, including the disruption of relationship-based care, the risk of depersonalization and an overemphasis on efficiency and technical processes, which can overshadow the emotional and ethical aspects of care. Additionally, both healthcare professionals and patients may become increasingly vulnerable as their reliance on technology grows. At the 24th International Nursing Ethics Conference, Ellen Ramvi further explored these concerns. She emphasized that the true threat to care is not technology itself, but the structural conditions of scarcity. Furthermore, as long as communication and relationships remain central to care, technology is not opposed to ethical care. Therefore, it is important to create capacity for healthcare professionals to explore ways to balance the benefits of AI with the preservation of human connection in addressing these ethical challenges.
Reflections from PhD students at the University of Genoa
A platform to discuss issues openly
The 2024 International Nursing Ethics Conference addressed the ethical challenges faced by the global healthcare workforce amidst an ongoing care crisis. Central to the discussions were themes of moral distress, burnout and the ethical dilemmas healthcare professionals face when systemic issues hinder their ability to deliver adequate care. The conference underscored the pressing need to re-evaluate ethical frameworks to foster resilience and well-being for caregivers and patients alike. Many professionals find themselves unable to provide necessary care due to institutional constraints, a reality highlighted by participants who shared their experiences at the conference. The Nursing Ethics Conference provided us a platform to discuss these issues openly, offering diverse perspectives on how ethical leadership can mitigate the negative effects of the care crisis and giving us the opportunity to share our position presenting some of the projects we are working on.
Ethical leadership
A significant focus of the conference was the role of ethical leadership in addressing these challenges. Ethical leadership involves nurturing a culture where values like respect, dignity and care are prioritized. As highlighted by keynote speakers, ethical leadership transcends rule-following; it demands emotional and professional support for teams to maintain high standards of care. Presenting our project during a leadership-focused session sparked meaningful discussions about integrating leadership education early in nursing programs, differentiating between managerial and leadership roles, and effectively managing dissent in multidisciplinary teams. Such discussions are vital in preparing future healthcare professionals to navigate complex team dynamics while promoting a culture of ethical leadership.
Moral distress
The theme of moral distress aligns closely with our project on midwifery care, showcasing the interdisciplinary nature of this phenomenon. Moral distress affects not only nurses but also midwives and other healthcare professionals, underscoring the need for holistic, patient-centred care despite systemic barriers. In addition to discussing the severity of moral distress, the conference highlighted potential solutions. Advocates called for systemic changes, including improved staffing ratios, flexible working hours and enhanced mental health support for healthcare workers. One innovative proposal involved establishing ethical reflection groups to create a supportive environment for healthcare professionals to share experiences and tackle ethical dilemmas collectively. One of our presented projects focusing on reducing turnover among newly graduated nurses by ensuring a smooth transition from their bachelor’s degree into professional practice. The team recognizes that an effective transition is crucial for the well-being and professional development of healthcare professionals. By fostering a supportive environment during this critical phase, we aim to enhance job satisfaction and competence, thereby improving patient care and alleviating moral distress in the workforce.
The importance of ethics education
Finally, the conference emphasized the importance of ethics education that extends beyond theoretical knowledge to include practical training in handling real-world dilemmas. This approach will better prepare future healthcare professionals to navigate the complexities of modern healthcare environments with confidence and resilience. We commend the active participation and welcoming atmosphere fostered by the organizers and participants alike. This environment encouraged open dialogue, enabling us to reaffirm our professional identities and reinforcing our commitment to contribute to scientific discourse that adequately addresses the ethical dimensions of our field.
Bibliography
REFERENCE
1 Ramvi E, Hellstrand I, Jensen IB, , et al. Ethics of care in technology-mediated healthcare practices: A scoping review. Scand J Caring Sci 2023; 37: 1123–1135. DOI: 10.1111/scs.13186.
Graphic
Link to PDF
Classification
Language: ENGLISH
Publication-Type: Magazines & Journals
Subject: EDITORIALS & OPINIONS (99%); STUDENTS & STUDENT LIFE (92%); CONFERENCES & CONVENTIONS (90%); ETHICS (90%); HEALTH CARE PROFESSIONALS (90%); MEDICAL ETHICS (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (90%); SCHOLARSHIPS & GRANTS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); NURSES & NURSING (89%); PROFESSIONAL WORKERS (89%); OCCUPATIONAL THERAPY (88%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGE STUDENTS (78%); PUBLIC HEALTH ADMINISTRATION (78%); TALKS & MEETINGS (78%); TRADE SHOWS (78%); PHYSICAL THERAPY (74%)
Industry: HEALTH CARE PROFESSIONALS (90%); NURSES & NURSING (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGE STUDENTS (78%)
Geographic: LONDON, ENGLAND (90%); ITALY (72%); UNITED KINGDOM (57%)
Load-Date: November 21, 2024","The 2024 nursing ethics conference brought together health and social care professionals, educators, leaders, ethicists and students to share international and interdisciplinary research and scholarship.
Brunel students contributed to the success of the conference by acting as volunteers and reading citations relating to the Human Rights and Nursing Awards. Students from the University of Genoa, Italy, presented their research in parallel sessions.
This Editorial captures the perspectives of students from Brunel University of London and from the University of Genoa. Student reflections are informative and important as they illuminate issues students perceived as most interesting and engaging.
Brunel University of London Pre-registration Student Authors: Sin Hang (John) Yip, BSc, in Occupational Therapy; Miriam Isaacs, MSc, Occupational Therapy; Elena Lambrianou, MSc, Physiotherapy and Chelsey Mordue, BSc, Nursing (Adult), Department of Health Sciences, Brunel University of London, Kingston Lane, Uxbridge, Middlesex UB8 3PH.
Email: ann.gallagher@brunel.ac.uk.
University of Genoa PhD Student Authors: Lara Delbene, Martin Barbieri, Michela Calzolari, Department of Health Sciences, University of Genoa, Via A. Pastore 116132, Genoa, Italy.
Email: giuseppe.aleo@edu.unige.it
Reflections from pre-registration students at Brunel University of London
The human rights and nursing awards – celebrating success and transferable insights
The importance of celebrating success and encouraging nurses to strive for excellence through the international nursing awards provided a good contrast to hearing about the challenges that nurses faced. As a Physiotherapy student, I was not aware of the scope of nursing and hearing about ethical challenges in a multinational setting was definitely a highlight. It was clear that although this was a nursing conference, a lot of the issues raised are transferable to all Allied Health Professionals – such as not being able to get the fundamentals right, timing constraints, pressure and the practitioner’s own perspectives. Despite a large focus on being on challenges, the discussions in the breakout sessions and vignettes of the award winners gave a sense of hope. I believe it was largely beneficial to hear about all three award winners as they had very different career paths and worked in different countries, overcoming different issues. Therefore, there was potential to inspire multiple groups of people who attended the awards, especially the students.
Fundamentals of care
The two-day conference began with an excellent exposition by Professor Sarah Banks on care in a ‘crisis’-stricken world. The point that struck me most keenly was how a discourse of crisis leads to suboptimal care being accepted. A lack of trust between patient and care-giver, bullying in the workforce and moral distress are likely to flourish in these conditions. The conference facilitated an interprofessional and international dialogue as to how we move from a framework of reactive care to proactive care. One of the key takeaways was a reflection made by Fiona Timmins that we must focus on the fundamentals of care. This struck me as an important antidote to the crisis narratives. A strong foundation has the potential to build trust, highlight ineffective and unethical practices and ensure that the cornerstones of care are firmly instilled.
Education as a positive force
The significance of education as a mechanism through which real and potential workforce crises could be resolved permeated discussions throughout the conference. Perhaps unsurprisingly, conference delegates, with backgrounds in health and social care and academia, viewed education as a positive force for change in the pursuit of ethically conscious healthcare provision. As has often been the case, education was lauded by many as a conduit for changing wider healthcare values and ethics.
Yet the crises facing nurse education were recognized as barriers to better workforce outcomes more widely. The English example of nurse education evidences a flawed construction on already unstable foundations; falling number of applicants, strained funding for both HEIs and students alike and, arguably, an excessive requirement of 2300 hours of unpaid clinical practice are a few of the mounting obstacles. In the shadow of such practical challenges, engaging students on matters of morals, values and ethics becomes increasingly difficult. As many delegates recognized, resolving workforce crises through education is not merely a matter of instructing students to bear ethics in mind. Rather, we need to teach students to be curious, to engage with the world at large and to think critically about what we do and why we do it.
Ethical competence
The work of the PROMOCON Project presented by an international team of researchers at the conference might be the future of producing morally competent nurses through the engagement of students with a purposively designed Massive Open Online Course (MOOC) exploring the ethical conditions of the profession. We look forward to the 25th international conference to learn of the project’s outcomes. While a perfect strategy for achieving an ethically minded workforce may not yet exist, the passion and commitment of delegates at the conference highlights that this is not yet the time for cynicism on the matter.
Impact of technology and Artificial Intelligence (AI) on care
Wes Streeting, the Secretary of State for Health and Social Care, declared that “the NHS is broken,” and his mission is to save it. One key change he proposes is transitioning the NHS from analogue to digital, an important step as AI rapidly emerges in clinical work. The benefits of using AI in clinical settings seem obvious – automation, and more efficient data processing could help ease the stress and burnout faced by healthcare professionals. Expanding technology in healthcare seems unavoidable, yet the ethical concerns surrounding the use of AI in clinical work remain urgent. These issues must be carefully explored and addressed, with clear principles established to ensure that ethical standards are upheld.
Ramvi et al.1 identified several challenges posed by technology in healthcare, including the disruption of relationship-based care, the risk of depersonalization and an overemphasis on efficiency and technical processes, which can overshadow the emotional and ethical aspects of care. Additionally, both healthcare professionals and patients may become increasingly vulnerable as their reliance on technology grows. At the 24th International Nursing Ethics Conference, Ellen Ramvi further explored these concerns. She emphasized that the true threat to care is not technology itself, but the structural conditions of scarcity. Furthermore, as long as communication and relationships remain central to care, technology is not opposed to ethical care. Therefore, it is important to create capacity for healthcare professionals to explore ways to balance the benefits of AI with the preservation of human connection in addressing these ethical challenges.
Reflections from PhD students at the University of Genoa
A platform to discuss issues openly
The 2024 International Nursing Ethics Conference addressed the ethical challenges faced by the global healthcare workforce amidst an ongoing care crisis. Central to the discussions were themes of moral distress, burnout and the ethical dilemmas healthcare professionals face when systemic issues hinder their ability to deliver adequate care. The conference underscored the pressing need to re-evaluate ethical frameworks to foster resilience and well-being for caregivers and patients alike. Many professionals find themselves unable to provide necessary care due to institutional constraints, a reality highlighted by participants who shared their experiences at the conference. The Nursing Ethics Conference provided us a platform to discuss these issues openly, offering diverse perspectives on how ethical leadership can mitigate the negative effects of the care crisis and giving us the opportunity to share our position presenting some of the projects we are working on.
Ethical leadership
A significant focus of the conference was the role of ethical leadership in addressing these challenges. Ethical leadership involves nurturing a culture where values like respect, dignity and care are prioritized. As highlighted by keynote speakers, ethical leadership transcends rule-following; it demands emotional and professional support for teams to maintain high standards of care. Presenting our project during a leadership-focused session sparked meaningful discussions about integrating leadership education early in nursing programs, differentiating between managerial and leadership roles, and effectively managing dissent in multidisciplinary teams. Such discussions are vital in preparing future healthcare professionals to navigate complex team dynamics while promoting a culture of ethical leadership.
Moral distress
The theme of moral distress aligns closely with our project on midwifery care, showcasing the interdisciplinary nature of this phenomenon. Moral distress affects not only nurses but also midwives and other healthcare professionals, underscoring the need for holistic, patient-centred care despite systemic barriers. In addition to discussing the severity of moral distress, the conference highlighted potential solutions. Advocates called for systemic changes, including improved staffing ratios, flexible working hours and enhanced mental health support for healthcare workers. One innovative proposal involved establishing ethical reflection groups to create a supportive environment for healthcare professionals to share experiences and tackle ethical dilemmas collectively. One of our presented projects focusing on reducing turnover among newly graduated nurses by ensuring a smooth transition from their bachelor’s degree into professional practice. The team recognizes that an effective transition is crucial for the well-being and professional development of healthcare professionals. By fostering a supportive environment during this critical phase, we aim to enhance job satisfaction and competence, thereby improving patient care and alleviating moral distress in the workforce.
The importance of ethics education
Finally, the conference emphasized the importance of ethics education that extends beyond theoretical knowledge to include practical training in handling real-world dilemmas. This approach will better prepare future healthcare professionals to navigate the complexities of modern healthcare environments with confidence and resilience. We commend the active participation and welcoming atmosphere fostered by the organizers and participants alike. This environment encouraged open dialogue, enabling us to reaffirm our professional identities and reinforcing our commitment to contribute to scientific discourse that adequately addresses the ethical dimensions of our field.
Bibliography
REFERENCE
1 Ramvi E, Hellstrand I, Jensen IB, , et al. Ethics of care in technology-mediated healthcare practices: A scoping review. Scand J Caring Sci 2023; 37: 1123–1135. DOI: 10.1111/scs.13186.
Graphic
Link to PDF
Classification
Language: ENGLISH
Publication-Type: Magazines & Journals
Subject: EDITORIALS & OPINIONS (99%); STUDENTS & STUDENT LIFE (92%); CONFERENCES & CONVENTIONS (90%); ETHICS (90%); HEALTH CARE PROFESSIONALS (90%); MEDICAL ETHICS (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (90%); SCHOLARSHIPS & GRANTS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); NURSES & NURSING (89%); PROFESSIONAL WORKERS (89%); OCCUPATIONAL THERAPY (88%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGE STUDENTS (78%); PUBLIC HEALTH ADMINISTRATION (78%); TALKS & MEETINGS (78%); TRADE SHOWS (78%); PHYSICAL THERAPY (74%)
Industry: HEALTH CARE PROFESSIONALS (90%); NURSES & NURSING (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGE STUDENTS (78%)
Geographic: LONDON, ENGLAND (90%); ITALY (72%); UNITED KINGDOM (57%)
Load-Date: November 21, 2024",positive,0.5533085465431213,balanced/neutral,['human rights'],['dignity'],"['standards', 'framework', 'must', 'need to']",[],1,1,4,0
2024,Unknown Title,"Body
2024 NOV 26 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- A new study on artificial intelligence is now available. According to news reporting from Near East University by NewsRx journalists, research stated, ""This paper argues that ethical AI cannot be fostered in a vacuum, challenging the perspective that AI ethics research should be isolated from technological advancements and industry collaborations."" 
 Our news reporters obtained a quote from the research from Near East University: ""It refutes the argument presented by Gerdes (Discov Artif Intell. 2022;2(25)), which suggests that industry involvement inherently undermines the integrity of AI ethics research. Through an exploration of historical and contemporary examples of successful academia-industry collaborations, the paper advocates for a synergistic approach that harnesses industry resources and insights to advance ethical AI development."" 
 According to the news editors, the research concluded: ""Emphasising the importance of diverse funding, the value of industry insights, and the impracticality of separating AI ethics from computer science, the paper contends that a collaborative, transparent, and inclusive model of AI ethics research is essential for developing practical, relevant, and ethically sound AI technologies aligned with societal values and norms."" 
 For more information on this research see: Ethical AI cannot be fostered in a vacuum: why AI ethics research needs industry involvement. Discover Artificial Intelligence, 2024,4(1):1-7. The publisher for Discover Artificial Intelligence is Springer. 
 A free version of this journal article is available at https://doi.org/10.1007/s44163-024-00182-9. 
 Our news journalists report that more information may be obtained by contacting Ahmet Kucukuncular, Near East University CY. 
 Keywords for this news article include: Near East University, Artificial Intelligence, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); JOURNALISM (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); TECHNOLOGY (90%); COMPUTER SCIENCE (79%); WRITERS (78%); COLLEGES & UNIVERSITIES (77%); EXPERIMENTATION & RESEARCH (77%); NEWS REPORTING (73%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (71%); Artificial Intelligence;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); WRITERS (78%); COLLEGES & UNIVERSITIES (77%); NEWS REPORTING (73%)
Load-Date: November 26, 2024","2024 NOV 26 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- A new study on artificial intelligence is now available. According to news reporting from Near East University by NewsRx journalists, research stated, ""This paper argues that ethical AI cannot be fostered in a vacuum, challenging the perspective that AI ethics research should be isolated from technological advancements and industry collaborations."" 
 Our news reporters obtained a quote from the research from Near East University: ""It refutes the argument presented by Gerdes (Discov Artif Intell. 2022;2(25)), which suggests that industry involvement inherently undermines the integrity of AI ethics research. Through an exploration of historical and contemporary examples of successful academia-industry collaborations, the paper advocates for a synergistic approach that harnesses industry resources and insights to advance ethical AI development."" 
 According to the news editors, the research concluded: ""Emphasising the importance of diverse funding, the value of industry insights, and the impracticality of separating AI ethics from computer science, the paper contends that a collaborative, transparent, and inclusive model of AI ethics research is essential for developing practical, relevant, and ethically sound AI technologies aligned with societal values and norms."" 
 For more information on this research see: Ethical AI cannot be fostered in a vacuum: why AI ethics research needs industry involvement. Discover Artificial Intelligence, 2024,4(1):1-7. The publisher for Discover Artificial Intelligence is Springer. 
 A free version of this journal article is available at https://doi.org/10.1007/s44163-024-00182-9. 
 Our news journalists report that more information may be obtained by contacting Ahmet Kucukuncular, Near East University CY. 
 Keywords for this news article include: Near East University, Artificial Intelligence, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); JOURNALISM (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); TECHNOLOGY (90%); COMPUTER SCIENCE (79%); WRITERS (78%); COLLEGES & UNIVERSITIES (77%); EXPERIMENTATION & RESEARCH (77%); NEWS REPORTING (73%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (71%); Artificial Intelligence;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); WRITERS (78%); COLLEGES & UNIVERSITIES (77%); NEWS REPORTING (73%)
Load-Date: November 26, 2024",neutral,0.9078885912895203,balanced/neutral,[],[],['should'],"['machine learning', 'robotics']",0,0,1,2
2024,Unknown Title,"Body
September 23, 2024
Release date- 20092024 - Groundbreaking research led by Northumbria University has revealed how the use of an independent Data Ethics Advisory Committee by West Midlands Police has transformed the understanding of how to achieve responsible artificial intelligence (AI) in policing, offering a blueprint for a national model of oversight.
Over the past five years, the West Midlands Police and Crime Commissioner (WMOPCC) and West Midlands Police (WMP) have maintained an innovative Data Ethics Committee. This interdisciplinary body, comprised of independent experts in law, computer science, ethics, social impact, and victims' rights, advises on the design, development, and deployment of advanced AI tools and data analytics in policing. The new research highlights how this independent advisory model has transformed police officers' understanding of the ethical and technical implications of AI, while simultaneously ensuring that human rights are at the forefront of thinking around new technology initiatives.
The research has been led by Professor Marion Oswald MBE from Northumbria Law School, in collaboration with colleagues from Northumbria, Northampton, Glasgow and Aberdeen Universities, and partnering with the office of the West Midlands Police and Crime Commissioner and West Midlands Police. Funded by the Arts and Humanities Research Council (AHRC) through its Bridging Responsible AI Divides (BRAID) programme, the research concludes that this type of independent advice can help to bridge the gap between ethical reflection, scientific rigor, and human rights considerations in law enforcement.
The study found that the Committee's work did not impede operational policing, but rather supported it, leading to more responsible and ethical AI use. It concluded that such independent scrutiny could serve as a model for responsible AI use nationwide.
Commenting on the significance of the research, Assistant Chief Constable Matt Welsted from West Midlands Police said: 'WMP is a highly innovative force dedicated to delivering the best possible service to the public in the most efficient and effective way. Often this involves cutting edge technology and sophisticated data analytics which although exciting, comes with significant responsibilities. This research and the recommendations made will be invaluable to helping us and other forces get this balance right and ensure that the decisions we make and the tools we use to police our communities are ethical and legitimate'.
Key Findings:
Police officers gained valuable insights into technical, operational, legal, and ethical aspects of AI through engagement with the Committee. One officer reflected: 'When I went to the ethics committee, I actually had my eyes opened... There were some considerations that I didn't understand initially, but as I got more into the project, I could absolutely see the relevance.'
The Committee's advice directly influenced the development of AI and data tools, with adjustments made based on its recommendations.
The Committee members, in turn, gained a deeper understanding of the operational pressures police officers face and the potential of AI to enhance policing services, while still protecting community interests and victims' rights.
The research, which included interviews with Committee members, police officers, data scientists, and community representatives, as well as a review of Committee documents and observations of technology in action, calls for greater community involvement in the data ethics process. The research team emphasizes that community trust in AI policing tools can only be achieved if the voices of community representatives are respected and visibly influential. The research also concluded that more attention should be paid to a wider range of human rights responsibilities. There also needed to be sufficient time taken in Committee meetings to understand technical details, how AI outputs will be used in operational policing and how AI might support police responsibilities for public safety.
Professor Marion Oswald MBE, chair of the Committee, led the research project, with the interviews and research analysis being carried out by other members of the research team. Professor Oswald said: 'An interdisciplinary Data Ethics Committee, such as the one maintained by West Midlands Police, is crucial for ensuring responsible use of AI in policing. By integrating diverse perspectives and expertise, the Committee enhances the validity and ethical grounding of AI tools, fosters transparent dialogue, and addresses critical issues of privacy and public safety. Its success hinges on clear roles, community representation, and robust support, offering a model for national strategy and guiding others in the ethical deployment of advanced data technologies.
'Our research underscores the importance of balancing technological advancement with ethical oversight, advocating for a structured, transparent, and inclusive approach to AI in policing, with the West Midlands Data Ethics Committee serving as a leading example.'
Northumbria University has a global reputation for research and teaching in AI and Professor Oswald is the principal investigator of the Responsible AI UK Keystone project 'PROBabLE Futures: Probabilistic AI Systems in Law Enforcement Futures'. The University was recently awarded GBP9 million by UK Research and Innovation to establish a Centre for Doctoral Training in the field of AI. Known as the Citizen-Centred AI (CCAI), it focuses on the inclusion of citizens in the design and evaluation of AI - helping to make the rapidly advancing technology work for ordinary people.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]     
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: M2PW
Subject: ETHICS (93%); CRIME, LAW ENFORCEMENT & CORRECTIONS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HUMAN RIGHTS (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); LAW ENFORCEMENT (90%); NEGATIVE NEWS (90%); DATA ANALYTICS (89%); DATA SCIENCE (89%); TECHNOLOGY (89%); COMPUTER SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); HUMANITIES & SOCIAL SCIENCE (78%); LAW SCHOOLS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EMERGING TECHNOLOGY (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); GRADUATE & PROFESSIONAL SCHOOLS (73%); HUMANITIES (73%); LAWYERS (73%); RESEARCH REPORTS (73%); VICTIMS RIGHTS (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (89%); DATA SCIENCE (89%); INFORMATION MANAGEMENT & TECHNOLOGY (89%); COMPUTER SCIENCE (78%); LAW SCHOOLS (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); GRADUATE & PROFESSIONAL SCHOOLS (73%); LAWYERS (73%)
Geographic: GLASGOW, SCOTLAND (55%)
Load-Date: September 23, 2024","September 23, 2024
Release date- 20092024 - Groundbreaking research led by Northumbria University has revealed how the use of an independent Data Ethics Advisory Committee by West Midlands Police has transformed the understanding of how to achieve responsible artificial intelligence (AI) in policing, offering a blueprint for a national model of oversight.
Over the past five years, the West Midlands Police and Crime Commissioner (WMOPCC) and West Midlands Police (WMP) have maintained an innovative Data Ethics Committee. This interdisciplinary body, comprised of independent experts in law, computer science, ethics, social impact, and victims' rights, advises on the design, development, and deployment of advanced AI tools and data analytics in policing. The new research highlights how this independent advisory model has transformed police officers' understanding of the ethical and technical implications of AI, while simultaneously ensuring that human rights are at the forefront of thinking around new technology initiatives.
The research has been led by Professor Marion Oswald MBE from Northumbria Law School, in collaboration with colleagues from Northumbria, Northampton, Glasgow and Aberdeen Universities, and partnering with the office of the West Midlands Police and Crime Commissioner and West Midlands Police. Funded by the Arts and Humanities Research Council (AHRC) through its Bridging Responsible AI Divides (BRAID) programme, the research concludes that this type of independent advice can help to bridge the gap between ethical reflection, scientific rigor, and human rights considerations in law enforcement.
The study found that the Committee's work did not impede operational policing, but rather supported it, leading to more responsible and ethical AI use. It concluded that such independent scrutiny could serve as a model for responsible AI use nationwide.
Commenting on the significance of the research, Assistant Chief Constable Matt Welsted from West Midlands Police said: 'WMP is a highly innovative force dedicated to delivering the best possible service to the public in the most efficient and effective way. Often this involves cutting edge technology and sophisticated data analytics which although exciting, comes with significant responsibilities. This research and the recommendations made will be invaluable to helping us and other forces get this balance right and ensure that the decisions we make and the tools we use to police our communities are ethical and legitimate'.
Key Findings:
Police officers gained valuable insights into technical, operational, legal, and ethical aspects of AI through engagement with the Committee. One officer reflected: 'When I went to the ethics committee, I actually had my eyes opened... There were some considerations that I didn't understand initially, but as I got more into the project, I could absolutely see the relevance.'
The Committee's advice directly influenced the development of AI and data tools, with adjustments made based on its recommendations.
The Committee members, in turn, gained a deeper understanding of the operational pressures police officers face and the potential of AI to enhance policing services, while still protecting community interests and victims' rights.
The research, which included interviews with Committee members, police officers, data scientists, and community representatives, as well as a review of Committee documents and observations of technology in action, calls for greater community involvement in the data ethics process. The research team emphasizes that community trust in AI policing tools can only be achieved if the voices of community representatives are respected and visibly influential. The research also concluded that more attention should be paid to a wider range of human rights responsibilities. There also needed to be sufficient time taken in Committee meetings to understand technical details, how AI outputs will be used in operational policing and how AI might support police responsibilities for public safety.
Professor Marion Oswald MBE, chair of the Committee, led the research project, with the interviews and research analysis being carried out by other members of the research team. Professor Oswald said: 'An interdisciplinary Data Ethics Committee, such as the one maintained by West Midlands Police, is crucial for ensuring responsible use of AI in policing. By integrating diverse perspectives and expertise, the Committee enhances the validity and ethical grounding of AI tools, fosters transparent dialogue, and addresses critical issues of privacy and public safety. Its success hinges on clear roles, community representation, and robust support, offering a model for national strategy and guiding others in the ethical deployment of advanced data technologies.
'Our research underscores the importance of balancing technological advancement with ethical oversight, advocating for a structured, transparent, and inclusive approach to AI in policing, with the West Midlands Data Ethics Committee serving as a leading example.'
Northumbria University has a global reputation for research and teaching in AI and Professor Oswald is the principal investigator of the Responsible AI UK Keystone project 'PROBabLE Futures: Probabilistic AI Systems in Law Enforcement Futures'. The University was recently awarded GBP9 million by UK Research and Innovation to establish a Centre for Doctoral Training in the field of AI. Known as the Citizen-Centred AI (CCAI), it focuses on the inclusion of citizens in the design and evaluation of AI - helping to make the rapidly advancing technology work for ordinary people.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]     
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: M2PW
Subject: ETHICS (93%); CRIME, LAW ENFORCEMENT & CORRECTIONS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HUMAN RIGHTS (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); LAW ENFORCEMENT (90%); NEGATIVE NEWS (90%); DATA ANALYTICS (89%); DATA SCIENCE (89%); TECHNOLOGY (89%); COMPUTER SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); HUMANITIES & SOCIAL SCIENCE (78%); LAW SCHOOLS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EMERGING TECHNOLOGY (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); GRADUATE & PROFESSIONAL SCHOOLS (73%); HUMANITIES (73%); LAWYERS (73%); RESEARCH REPORTS (73%); VICTIMS RIGHTS (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (89%); DATA SCIENCE (89%); INFORMATION MANAGEMENT & TECHNOLOGY (89%); COMPUTER SCIENCE (78%); LAW SCHOOLS (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); GRADUATE & PROFESSIONAL SCHOOLS (73%); LAWYERS (73%)
Geographic: GLASGOW, SCOTLAND (55%)
Load-Date: September 23, 2024",positive,0.6214174032211304,balanced/neutral,"['privacy', 'safety', 'human rights']",[],"['oversight', 'law', 'should', 'calls for']",[],3,0,4,0
2024,Unknown Title,"Body
Link to Story
""Elegance, innovation, and sustainability-Ethicarat redefines modern luxury for the conscious consumer. Discover the future of fine jewelry.""
The fine jewelry world has just welcomed a bold new player: Ethicarat, a brand that seamlessly blends timeless craftsmanship with modern innovation.
Elegance, innovation, and sustainability-Ethicarat redefines modern luxury for the conscious consumer. Discover the future of fine jewelry."" - Komal PatelAUSTIN, TX, UNITED STATES, October 16, 2024EINPresswire -- The fine jewelry world has just welcomed a bold new player: Ethicarat , a brand that seamlessly blends timeless craftsmanship with modern innovation. Officially launched this fall, Ethicarat is transforming the luxury jewelry landscape with its focus on sustainability, elegance, and cutting-edge AI technology.
Founded by Komal Patel, a tech industry leader with over two decades of experience in building enterprise and consumer tech hardware and software, Ethicarat brings a unique perspective to the jewelry world.
Leveraging her background in AI and innovation, Komal has fused her family's five-generation legacy in fine jewelry business with sustainable practices and technology-forward solutions to create a brand that meets the demands of today's conscious consumer.
The Future is a Soulitaire: At the heart of Ethicarat's philosophy is the belief that luxury and individuality can go hand-in-hand. The brand's tagline,""The Future is a Soulitaire,"" captures the vision of creating jewelry that is not only elegant but also personal and ethical. Every piece is a reflection of the wearer's soul-a one-of-a-kind expression of beauty and purpose, where innovation and sustainability come together to define the future of luxury.
Curated Collections for Every Occasion: Ethicarat's debut includes a series of carefully curated collections, with designs that are minimal, timeless, and wearable. These pieces are crafted to seamlessly transition from everyday moments to special occasions, combining both elegance and functionality.
- Soulitaire: Embrace timeless beauty with designs that honor tradition and sustainability.
- Éclat: Revel in vibrant luxury with dazzling diamonds and innovative designs.
- Epoch: Celebrate significant milestones with birthstone and zodiac-inspired jewelry that adds a personalized touch to life's special moments.
- Zenith: Merge ethical luxury with natural beauty, perfect for those seeking refined sophistication.
- Gaia: Enjoy exquisite craftsmanship inspired by nature, harmonizing luxury with environmental responsibility.
Each piece is crafted from lab-grown diamonds and recycled solid 14K and 18K gold, combining ethics with elegance to create luxury that doesn't compromise on values.
Introducing the AI-Powered Designer: In addition to the launch collections, Ethicarat has unveiled a game-changing innovation: its proprietary AI-powered designer tool. This unique tool allows customers to craft their own custom jewelry, offering personalization that was previously only available through time-consuming consultations with traditional jewelers. With just a few clicks, customers can design bespoke pieces that reflect their individuality, all while enjoying the peace of mind that comes from knowing their jewelry is made from sustainably sourced materials.
""Our AI designer represents the future of personalized luxury,"" says Komal Patel.""We're bringing cutting-edge technology to an age-old craft, making it easier than ever for customers to create pieces that are uniquely theirs."" The AI-powered designer is currently available by invitation only, further adding to its exclusivity and allure.
Gift A Luxury That Sparkles Every Day: Ethicarat's pieces are not just reserved for special occasions. Their watch band accessories, part of the launch collection , are designed to add a touch of luxury to your everyday life. Crafted with the same attention to detail as their high-end jewelry, these pieces offer an easy way to incorporate sophisticated sparkle into any outfit, effortlessly elevating your daily wear.
""Our watch band accessories, in particular, are a standout,"" says Patel.""They offer a one-of-a-kind luxury experience, bringing an eco-conscious sparkle to everyday wear, making them the perfect gift this holiday season.""
Ethicarat: Leading the Way in Sustainable Luxury
Now fully launched, Ethicarat stands at the forefront of a new era of luxury, offering customers a chance to blend their personal style with the brand's ethos of sustainability and craftsmanship. The launch collections, paired with the innovative AI designer, are a testament to how the brand is rethinking luxury for the modern world. As consumers seek personalization and ethically crafted products, Ethicarat offers a forward-thinking, responsible option in the fine jewelry space.
For more information or to explore the full collection and AI designer, visit Ethicarat, and don't forget to follow us on Instagram @ethicarat_jewelry for the latest updates and exclusive previews.Komal Patel
Ethicarat
email us here
Visit us on social media:
Facebook
LinkedIn
Instagram
Other
Legal Disclaimer:
EIN Presswire provides this news content ""as is"" without warranty of any kind. We do not accept any responsibility or liability for the accuracy, content, images, videos, licenses, completeness, legality, or reliability of the information contained in this article. If you have any complaints or copyright issues related to this article, kindly contact the author above.
MENAFN16102024003118003196ID1108786427
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: PRESS RELEASES (90%); SUSTAINABILITY (90%); SUSTAINABLE DEVELOPMENT (90%); TECHNOLOGY (90%); ETHICS (89%); ARTIFICIAL INTELLIGENCE (88%); CORPORATE ENVIRONMENTAL RESPONSIBILITY (78%); CORPORATE SOCIAL RESPONSIBILITY (78%); DIAMONDS (78%); PRODUCT INNOVATION (78%); ENVIRONMENT & NATURAL RESOURCES (60%)
Industry: FINE JEWELRY (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE (88%); JEWELRY (78%); JEWELRY INDUSTRY (78%); INFORMATION TECHNOLOGY INDUSTRY (74%); SOFTWARE SERVICES & APPLICATIONS (74%); ADVERTISING SLOGANS (72%); FINE JEWELRY MFG (72%); COMPUTER SOFTWARE (68%)
Load-Date: March 5, 2025","Link to Story
""Elegance, innovation, and sustainability-Ethicarat redefines modern luxury for the conscious consumer. Discover the future of fine jewelry.""
The fine jewelry world has just welcomed a bold new player: Ethicarat, a brand that seamlessly blends timeless craftsmanship with modern innovation.
Elegance, innovation, and sustainability-Ethicarat redefines modern luxury for the conscious consumer. Discover the future of fine jewelry."" - Komal PatelAUSTIN, TX, UNITED STATES, October 16, 2024EINPresswire -- The fine jewelry world has just welcomed a bold new player: Ethicarat , a brand that seamlessly blends timeless craftsmanship with modern innovation. Officially launched this fall, Ethicarat is transforming the luxury jewelry landscape with its focus on sustainability, elegance, and cutting-edge AI technology.
Founded by Komal Patel, a tech industry leader with over two decades of experience in building enterprise and consumer tech hardware and software, Ethicarat brings a unique perspective to the jewelry world.
Leveraging her background in AI and innovation, Komal has fused her family's five-generation legacy in fine jewelry business with sustainable practices and technology-forward solutions to create a brand that meets the demands of today's conscious consumer.
The Future is a Soulitaire: At the heart of Ethicarat's philosophy is the belief that luxury and individuality can go hand-in-hand. The brand's tagline,""The Future is a Soulitaire,"" captures the vision of creating jewelry that is not only elegant but also personal and ethical. Every piece is a reflection of the wearer's soul-a one-of-a-kind expression of beauty and purpose, where innovation and sustainability come together to define the future of luxury.
Curated Collections for Every Occasion: Ethicarat's debut includes a series of carefully curated collections, with designs that are minimal, timeless, and wearable. These pieces are crafted to seamlessly transition from everyday moments to special occasions, combining both elegance and functionality.
- Soulitaire: Embrace timeless beauty with designs that honor tradition and sustainability.
- Éclat: Revel in vibrant luxury with dazzling diamonds and innovative designs.
- Epoch: Celebrate significant milestones with birthstone and zodiac-inspired jewelry that adds a personalized touch to life's special moments.
- Zenith: Merge ethical luxury with natural beauty, perfect for those seeking refined sophistication.
- Gaia: Enjoy exquisite craftsmanship inspired by nature, harmonizing luxury with environmental responsibility.
Each piece is crafted from lab-grown diamonds and recycled solid 14K and 18K gold, combining ethics with elegance to create luxury that doesn't compromise on values.
Introducing the AI-Powered Designer: In addition to the launch collections, Ethicarat has unveiled a game-changing innovation: its proprietary AI-powered designer tool. This unique tool allows customers to craft their own custom jewelry, offering personalization that was previously only available through time-consuming consultations with traditional jewelers. With just a few clicks, customers can design bespoke pieces that reflect their individuality, all while enjoying the peace of mind that comes from knowing their jewelry is made from sustainably sourced materials.
""Our AI designer represents the future of personalized luxury,"" says Komal Patel.""We're bringing cutting-edge technology to an age-old craft, making it easier than ever for customers to create pieces that are uniquely theirs."" The AI-powered designer is currently available by invitation only, further adding to its exclusivity and allure.
Gift A Luxury That Sparkles Every Day: Ethicarat's pieces are not just reserved for special occasions. Their watch band accessories, part of the launch collection , are designed to add a touch of luxury to your everyday life. Crafted with the same attention to detail as their high-end jewelry, these pieces offer an easy way to incorporate sophisticated sparkle into any outfit, effortlessly elevating your daily wear.
""Our watch band accessories, in particular, are a standout,"" says Patel.""They offer a one-of-a-kind luxury experience, bringing an eco-conscious sparkle to everyday wear, making them the perfect gift this holiday season.""
Ethicarat: Leading the Way in Sustainable Luxury
Now fully launched, Ethicarat stands at the forefront of a new era of luxury, offering customers a chance to blend their personal style with the brand's ethos of sustainability and craftsmanship. The launch collections, paired with the innovative AI designer, are a testament to how the brand is rethinking luxury for the modern world. As consumers seek personalization and ethically crafted products, Ethicarat offers a forward-thinking, responsible option in the fine jewelry space.
For more information or to explore the full collection and AI designer, visit Ethicarat, and don't forget to follow us on Instagram @ethicarat_jewelry for the latest updates and exclusive previews.Komal Patel
Ethicarat
email us here
Visit us on social media:
Facebook
LinkedIn
Instagram
Other
Legal Disclaimer:
EIN Presswire provides this news content ""as is"" without warranty of any kind. We do not accept any responsibility or liability for the accuracy, content, images, videos, licenses, completeness, legality, or reliability of the information contained in this article. If you have any complaints or copyright issues related to this article, kindly contact the author above.
MENAFN16102024003118003196ID1108786427
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: PRESS RELEASES (90%); SUSTAINABILITY (90%); SUSTAINABLE DEVELOPMENT (90%); TECHNOLOGY (90%); ETHICS (89%); ARTIFICIAL INTELLIGENCE (88%); CORPORATE ENVIRONMENTAL RESPONSIBILITY (78%); CORPORATE SOCIAL RESPONSIBILITY (78%); DIAMONDS (78%); PRODUCT INNOVATION (78%); ENVIRONMENT & NATURAL RESOURCES (60%)
Industry: FINE JEWELRY (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE (88%); JEWELRY (78%); JEWELRY INDUSTRY (78%); INFORMATION TECHNOLOGY INDUSTRY (74%); SOFTWARE SERVICES & APPLICATIONS (74%); ADVERTISING SLOGANS (72%); FINE JEWELRY MFG (72%); COMPUTER SOFTWARE (68%)
Load-Date: March 5, 2025",positive,0.7978929281234741,balanced/neutral,[],[],[],[],0,0,0,0
2024,Unknown Title,"Byline: The Peninsula Newspaper
Body
Doha, Qatar: The Ministry of Public Health (MoPH) recently organised the National Health Research Ethics Workshop 2024 on the use of artificial intelligence (AI) in health research in collaboration with the National Cyber Security Agency (NCSA), Qatar University (QU), and Hamad Bin Khalifa University (HBKU).
The workshop explored the latest global developments in the use of artificial intelligence in health research, data management, and national policies. It featured a range of sessions delivered by local and international experts in biomedical and health research, with representatives from 20 relevant institutions in Qatar participating.
This collective effort underscores a shared commitment to advancing health research standards.
The workshop also addressed emerging trends in the governance of medical AI, balancing innovation with privacy in AI healthcare applications in Qatar, AI in medical devices, ethical collaboration in health research, ethical and religious perspectives on AI use in medicine, and the integration of AI into clinical practice.
The main objective of the workshop was to emphasise the ethical considerations involved in using AI in health research, data management, and national policies. It focused on ensuring the safe and ethical application of AI in line with the highest global standards.
Additionally, the workshop aimed to enhance the knowledge and skills of local researchers and professionals in health research, contributing to the growth and quality of Qatar's research and development sector, and reflects a strong commitment towards aligning technological advancements in AI with ethical principles and international best practices.
In her opening speech, Dr Alexandra Haddad, Senior Research Grants Specialist at the Health Research Regulatory Department at the MoPH, stated, ""The annual National Health Research Ethics Workshop contributes to raising awareness among local researchers in the State of Qatar on the importance of health research ethics. It also reviews regulations governing health research and establishes ethical principles for AI use in health research.""
Dr Haddad also highlighted the Health Research Regulatory Department's mission to educate and empower all stakeholders in the health research field through this annual workshop and other initiatives. The department is also responsible for proposing, developing, and amending legislative tools, policies, and regulations related to health and medical research to foster a safe and progressive research environment.
Furthermore, it oversees and monitors health research activities in Qatar.
The workshop was attended by approximately 250 participants, including researchers, members of Institutional Animal Care and Use Committees (IACUCs), members of Institutional Review Boards (IRBs) overseeing human research applications, members of Institutional Biosafety Committees (IBCs) in the State of Qatar, healthcare practitioners including doctors, nurses, dentists, pharmacists, allied health professionals, complementary medicine practitioners, university students, secondary school students preparing for university, as well as other stakeholders in Qatar's research and development sector.
A group photo of the participants during the workshop. - Image
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1059
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); HEALTH DEPARTMENTS (90%); MEDICINE & HEALTH (90%); PUBLIC HEALTH (90%); PUBLIC POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HEALTH CARE PROFESSIONALS (89%); MEDICAL RESEARCH (89%); RESEARCH & DEVELOPMENT (89%); SCIENTIFIC SOFTWARE (89%); PROFESSIONAL WORKERS (88%); COLLEGE STUDENTS (78%); EDUCATION & TRAINING (78%); GOVERNMENT BODIES & OFFICES (78%); MEDICAL ETHICS (78%); PHARMACISTS (78%); PUBLIC HEALTH ADMINISTRATION (78%); TECHNOLOGY (78%); STUDENTS & STUDENT LIFE (77%); BEST PRACTICES (76%); TRENDS (75%); ALTERNATIVE MEDICINE (73%); ANIMALS & SOCIETY (73%); GRANTS & GIFTS (73%); MEDICAL DEVICES (70%); STANDARDS & MEASUREMENTS (69%); SECONDARY SCHOOLS (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); HEALTH DEPARTMENTS (90%); INFORMATION MANAGEMENT & TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HEALTH CARE (89%); HEALTH CARE PROFESSIONALS (89%); SCIENTIFIC SOFTWARE (89%); COLLEGE STUDENTS (78%); PHARMACEUTICALS & BIOTECHNOLOGY (78%); PHARMACISTS (78%); INFORMATION SECURITY & PRIVACY (77%); ALTERNATIVE MEDICINE (73%); CYBERSECURITY (72%); MEDICAL DEVICES (70%); SECONDARY SCHOOLS (50%)
Geographic: DOHA, QATAR (59%); QATAR (94%)
Load-Date: December 2, 2024","Doha, Qatar: The Ministry of Public Health (MoPH) recently organised the National Health Research Ethics Workshop 2024 on the use of artificial intelligence (AI) in health research in collaboration with the National Cyber Security Agency (NCSA), Qatar University (QU), and Hamad Bin Khalifa University (HBKU).
The workshop explored the latest global developments in the use of artificial intelligence in health research, data management, and national policies. It featured a range of sessions delivered by local and international experts in biomedical and health research, with representatives from 20 relevant institutions in Qatar participating.
This collective effort underscores a shared commitment to advancing health research standards.
The workshop also addressed emerging trends in the governance of medical AI, balancing innovation with privacy in AI healthcare applications in Qatar, AI in medical devices, ethical collaboration in health research, ethical and religious perspectives on AI use in medicine, and the integration of AI into clinical practice.
The main objective of the workshop was to emphasise the ethical considerations involved in using AI in health research, data management, and national policies. It focused on ensuring the safe and ethical application of AI in line with the highest global standards.
Additionally, the workshop aimed to enhance the knowledge and skills of local researchers and professionals in health research, contributing to the growth and quality of Qatar's research and development sector, and reflects a strong commitment towards aligning technological advancements in AI with ethical principles and international best practices.
In her opening speech, Dr Alexandra Haddad, Senior Research Grants Specialist at the Health Research Regulatory Department at the MoPH, stated, ""The annual National Health Research Ethics Workshop contributes to raising awareness among local researchers in the State of Qatar on the importance of health research ethics. It also reviews regulations governing health research and establishes ethical principles for AI use in health research.""
Dr Haddad also highlighted the Health Research Regulatory Department's mission to educate and empower all stakeholders in the health research field through this annual workshop and other initiatives. The department is also responsible for proposing, developing, and amending legislative tools, policies, and regulations related to health and medical research to foster a safe and progressive research environment.
Furthermore, it oversees and monitors health research activities in Qatar.
The workshop was attended by approximately 250 participants, including researchers, members of Institutional Animal Care and Use Committees (IACUCs), members of Institutional Review Boards (IRBs) overseeing human research applications, members of Institutional Biosafety Committees (IBCs) in the State of Qatar, healthcare practitioners including doctors, nurses, dentists, pharmacists, allied health professionals, complementary medicine practitioners, university students, secondary school students preparing for university, as well as other stakeholders in Qatar's research and development sector.
A group photo of the participants during the workshop. - Image
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1059
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); HEALTH DEPARTMENTS (90%); MEDICINE & HEALTH (90%); PUBLIC HEALTH (90%); PUBLIC POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HEALTH CARE PROFESSIONALS (89%); MEDICAL RESEARCH (89%); RESEARCH & DEVELOPMENT (89%); SCIENTIFIC SOFTWARE (89%); PROFESSIONAL WORKERS (88%); COLLEGE STUDENTS (78%); EDUCATION & TRAINING (78%); GOVERNMENT BODIES & OFFICES (78%); MEDICAL ETHICS (78%); PHARMACISTS (78%); PUBLIC HEALTH ADMINISTRATION (78%); TECHNOLOGY (78%); STUDENTS & STUDENT LIFE (77%); BEST PRACTICES (76%); TRENDS (75%); ALTERNATIVE MEDICINE (73%); ANIMALS & SOCIETY (73%); GRANTS & GIFTS (73%); MEDICAL DEVICES (70%); STANDARDS & MEASUREMENTS (69%); SECONDARY SCHOOLS (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); HEALTH DEPARTMENTS (90%); INFORMATION MANAGEMENT & TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HEALTH CARE (89%); HEALTH CARE PROFESSIONALS (89%); SCIENTIFIC SOFTWARE (89%); COLLEGE STUDENTS (78%); PHARMACEUTICALS & BIOTECHNOLOGY (78%); PHARMACISTS (78%); INFORMATION SECURITY & PRIVACY (77%); ALTERNATIVE MEDICINE (73%); CYBERSECURITY (72%); MEDICAL DEVICES (70%); SECONDARY SCHOOLS (50%)
Geographic: DOHA, QATAR (59%); QATAR (94%)
Load-Date: December 2, 2024",neutral,0.7654097080230713,balanced/neutral,"['privacy', 'security', 'agency']",[],"['policy', 'governance', 'standards']",[],3,0,3,0
2024,Unknown Title,"Body
Link to Story
NEW YORK, Dec. 11, 2024 (GLOBE NEWSWIRE) -- Ethical Web AI (d/b/a Bubblr Inc.) (OTC: BBLR), a leader in ethical technology innovation, proudly announces a landmark partnership with BolgiaTen Limited. This collaboration brings together Ethical Web AI's AI Seek and BolgiaTen's Promptathone training program, marking a pivotal shift in the company's strategy to focus on enterprise sales of generative AI solutions. This move is expected to significantly enhance revenue forecasts for the first half of 2025 and beyond; given that the company has access to over 850 organizations covering 40% of the world's mobile connections, it sees a wide range of future opportunities. Under the terms of the partnership, The bespoke AI Seek license will be billed directly to the clients of BolgiaTen, creating a monthly revenue with excellent margins for Ethical Web AI. The partnership started on December 9th, 2024, with the first revenue anticipated in Q1 2025.
Award-winning BolgiaTen ( ) guides companies and governments in achieving the best AI-driven, value-centric outcomes in domains like social media, mobility, AI, big data, and the cloud.
The Promptathone program is a specialized training initiative designed to help companies train their staff to become proficient, prompt engineers , unlocking the full potential of Generative AI (GenAI). This program is supported by a bespoke version of AI Seek , which offers critical advantages for enterprises, including:
Public Wi-Fi Protection: A VPN shields your device from potential attacks when connected to unsecured networks, such as in airports or cafes.
This enterprise-focused approach positions Ethical Web AI as a key provider of innovative and secure AI solutions. After using AI Seek in training, companies are highly likely to adopt it as their primary AI platform, establishing a recurring revenue model for Ethical Web AI.
Steve Morris, CTO of Ethical Web AI, remarked:
""This partnership represents a transformative moment for Ethical Web AI. Shifting to enterprise sales has created a substantial pipeline of opportunities and fundamentally reshaped our business strategy for the better. The enterprise focus will drive significant revenue in 2025, providing a more sustainable and scalable foundation for our future. We are finally turning the corner into revenue.""
He added, ""Having Professor Paul Morrissey, CEO of BolgiaTen and Global AI Ambassador for TM Forum, championing AI Seek amplifies the impact of this partnership. TM Forum, as the key standards body for the global communications industry, represents over 850 member organizations and 40% of the world's mobile connections. This partnership positions AI Seek at the forefront of enterprise AI innovation, reaching a highly influential audience in a rapidly growing market.""
Professor Paul Morrissey stated:
""Integrating AI Seek into our Promptathone program aligns perfectly with our mission to empower enterprises with ethical, cutting-edge AI solutions. TM Forum's global network offers unparalleled access to businesses ready to adopt AI that prioritizes privacy and security. Together, we are enabling organizations to revolutionize their operations while maintaining control over their data.""
This shift to enterprise sales has already begun to redefine Ethical Web AI's business plans, replacing a consumer-focused model with a more lucrative enterprise-driven approach. The partnership with BolgiaTen is expected to significantly boost revenue in the first half of 2025, with ongoing benefits as AI Seek becomes a preferred solution for enterprise AI needs.
About Ethical Web AI:
Ethical Web AI is an ethical technology company championing an anonymous, safe, and fair new internet. We produce unique intellectual property and technology made defensible by our valuable utility software patents.
Visit the new AI Seek website at .
For more information about our company and products, please visit our website at .
Media Contact:
Steve Morris
Bubblr, Inc.
(646) 814 7184
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management. They are subject to several uncertainties and risks that could significantly affect the company's current plans and expectations, future operations, and financial condition. The company reserves the right to update or alter its forward-looking statements, whether due to new information, future events or otherwise.
MENAFN11122024004107003653ID1108981295
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: GENERATIVE AI (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); COMPANY STRATEGY (89%); EMERGING TECHNOLOGY (89%); ETHICS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); EMPLOYEE TRAINING (77%); EXECUTIVES (77%); PRODUCT INNOVATION (77%); BUSINESS FORECASTS (75%); SOCIAL MEDIA (73%); ASSOCIATIONS & ORGANIZATIONS (69%)
Industry: GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); MEDIA & TELECOMMUNICATIONS (78%); WIRELESS INTERNET ACCESS (78%); TELECOMMUNICATIONS (74%); SOCIAL MEDIA (73%)
Load-Date: March 5, 2025","Link to Story
NEW YORK, Dec. 11, 2024 (GLOBE NEWSWIRE) -- Ethical Web AI (d/b/a Bubblr Inc.) (OTC: BBLR), a leader in ethical technology innovation, proudly announces a landmark partnership with BolgiaTen Limited. This collaboration brings together Ethical Web AI's AI Seek and BolgiaTen's Promptathone training program, marking a pivotal shift in the company's strategy to focus on enterprise sales of generative AI solutions. This move is expected to significantly enhance revenue forecasts for the first half of 2025 and beyond; given that the company has access to over 850 organizations covering 40% of the world's mobile connections, it sees a wide range of future opportunities. Under the terms of the partnership, The bespoke AI Seek license will be billed directly to the clients of BolgiaTen, creating a monthly revenue with excellent margins for Ethical Web AI. The partnership started on December 9th, 2024, with the first revenue anticipated in Q1 2025.
Award-winning BolgiaTen ( ) guides companies and governments in achieving the best AI-driven, value-centric outcomes in domains like social media, mobility, AI, big data, and the cloud.
The Promptathone program is a specialized training initiative designed to help companies train their staff to become proficient, prompt engineers , unlocking the full potential of Generative AI (GenAI). This program is supported by a bespoke version of AI Seek , which offers critical advantages for enterprises, including:
Public Wi-Fi Protection: A VPN shields your device from potential attacks when connected to unsecured networks, such as in airports or cafes.
This enterprise-focused approach positions Ethical Web AI as a key provider of innovative and secure AI solutions. After using AI Seek in training, companies are highly likely to adopt it as their primary AI platform, establishing a recurring revenue model for Ethical Web AI.
Steve Morris, CTO of Ethical Web AI, remarked:
""This partnership represents a transformative moment for Ethical Web AI. Shifting to enterprise sales has created a substantial pipeline of opportunities and fundamentally reshaped our business strategy for the better. The enterprise focus will drive significant revenue in 2025, providing a more sustainable and scalable foundation for our future. We are finally turning the corner into revenue.""
He added, ""Having Professor Paul Morrissey, CEO of BolgiaTen and Global AI Ambassador for TM Forum, championing AI Seek amplifies the impact of this partnership. TM Forum, as the key standards body for the global communications industry, represents over 850 member organizations and 40% of the world's mobile connections. This partnership positions AI Seek at the forefront of enterprise AI innovation, reaching a highly influential audience in a rapidly growing market.""
Professor Paul Morrissey stated:
""Integrating AI Seek into our Promptathone program aligns perfectly with our mission to empower enterprises with ethical, cutting-edge AI solutions. TM Forum's global network offers unparalleled access to businesses ready to adopt AI that prioritizes privacy and security. Together, we are enabling organizations to revolutionize their operations while maintaining control over their data.""
This shift to enterprise sales has already begun to redefine Ethical Web AI's business plans, replacing a consumer-focused model with a more lucrative enterprise-driven approach. The partnership with BolgiaTen is expected to significantly boost revenue in the first half of 2025, with ongoing benefits as AI Seek becomes a preferred solution for enterprise AI needs.
About Ethical Web AI:
Ethical Web AI is an ethical technology company championing an anonymous, safe, and fair new internet. We produce unique intellectual property and technology made defensible by our valuable utility software patents.
Visit the new AI Seek website at .
For more information about our company and products, please visit our website at .
Media Contact:
Steve Morris
Bubblr, Inc.
(646) 814 7184
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management. They are subject to several uncertainties and risks that could significantly affect the company's current plans and expectations, future operations, and financial condition. The company reserves the right to update or alter its forward-looking statements, whether due to new information, future events or otherwise.
MENAFN11122024004107003653ID1108981295
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: GENERATIVE AI (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); COMPANY STRATEGY (89%); EMERGING TECHNOLOGY (89%); ETHICS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); EMPLOYEE TRAINING (77%); EXECUTIVES (77%); PRODUCT INNOVATION (77%); BUSINESS FORECASTS (75%); SOCIAL MEDIA (73%); ASSOCIATIONS & ORGANIZATIONS (69%)
Industry: GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); MEDIA & TELECOMMUNICATIONS (78%); WIRELESS INTERNET ACCESS (78%); TELECOMMUNICATIONS (74%); SOCIAL MEDIA (73%)
Load-Date: March 5, 2025",positive,0.6896091103553772,balanced/neutral,"['privacy', 'security', 'access']",[],['standards'],['generative ai'],3,0,1,1
2024,Unknown Title,"Body
ALFIE (Assessment of Learning Technologies and Frameworks for Intelligent and Ethical AI) aims to create an ecosystem that combines advances AI technology with ethical standards to ensure that the resulting systems are not only offer high performance, but are also fair, transparent and non-bias. The UAB is involved in this project through its Transmedia Catalonia Research Group from the Department of Translation and Interpreting  East Asian Studies, led by lecturer Pilar Orero.
Projecte ALFIE
The reseach team is working on generating two fundamental tools. First, the EthiTech Dialogue Hub (ETD-Hub), a platform that will allow debating and exchanging ideas on ethical and legal implications with AI experts, politicians, law professionals and citizens, understand social needs and define policies needed to guarantee the use of AI technologies in a responsible manner. Second, the AutoML Platform, which allows creating machine learning models without the need of technical knowledge. 'This automation of algorithms and model adjustments will make AI more accessible, while always prioritising an ethical and fair use, and it will comply with EU regulations', Pilar Orero highlights.
The ALFIE consortium is made up of ten partners from six European countries (Cyprus, Greece, Slovakia, Spain, the Netherlands and the United Kingdom) with ample experience in AI innovation and ethical applications. Academically, the UAB will be working with the University of Brighton, Edge Hill University and Eindhoven Univeristy of Technology. Other members of the project include the Centre for Research  Technology-Hellas (CERTH) and the Kempelen Institute of Intelligent Technologies (KInIT).
For more information please visit https://alfie-project.eu/.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SMART TECHNOLOGY (78%); EUROPEAN UNION (77%); ASIAN STUDIES (76%); RESEARCH INSTITUTES (76%); EUROPEAN UNION LAW (74%); EUROPEAN UNION REGULATION & POLICY (74%); MACHINE LEARNING (73%); ETHNIC & CULTURAL STUDIES (71%); EXPERIMENTATION & RESEARCH (71%); PROFESSIONAL WORKERS (54%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SMART TECHNOLOGY (78%); MACHINE LEARNING (73%)
Geographic: CATALONIA, SPAIN (57%); NETHERLANDS (90%); SLOVAKIA (79%); SPAIN (79%); UNITED KINGDOM (79%); ASIA (78%); CYPRUS (77%); EUROPE (73%); GREECE (57%)
Load-Date: October 16, 2024","ALFIE (Assessment of Learning Technologies and Frameworks for Intelligent and Ethical AI) aims to create an ecosystem that combines advances AI technology with ethical standards to ensure that the resulting systems are not only offer high performance, but are also fair, transparent and non-bias. The UAB is involved in this project through its Transmedia Catalonia Research Group from the Department of Translation and Interpreting  East Asian Studies, led by lecturer Pilar Orero.
Projecte ALFIE
The reseach team is working on generating two fundamental tools. First, the EthiTech Dialogue Hub (ETD-Hub), a platform that will allow debating and exchanging ideas on ethical and legal implications with AI experts, politicians, law professionals and citizens, understand social needs and define policies needed to guarantee the use of AI technologies in a responsible manner. Second, the AutoML Platform, which allows creating machine learning models without the need of technical knowledge. 'This automation of algorithms and model adjustments will make AI more accessible, while always prioritising an ethical and fair use, and it will comply with EU regulations', Pilar Orero highlights.
The ALFIE consortium is made up of ten partners from six European countries (Cyprus, Greece, Slovakia, Spain, the Netherlands and the United Kingdom) with ample experience in AI innovation and ethical applications. Academically, the UAB will be working with the University of Brighton, Edge Hill University and Eindhoven Univeristy of Technology. Other members of the project include the Centre for Research  Technology-Hellas (CERTH) and the Kempelen Institute of Intelligent Technologies (KInIT).
For more information please visit https://alfie-project.eu/.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SMART TECHNOLOGY (78%); EUROPEAN UNION (77%); ASIAN STUDIES (76%); RESEARCH INSTITUTES (76%); EUROPEAN UNION LAW (74%); EUROPEAN UNION REGULATION & POLICY (74%); MACHINE LEARNING (73%); ETHNIC & CULTURAL STUDIES (71%); EXPERIMENTATION & RESEARCH (71%); PROFESSIONAL WORKERS (54%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SMART TECHNOLOGY (78%); MACHINE LEARNING (73%)
Geographic: CATALONIA, SPAIN (57%); NETHERLANDS (90%); SLOVAKIA (79%); SPAIN (79%); UNITED KINGDOM (79%); ASIA (78%); CYPRUS (77%); EUROPE (73%); GREECE (57%)
Load-Date: October 16, 2024",neutral,0.6343463063240051,balanced/neutral,['bias'],[],"['regulation', 'policy', 'standards', 'law', 'should']",['machine learning'],1,0,5,1
2024,Unknown Title,"Byline: Jeremy Moser
Body
Artificial intelligence (AI) has changed the way we live and work. Technology is influencing every field, from marketing and technology to healthcare.
AI enthusiasts are scrambling to understand how technology can solve the most complex problems the world grapples with today using machine learning (ML) as its bedrock.
ML is the process of feeding data to a system to enable the system to perform tasks. Now, that might not sound like anything new, but what's fascinating about ML is that a system can use the data it's given to self-learn the task and even get better at performing the task without needing a human to give it instructions explicitly, which was the norm before AI's explosion.
This is why we're heading towards things like self-driving cars, which were inconceivable before. Powered by ML, such cars and 'learn' to become better 'drivers' over time.
But, a word of caution.
AI is quickly taking over tasks that directly affect human life. Naturally, questions are being asked:
- Is AI fair, or is it biased?
- Will AI breach our fundamental human rights?
Such discourses have become known as AI ethics–the practice of identifying and addressing how we use AI without contradicting human values.
In this blog, we will discuss and navigate how to have difficult and frank conversations about aligning AI and ML's moral compass.
What Is AI Ethics?
Ethical AI closely examines how AI interacts with and affects human society. People involved in ethical AI discuss how to build an AI system fairly–specifically in how AI makes decisions from data in a way that minimizes any risks.
To drive home the point, let's use the example of surgery.
An example of healthcare AI could be providers training a system to help doctors prioritize patients on a surgery waiting list. In this instance, AI ethicists would make sure the system uses appropriate metrics to determine priority (like severity of medical condition), not unethical factors (like prioritizing people from richer neighborhoods.)
Additionally, ethicists would make sure AI is fed on fair data. If AI is given biased data to learn from, it will only perpetuate hurtful stereotypes.
Overall, the core of ethical AI is to create systems that benefit society and minimize harm.
It's important not to get swayed by technological advancements to the extent it can jeopardize certain members of society.
Why AI Ethics Matters
Ethical AI protects an individual from harm in the following ways.
Protecting Fundamental Rights
AI in businesses often work with sensitive data, like a person's financial or biometric information.
If ethical safeguards aren't implemented, these systems could breach their human rights. For example:
In this regard, ethical AI's role would be to ensure these systems operate transparently.
Preventing Disparate Impacts
As intelligent as ML is, learning from data filled with human biases can have disastrous consequences. It would be like amplifying racism, sexism, and the like. The outcomes could result in:
Ethical systems design comes in to uproot cognitive and unconscious bias.
Addressing Existential and Societal Risks
AI misuse in a way that causes existential crises is a real problem. A prime example is deepfakes.
Deepfakes are the name given to creating hyper-realistic fake media. A malicious actor could create a deepfake (lookalike) of a celebrity and make it say anything it wants–just think about how damaging that could be to the victim and society at large.
Deepfakes can result in:
Deepfake-based identity fraud is on a sharp rise. (Image source.)
Such consequences can be catastrophic during global events like general elections.
Key Ethical Questions in AI Development
It's good that we're raising important questions surrounding AI's use, but how do we implement AI ethics? There are several questions to consider.
Who Decides What's Right?
Who decides what's right and wrong? After all, unless someone is following a strict code of conduct (like those found in organized religion), morality remains subjective.
What is your right could be my wrong.
So, who decides? (and who decides who decides?)
Should it be:
Generally speaking, the best way forward is a diverse steering group that perhaps holds opinions across different ends of the spectrum. The more diverse input we get, the greater the chances of making a sound choice because each group can make up for each other's respective AI blind spots.
And, as subjective as morality can be, there is a large part of it that has 99.99% human consensus, so the moral quagmire isn't necessarily going to be complex each and every time, but we'd need group decision-making.
How Do We Prevent Bias?
AI systems must be designed to avoid discrimination against individuals or groups. Biases in training data can lead to unfair outcomes, such as denying loans based on demographic factors. Ensuring fairness requires diverse datasets and rigorous testing to detect and correct biases.
Are We Being Transparent?
People need to understand how AI systems make decisions. A lack of transparency confuses and diminishes trust, especially in critical areas like healthcare or criminal justice. Explainable AI means people can understand the reasoning behind decisions.
Are We Protecting People's Privacy?
As an offshoot of transparency, systems should clearly communicate how user data is collected, stored, and shared–given how privacy is a primary ethical concern in AI.
Who Is Accountable When Things Go Wrong?
There needs to be a chain of command to follow when things go wrong.
Developers, organizations, or regulatory bodies must establish accountability frameworks to manage risks and provide redress for errors.
To What Extent Does AI Reasoning Replace a Human's?
The human factor should never be taken out of the AI equation. AI decisions without human oversight can be damaging.
Impact on Jobs
AI has the potential to automate tasks, which can displace workers in various industries.
Companies feel AI-related layoffs are inevitable. (Image source.)
Ethical AI includes strategies to address these disruptions, such as retraining programs or creating new job opportunities to mitigate economic effects.
Misinformation
As mentioned, AI technologies like deepfakes can spread false information and manipulate public opinion.
Misinformation is arguably AI's biggest challenge. (Image source.)
Ethical frameworks must focus on detecting and preventing the misuse of AI to safeguard the integrity of information and democratic processes.
When AI Goes Wrong: Real-Life Case Studies
The aforementioned concerns are valid, given how AI has gone wrong in specific instances over the last several years.
Biased AI Recruitment
Amazon's AIrecruiting tool penalized resumes with terms like ""women's,"" favoring male candidates due to patterns in historical hiring data.
Algorithmic Discrimination in Government
The Dutch childcare benefits scandal is a glaring example of algorithmic bias in government applications. An AI systemflagged low-income families and those with dual nationality as potential fraudsters, leading to false accusations.
Data Manipulation for Political Gain
The Cambridge Analytica scandal revealed how AI-powered analytics can be misused in politics. By exploiting Facebook users' data, the company influenced the 2016 U.S. presidential election, sparking debates about data privacy and the ethical boundaries of AI in shaping political outcomes.
Steps to Develop Ethical AI Systems
As you can see, AI can be just as destructive as it is a source of good. As a result, there's a huge need to develop AI ethically.
Here's how.
Building Ethical AI Principles
Every organization needs an ethical AI SOP that outlines how they plan to use AI responsibly. These should become mandatory to publish. Good AI ethics prioritizes human rights, privacy, and democratic values.
This SOP then acts as an organization's North Star. A report last year recommended AI companies spend 30% of their funding on R&D in safety and ethics.
And it's not just for-profit companies who need ethical AI. Even top UK universities are developing guiding ethical AI principles.
Conducting Ethical Risk Assessments
It's not enough to simply have a policy in place. Companies need to audit their AI development and usage regularly to identify kinks like privacy violations and discriminatory outputs.
Essentially, it's using good AI (like predictive analytics that can foresee potential risks) to outwit bad AI (whether malicious or innocuous.)
Implement Sound Ethical Principles
Bright Data sets itself apart in AI and data collection by prioritizing ethical practices. They work with organizations like the World Ethical Data Forum to address the challenges of responsible data use in the tech world.
Clear ethical guidelines are their approach, supporting transparency and accountability in how data is collected and handled.
Their commitment is further demonstrated through initiatives like their Trust Center, which sets standards for ethical web data collection while safeguarding customer and partner interests.
By focusing on clear user consent and complying with regulations like GDPR and CCPA, Bright Data shows how responsible practices can go hand in hand with innovation. Their dedication to ethical practices has made it a standout in the AI and data collection space, setting an example of how innovation and responsibility can go hand in hand.
Final Thoughts
The ethical development of AI is essential for navigating the moral challenges ML poses.
When we address ethical concerns like privacy, fairness, and societal impact, we can help AI systems align with human values and promote trust.
For organizations, integrating ethical AI principles into their development processes goes beyond a moral or legal obligation. It is a prerequisite to responsible innovation.
The post AI Ethics 101: Navigating the Moral Landscape of Machine Learning appeared first on Metaverse Post.
AI Ethics 101: Navigating the Moral Landscape of Machine Learning - Image
Link to Image
Companies use of Ai to replace workers - Image
Ipsos | Data dive | Artificial intelligence - Image
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 12806
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MACHINE LEARNING (90%); TECHNOLOGY (89%); HUMAN RIGHTS VIOLATIONS (78%); BLOGS & MESSAGE BOARDS (73%); DISEASES & DISORDERS (73%); MEDICINE & HEALTH (73%); HUMAN RIGHTS (71%); BIOMETRICS (66%)
Company:  AI SYSTEMS (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); METAVERSE (90%); BLOGS & MESSAGE BOARDS (73%); AUTONOMOUS MOTOR VEHICLES (68%)
Load-Date: December 26, 2024","Artificial intelligence (AI) has changed the way we live and work. Technology is influencing every field, from marketing and technology to healthcare.
AI enthusiasts are scrambling to understand how technology can solve the most complex problems the world grapples with today using machine learning (ML) as its bedrock.
ML is the process of feeding data to a system to enable the system to perform tasks. Now, that might not sound like anything new, but what's fascinating about ML is that a system can use the data it's given to self-learn the task and even get better at performing the task without needing a human to give it instructions explicitly, which was the norm before AI's explosion.
This is why we're heading towards things like self-driving cars, which were inconceivable before. Powered by ML, such cars and 'learn' to become better 'drivers' over time.
But, a word of caution.
AI is quickly taking over tasks that directly affect human life. Naturally, questions are being asked:
- Is AI fair, or is it biased?
- Will AI breach our fundamental human rights?
Such discourses have become known as AI ethics–the practice of identifying and addressing how we use AI without contradicting human values.
In this blog, we will discuss and navigate how to have difficult and frank conversations about aligning AI and ML's moral compass.
What Is AI Ethics?
Ethical AI closely examines how AI interacts with and affects human society. People involved in ethical AI discuss how to build an AI system fairly–specifically in how AI makes decisions from data in a way that minimizes any risks.
To drive home the point, let's use the example of surgery.
An example of healthcare AI could be providers training a system to help doctors prioritize patients on a surgery waiting list. In this instance, AI ethicists would make sure the system uses appropriate metrics to determine priority (like severity of medical condition), not unethical factors (like prioritizing people from richer neighborhoods.)
Additionally, ethicists would make sure AI is fed on fair data. If AI is given biased data to learn from, it will only perpetuate hurtful stereotypes.
Overall, the core of ethical AI is to create systems that benefit society and minimize harm.
It's important not to get swayed by technological advancements to the extent it can jeopardize certain members of society.
Why AI Ethics Matters
Ethical AI protects an individual from harm in the following ways.
Protecting Fundamental Rights
AI in businesses often work with sensitive data, like a person's financial or biometric information.
If ethical safeguards aren't implemented, these systems could breach their human rights. For example:
In this regard, ethical AI's role would be to ensure these systems operate transparently.
Preventing Disparate Impacts
As intelligent as ML is, learning from data filled with human biases can have disastrous consequences. It would be like amplifying racism, sexism, and the like. The outcomes could result in:
Ethical systems design comes in to uproot cognitive and unconscious bias.
Addressing Existential and Societal Risks
AI misuse in a way that causes existential crises is a real problem. A prime example is deepfakes.
Deepfakes are the name given to creating hyper-realistic fake media. A malicious actor could create a deepfake (lookalike) of a celebrity and make it say anything it wants–just think about how damaging that could be to the victim and society at large.
Deepfakes can result in:
Deepfake-based identity fraud is on a sharp rise. (Image source.)
Such consequences can be catastrophic during global events like general elections.
Key Ethical Questions in AI Development
It's good that we're raising important questions surrounding AI's use, but how do we implement AI ethics? There are several questions to consider.
Who Decides What's Right?
Who decides what's right and wrong? After all, unless someone is following a strict code of conduct (like those found in organized religion), morality remains subjective.
What is your right could be my wrong.
So, who decides? (and who decides who decides?)
Should it be:
Generally speaking, the best way forward is a diverse steering group that perhaps holds opinions across different ends of the spectrum. The more diverse input we get, the greater the chances of making a sound choice because each group can make up for each other's respective AI blind spots.
And, as subjective as morality can be, there is a large part of it that has 99.99% human consensus, so the moral quagmire isn't necessarily going to be complex each and every time, but we'd need group decision-making.
How Do We Prevent Bias?
AI systems must be designed to avoid discrimination against individuals or groups. Biases in training data can lead to unfair outcomes, such as denying loans based on demographic factors. Ensuring fairness requires diverse datasets and rigorous testing to detect and correct biases.
Are We Being Transparent?
People need to understand how AI systems make decisions. A lack of transparency confuses and diminishes trust, especially in critical areas like healthcare or criminal justice. Explainable AI means people can understand the reasoning behind decisions.
Are We Protecting People's Privacy?
As an offshoot of transparency, systems should clearly communicate how user data is collected, stored, and shared–given how privacy is a primary ethical concern in AI.
Who Is Accountable When Things Go Wrong?
There needs to be a chain of command to follow when things go wrong.
Developers, organizations, or regulatory bodies must establish accountability frameworks to manage risks and provide redress for errors.
To What Extent Does AI Reasoning Replace a Human's?
The human factor should never be taken out of the AI equation. AI decisions without human oversight can be damaging.
Impact on Jobs
AI has the potential to automate tasks, which can displace workers in various industries.
Companies feel AI-related layoffs are inevitable. (Image source.)
Ethical AI includes strategies to address these disruptions, such as retraining programs or creating new job opportunities to mitigate economic effects.
Misinformation
As mentioned, AI technologies like deepfakes can spread false information and manipulate public opinion.
Misinformation is arguably AI's biggest challenge. (Image source.)
Ethical frameworks must focus on detecting and preventing the misuse of AI to safeguard the integrity of information and democratic processes.
When AI Goes Wrong: Real-Life Case Studies
The aforementioned concerns are valid, given how AI has gone wrong in specific instances over the last several years.
Biased AI Recruitment
Amazon's AIrecruiting tool penalized resumes with terms like ""women's,"" favoring male candidates due to patterns in historical hiring data.
Algorithmic Discrimination in Government
The Dutch childcare benefits scandal is a glaring example of algorithmic bias in government applications. An AI systemflagged low-income families and those with dual nationality as potential fraudsters, leading to false accusations.
Data Manipulation for Political Gain
The Cambridge Analytica scandal revealed how AI-powered analytics can be misused in politics. By exploiting Facebook users' data, the company influenced the 2016 U.S. presidential election, sparking debates about data privacy and the ethical boundaries of AI in shaping political outcomes.
Steps to Develop Ethical AI Systems
As you can see, AI can be just as destructive as it is a source of good. As a result, there's a huge need to develop AI ethically.
Here's how.
Building Ethical AI Principles
Every organization needs an ethical AI SOP that outlines how they plan to use AI responsibly. These should become mandatory to publish. Good AI ethics prioritizes human rights, privacy, and democratic values.
This SOP then acts as an organization's North Star. A report last year recommended AI companies spend 30% of their funding on R&D in safety and ethics.
And it's not just for-profit companies who need ethical AI. Even top UK universities are developing guiding ethical AI principles.
Conducting Ethical Risk Assessments
It's not enough to simply have a policy in place. Companies need to audit their AI development and usage regularly to identify kinks like privacy violations and discriminatory outputs.
Essentially, it's using good AI (like predictive analytics that can foresee potential risks) to outwit bad AI (whether malicious or innocuous.)
Implement Sound Ethical Principles
Bright Data sets itself apart in AI and data collection by prioritizing ethical practices. They work with organizations like the World Ethical Data Forum to address the challenges of responsible data use in the tech world.
Clear ethical guidelines are their approach, supporting transparency and accountability in how data is collected and handled.
Their commitment is further demonstrated through initiatives like their Trust Center, which sets standards for ethical web data collection while safeguarding customer and partner interests.
By focusing on clear user consent and complying with regulations like GDPR and CCPA, Bright Data shows how responsible practices can go hand in hand with innovation. Their dedication to ethical practices has made it a standout in the AI and data collection space, setting an example of how innovation and responsibility can go hand in hand.
Final Thoughts
The ethical development of AI is essential for navigating the moral challenges ML poses.
When we address ethical concerns like privacy, fairness, and societal impact, we can help AI systems align with human values and promote trust.
For organizations, integrating ethical AI principles into their development processes goes beyond a moral or legal obligation. It is a prerequisite to responsible innovation.
The post AI Ethics 101: Navigating the Moral Landscape of Machine Learning appeared first on Metaverse Post.
AI Ethics 101: Navigating the Moral Landscape of Machine Learning - Image
Link to Image
Companies use of Ai to replace workers - Image
Ipsos | Data dive | Artificial intelligence - Image
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 12806
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MACHINE LEARNING (90%); TECHNOLOGY (89%); HUMAN RIGHTS VIOLATIONS (78%); BLOGS & MESSAGE BOARDS (73%); DISEASES & DISORDERS (73%); MEDICINE & HEALTH (73%); HUMAN RIGHTS (71%); BIOMETRICS (66%)
Company:  AI SYSTEMS (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); METAVERSE (90%); BLOGS & MESSAGE BOARDS (73%); AUTONOMOUS MOTOR VEHICLES (68%)
Load-Date: December 26, 2024",positive,0.669356644153595,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'safety', 'human rights', 'consent', 'manipulation', 'misinformation']","['justice', 'fairness', 'justice']","['policy', 'oversight', 'standards', 'guidelines', 'audit', 'should', 'must', 'need to']","['machine learning', 'predictive analytics']",11,3,8,2
2024,Unknown Title,"Body
The number of students registering for the O-level exam in ethics has increased by a staggering 32% between 2023 and 2024, with 738 candidates taking up the subject.
Official statistics show that the number of ethics students has been constantly increasing since 2018 from just 38 who first sat for the exam.
Ethics is currently only available to students whose parents opt out of Catholic religious education (CRE), but a new National Strategy for Education is proposing making ethics an option to CRE students at Year-9 (13 years of age), without having to drop out of religion. A number of independent schools have already gone further by offering both religion and ethics in parallel to all students, even to early-year pupils.
Official statistics suggest that the growth in interest in ethics has not been achieved at the cost of religious instruction: The increase in candidates sitting for CRE has remained stable, declining from 3,123 in 2021 to 2,839 in 2023 only to rise again to 2,990 in 2024.
The primary aim of the ethics programme is that of providing students with a ""moral education"" and ensure that they can ""think and deal reflectively with moral matters, to understand the moral issues they will encounter in their daily lives as adult members of Maltese society and of the world human community.""
Students are also taught to exercise ""practical wisdom in articulating their moral judgement, to understand and tolerate cultures, life-styles, outlooks, and life choices different from their own"" and to offer solidarity to those in their community and elsewhere who suffer injustice and to respect and support ""human rights, social justice, and democratic practice"".
Why more students are choosing ethics
Dr Lucianne Zammit, a lecturer at the University of Malta and coordinator of the Teaching Ethics in Schools Platform told MaltaToday that ever since ethics was introduced in 2014 through a gradual rollout, the number of students choosing the subject has been increasing steadily each year.
""This growth, in my view, is largely due to a highly relevant and contemporary syllabus for moral education that is based on critical thinking, covering topics such as AI and digital ethics, environmental ethics, cyberbullying, and misinformation.""
Moreover, the secondary school syllabus also deals with the ethical responsibilities associated with voting, emphasising the importance of informed decision-making to counter misinformation. ""This focus is particularly timely given the recent lowering of the voting age to sixteen, which coincides with the end of compulsory schooling.""
According to Zammit, students find Ethics valuable for their personal development, as it equips them with the"" reasoning skills and awareness needed in both civic and personal contexts"".
Moreover, while recognising that ethics is a popular choice among children of non-Maltese residents, it is also being widely chosen by Maltese students, with the national and MATSEC examination papers offered in both Maltese and English.
Even examiners are noting that students are finding the subject engaging, with an SEC exam report noting the performance of such candidates ""demonstrated a strong engagement with the material, particularly in areas related to practical ethical issues"".
Moreover, the majority of candidates showed a commendable understanding of the fundamental ethical concepts and were able to articulate their thoughts clearly in both the multiple-choice and essay sections.
For example, when writing an essay on bullying the vast majority of candidates provided real-life strategies to discourage and address bullying. ""Strong essays incorporated ethical virtues such as empathy and linked the discussion to important concepts like the ethics of care and self-esteem,"" the report says.
And when quizzed on animal rights examiners even found ""some standout essays"" which discussed ""advanced concepts such as sentience, speciesism, the role of PETA, and the notion of animals' voicelessness"".
The way forward
Ethics was originally introduced in the 2012 National Curriculum Framework as an alternative for parents who wished to withdraw their children from Catholic religious education. But since then, ethics has gained popularity with a broad range of students.
According to Zammit, this appeal ""stems from its focus on pressing ethical issues affecting society and the engaging teaching methodologies that emphasise class discussions and critical thinking.""
She notes that many parents and students have expressed the wish for ethics to be available to all students without requiring withdrawal from CRE.
One of the measures in the newly launched National Education Strategy is to make ethics available as an optional subject for all students in Year 9 (Form 3).
This change will allow secondary school students to continue studying CRE while also choosing ethics as one of their option subjects. ""In my opinion, all students at all educational levels should have the opportunity to study ethics alongside CRE, without the need to choose one over the other,"" Zammit said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1592
Subject: RELIGION (91%); ACADEMIC TESTING (90%); ETHICS (90%); RELIGIOUS EDUCATION (90%); STUDENTS & STUDENT LIFE (90%); CURRICULA (89%); SECONDARY SCHOOLS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); SOCIAL JUSTICE (78%); ADULTS (76%); CHILDREN, ADOLESCENTS & TEENS (76%); SELF IMPROVEMENT (76%); COMPULSORY EDUCATION (73%); CATHOLICS & CATHOLICISM (71%); DISINFORMATION & MISINFORMATION (64%); HUMAN RIGHTS (63%); VOTERS & VOTING (60%); CYBERBULLYING (50%)
Industry: SECONDARY SCHOOLS (89%); EDUCATIONAL SERVICES (78%)
Load-Date: November 21, 2024","The number of students registering for the O-level exam in ethics has increased by a staggering 32% between 2023 and 2024, with 738 candidates taking up the subject.
Official statistics show that the number of ethics students has been constantly increasing since 2018 from just 38 who first sat for the exam.
Ethics is currently only available to students whose parents opt out of Catholic religious education (CRE), but a new National Strategy for Education is proposing making ethics an option to CRE students at Year-9 (13 years of age), without having to drop out of religion. A number of independent schools have already gone further by offering both religion and ethics in parallel to all students, even to early-year pupils.
Official statistics suggest that the growth in interest in ethics has not been achieved at the cost of religious instruction: The increase in candidates sitting for CRE has remained stable, declining from 3,123 in 2021 to 2,839 in 2023 only to rise again to 2,990 in 2024.
The primary aim of the ethics programme is that of providing students with a ""moral education"" and ensure that they can ""think and deal reflectively with moral matters, to understand the moral issues they will encounter in their daily lives as adult members of Maltese society and of the world human community.""
Students are also taught to exercise ""practical wisdom in articulating their moral judgement, to understand and tolerate cultures, life-styles, outlooks, and life choices different from their own"" and to offer solidarity to those in their community and elsewhere who suffer injustice and to respect and support ""human rights, social justice, and democratic practice"".
Why more students are choosing ethics
Dr Lucianne Zammit, a lecturer at the University of Malta and coordinator of the Teaching Ethics in Schools Platform told MaltaToday that ever since ethics was introduced in 2014 through a gradual rollout, the number of students choosing the subject has been increasing steadily each year.
""This growth, in my view, is largely due to a highly relevant and contemporary syllabus for moral education that is based on critical thinking, covering topics such as AI and digital ethics, environmental ethics, cyberbullying, and misinformation.""
Moreover, the secondary school syllabus also deals with the ethical responsibilities associated with voting, emphasising the importance of informed decision-making to counter misinformation. ""This focus is particularly timely given the recent lowering of the voting age to sixteen, which coincides with the end of compulsory schooling.""
According to Zammit, students find Ethics valuable for their personal development, as it equips them with the"" reasoning skills and awareness needed in both civic and personal contexts"".
Moreover, while recognising that ethics is a popular choice among children of non-Maltese residents, it is also being widely chosen by Maltese students, with the national and MATSEC examination papers offered in both Maltese and English.
Even examiners are noting that students are finding the subject engaging, with an SEC exam report noting the performance of such candidates ""demonstrated a strong engagement with the material, particularly in areas related to practical ethical issues"".
Moreover, the majority of candidates showed a commendable understanding of the fundamental ethical concepts and were able to articulate their thoughts clearly in both the multiple-choice and essay sections.
For example, when writing an essay on bullying the vast majority of candidates provided real-life strategies to discourage and address bullying. ""Strong essays incorporated ethical virtues such as empathy and linked the discussion to important concepts like the ethics of care and self-esteem,"" the report says.
And when quizzed on animal rights examiners even found ""some standout essays"" which discussed ""advanced concepts such as sentience, speciesism, the role of PETA, and the notion of animals' voicelessness"".
The way forward
Ethics was originally introduced in the 2012 National Curriculum Framework as an alternative for parents who wished to withdraw their children from Catholic religious education. But since then, ethics has gained popularity with a broad range of students.
According to Zammit, this appeal ""stems from its focus on pressing ethical issues affecting society and the engaging teaching methodologies that emphasise class discussions and critical thinking.""
She notes that many parents and students have expressed the wish for ethics to be available to all students without requiring withdrawal from CRE.
One of the measures in the newly launched National Education Strategy is to make ethics available as an optional subject for all students in Year 9 (Form 3).
This change will allow secondary school students to continue studying CRE while also choosing ethics as one of their option subjects. ""In my opinion, all students at all educational levels should have the opportunity to study ethics alongside CRE, without the need to choose one over the other,"" Zammit said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1592
Subject: RELIGION (91%); ACADEMIC TESTING (90%); ETHICS (90%); RELIGIOUS EDUCATION (90%); STUDENTS & STUDENT LIFE (90%); CURRICULA (89%); SECONDARY SCHOOLS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); SOCIAL JUSTICE (78%); ADULTS (76%); CHILDREN, ADOLESCENTS & TEENS (76%); SELF IMPROVEMENT (76%); COMPULSORY EDUCATION (73%); CATHOLICS & CATHOLICISM (71%); DISINFORMATION & MISINFORMATION (64%); HUMAN RIGHTS (63%); VOTERS & VOTING (60%); CYBERBULLYING (50%)
Industry: SECONDARY SCHOOLS (89%); EDUCATIONAL SERVICES (78%)
Load-Date: November 21, 2024",neutral,0.5938591361045837,balanced/neutral,"['human rights', 'misinformation', 'disinformation']","['virtues', 'justice', 'justice']","['framework', 'should', 'need to', 'suggest']",[],3,3,4,0
2024,Unknown Title,"Body
2024 DEC 17 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from Alice, South Africa, by NewsRx correspondents, research stated, ""In this article, I will consider the moral issues that might arise from the possibility of creating more complex and sophisticated autonomous intelligent machines or simply artificial intelligence (AI) that would have the human capacity for moral reasoning, judgment, and decision-making, and (the possibility) of humans enhancing their moral capacities beyond what is considered normal for humanity."" 
 Our news reporters obtained a quote from the research from University of Fort Hare: ""These two possibilities raise an urgency for ethical principles that could be used to analyze the moral consequences of the intersection of AI and transhumanism. In this article, I deploy personhood-based relational ethics grounded on Afro-communitarianism as an African ethical framework to evaluate some of the moral problems at the intersection of AI and transhumanism."" 
 According to the news editors, the research concluded: ""In doing so, I will propose some Afro-ethical principles for research and policy development in AI and transhumanism."" 
 For more information on this research see: The ethics at the intersection of artificial intelligence and transhumanism: a personhood-based approach. Data & Policy, 2024,6. The publisher for Data & Policy is Cambridge University Press. 
 A free version of this journal article is available at https://doi.org/10.1017/dap.2024.59. 
 Our news journalists report that more information may be obtained by contacting Amara Esther Chimakonam, Centre for African Phenomenology, University of Fort Hare, Alice, South Africa. 
 Keywords for this news article include: University of Fort Hare, Alice, South Africa, Africa, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); JOURNALISM (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); PHILOSOPHY (77%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); WRITERS (73%); EXPERIMENTATION & RESEARCH (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); PUBLISHING (78%); WRITERS (73%)
Geographic: AFRICA (78%)
Load-Date: December 17, 2024","2024 DEC 17 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from Alice, South Africa, by NewsRx correspondents, research stated, ""In this article, I will consider the moral issues that might arise from the possibility of creating more complex and sophisticated autonomous intelligent machines or simply artificial intelligence (AI) that would have the human capacity for moral reasoning, judgment, and decision-making, and (the possibility) of humans enhancing their moral capacities beyond what is considered normal for humanity."" 
 Our news reporters obtained a quote from the research from University of Fort Hare: ""These two possibilities raise an urgency for ethical principles that could be used to analyze the moral consequences of the intersection of AI and transhumanism. In this article, I deploy personhood-based relational ethics grounded on Afro-communitarianism as an African ethical framework to evaluate some of the moral problems at the intersection of AI and transhumanism."" 
 According to the news editors, the research concluded: ""In doing so, I will propose some Afro-ethical principles for research and policy development in AI and transhumanism."" 
 For more information on this research see: The ethics at the intersection of artificial intelligence and transhumanism: a personhood-based approach. Data & Policy, 2024,6. The publisher for Data & Policy is Cambridge University Press. 
 A free version of this journal article is available at https://doi.org/10.1017/dap.2024.59. 
 Our news journalists report that more information may be obtained by contacting Amara Esther Chimakonam, Centre for African Phenomenology, University of Fort Hare, Alice, South Africa. 
 Keywords for this news article include: University of Fort Hare, Alice, South Africa, Africa, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); JOURNALISM (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); PHILOSOPHY (77%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); WRITERS (73%); EXPERIMENTATION & RESEARCH (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); PUBLISHING (78%); WRITERS (73%)
Geographic: AFRICA (78%)
Load-Date: December 17, 2024",neutral,0.9306263327598572,balanced/neutral,[],[],"['regulation', 'policy', 'framework', 'propose']","['machine learning', 'robotics']",0,0,4,2
2024,Unknown Title,"Body
December 4th, 2024 (NevilleHobson.com — Delivered by Newstex)
Wikipedia is undeniably one of the most important digital resources in existence. As the fifth most visited website globally, it shapes public perception, informs billions of users, and serves as a vital repository for AI training models. Its open, collaborative nature is a testament to the power of collective knowledge.
In a time where AI tools and language models increasingly depend on Wikipedia for training data, and misinformation spreads rapidly, ensuring ethical engagement with the platform is more critical than ever.
However, for communicators and PR professionals, navigating Wikipedia's strict guidelines and policies on creating and editing content in any of the different language versions of the encyclopedia can be a daunting challenge.
Before discussing insights, it's worth expanding on this point as it is key to understanding why it often is such a challenge for communicators, especially PR professionals.
Understand the Rules
Wikipedia's guidelines are designed to preserve its integrity as a reliable, unbiased source of information. At the heart of this complexity is the labyrinthine nature of Wikipedia's policies and guidelines.The labyrinth that is Wikipedia policies and guidelines.
From its 'Neutral Point of View' policy to its rules on  conflicts of interest and  verifiability, understanding and following these guidelines requires significant time and effort, particularly for newcomers.
The platform's sprawling documentation and intricate community expectations often leave even experienced communicators unsure of where to start or how to proceed.
For example, the 'Neutral Point of View' policy requires content to be written without bias, a standard that is simple in theory but often difficult to execute in practice, especially for corporate entities with vested interests.
Compounding this challenge is the entrenched attitudes of some PR practitioners who view Wikipedia's guidelines as obstacles to bypass rather than standards to uphold. This approach can lead to unethical practices, such as covert edits or attempts to manipulate content, which have created  a legacy of mistrust between the PR industry and Wikipedia's editing community. 
While organisations like Beutler Ink have demonstrated how ethical engagement can work, explained below, this mistrust still casts a long shadow, making collaborative efforts harder for those who genuinely wish to follow the rules.
Thankfully, professional bodies such as the CIPR have taken  clear steps to build a new 'climate of trust' during the past decade.
Finally, there is the decentralised, volunteer-driven nature of Wikipedia. Unlike traditional platforms, there is no central authority to appeal to when edits are delayed or contested. Communicators must navigate interactions with individual volunteer editors, some of whom may be unresponsive or overly rigid in their interpretation of the rules.
For those without prior experience or connections within the Wikipedia community, this decentralisation can make the process frustratingly opaque and time-consuming.
Together, these factors — policy complexity, lingering mistrust, and the unique dynamics of Wikipedia's volunteer ecosystem — create a steep learning curve for communicators. However, understanding and respecting these elements is essential for building trust and achieving success on the platform.
Apply Four Guiding Principles
In the November long-form edition of our For Immediate Release podcast, episode 437, Shel Holtz and I discuss the topic of ethical Wikipedia editing, using Beutler Ink as a prime example of best practices.
Beutler Ink, founded by  William Beutler, is a digital agency that has become synonymous with ethical Wikipedia consulting. Their approach, rooted in transparency and collaboration, sets a high standard that all communicators should strive to emulate.While everything in this post is to do with the English-language Wikipedia, the principles apply no matter the language.
In an article published on 25 November, Beutler Ink outlined their four guiding principles for engaging with Wikipedia. These principles form a framework that any organisation can adopt to ensure ethical engagement:
Neutral Point of View: Edits must be balanced, accurate, and free from bias.
Transparency: Conflicts of interest must be disclosed to the Wikipedia editing community.
Collaboration: Work with Wikipedia's volunteer editors instead of bypassing them.
Respect for Wikipedia's Rules: Follow the platform's guidelines without exception.
These principles serve as a practical toolkit for any communicator seeking to engage with Wikipedia while maintaining its integrity and their own professional credibility.
Note that the CIPR's guidelines, emphasising transparency and collaboration as cornerstones of ethical engagement, align closely with Beutler Ink's principles. Collectively, these resources offer communicators a practical roadmap for navigating Wikipedia effectively and ethically.
By prioritising collaboration and transparency, Beutler Ink has avoided the pitfalls of unethical editing, earning trust from both the Wikipedia community and their clients.
This approach builds on the call to PR practitioners to re-engage with the principles of ethical Wikipedia engagement that William Beutler made when Shel and I interviewed him last March in an FIR Interviews podcast.
I mentioned during the latest podcast that I've led projects in the past that required strict adherence to Wikipedia's policies. These experiences taught me just how important it is to understand and respect the platform's rules. Ethical editing isn't just about following guidelines — it's about maintaining the trust of audiences who rely on Wikipedia for impartial information.
Shel and I also discussed the challenges faced by PR professionals who are new to Wikipedia, such as I've explained above. Without a clear understanding of the rules, it's easy to misstep.
That's why frameworks like Beutler Ink's are invaluable. They offer a clear path for communicators to engage with Wikipedia in a way that is both ethical and effective, showing how transparency and collaboration can bridge the gap between corporate interests and community expectations.
As AI models increasingly rely on Wikipedia's vast repository of information, the accuracy and integrity of its content are more critical than ever. Misinformation introduced through unethical editing could amplify errors across countless AI-powered tools, underscoring the urgent need for ethical engagement.
The stakes for maintaining the platform's integrity have never been higher. Communicators must lead by example, adopting practices that align with Wikipedia's ethos of neutrality and transparency. Beutler Ink's ethical guidelines provide an excellent starting point for organisations looking to improve their approach.
If you're a communicator, here's where to start:
Review your company's or your client's Wikipedia page for accuracy and neutrality.
Familiarise yourself with Wikipedia's core policies, such as Neutral Point of View and Conflict of Interest.
Engage transparently with Wikipedia's editor community by using Talk pages to suggest edits.
Reference trusted third-party sources to support your contributions.
As communicators, we have a responsibility to uphold the values of transparency, neutrality, and collaboration in every interaction with Wikipedia. By adopting frameworks like Beutler Ink's, we can set the standard for ethical engagement and contribute to a more trustworthy digital ecosystem — one that informs billions and shapes the future of AI.
Failing to follow ethical practices risks not only reputational damage but also the potential for public backlash in today's hyperconnected world.
Listen to FIR 437
You can listen to our conversation about ethical Wikipedia editing right here, as part of the 92-minute episode; we start talking about Wikipedia at around the 34-minute mark. While you're here, why not sample the entire episode? 
If you don't see the embedded audio player, listen on the episode 437 show notes page on the podcast website. You can also find links there to all the source material we used in this episode, along with a verbatim transcript of our whole conversation.
Embed Player
Related Reading, Listening & Viewing:
Wikipedia and PR: Navigating a Complex Relationship (FIR Interview with William Beutler, 11 March 2024)
Wikipedia is about to get easier to edit (31 October 2022)
Civilising Wikipedia (14 February 2021)
The journey begins: guidance from the CIPR on PR and Wikipedia published (27 June 2012)
Closing the chasm between PR and Wikipedia (19 April 2012)
FIR Video Interview with Stuart Bruce and Phil Gomes on PR and Wikipedia (on YouTube, 12 January 2012)
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: Newstex Blogs
Subject: INTERNET SOCIAL NETWORKING (90%); ETHICS (89%); BLOGS & MESSAGE BOARDS (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (75%); CONFLICTS OF INTEREST (73%); ARTIFICIAL INTELLIGENCE (72%); DISINFORMATION & MISINFORMATION (72%); ASSOCIATIONS & ORGANIZATIONS (64%); Public Relations (%); Communication (%); Ethics (%); Beutler Ink (%); ethical editing (%); guidelines (%); policies (%); principles (%); public relations (%); wikipedia (%); William Beutler (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PUBLIC RELATIONS (89%); BLOGS & MESSAGE BOARDS (78%); ARTIFICIAL INTELLIGENCE (72%)
Load-Date: December 4, 2024","December 4th, 2024 (NevilleHobson.com — Delivered by Newstex)
Wikipedia is undeniably one of the most important digital resources in existence. As the fifth most visited website globally, it shapes public perception, informs billions of users, and serves as a vital repository for AI training models. Its open, collaborative nature is a testament to the power of collective knowledge.
In a time where AI tools and language models increasingly depend on Wikipedia for training data, and misinformation spreads rapidly, ensuring ethical engagement with the platform is more critical than ever.
However, for communicators and PR professionals, navigating Wikipedia's strict guidelines and policies on creating and editing content in any of the different language versions of the encyclopedia can be a daunting challenge.
Before discussing insights, it's worth expanding on this point as it is key to understanding why it often is such a challenge for communicators, especially PR professionals.
Understand the Rules
Wikipedia's guidelines are designed to preserve its integrity as a reliable, unbiased source of information. At the heart of this complexity is the labyrinthine nature of Wikipedia's policies and guidelines.The labyrinth that is Wikipedia policies and guidelines.
From its 'Neutral Point of View' policy to its rules on  conflicts of interest and  verifiability, understanding and following these guidelines requires significant time and effort, particularly for newcomers.
The platform's sprawling documentation and intricate community expectations often leave even experienced communicators unsure of where to start or how to proceed.
For example, the 'Neutral Point of View' policy requires content to be written without bias, a standard that is simple in theory but often difficult to execute in practice, especially for corporate entities with vested interests.
Compounding this challenge is the entrenched attitudes of some PR practitioners who view Wikipedia's guidelines as obstacles to bypass rather than standards to uphold. This approach can lead to unethical practices, such as covert edits or attempts to manipulate content, which have created  a legacy of mistrust between the PR industry and Wikipedia's editing community. 
While organisations like Beutler Ink have demonstrated how ethical engagement can work, explained below, this mistrust still casts a long shadow, making collaborative efforts harder for those who genuinely wish to follow the rules.
Thankfully, professional bodies such as the CIPR have taken  clear steps to build a new 'climate of trust' during the past decade.
Finally, there is the decentralised, volunteer-driven nature of Wikipedia. Unlike traditional platforms, there is no central authority to appeal to when edits are delayed or contested. Communicators must navigate interactions with individual volunteer editors, some of whom may be unresponsive or overly rigid in their interpretation of the rules.
For those without prior experience or connections within the Wikipedia community, this decentralisation can make the process frustratingly opaque and time-consuming.
Together, these factors — policy complexity, lingering mistrust, and the unique dynamics of Wikipedia's volunteer ecosystem — create a steep learning curve for communicators. However, understanding and respecting these elements is essential for building trust and achieving success on the platform.
Apply Four Guiding Principles
In the November long-form edition of our For Immediate Release podcast, episode 437, Shel Holtz and I discuss the topic of ethical Wikipedia editing, using Beutler Ink as a prime example of best practices.
Beutler Ink, founded by  William Beutler, is a digital agency that has become synonymous with ethical Wikipedia consulting. Their approach, rooted in transparency and collaboration, sets a high standard that all communicators should strive to emulate.While everything in this post is to do with the English-language Wikipedia, the principles apply no matter the language.
In an article published on 25 November, Beutler Ink outlined their four guiding principles for engaging with Wikipedia. These principles form a framework that any organisation can adopt to ensure ethical engagement:
Neutral Point of View: Edits must be balanced, accurate, and free from bias.
Transparency: Conflicts of interest must be disclosed to the Wikipedia editing community.
Collaboration: Work with Wikipedia's volunteer editors instead of bypassing them.
Respect for Wikipedia's Rules: Follow the platform's guidelines without exception.
These principles serve as a practical toolkit for any communicator seeking to engage with Wikipedia while maintaining its integrity and their own professional credibility.
Note that the CIPR's guidelines, emphasising transparency and collaboration as cornerstones of ethical engagement, align closely with Beutler Ink's principles. Collectively, these resources offer communicators a practical roadmap for navigating Wikipedia effectively and ethically.
By prioritising collaboration and transparency, Beutler Ink has avoided the pitfalls of unethical editing, earning trust from both the Wikipedia community and their clients.
This approach builds on the call to PR practitioners to re-engage with the principles of ethical Wikipedia engagement that William Beutler made when Shel and I interviewed him last March in an FIR Interviews podcast.
I mentioned during the latest podcast that I've led projects in the past that required strict adherence to Wikipedia's policies. These experiences taught me just how important it is to understand and respect the platform's rules. Ethical editing isn't just about following guidelines — it's about maintaining the trust of audiences who rely on Wikipedia for impartial information.
Shel and I also discussed the challenges faced by PR professionals who are new to Wikipedia, such as I've explained above. Without a clear understanding of the rules, it's easy to misstep.
That's why frameworks like Beutler Ink's are invaluable. They offer a clear path for communicators to engage with Wikipedia in a way that is both ethical and effective, showing how transparency and collaboration can bridge the gap between corporate interests and community expectations.
As AI models increasingly rely on Wikipedia's vast repository of information, the accuracy and integrity of its content are more critical than ever. Misinformation introduced through unethical editing could amplify errors across countless AI-powered tools, underscoring the urgent need for ethical engagement.
The stakes for maintaining the platform's integrity have never been higher. Communicators must lead by example, adopting practices that align with Wikipedia's ethos of neutrality and transparency. Beutler Ink's ethical guidelines provide an excellent starting point for organisations looking to improve their approach.
If you're a communicator, here's where to start:
Review your company's or your client's Wikipedia page for accuracy and neutrality.
Familiarise yourself with Wikipedia's core policies, such as Neutral Point of View and Conflict of Interest.
Engage transparently with Wikipedia's editor community by using Talk pages to suggest edits.
Reference trusted third-party sources to support your contributions.
As communicators, we have a responsibility to uphold the values of transparency, neutrality, and collaboration in every interaction with Wikipedia. By adopting frameworks like Beutler Ink's, we can set the standard for ethical engagement and contribute to a more trustworthy digital ecosystem — one that informs billions and shapes the future of AI.
Failing to follow ethical practices risks not only reputational damage but also the potential for public backlash in today's hyperconnected world.
Listen to FIR 437
You can listen to our conversation about ethical Wikipedia editing right here, as part of the 92-minute episode; we start talking about Wikipedia at around the 34-minute mark. While you're here, why not sample the entire episode? 
If you don't see the embedded audio player, listen on the episode 437 show notes page on the podcast website. You can also find links there to all the source material we used in this episode, along with a verbatim transcript of our whole conversation.
Embed Player
Related Reading, Listening & Viewing:
Wikipedia and PR: Navigating a Complex Relationship (FIR Interview with William Beutler, 11 March 2024)
Wikipedia is about to get easier to edit (31 October 2022)
Civilising Wikipedia (14 February 2021)
The journey begins: guidance from the CIPR on PR and Wikipedia published (27 June 2012)
Closing the chasm between PR and Wikipedia (19 April 2012)
FIR Video Interview with Stuart Bruce and Phil Gomes on PR and Wikipedia (on YouTube, 12 January 2012)
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: Newstex Blogs
Subject: INTERNET SOCIAL NETWORKING (90%); ETHICS (89%); BLOGS & MESSAGE BOARDS (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (75%); CONFLICTS OF INTEREST (73%); ARTIFICIAL INTELLIGENCE (72%); DISINFORMATION & MISINFORMATION (72%); ASSOCIATIONS & ORGANIZATIONS (64%); Public Relations (%); Communication (%); Ethics (%); Beutler Ink (%); ethical editing (%); guidelines (%); policies (%); principles (%); public relations (%); wikipedia (%); William Beutler (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PUBLIC RELATIONS (89%); BLOGS & MESSAGE BOARDS (78%); ARTIFICIAL INTELLIGENCE (72%)
Load-Date: December 4, 2024",neutral,0.5214200019836426,balanced/neutral,"['bias', 'transparency', 'agency', 'misinformation', 'disinformation']",[],"['policy', 'standards', 'guidelines', 'framework', 'should', 'must', 'suggest']",[],5,0,7,0
2024,Unknown Title,"Byline: BF Firos
Body
Kartik Mehta, Head of Asia at Channel Factory, has been at the forefront of transforming video advertising by leveraging data, AI, and precision targeting. With the evolving digital landscape and increasing demand for ethical, conscious, and brand-safe advertising practices, Mehta brings unique insights into how technology is reshaping the industry. As 2025 approaches, the intersection of AI, sustainability, and inclusion is more crucial than ever for brands aiming to balance profitability with social responsibility.
In this interview with Adgully, Kartik Mehta, Head of Asia, Channel Factory, shares his vision on how platforms like ViewIQ are set to enhance brand safety, targeting precision, and conscious advertising in video marketing. He dives into the evolving role of AI, the need for authentic representation, and how brands can stay ahead by adopting purpose-driven strategies that resonate with modern consumers.
As we approach 2025, how do you see data-driven platforms like ViewIQ evolving to offer even greater precision, brand safety, and targeting capabilities in video advertising? What new technologies might play a role? 
As we step into 2025, data-driven platforms like ViewIQ will play a pivotal role in achieving hyper-precision, ensuring both brand safety and suitability. With the rapid evolution of AI-powered categorization and machine learning models, we anticipate greater advancements in real-time video analysis and contextual targeting. The ability to process vast volumes of content with natural language processing (NLP) and sentiment analysis will help platforms like ViewIQ ensure ads appear in the right context, resonating with audiences more effectively.
Technologies such as predictive analytics, computer vision, and AI-driven audience segmentation will further enhance targeting capabilities. For example, understanding behavioural signals from short-form video platforms like TikTok or Instagram Reels, and correlating them with audience intent, will redefine precision. ViewIQ will evolve to not just meet, but anticipate advertiser needs, delivering performance while maintaining an unwavering commitment to brand safety.
How can brands balance profit-driven goals with ethical imperatives in an increasingly conscious marketplace? Do you foresee more global adoption of conscious advertising strategies by 2025? 
The shift towards conscious advertising is no longer optional; it is imperative. Brands today are navigating an increasingly aware consumer base that values transparency, inclusivity, and purpose. Balancing profit-driven goals with ethical imperatives requires brands to view conscious advertising as a growth strategy rather than a trade-off. By leveraging platforms like ViewIQ, brands can align their messaging with contextually relevant, brand-suitable content while adhering to ethical advertising standards.
We anticipate significant global adoption of conscious advertising strategies by 2025. Leading markets in Asia, Europe, and North America are already driving initiatives focused on sustainability, inclusivity, and social impact. AI-powered tools will empower brands to measure the alignment between ethical narratives and audience perceptions, ensuring measurable ROI alongside societal good. Brands that lead this movement will benefit not only from consumer loyalty but also from long-term sustainable growth.
By 2025, how can inclusion-first approaches in media be further scaled to ensure diverse voices are genuinely represented and not just tokenized? What metrics will define success for these inclusive campaigns? 
Scaling inclusion-first approaches requires a shift from performative actions to tangible, measurable impact. By 2025, platforms like Channel Factory's ViewIQ will lead this evolution by providing data-backed insights to ensure diverse voices and creators are genuinely represented in advertising ecosystems. Inclusion-first strategies will thrive when brands actively collaborate with diverse creators, produce localized content, and embrace contextual inclusivity across all platforms.
Success will be defined by metrics beyond reach and impressions. Authenticity, representation, and engagement rates within diverse communities will take center stage. Metrics like share of voice from underrepresented creators, audience sentiment analysis, and incremental impact on cultural resonance will quantify success. Advertisers must hold themselves accountable to meaningful representation by measuring the societal impact alongside business outcomes.
What future tools or frameworks do you anticipate will be developed to further tackle unconscious biases in content promotion and audience targeting? How can these innovations reshape digital media by 2025? 
The fight against unconscious bias will be further accelerated by AI frameworks designed to identify and eliminate prejudices in content promotion and targeting. By 2025, we foresee the development of tools that combine algorithmic fairness with ethical AI principles, ensuring ads are delivered in a way that avoids reinforcing stereotypes or marginalizing certain groups.
For example, advanced bias-detection tools integrated within platforms like ViewIQ can audit campaigns in real-time, flagging biased targeting or misaligned content placement. Moreover, AI-driven content classifiers will ensure fair representation across all demographics. These innovations will reshape digital media by fostering a more inclusive, equitable ecosystem where content speaks to diverse audiences authentically. Brands that embrace these frameworks will set new benchmarks for ethical marketing.
How do you envision the Conscious Advertising Program in India evolving by 2025, particularly in terms of sustainability and diversity? What milestones should brands aim to achieve to stay aligned with societal expectations? 
India is uniquely positioned to lead the Conscious Advertising movement by 2025, given its dynamic media landscape and cultural diversity. Programs like the Conscious Advertising Program will evolve to address critical issues such as sustainability, content inclusivity, and social responsibility. Brands will adopt holistic approaches that prioritize environmentally sustainable messaging and showcase diversity in meaningful ways.
Milestones for brands will include:
* Net-zero advertising practices, reducing carbon footprints through sustainable ad delivery.
* Increasing representation of diverse voices within campaigns, particularly from regional creators and communities.
* Transparency benchmarks, where brands commit to sharing progress on ethical initiatives, diversity metrics, and audience inclusivity.
* Platforms like Channel Factory will empower brands to meet these milestones through AI-led tools that ensure campaigns align with both consumer sentiment and societal expectations.
Looking ahead, how can brands stay ahead of the curve in a purpose-driven market? What emerging trends or technologies might enable brands to seamlessly integrate ethical practices with data-driven insights? 
In a purpose-driven market, brands that combine ethical storytelling with data-driven precision will lead the charge.
Emerging trends include:
*AI-powered sentiment tracking, enabling brands to monitor how campaigns resonate with purpose-driven audiences in real-time.
*Predictive audience modelling, helping brands anticipate shifts in consumer consciousness and tailor messages accordingly.
*Interactive and immersive formats, such as AR/VR, to create experiences that educate, inspire, and connect with audiences on deeper, emotional levels.
By embedding ethical practices into campaign strategies, brands can strike the perfect balance between profitability and purpose. Platforms like Channel Factory will play a critical role in ensuring data-driven insights are aligned with the values of modern consumers, helping brands stay relevant, resonant, and responsible in 2025.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING FACILITIES (90%); SAFETY (90%); CONSUMERS (89%); ETHICS (89%); OUTPUT & DEMAND (89%); SHORT FORM VIDEOS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); BRANDING (78%); BUSINESS ANALYTICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); MACHINE LEARNING (78%); NATURAL LANGUAGE PROCESSING (78%); PHOTO & VIDEO SHARING (78%); PREDICTIVE ANALYTICS (78%); PURPOSE DRIVEN BUSINESS (78%); COMPANY STRATEGY (77%); MACHINE VISION (75%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING FACILITIES (90%); MARKETING & ADVERTISING (89%); MARKETING STRATEGY (89%); SHORT FORM VIDEOS (89%); BRANDING (78%); BUSINESS ANALYTICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); MACHINE LEARNING (78%); MARKET SEGMENTATION (78%); NATURAL LANGUAGE PROCESSING (78%); PHOTO & VIDEO SHARING (78%); PREDICTIVE ANALYTICS (78%); VIDEO INDUSTRY (78%); IMAGE PROCESSING & COMPUTER VISION (77%); MACHINE VISION (75%); SHORT FORM CONTENT (63%)
Geographic: ASIA (90%); EUROPE (71%)
Load-Date: December 26, 2024","Kartik Mehta, Head of Asia at Channel Factory, has been at the forefront of transforming video advertising by leveraging data, AI, and precision targeting. With the evolving digital landscape and increasing demand for ethical, conscious, and brand-safe advertising practices, Mehta brings unique insights into how technology is reshaping the industry. As 2025 approaches, the intersection of AI, sustainability, and inclusion is more crucial than ever for brands aiming to balance profitability with social responsibility.
In this interview with Adgully, Kartik Mehta, Head of Asia, Channel Factory, shares his vision on how platforms like ViewIQ are set to enhance brand safety, targeting precision, and conscious advertising in video marketing. He dives into the evolving role of AI, the need for authentic representation, and how brands can stay ahead by adopting purpose-driven strategies that resonate with modern consumers.
As we approach 2025, how do you see data-driven platforms like ViewIQ evolving to offer even greater precision, brand safety, and targeting capabilities in video advertising? What new technologies might play a role? 
As we step into 2025, data-driven platforms like ViewIQ will play a pivotal role in achieving hyper-precision, ensuring both brand safety and suitability. With the rapid evolution of AI-powered categorization and machine learning models, we anticipate greater advancements in real-time video analysis and contextual targeting. The ability to process vast volumes of content with natural language processing (NLP) and sentiment analysis will help platforms like ViewIQ ensure ads appear in the right context, resonating with audiences more effectively.
Technologies such as predictive analytics, computer vision, and AI-driven audience segmentation will further enhance targeting capabilities. For example, understanding behavioural signals from short-form video platforms like TikTok or Instagram Reels, and correlating them with audience intent, will redefine precision. ViewIQ will evolve to not just meet, but anticipate advertiser needs, delivering performance while maintaining an unwavering commitment to brand safety.
How can brands balance profit-driven goals with ethical imperatives in an increasingly conscious marketplace? Do you foresee more global adoption of conscious advertising strategies by 2025? 
The shift towards conscious advertising is no longer optional; it is imperative. Brands today are navigating an increasingly aware consumer base that values transparency, inclusivity, and purpose. Balancing profit-driven goals with ethical imperatives requires brands to view conscious advertising as a growth strategy rather than a trade-off. By leveraging platforms like ViewIQ, brands can align their messaging with contextually relevant, brand-suitable content while adhering to ethical advertising standards.
We anticipate significant global adoption of conscious advertising strategies by 2025. Leading markets in Asia, Europe, and North America are already driving initiatives focused on sustainability, inclusivity, and social impact. AI-powered tools will empower brands to measure the alignment between ethical narratives and audience perceptions, ensuring measurable ROI alongside societal good. Brands that lead this movement will benefit not only from consumer loyalty but also from long-term sustainable growth.
By 2025, how can inclusion-first approaches in media be further scaled to ensure diverse voices are genuinely represented and not just tokenized? What metrics will define success for these inclusive campaigns? 
Scaling inclusion-first approaches requires a shift from performative actions to tangible, measurable impact. By 2025, platforms like Channel Factory's ViewIQ will lead this evolution by providing data-backed insights to ensure diverse voices and creators are genuinely represented in advertising ecosystems. Inclusion-first strategies will thrive when brands actively collaborate with diverse creators, produce localized content, and embrace contextual inclusivity across all platforms.
Success will be defined by metrics beyond reach and impressions. Authenticity, representation, and engagement rates within diverse communities will take center stage. Metrics like share of voice from underrepresented creators, audience sentiment analysis, and incremental impact on cultural resonance will quantify success. Advertisers must hold themselves accountable to meaningful representation by measuring the societal impact alongside business outcomes.
What future tools or frameworks do you anticipate will be developed to further tackle unconscious biases in content promotion and audience targeting? How can these innovations reshape digital media by 2025? 
The fight against unconscious bias will be further accelerated by AI frameworks designed to identify and eliminate prejudices in content promotion and targeting. By 2025, we foresee the development of tools that combine algorithmic fairness with ethical AI principles, ensuring ads are delivered in a way that avoids reinforcing stereotypes or marginalizing certain groups.
For example, advanced bias-detection tools integrated within platforms like ViewIQ can audit campaigns in real-time, flagging biased targeting or misaligned content placement. Moreover, AI-driven content classifiers will ensure fair representation across all demographics. These innovations will reshape digital media by fostering a more inclusive, equitable ecosystem where content speaks to diverse audiences authentically. Brands that embrace these frameworks will set new benchmarks for ethical marketing.
How do you envision the Conscious Advertising Program in India evolving by 2025, particularly in terms of sustainability and diversity? What milestones should brands aim to achieve to stay aligned with societal expectations? 
India is uniquely positioned to lead the Conscious Advertising movement by 2025, given its dynamic media landscape and cultural diversity. Programs like the Conscious Advertising Program will evolve to address critical issues such as sustainability, content inclusivity, and social responsibility. Brands will adopt holistic approaches that prioritize environmentally sustainable messaging and showcase diversity in meaningful ways.
Milestones for brands will include:
* Net-zero advertising practices, reducing carbon footprints through sustainable ad delivery.
* Increasing representation of diverse voices within campaigns, particularly from regional creators and communities.
* Transparency benchmarks, where brands commit to sharing progress on ethical initiatives, diversity metrics, and audience inclusivity.
* Platforms like Channel Factory will empower brands to meet these milestones through AI-led tools that ensure campaigns align with both consumer sentiment and societal expectations.
Looking ahead, how can brands stay ahead of the curve in a purpose-driven market? What emerging trends or technologies might enable brands to seamlessly integrate ethical practices with data-driven insights? 
In a purpose-driven market, brands that combine ethical storytelling with data-driven precision will lead the charge.
Emerging trends include:
*AI-powered sentiment tracking, enabling brands to monitor how campaigns resonate with purpose-driven audiences in real-time.
*Predictive audience modelling, helping brands anticipate shifts in consumer consciousness and tailor messages accordingly.
*Interactive and immersive formats, such as AR/VR, to create experiences that educate, inspire, and connect with audiences on deeper, emotional levels.
By embedding ethical practices into campaign strategies, brands can strike the perfect balance between profitability and purpose. Platforms like Channel Factory will play a critical role in ensuring data-driven insights are aligned with the values of modern consumers, helping brands stay relevant, resonant, and responsible in 2025.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING FACILITIES (90%); SAFETY (90%); CONSUMERS (89%); ETHICS (89%); OUTPUT & DEMAND (89%); SHORT FORM VIDEOS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); BRANDING (78%); BUSINESS ANALYTICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); MACHINE LEARNING (78%); NATURAL LANGUAGE PROCESSING (78%); PHOTO & VIDEO SHARING (78%); PREDICTIVE ANALYTICS (78%); PURPOSE DRIVEN BUSINESS (78%); COMPANY STRATEGY (77%); MACHINE VISION (75%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING FACILITIES (90%); MARKETING & ADVERTISING (89%); MARKETING STRATEGY (89%); SHORT FORM VIDEOS (89%); BRANDING (78%); BUSINESS ANALYTICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); MACHINE LEARNING (78%); MARKET SEGMENTATION (78%); NATURAL LANGUAGE PROCESSING (78%); PHOTO & VIDEO SHARING (78%); PREDICTIVE ANALYTICS (78%); VIDEO INDUSTRY (78%); IMAGE PROCESSING & COMPUTER VISION (77%); MACHINE VISION (75%); SHORT FORM CONTENT (63%)
Geographic: ASIA (90%); EUROPE (71%)
Load-Date: December 26, 2024",positive,0.5995155572891235,balanced/neutral,"['bias', 'fairness', 'transparency', 'safety', 'inclusivity']",['fairness'],"['standards', 'audit', 'should', 'must']","['machine learning', 'computer vision', 'natural language processing', 'nlp', 'predictive analytics']",5,1,4,5
2024,Unknown Title,"Body
December 11th, 2024 ( GuruFocus.com  - Delivered by  Newstex )
NEW YORK, Dec. 11, 2024 (GLOBE NEWSWIRE) -- Ethical Web AI (d/b/a Bubblr Inc.) ( BBLR), a leader in ethical technology innovation, proudly announces a landmark partnership with BolgiaTen Limited. This collaboration brings together Ethical Web AI's AI Seek and BolgiaTen's Promptathone training program, marking a pivotal shift in the company's strategy to focus on enterprise sales of generative AI solutions. This move is expected to significantly enhance revenue forecasts for the first half of 2025 and beyond; given that the company has access to over 850 organizations covering 40% of the world's mobile connections, it sees a wide range of future opportunities. Under the terms of the partnership, The bespoke AI Seek license will be billed directly to the clients of BolgiaTen, creating a monthly revenue with excellent margins for Ethical Web AI.
The partnership started on December 9th, 2024, with the first revenue anticipated in Q1 2025.
Award-winning BolgiaTen ( https://www.bolgiaten.com/) guides companies and governments in achieving the best AI-driven, value-centric outcomes in domains like social media, mobility, AI, big data, and the cloud.
The Promptathone program is a specialized training initiative designed to help companies train their staff to become proficient, prompt engineers, unlocking the full potential of Generative AI (GenAI). This program is supported by a bespoke version of AI Seek, which offers critical advantages for enterprises, including:
Enhanced security, ensuring all prompt and answer data remain internal.
Cost savings compared to traditional generative AI solutions.
Flexibility to integrate AI seamlessly across operations, from Finance and HR to Operations and Distribution.
This enterprise-focused approach positions Ethical Web AI as a key provider of innovative and secure AI solutions. After using AI Seek in training, companies are highly likely to adopt it as their primary AI platform, establishing a recurring revenue model for Ethical Web AI.
Steve Morris, CTO of Ethical Web AI, remarked:
""This partnership represents a transformative moment for Ethical Web AI. Shifting to enterprise sales has created a substantial pipeline of opportunities and fundamentally reshaped our business strategy for the better. The enterprise focus will drive significant revenue in 2025, providing a more sustainable and scalable foundation for our future. We are finally turning the corner into revenue.""
He added, ""Having Professor Paul Morrissey, CEO of BolgiaTen and Global AI Ambassador for TM Forum, championing AI Seek amplifies the impact of this partnership. TM Forum, as the key standards body for the global communications industry, represents over 850 member organizations and 40% of the world's mobile connections. This partnership positions AI Seek at the forefront of enterprise AI innovation, reaching a highly influential audience in a rapidly growing market.""
Professor Paul Morrissey stated:
""Integrating AI Seek into our Promptathone program aligns perfectly with our mission to empower enterprises with ethical, cutting-edge AI solutions. TM Forum's global network offers unparalleled access to businesses ready to adopt AI that prioritizes privacy and security. Together, we are enabling organizations to revolutionize their operations while maintaining control over their data.""
This shift to enterprise sales has already begun to redefine Ethical Web AI's business plans, replacing a consumer-focused model with a more lucrative enterprise-driven approach. The partnership with BolgiaTen is expected to significantly boost revenue in the first half of 2025, with ongoing benefits as AI Seek becomes a preferred solution for enterprise AI needs.
About Ethical Web AI:
Ethical Web AI is an ethical technology company championing an anonymous, safe, and fair new internet. We produce unique intellectual property and technology made defensible by our valuable utility software patents.
Visit the new AI Seek website at  https://www.aiseek.ai.
For more information about our company and products, please visit our website at  www.ethicalweb.ai.
Media Contact:
Steve Morris
Bubblr, Inc.
(646) 814 7184
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management. They are subject to several uncertainties and risks that could significantly affect the company's current plans and expectations, future operations, and financial condition. The company reserves the right to update or alter its forward-looking statements, whether due to new information, future events or otherwise.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 108642
Subject: FINANCIAL MARKET UPDATES (90%); GENERATIVE AI (90%); PRESS RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); COMPANY STRATEGY (89%); ETHICS (89%); BLOGS & MESSAGE BOARDS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); EMERGING TECHNOLOGY (78%); SOCIAL MEDIA (78%); TECHNOLOGY (78%); EMPLOYEE TRAINING (77%); EXECUTIVES (77%); BUSINESS FORECASTS (75%); PRODUCT INNOVATION (72%); ASSOCIATIONS & ORGANIZATIONS (69%); BBLR (%)
Industry: FINANCIAL MARKET UPDATES (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); BLOGS & MESSAGE BOARDS (78%); MEDIA & TELECOMMUNICATIONS (78%); SOCIAL MEDIA (78%); TELECOMMUNICATIONS (74%); BIG DATA (70%)
Load-Date: December 11, 2024","December 11th, 2024 ( GuruFocus.com  - Delivered by  Newstex )
NEW YORK, Dec. 11, 2024 (GLOBE NEWSWIRE) -- Ethical Web AI (d/b/a Bubblr Inc.) ( BBLR), a leader in ethical technology innovation, proudly announces a landmark partnership with BolgiaTen Limited. This collaboration brings together Ethical Web AI's AI Seek and BolgiaTen's Promptathone training program, marking a pivotal shift in the company's strategy to focus on enterprise sales of generative AI solutions. This move is expected to significantly enhance revenue forecasts for the first half of 2025 and beyond; given that the company has access to over 850 organizations covering 40% of the world's mobile connections, it sees a wide range of future opportunities. Under the terms of the partnership, The bespoke AI Seek license will be billed directly to the clients of BolgiaTen, creating a monthly revenue with excellent margins for Ethical Web AI.
The partnership started on December 9th, 2024, with the first revenue anticipated in Q1 2025.
Award-winning BolgiaTen ( https://www.bolgiaten.com/) guides companies and governments in achieving the best AI-driven, value-centric outcomes in domains like social media, mobility, AI, big data, and the cloud.
The Promptathone program is a specialized training initiative designed to help companies train their staff to become proficient, prompt engineers, unlocking the full potential of Generative AI (GenAI). This program is supported by a bespoke version of AI Seek, which offers critical advantages for enterprises, including:
Enhanced security, ensuring all prompt and answer data remain internal.
Cost savings compared to traditional generative AI solutions.
Flexibility to integrate AI seamlessly across operations, from Finance and HR to Operations and Distribution.
This enterprise-focused approach positions Ethical Web AI as a key provider of innovative and secure AI solutions. After using AI Seek in training, companies are highly likely to adopt it as their primary AI platform, establishing a recurring revenue model for Ethical Web AI.
Steve Morris, CTO of Ethical Web AI, remarked:
""This partnership represents a transformative moment for Ethical Web AI. Shifting to enterprise sales has created a substantial pipeline of opportunities and fundamentally reshaped our business strategy for the better. The enterprise focus will drive significant revenue in 2025, providing a more sustainable and scalable foundation for our future. We are finally turning the corner into revenue.""
He added, ""Having Professor Paul Morrissey, CEO of BolgiaTen and Global AI Ambassador for TM Forum, championing AI Seek amplifies the impact of this partnership. TM Forum, as the key standards body for the global communications industry, represents over 850 member organizations and 40% of the world's mobile connections. This partnership positions AI Seek at the forefront of enterprise AI innovation, reaching a highly influential audience in a rapidly growing market.""
Professor Paul Morrissey stated:
""Integrating AI Seek into our Promptathone program aligns perfectly with our mission to empower enterprises with ethical, cutting-edge AI solutions. TM Forum's global network offers unparalleled access to businesses ready to adopt AI that prioritizes privacy and security. Together, we are enabling organizations to revolutionize their operations while maintaining control over their data.""
This shift to enterprise sales has already begun to redefine Ethical Web AI's business plans, replacing a consumer-focused model with a more lucrative enterprise-driven approach. The partnership with BolgiaTen is expected to significantly boost revenue in the first half of 2025, with ongoing benefits as AI Seek becomes a preferred solution for enterprise AI needs.
About Ethical Web AI:
Ethical Web AI is an ethical technology company championing an anonymous, safe, and fair new internet. We produce unique intellectual property and technology made defensible by our valuable utility software patents.
Visit the new AI Seek website at  https://www.aiseek.ai.
For more information about our company and products, please visit our website at  www.ethicalweb.ai.
Media Contact:
Steve Morris
Bubblr, Inc.
(646) 814 7184
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management. They are subject to several uncertainties and risks that could significantly affect the company's current plans and expectations, future operations, and financial condition. The company reserves the right to update or alter its forward-looking statements, whether due to new information, future events or otherwise.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 108642
Subject: FINANCIAL MARKET UPDATES (90%); GENERATIVE AI (90%); PRESS RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); COMPANY STRATEGY (89%); ETHICS (89%); BLOGS & MESSAGE BOARDS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); EMERGING TECHNOLOGY (78%); SOCIAL MEDIA (78%); TECHNOLOGY (78%); EMPLOYEE TRAINING (77%); EXECUTIVES (77%); BUSINESS FORECASTS (75%); PRODUCT INNOVATION (72%); ASSOCIATIONS & ORGANIZATIONS (69%); BBLR (%)
Industry: FINANCIAL MARKET UPDATES (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); BLOGS & MESSAGE BOARDS (78%); MEDIA & TELECOMMUNICATIONS (78%); SOCIAL MEDIA (78%); TELECOMMUNICATIONS (74%); BIG DATA (70%)
Load-Date: December 11, 2024",positive,0.5658136010169983,balanced/neutral,"['privacy', 'security', 'access']",[],"['standards', 'should']",['generative ai'],3,0,2,1
2024,Unknown Title,"Byline: Brett Farmiloe
Body
December 2nd, 2024 ( TechBullion  - Delivered by  Newstex )
How Do You Navigate Ethical Considerations in the Process of Technological Innovation?
As technology advances at breakneck speed, the ethical challenges it brings are more pressing than ever. In this article, C-suite leaders and cybersecurity experts share their strategies for navigating these complex issues. From the importance of proactive planning and transparency to tackling bias in AI algorithms, these 21 expert insights offer a roadmap for responsible innovation. Whether you're developing new tech or refining existing solutions, this guide will help you balance progress with integrity and accountability.
Proactively Plan and Commit to Transparency
Stay Connected to Industry Ecosystem
Embrace Constraints as Creativity Drivers
Design with Empathy
Prioritize Human Dignity and Social Good
Enhance User Value Ethically
Keep User Well-Being at Center
Balance Innovation with Basic Rights
Hold Privacy as Core Value
Think Ethics by Design
Build with Intention and Impact
Prioritize User Empowerment
Foster Transparency and Open Dialogue
Ensure Responsible and Transparent Use
Prioritize Transparency and Accountability
Lead Development Under Clear Regulations
Make Technology Accessible to Everyone
View Technology as Human Assistant
Establish Stringent Code of Ethics
Reference Handbook for Compliance
Address Bias in AI Algorithms
Proactively Plan and Commit to Transparency
Navigating ethical considerations in technological innovation requires proactive planning and a commitment to transparency. A guiding principle I follow is 'anticipate, evaluate, and act'-anticipate potential ethical challenges, evaluate their impact, and act responsibly to address them before they escalate.
During a project involving AI-driven customer profiling, we anticipated concerns about data privacy. By designing the system with privacy-first principles-like minimizing data collection, anonymizing user data, and implementing clear opt-in policies-we ensured compliance and maintained user trust. Open communication with stakeholders about how data was used also helped us navigate potential concerns.
My advice for businesses? Embed ethics into your innovation process from the start. Create an ethics review framework that evaluates risks at every stage of development, involve diverse stakeholders for balanced perspectives, and prioritize transparency with users. Ethical foresight isn't just about avoiding backlash-it builds trust, loyalty, and long-term success.
Inge von Aulock, COO, Penfriend
Stay Connected to Industry Ecosystem
In my work in emerging technologies within enterprises, ethical considerations have been a constant and critical focus, particularly with the adoption of Artificial Intelligence (AI). AI's potential for bias and unintended discrimination, such as in hiring algorithms or facial recognition systems, highlighted the importance of tackling these issues early. I often had to factor these concerns into the projects I led and I quickly realised that staying connected to the broader organisation and industry ecosystem was essential for doing this effectively.
For example, I attended AI ethics panels and workshops to understand the latest thinking on mitigating algorithmic bias. Engaging with researchers and practitioners through these events, as well as connecting with thought leaders across the enterprise and on platforms like LinkedIn, provided insights that were invaluable for key ethical risks. For instance, I learned about de-biasing techniques and tools that I shared with development teams, ensuring that our projects reflected the latest advancements in ethical AI practices. This collaboration helped me align our work with the best practices emerging from the wider ecosystem.
Connecting to the industry also highlighted the need to stay ahead of at times slow-moving regulations that can't match the pace of changing innovations. At the time, many of the rules surrounding AI ethics were still evolving, particularly with the boom of Generative AI. Through my ecosystem engagement, I saw how companies were proactively addressing issues like transparency and fairness to fill this gap. Participating in these conversations wasn't just informative, it allowed me to bring back valuable knowledge to my own work, ensuring that ethical considerations weren't an afterthought but an integral part of the process.
The biggest takeaway for me has been that no organisation can navigate these challenges alone. By connecting to the broader ecosystem through events, partnerships and discussions, we can access diverse perspectives and shared knowledge. As a guiding principle, it is essential to be proactive in understanding and managing ethical concerns when it comes to new technologies at both a company and industry level. Rather than simply reacting to delayed introductions of regulations.
Elsie Day, Cyber Security Analyst, CyPro
Embrace Constraints as Creativity Drivers
When navigating ethical considerations in technological innovation, I think what's a crucial principle I focus on is embracing constraints as a driver of creativity. Many businesses see ethical frameworks as barriers to innovation, but I've found that they can spark some of the most groundbreaking ideas.
For example, when working with startups, I've encouraged teams to treat ethical dilemmas not as limitations but as opportunities to redefine their approach. Take user data privacy, which is a common ethical concern. Instead of relying on traditional data collection methods that could border on invasive, one client built an entirely privacy-first AI platform that analyzed user data locally.
At first, the idea felt restrictive. How do you create meaningful user insights without centralized data? However, this challenge forced the team to innovate, resulting in a decentralized model that earned user trust and positioned them as leaders in a growing ethical tech movement.
The guiding principle I always emphasize is this: design your innovation process around values, not just outcomes. It may seem counterproductive, but when ethics are embedded from the start, you build products that don't just solve problems but also resonate deeply with people. This resonance is what sets ethical businesses apart in today's tech landscape.
Nicholas Robb, Design agency for startups, Design Hero
Design with Empathy
My principle is always to 'design with empathy.' For us, it's about making sure our product doesn't just work, but that it works in a way that respects users and meets their real needs. For example, when we were building our AI tool, we paid close attention to how it could potentially impact users in terms of privacy and data security. We made sure that users had clear control over their data, and we avoided features that could be intrusive or overly complicated.
The key is to think beyond functionality. Technology shouldn't just solve a problem, it should also offer solutions in a way that doesn't create new ones. For businesses, this means actively involving users in the design process, getting feedback, and constantly asking if your product is doing more for your customers than just providing a service. It also helps to have a team that can look at your tech from different angles-social, cultural, and ethical-before you launch anything. That's how you create products that people trust.
Roman Hipp, Co-founder, BetterContact
Prioritize Human Dignity and Social Good
As someone who has worked in tech innovation for over two decades, I've seen firsthand how rapidly advancing technology can outpace ethical considerations. It's crucial that innovators make ethics a priority from the very start of the design process.
My guiding principle is to always put human dignity and the greater social good above profits or convenience. Before creating any new product or platform, carefully consider how it could be misused to cause harm, erode privacy, or amplify inequality. Consult with diverse stakeholders-not just other tech experts-to identify potential pitfalls. And be ready to make difficult choices, even if it means shelving a profitable idea.
Tech leaders also have an obligation to use their platforms responsibly once launched. Be transparent about data collection and algorithmic biases. Allow for outside audits. And build systems to quickly identify and mitigate emerging issues. No technology is value-neutral-you must steward it with wisdom.
Innovation without conscience is not true progress. If we make ethics the compass that guides our work, the tech industry can be a powerful force for human flourishing.
Philip Stoelman, Founder & CEO, Network Republic
Enhance User Value Ethically
Addressing ethical concerns in tech means actively balancing innovation with respect for user trust. Our approach centers around one core value: 'If it doesn't enhance user value ethically, it doesn't belong.' This principle guides every new feature or tool we consider.
When developing new functionalities, we prioritize transparency. For instance, we make it a point to clearly explain AI-generated outputs and data usage so that users know exactly what's happening behind the scenes. This fosters trust and avoids the 'black box' effect, where users feel uncertain about how their data or content is handled.
One bit of advice I'd offer to other businesses is to build an ethical review step during development. Before launching a feature, ask: Does this serve users fairly? Is it honest and clear? It can help you steer clear of unintended consequences and ensure tech aligns with your values. This small step can go a long way in creating a tech environment that respects users while driving genuine, sustainable growth.
Josh Bluman, Co-Founder, Hoppy Copy
Keep User Well-Being at Center
Ethical navigation for us means keeping the user's well-being at the center, evaluating every new feature by asking if it genuinely helps users without causing stress or over-surveillance. This involves balancing efficiency with a respectful approach to personal data, minimizing the information collected and ensuring it's solely used to improve user experience. By treating users as partners, not data sources, we maintain a respectful, responsible approach.
I would advise businesses to 'make ethical commitments as visible as your product features,' letting users know where you stand on data and privacy. Be open about your principles and practices, as transparency fosters trust and accountability. When users see ethics as a core part of your brand, they are more likely to engage and remain loyal.
Alari Aho, CEO and Founder, Toggl Inc
Balance Innovation with Basic Rights
Ethical AI development isn't just about making new technologies; it's also about making systems that make people smarter and more capable while still respecting basic rights and values. Finding the right balance between new ideas and being responsible is hard. We need to make sure that technological progress doesn't hurt people's rights or the well-being of society.
At its core, developing AI in an ethical way needs a multilayered approach. Before any development can start, organizations must first set clear ethical rules. These rules should cover important topics like data privacy, fair algorithms, openness, and responsibility. It is important to describe success not only in technical terms but also in terms of what is right and wrong.
A structured framework should be used for the implementation process. Do a risk assessment first to find possible ethical problems before they become issues. This includes looking at how it will affect different stakeholder groups, how it might be used wrongly, and what the long-term effects will be on society. Then, put in place safety measures like systems that look for bias, regular audits of ethics, and clear ways to hold people accountable.
For businesses trying to figure out how to operate in this environment, I suggest the following rules:
Set up strong governance structures and make sure there are clear lines of responsibility for keeping an eye on ethics. This could mean setting up an ethics board, laying out how to report ethical problems, and making sure that AI systems can be reviewed by people who aren't connected to the project.
Prioritize human agency-make sure that AI systems help people make decisions, not take their place, especially when there is a lot at stake. Create systems that give users control over their data and how they interact with AI.
The most important thing I can tell businesses is that they shouldn't see ethical concerns as limits, but as chances to come up with new ideas. When organizations deal with these problems successfully, they often come up with stronger, more reliable, and long-lasting solutions. They also get closer to their users and other important people, which creates long-term value that goes beyond short-term technical wins.
Elvis Sun, Software Engineer & Founder, Press Pulse
Hold Privacy as Core Value
As the first-ever privacy-focused search engine, we understand that ethical considerations are essential for businesses that want to grow in a sustainable manner. Customers are becoming more and more aware of the privacy violations, environmental waste, and lobbying which is inherent in the sector, and are taking actions to avoid the worst offenders. We hold privacy as one of our unshakeable core values, ensuring that every decision we make aligns with this. I would advise that businesses ensure that their core values are clearly written down and reiterated to members of staff at all levels regularly. Hire based upon values matches, and never allow anything to get in the way of the better vision you have for the world!
Joshua Long, Head of Comms, Mojeek Limited
Think Ethics by Design
I have seen how rushing new tech without thinking about ethics can cause big problems. Last year, a friend's startup had to redo their AI feature because they didn't think about privacy. It cost them a lot of money, but the worst part was losing their customers' trust.
Today, being ethical isn't just a good idea; it's necessary to succeed.
What's at stake?
Think of ethics like a compass for your company. Every choice we make in tech affects real people. Whether it's about data privacy, fairness in algorithms, or the environment, these things matter to your neighbors, friends, and even to the community. The real question isn't just, 'Can we make it?' but, 'Should we make it?'
How to approach it?
I follow a simple rule: 'Ethics by Design.' This means thinking about what's right from the start, not later. Before creating anything new, ask three questions:
Who could this hurt?
How can we stop that?
What values are we sharing?
Make these questions part of your regular meetings, just like you talk about technical details.
Remember that the key isn't perfection; it's awareness and intention. Better to catch ethical issues early than apologize later.
Farrukh Muzaffar, CMO | Co-Founder | Business strategist, Sustainability Jobs
Build with Intention and Impact
Navigating ethical considerations in tech innovation requires a commitment to sustainability and responsible development practices. One guiding principle we follow is, 'Build with intention and impact,' which means assessing the environmental and societal effects of every technology we develop or use. This includes choosing environmentally friendly programming languages like Rust or Go, which are known for efficient resource usage and reduced energy consumption.
We also integrate tools that support sustainable practices, such as cloud services with carbon-neutral goals and energy-efficient infrastructure. By prioritizing tools and languages that minimize environmental impact, we not only address ethical concerns but also promote long-term efficiency.
For businesses, my advice is to embed ethics into the development lifecycle-from design to deployment. Regularly evaluate the environmental footprint, data privacy, and societal impact of your technologies. Making ethics a core part of innovation fosters trust with customers and sets a foundation for responsible growth.
Sergiy Fitsak, Managing Director, Fintech Expert, Softjourn
Prioritize User Empowerment
In the digital age, ethical tech design prioritizes user empowerment, especially when it comes to managing personal data. Many companies overlook the importance of clear communication, but making privacy settings transparent and user-friendly is crucial. Users should be informed about what data is being collected and how it's used. Often, interfaces are cluttered and confusing, leading to uninformed consent. Streamlining this process through intuitive design and clear language not only builds trust but also aligns with ethical standards.
A vital approach in this realm is implementing Privacy by Design (PbD). This method integrates privacy into the core of product development from the beginning, not as an afterthought. PbD requires companies to prioritize data protection, building user privacy directly into systems and processes. It's about giving users straightforward choices and immediate access to their data settings. Regular privacy checklists can ensure that new tech complies with these principles. This empowers users, ensuring they control their data while businesses maintain ethical transparency.
Roy Benesh, CTO and Co-Founder, eSIMple
Foster Transparency and Open Dialogue
As technological innovation accelerates, addressing ethical considerations has become paramount for businesses. One effective way to navigate these concerns is by fostering a culture of transparency and open dialogue among team members and stakeholders. Implementing ethical reviews at each stage of the development process can help identify potential risks and implications early on. A guiding principle for businesses is to prioritize user well-being and societal impact over profit maximization, ensuring that innovation serves the greater good. Ultimately, maintaining a commitment to ethical practices not only builds trust with consumers but also enhances long-term sustainability and success in the tech industry.
Chrissy Steed, CEO, Small Business Certified
Ensure Responsible and Transparent Use
Addressing ethical considerations in technological innovation demands a deliberate and focused strategy to ensure that the technologies we create are both responsible and transparent in their use.
Bringing together diverse teams helps to see the bigger picture and understand the potential impacts of your products. Regular assessments of the social, environmental, and economic implications of these innovations, both in the short and long term, are essential. Most critically, when deploying technologies like AI, prioritize transparency in decision-making processes, particularly when they directly affect end-users. These practices form a solid foundation for businesses striving to integrate ethics into innovation effectively.
Siddhyesh Narkar, Chief Technology Officer
Prioritize Transparency and Accountability
In today's tech landscape, ethical considerations are integral to innovation. We believe that sustainable and responsible growth goes hand in hand with ethics, especially as we navigate environmental and social impact.
A guiding principle we uphold is transparency-ensuring that our actions, from product development to user engagement, align with our commitments to a positive environmental footprint.
My advice to businesses is to prioritize accountability by implementing ethical standards at every stage of the innovation process. This practice not only builds trust but also strengthens the alignment between technological advancements and societal values.
Mike English, Creator and CTO, impt.io
Lead Development Under Clear Regulations
Innovation is inevitable-if ethical companies in regulated markets don't develop new technologies, someone else will. Looking at AI development, companies in China or other less restricted regions will push ahead regardless of Western ethical concerns about training data or other issues.
The key question isn't whether potentially controversial innovations should happen-they'll happen anyway. The real question is whether we want established companies operating under clear regulatory frameworks to lead development, or if we'll cede that ground to actors with fewer constraints.
Trying to completely avoid ethical gray areas means falling behind in critical technological progress. Sometimes what seems ethically questionable today becomes standard practice tomorrow. Just like fundamental scientific discoveries, many technological advances are less about invention and more about uncovering what's already possible. The choice is really about who gets there first and sets the standards for responsible deployment.
Vincent Schmalbach, Web Developer, AI Engineer & SEO Expert, Vincent Schmalbach
Make Technology Accessible to Everyone
A guiding principle that we follow is making sure technology is accessible to everyone, regardless of socioeconomic background, ability, or geography.
We design our products with inclusivity in mind by integrating features that cater to diverse needs, such as affordable pricing and accessibility tools. Ensuring that our tech is usable for people with varying abilities or resources allows us to bridge the digital divide and create more equal opportunities.
We believe that technology should uplift communities, not exclude them, so we prioritize accessibility in every phase of development. As we increase our focus on inclusivity, we meet the ethical standards of today and lay the groundwork to enhance equity in the future.
My advice? Keep inclusivity at the heart of your innovation process-this will help you create a more impactful and socially responsible product.
Rodger Desai, CEO, Prove
View Technology as Human Assistant
Technological innovation requires a balanced and thoughtful approach. When integrating new technology into business processes, a guiding principle is to view it as an assistant, not a replacement for human input. While AI-powered tools can streamline operations and reduce costs, human oversight remains essential. Conduct tests, analyze data, and monitor performance to identify inconsistencies. Ensure the innovation aligns with your processes and values to enhance, rather than disrupt, service quality and customer experience.
Michael Podolsky, Co-Founder and CEO, PissedConsumer.com
Establish Stringent Code of Ethics
Lack of ethical practices in businesses can lead to several negative consequences ranging from financial losses, damaged reputation, negative publicity, brand erosion, loss of trust, and many more. The new age Generative AI and other new age technologies need to be administered with a lot of caution and careful consideration. While Generative AI technology enhances efficiency and productivity, it also introduces several risks which if not managed and mitigated can have negative repercussions for the business.
In order to navigate and address ethical considerations, businesses must establish a stringent code of ethics and every employee must be trained on the code of ethics by providing adequate training. The business must focus on education, awareness, and reiteration of the code of ethics to ensure employees understand and practice ethical considerations. Employees must be encouraged to blow the whistle without fear of consequence to report any unethical practice. Data management-including source of data, processing, storage, and disbursal-must be clear to employees as well as customers, with permissions in place for data management. Standard operating procedures for managing security of data at rest and in transit and encryption must be available and practiced. Data privacy must be maintained.
The guiding principle for businesses is to ensure legal, security, and compliance functions are established to enforce and manage the code of ethics. Standard operating procedures must be in place for handling data privacy and security for all technology. Mandatory certifications and accreditations should be implemented and regular audits performed by external agencies to ensure the highest standards of ethical compliance are adhered to.
Swagata Ashwani, Principal Data Scientist, Boomi
Reference Handbook for Compliance
Make sure that you have a handbook, digital or otherwise, that leadership and operational teams are able to reference to ensure that you remain compliant to industry standards without compromising anything. Remember, technology should not compromise people's sensitive information and privacy. Don't get too blinded by the potential cost-savings or profit your business is going to get through technological innovations that you sacrifice your integrity and respect for ethical boundaries.
Matthew Franzyshen, Business Development Manager, Ascendant Technologies, Inc.
Address Bias in AI Algorithms
AI in educational video-making opens up a unique opportunity to revolutionize the way we learn. With AI-powered tools, educators can create more engaging, personalized, and accessible learning experiences. However, as with any technological advancement, it's crucial to address the ethical implications to ensure responsible and beneficial use.
One key ethical consideration is the potential for bias in AI algorithms. If not carefully trained and monitored, AI systems could perpetuate existing biases, leading to unfair or discriminatory outcomes. To mitigate this, developers and educators must prioritize transparency, accountability, and fairness in the development and deployment of AI tools.
Additionally, it's essential to consider the potential for AI to replace human interaction, which could negatively impact the social and emotional development of learners. Striking a balance between AI-powered tools and human connection is crucial to ensure a well-rounded learning experience.
Daria Globchak, Generative AI Expert, Elai.io
Related Articles
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (96%); TECHNOLOGY (96%); EMERGING TECHNOLOGY (90%); PRODUCT INNOVATION (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); NEGATIVE SOCIETAL NEWS (76%); REGULATORY COMPLIANCE (76%); HUMAN RIGHTS (74%); BIOMETRICS (72%); PRIVACY RIGHTS (68%); Innovation (%); Ethical Considerations (%); innovation (%); Technological Innovation (%)
Industry: ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DATA PRIVACY (77%); CYBERSECURITY (72%); PATTERN RECOGNITION (71%)
Load-Date: December 2, 2024","December 2nd, 2024 ( TechBullion  - Delivered by  Newstex )
How Do You Navigate Ethical Considerations in the Process of Technological Innovation?
As technology advances at breakneck speed, the ethical challenges it brings are more pressing than ever. In this article, C-suite leaders and cybersecurity experts share their strategies for navigating these complex issues. From the importance of proactive planning and transparency to tackling bias in AI algorithms, these 21 expert insights offer a roadmap for responsible innovation. Whether you're developing new tech or refining existing solutions, this guide will help you balance progress with integrity and accountability.
Proactively Plan and Commit to Transparency
Stay Connected to Industry Ecosystem
Embrace Constraints as Creativity Drivers
Design with Empathy
Prioritize Human Dignity and Social Good
Enhance User Value Ethically
Keep User Well-Being at Center
Balance Innovation with Basic Rights
Hold Privacy as Core Value
Think Ethics by Design
Build with Intention and Impact
Prioritize User Empowerment
Foster Transparency and Open Dialogue
Ensure Responsible and Transparent Use
Prioritize Transparency and Accountability
Lead Development Under Clear Regulations
Make Technology Accessible to Everyone
View Technology as Human Assistant
Establish Stringent Code of Ethics
Reference Handbook for Compliance
Address Bias in AI Algorithms
Proactively Plan and Commit to Transparency
Navigating ethical considerations in technological innovation requires proactive planning and a commitment to transparency. A guiding principle I follow is 'anticipate, evaluate, and act'-anticipate potential ethical challenges, evaluate their impact, and act responsibly to address them before they escalate.
During a project involving AI-driven customer profiling, we anticipated concerns about data privacy. By designing the system with privacy-first principles-like minimizing data collection, anonymizing user data, and implementing clear opt-in policies-we ensured compliance and maintained user trust. Open communication with stakeholders about how data was used also helped us navigate potential concerns.
My advice for businesses? Embed ethics into your innovation process from the start. Create an ethics review framework that evaluates risks at every stage of development, involve diverse stakeholders for balanced perspectives, and prioritize transparency with users. Ethical foresight isn't just about avoiding backlash-it builds trust, loyalty, and long-term success.
Inge von Aulock, COO, Penfriend
Stay Connected to Industry Ecosystem
In my work in emerging technologies within enterprises, ethical considerations have been a constant and critical focus, particularly with the adoption of Artificial Intelligence (AI). AI's potential for bias and unintended discrimination, such as in hiring algorithms or facial recognition systems, highlighted the importance of tackling these issues early. I often had to factor these concerns into the projects I led and I quickly realised that staying connected to the broader organisation and industry ecosystem was essential for doing this effectively.
For example, I attended AI ethics panels and workshops to understand the latest thinking on mitigating algorithmic bias. Engaging with researchers and practitioners through these events, as well as connecting with thought leaders across the enterprise and on platforms like LinkedIn, provided insights that were invaluable for key ethical risks. For instance, I learned about de-biasing techniques and tools that I shared with development teams, ensuring that our projects reflected the latest advancements in ethical AI practices. This collaboration helped me align our work with the best practices emerging from the wider ecosystem.
Connecting to the industry also highlighted the need to stay ahead of at times slow-moving regulations that can't match the pace of changing innovations. At the time, many of the rules surrounding AI ethics were still evolving, particularly with the boom of Generative AI. Through my ecosystem engagement, I saw how companies were proactively addressing issues like transparency and fairness to fill this gap. Participating in these conversations wasn't just informative, it allowed me to bring back valuable knowledge to my own work, ensuring that ethical considerations weren't an afterthought but an integral part of the process.
The biggest takeaway for me has been that no organisation can navigate these challenges alone. By connecting to the broader ecosystem through events, partnerships and discussions, we can access diverse perspectives and shared knowledge. As a guiding principle, it is essential to be proactive in understanding and managing ethical concerns when it comes to new technologies at both a company and industry level. Rather than simply reacting to delayed introductions of regulations.
Elsie Day, Cyber Security Analyst, CyPro
Embrace Constraints as Creativity Drivers
When navigating ethical considerations in technological innovation, I think what's a crucial principle I focus on is embracing constraints as a driver of creativity. Many businesses see ethical frameworks as barriers to innovation, but I've found that they can spark some of the most groundbreaking ideas.
For example, when working with startups, I've encouraged teams to treat ethical dilemmas not as limitations but as opportunities to redefine their approach. Take user data privacy, which is a common ethical concern. Instead of relying on traditional data collection methods that could border on invasive, one client built an entirely privacy-first AI platform that analyzed user data locally.
At first, the idea felt restrictive. How do you create meaningful user insights without centralized data? However, this challenge forced the team to innovate, resulting in a decentralized model that earned user trust and positioned them as leaders in a growing ethical tech movement.
The guiding principle I always emphasize is this: design your innovation process around values, not just outcomes. It may seem counterproductive, but when ethics are embedded from the start, you build products that don't just solve problems but also resonate deeply with people. This resonance is what sets ethical businesses apart in today's tech landscape.
Nicholas Robb, Design agency for startups, Design Hero
Design with Empathy
My principle is always to 'design with empathy.' For us, it's about making sure our product doesn't just work, but that it works in a way that respects users and meets their real needs. For example, when we were building our AI tool, we paid close attention to how it could potentially impact users in terms of privacy and data security. We made sure that users had clear control over their data, and we avoided features that could be intrusive or overly complicated.
The key is to think beyond functionality. Technology shouldn't just solve a problem, it should also offer solutions in a way that doesn't create new ones. For businesses, this means actively involving users in the design process, getting feedback, and constantly asking if your product is doing more for your customers than just providing a service. It also helps to have a team that can look at your tech from different angles-social, cultural, and ethical-before you launch anything. That's how you create products that people trust.
Roman Hipp, Co-founder, BetterContact
Prioritize Human Dignity and Social Good
As someone who has worked in tech innovation for over two decades, I've seen firsthand how rapidly advancing technology can outpace ethical considerations. It's crucial that innovators make ethics a priority from the very start of the design process.
My guiding principle is to always put human dignity and the greater social good above profits or convenience. Before creating any new product or platform, carefully consider how it could be misused to cause harm, erode privacy, or amplify inequality. Consult with diverse stakeholders-not just other tech experts-to identify potential pitfalls. And be ready to make difficult choices, even if it means shelving a profitable idea.
Tech leaders also have an obligation to use their platforms responsibly once launched. Be transparent about data collection and algorithmic biases. Allow for outside audits. And build systems to quickly identify and mitigate emerging issues. No technology is value-neutral-you must steward it with wisdom.
Innovation without conscience is not true progress. If we make ethics the compass that guides our work, the tech industry can be a powerful force for human flourishing.
Philip Stoelman, Founder & CEO, Network Republic
Enhance User Value Ethically
Addressing ethical concerns in tech means actively balancing innovation with respect for user trust. Our approach centers around one core value: 'If it doesn't enhance user value ethically, it doesn't belong.' This principle guides every new feature or tool we consider.
When developing new functionalities, we prioritize transparency. For instance, we make it a point to clearly explain AI-generated outputs and data usage so that users know exactly what's happening behind the scenes. This fosters trust and avoids the 'black box' effect, where users feel uncertain about how their data or content is handled.
One bit of advice I'd offer to other businesses is to build an ethical review step during development. Before launching a feature, ask: Does this serve users fairly? Is it honest and clear? It can help you steer clear of unintended consequences and ensure tech aligns with your values. This small step can go a long way in creating a tech environment that respects users while driving genuine, sustainable growth.
Josh Bluman, Co-Founder, Hoppy Copy
Keep User Well-Being at Center
Ethical navigation for us means keeping the user's well-being at the center, evaluating every new feature by asking if it genuinely helps users without causing stress or over-surveillance. This involves balancing efficiency with a respectful approach to personal data, minimizing the information collected and ensuring it's solely used to improve user experience. By treating users as partners, not data sources, we maintain a respectful, responsible approach.
I would advise businesses to 'make ethical commitments as visible as your product features,' letting users know where you stand on data and privacy. Be open about your principles and practices, as transparency fosters trust and accountability. When users see ethics as a core part of your brand, they are more likely to engage and remain loyal.
Alari Aho, CEO and Founder, Toggl Inc
Balance Innovation with Basic Rights
Ethical AI development isn't just about making new technologies; it's also about making systems that make people smarter and more capable while still respecting basic rights and values. Finding the right balance between new ideas and being responsible is hard. We need to make sure that technological progress doesn't hurt people's rights or the well-being of society.
At its core, developing AI in an ethical way needs a multilayered approach. Before any development can start, organizations must first set clear ethical rules. These rules should cover important topics like data privacy, fair algorithms, openness, and responsibility. It is important to describe success not only in technical terms but also in terms of what is right and wrong.
A structured framework should be used for the implementation process. Do a risk assessment first to find possible ethical problems before they become issues. This includes looking at how it will affect different stakeholder groups, how it might be used wrongly, and what the long-term effects will be on society. Then, put in place safety measures like systems that look for bias, regular audits of ethics, and clear ways to hold people accountable.
For businesses trying to figure out how to operate in this environment, I suggest the following rules:
Set up strong governance structures and make sure there are clear lines of responsibility for keeping an eye on ethics. This could mean setting up an ethics board, laying out how to report ethical problems, and making sure that AI systems can be reviewed by people who aren't connected to the project.
Prioritize human agency-make sure that AI systems help people make decisions, not take their place, especially when there is a lot at stake. Create systems that give users control over their data and how they interact with AI.
The most important thing I can tell businesses is that they shouldn't see ethical concerns as limits, but as chances to come up with new ideas. When organizations deal with these problems successfully, they often come up with stronger, more reliable, and long-lasting solutions. They also get closer to their users and other important people, which creates long-term value that goes beyond short-term technical wins.
Elvis Sun, Software Engineer & Founder, Press Pulse
Hold Privacy as Core Value
As the first-ever privacy-focused search engine, we understand that ethical considerations are essential for businesses that want to grow in a sustainable manner. Customers are becoming more and more aware of the privacy violations, environmental waste, and lobbying which is inherent in the sector, and are taking actions to avoid the worst offenders. We hold privacy as one of our unshakeable core values, ensuring that every decision we make aligns with this. I would advise that businesses ensure that their core values are clearly written down and reiterated to members of staff at all levels regularly. Hire based upon values matches, and never allow anything to get in the way of the better vision you have for the world!
Joshua Long, Head of Comms, Mojeek Limited
Think Ethics by Design
I have seen how rushing new tech without thinking about ethics can cause big problems. Last year, a friend's startup had to redo their AI feature because they didn't think about privacy. It cost them a lot of money, but the worst part was losing their customers' trust.
Today, being ethical isn't just a good idea; it's necessary to succeed.
What's at stake?
Think of ethics like a compass for your company. Every choice we make in tech affects real people. Whether it's about data privacy, fairness in algorithms, or the environment, these things matter to your neighbors, friends, and even to the community. The real question isn't just, 'Can we make it?' but, 'Should we make it?'
How to approach it?
I follow a simple rule: 'Ethics by Design.' This means thinking about what's right from the start, not later. Before creating anything new, ask three questions:
Who could this hurt?
How can we stop that?
What values are we sharing?
Make these questions part of your regular meetings, just like you talk about technical details.
Remember that the key isn't perfection; it's awareness and intention. Better to catch ethical issues early than apologize later.
Farrukh Muzaffar, CMO | Co-Founder | Business strategist, Sustainability Jobs
Build with Intention and Impact
Navigating ethical considerations in tech innovation requires a commitment to sustainability and responsible development practices. One guiding principle we follow is, 'Build with intention and impact,' which means assessing the environmental and societal effects of every technology we develop or use. This includes choosing environmentally friendly programming languages like Rust or Go, which are known for efficient resource usage and reduced energy consumption.
We also integrate tools that support sustainable practices, such as cloud services with carbon-neutral goals and energy-efficient infrastructure. By prioritizing tools and languages that minimize environmental impact, we not only address ethical concerns but also promote long-term efficiency.
For businesses, my advice is to embed ethics into the development lifecycle-from design to deployment. Regularly evaluate the environmental footprint, data privacy, and societal impact of your technologies. Making ethics a core part of innovation fosters trust with customers and sets a foundation for responsible growth.
Sergiy Fitsak, Managing Director, Fintech Expert, Softjourn
Prioritize User Empowerment
In the digital age, ethical tech design prioritizes user empowerment, especially when it comes to managing personal data. Many companies overlook the importance of clear communication, but making privacy settings transparent and user-friendly is crucial. Users should be informed about what data is being collected and how it's used. Often, interfaces are cluttered and confusing, leading to uninformed consent. Streamlining this process through intuitive design and clear language not only builds trust but also aligns with ethical standards.
A vital approach in this realm is implementing Privacy by Design (PbD). This method integrates privacy into the core of product development from the beginning, not as an afterthought. PbD requires companies to prioritize data protection, building user privacy directly into systems and processes. It's about giving users straightforward choices and immediate access to their data settings. Regular privacy checklists can ensure that new tech complies with these principles. This empowers users, ensuring they control their data while businesses maintain ethical transparency.
Roy Benesh, CTO and Co-Founder, eSIMple
Foster Transparency and Open Dialogue
As technological innovation accelerates, addressing ethical considerations has become paramount for businesses. One effective way to navigate these concerns is by fostering a culture of transparency and open dialogue among team members and stakeholders. Implementing ethical reviews at each stage of the development process can help identify potential risks and implications early on. A guiding principle for businesses is to prioritize user well-being and societal impact over profit maximization, ensuring that innovation serves the greater good. Ultimately, maintaining a commitment to ethical practices not only builds trust with consumers but also enhances long-term sustainability and success in the tech industry.
Chrissy Steed, CEO, Small Business Certified
Ensure Responsible and Transparent Use
Addressing ethical considerations in technological innovation demands a deliberate and focused strategy to ensure that the technologies we create are both responsible and transparent in their use.
Bringing together diverse teams helps to see the bigger picture and understand the potential impacts of your products. Regular assessments of the social, environmental, and economic implications of these innovations, both in the short and long term, are essential. Most critically, when deploying technologies like AI, prioritize transparency in decision-making processes, particularly when they directly affect end-users. These practices form a solid foundation for businesses striving to integrate ethics into innovation effectively.
Siddhyesh Narkar, Chief Technology Officer
Prioritize Transparency and Accountability
In today's tech landscape, ethical considerations are integral to innovation. We believe that sustainable and responsible growth goes hand in hand with ethics, especially as we navigate environmental and social impact.
A guiding principle we uphold is transparency-ensuring that our actions, from product development to user engagement, align with our commitments to a positive environmental footprint.
My advice to businesses is to prioritize accountability by implementing ethical standards at every stage of the innovation process. This practice not only builds trust but also strengthens the alignment between technological advancements and societal values.
Mike English, Creator and CTO, impt.io
Lead Development Under Clear Regulations
Innovation is inevitable-if ethical companies in regulated markets don't develop new technologies, someone else will. Looking at AI development, companies in China or other less restricted regions will push ahead regardless of Western ethical concerns about training data or other issues.
The key question isn't whether potentially controversial innovations should happen-they'll happen anyway. The real question is whether we want established companies operating under clear regulatory frameworks to lead development, or if we'll cede that ground to actors with fewer constraints.
Trying to completely avoid ethical gray areas means falling behind in critical technological progress. Sometimes what seems ethically questionable today becomes standard practice tomorrow. Just like fundamental scientific discoveries, many technological advances are less about invention and more about uncovering what's already possible. The choice is really about who gets there first and sets the standards for responsible deployment.
Vincent Schmalbach, Web Developer, AI Engineer & SEO Expert, Vincent Schmalbach
Make Technology Accessible to Everyone
A guiding principle that we follow is making sure technology is accessible to everyone, regardless of socioeconomic background, ability, or geography.
We design our products with inclusivity in mind by integrating features that cater to diverse needs, such as affordable pricing and accessibility tools. Ensuring that our tech is usable for people with varying abilities or resources allows us to bridge the digital divide and create more equal opportunities.
We believe that technology should uplift communities, not exclude them, so we prioritize accessibility in every phase of development. As we increase our focus on inclusivity, we meet the ethical standards of today and lay the groundwork to enhance equity in the future.
My advice? Keep inclusivity at the heart of your innovation process-this will help you create a more impactful and socially responsible product.
Rodger Desai, CEO, Prove
View Technology as Human Assistant
Technological innovation requires a balanced and thoughtful approach. When integrating new technology into business processes, a guiding principle is to view it as an assistant, not a replacement for human input. While AI-powered tools can streamline operations and reduce costs, human oversight remains essential. Conduct tests, analyze data, and monitor performance to identify inconsistencies. Ensure the innovation aligns with your processes and values to enhance, rather than disrupt, service quality and customer experience.
Michael Podolsky, Co-Founder and CEO, PissedConsumer.com
Establish Stringent Code of Ethics
Lack of ethical practices in businesses can lead to several negative consequences ranging from financial losses, damaged reputation, negative publicity, brand erosion, loss of trust, and many more. The new age Generative AI and other new age technologies need to be administered with a lot of caution and careful consideration. While Generative AI technology enhances efficiency and productivity, it also introduces several risks which if not managed and mitigated can have negative repercussions for the business.
In order to navigate and address ethical considerations, businesses must establish a stringent code of ethics and every employee must be trained on the code of ethics by providing adequate training. The business must focus on education, awareness, and reiteration of the code of ethics to ensure employees understand and practice ethical considerations. Employees must be encouraged to blow the whistle without fear of consequence to report any unethical practice. Data management-including source of data, processing, storage, and disbursal-must be clear to employees as well as customers, with permissions in place for data management. Standard operating procedures for managing security of data at rest and in transit and encryption must be available and practiced. Data privacy must be maintained.
The guiding principle for businesses is to ensure legal, security, and compliance functions are established to enforce and manage the code of ethics. Standard operating procedures must be in place for handling data privacy and security for all technology. Mandatory certifications and accreditations should be implemented and regular audits performed by external agencies to ensure the highest standards of ethical compliance are adhered to.
Swagata Ashwani, Principal Data Scientist, Boomi
Reference Handbook for Compliance
Make sure that you have a handbook, digital or otherwise, that leadership and operational teams are able to reference to ensure that you remain compliant to industry standards without compromising anything. Remember, technology should not compromise people's sensitive information and privacy. Don't get too blinded by the potential cost-savings or profit your business is going to get through technological innovations that you sacrifice your integrity and respect for ethical boundaries.
Matthew Franzyshen, Business Development Manager, Ascendant Technologies, Inc.
Address Bias in AI Algorithms
AI in educational video-making opens up a unique opportunity to revolutionize the way we learn. With AI-powered tools, educators can create more engaging, personalized, and accessible learning experiences. However, as with any technological advancement, it's crucial to address the ethical implications to ensure responsible and beneficial use.
One key ethical consideration is the potential for bias in AI algorithms. If not carefully trained and monitored, AI systems could perpetuate existing biases, leading to unfair or discriminatory outcomes. To mitigate this, developers and educators must prioritize transparency, accountability, and fairness in the development and deployment of AI tools.
Additionally, it's essential to consider the potential for AI to replace human interaction, which could negatively impact the social and emotional development of learners. Striking a balance between AI-powered tools and human connection is crucial to ensure a well-rounded learning experience.
Daria Globchak, Generative AI Expert, Elai.io
Related Articles
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (96%); TECHNOLOGY (96%); EMERGING TECHNOLOGY (90%); PRODUCT INNOVATION (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); NEGATIVE SOCIETAL NEWS (76%); REGULATORY COMPLIANCE (76%); HUMAN RIGHTS (74%); BIOMETRICS (72%); PRIVACY RIGHTS (68%); Innovation (%); Ethical Considerations (%); innovation (%); Technological Innovation (%)
Industry: ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DATA PRIVACY (77%); CYBERSECURITY (72%); PATTERN RECOGNITION (71%)
Load-Date: December 2, 2024",neutral,0.8122846484184265,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'safety', 'security', 'human rights', 'agency', 'consent', 'digital divide', 'inclusivity', 'access', 'inequality', 'environmental impact']","['fairness', 'equity', 'dignity']","['governance', 'oversight', 'standards', 'framework', 'compliance', 'should', 'must', 'need to', 'suggest']","['generative ai', 'facial recognition']",17,3,9,2
2024,Unknown Title,"Body
2024 DEC 19 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from Melbourne, Australia, by NewsRx correspondents, research stated, ""Artificial intelligence (AI) ethics has emerged as a global discourse within both academic and policy spheres. However, translating these principles into concrete, real-world applications for AI development remains a pressing need and a significant challenge."" 
 Funders for this research include Open Fund of Key Research Base of Philosophy And Social Science of Higher Education in Guangdong Province. 
 The news journalists obtained a quote from the research from Monash University: ""This study aims to bridge the gap between principles and practice from a regulatory government perspective and promote best practices in AI governance. To this end, we developed the Ethical Regulatory Framework for AI (ERF-AI) to guide regulatory bodies in constructing mechanisms, including role setups, procedural configurations, and strategy design. The framework was developed through a systematic review, thematic analysis, and the integration of interdisciplinary concepts. A comprehensive search was conducted across four electronic databases (PubMed, IEEE Xplore, Web of Science, and Scopus) and four additional sources containing AI standards and guidelines from various countries and international organizations, focusing on studies published from 2014 to 2024. Thematic analysis identified and refined key themes from the included literature and integrated concepts from process control theory, computer science, organizational management, information technology, and behavioral psychology. This study adhered to the PRISMA guidelines and employed NVivo for thematic analysis. The resulting framework encompasses 23 themes, particularly emphasizing three feedback-loop processes: the ethical review process, the incentive and penalty process, and the mechanism improvement process, offering theoretical guidance for the construction of ethical regulatory mechanisms."" 
 According to the news reporters, the research concluded: ""Based on this framework, a seven-step process and case examples for mechanism design are presented, enhancing the practicality of ERF-AI in developing ethical regulatory mechanisms. Future research is expected to explore customization of the framework to remain responsive to emerging AI trends and challenges, supported by empirical studies and rigorous testing for further refinement and expansion."" 
 For more information on this research see: Developing an Ethical Regulatory Framework for Artificial Intelligence: Integrating Systematic Review, Thematic Analysis, and Multidisciplinary Theories. IEEE Access, 2024,12():179383-179395. (IEEE Access - http://ieeexplore.ieee.org/servlet/opac?punumber=6287639). The publisher for IEEE Access is IEEE. 
 A free version of this journal article is available at https://doi.org/10.1109/ACCESS.2024.3501332. 
 Our news editors report that additional information may be obtained by contacting Jian Wang, School of Public Health and Preventive Medicine, Monash University, Melbourne, VIC, Australia. Additional authors for this research include Yujia Huo, Jinli Mahe, Zongyuan Ge, Zhangdaihong Liu, Wenxin Wang, Lin Zhang. 
 Keywords for this news article include: Monash University, Melbourne, Australia, Australia and New Zealand, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); COLLEGES & UNIVERSITIES (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); JOURNALISM (89%); COMPUTER SCIENCE (79%); TECHNOLOGY (79%); BEHAVIOR & COGNITION (78%); PSYCHOLOGY (78%); RESEARCH REPORTS (78%); SOCIAL SCIENCES (78%); WRITERS (78%); HUMANITIES & SOCIAL SCIENCE (77%); TRENDS (77%); BEST PRACTICES (76%); GOVERNMENT & PUBLIC ADMINISTRATION (76%); ASSOCIATIONS & ORGANIZATIONS (70%); MEDICINE & HEALTH (69%); PUBLIC HEALTH (68%); LIBRARY TECHNOLOGY (66%); PREVENTION & WELLNESS (60%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); PSYCHOLOGY (78%); PUBLISHING (78%); WRITERS (78%); LIBRARY TECHNOLOGY (66%)
Geographic: MELBOURNE, AUSTRALIA (88%); VICTORIA, AUSTRALIA (90%); GUANGDONG, CHINA (76%); SOUTH CHINA (57%); AUSTRALIA (92%); CHINA (77%)
Load-Date: December 19, 2024","2024 DEC 19 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from Melbourne, Australia, by NewsRx correspondents, research stated, ""Artificial intelligence (AI) ethics has emerged as a global discourse within both academic and policy spheres. However, translating these principles into concrete, real-world applications for AI development remains a pressing need and a significant challenge."" 
 Funders for this research include Open Fund of Key Research Base of Philosophy And Social Science of Higher Education in Guangdong Province. 
 The news journalists obtained a quote from the research from Monash University: ""This study aims to bridge the gap between principles and practice from a regulatory government perspective and promote best practices in AI governance. To this end, we developed the Ethical Regulatory Framework for AI (ERF-AI) to guide regulatory bodies in constructing mechanisms, including role setups, procedural configurations, and strategy design. The framework was developed through a systematic review, thematic analysis, and the integration of interdisciplinary concepts. A comprehensive search was conducted across four electronic databases (PubMed, IEEE Xplore, Web of Science, and Scopus) and four additional sources containing AI standards and guidelines from various countries and international organizations, focusing on studies published from 2014 to 2024. Thematic analysis identified and refined key themes from the included literature and integrated concepts from process control theory, computer science, organizational management, information technology, and behavioral psychology. This study adhered to the PRISMA guidelines and employed NVivo for thematic analysis. The resulting framework encompasses 23 themes, particularly emphasizing three feedback-loop processes: the ethical review process, the incentive and penalty process, and the mechanism improvement process, offering theoretical guidance for the construction of ethical regulatory mechanisms."" 
 According to the news reporters, the research concluded: ""Based on this framework, a seven-step process and case examples for mechanism design are presented, enhancing the practicality of ERF-AI in developing ethical regulatory mechanisms. Future research is expected to explore customization of the framework to remain responsive to emerging AI trends and challenges, supported by empirical studies and rigorous testing for further refinement and expansion."" 
 For more information on this research see: Developing an Ethical Regulatory Framework for Artificial Intelligence: Integrating Systematic Review, Thematic Analysis, and Multidisciplinary Theories. IEEE Access, 2024,12():179383-179395. (IEEE Access - http://ieeexplore.ieee.org/servlet/opac?punumber=6287639). The publisher for IEEE Access is IEEE. 
 A free version of this journal article is available at https://doi.org/10.1109/ACCESS.2024.3501332. 
 Our news editors report that additional information may be obtained by contacting Jian Wang, School of Public Health and Preventive Medicine, Monash University, Melbourne, VIC, Australia. Additional authors for this research include Yujia Huo, Jinli Mahe, Zongyuan Ge, Zhangdaihong Liu, Wenxin Wang, Lin Zhang. 
 Keywords for this news article include: Monash University, Melbourne, Australia, Australia and New Zealand, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); COLLEGES & UNIVERSITIES (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); JOURNALISM (89%); COMPUTER SCIENCE (79%); TECHNOLOGY (79%); BEHAVIOR & COGNITION (78%); PSYCHOLOGY (78%); RESEARCH REPORTS (78%); SOCIAL SCIENCES (78%); WRITERS (78%); HUMANITIES & SOCIAL SCIENCE (77%); TRENDS (77%); BEST PRACTICES (76%); GOVERNMENT & PUBLIC ADMINISTRATION (76%); ASSOCIATIONS & ORGANIZATIONS (70%); MEDICINE & HEALTH (69%); PUBLIC HEALTH (68%); LIBRARY TECHNOLOGY (66%); PREVENTION & WELLNESS (60%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); PSYCHOLOGY (78%); PUBLISHING (78%); WRITERS (78%); LIBRARY TECHNOLOGY (66%)
Geographic: MELBOURNE, AUSTRALIA (88%); VICTORIA, AUSTRALIA (90%); GUANGDONG, CHINA (76%); SOUTH CHINA (57%); AUSTRALIA (92%); CHINA (77%)
Load-Date: December 19, 2024",neutral,0.8982754349708557,balanced/neutral,['access'],[],"['regulation', 'policy', 'governance', 'standards', 'guidelines', 'framework']","['machine learning', 'robotics']",1,0,6,2
2024,Unknown Title,"Body
2024 DEC 17 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx Policy and Law Daily -- Researchers detail new data in agriculture. According to news reporting out of Sfax, Tunisia, by NewsRx editors, research stated, ""This paper explores the relationship between tax amnesty programs and Corporate Social Responsibility (CSR), focusing on the ethical challenges businesses face as they navigate financial decisions and societal obligations."" 
 The news editors obtained a quote from the research from University of Sfax: ""While tax amnesty offers financial relief, it raises significant concerns about ethical behavior and transparency. The evolution of CSR into a strategic priority necessitates a careful balance between financial goals and broader societal contributions. Emerging technologies, such as artficial intelligence (AI), blockchain, and data analytics, are transforming tax compliance and CSR practices by enhancing transparency and accountability, but they also introduce new ethical dilemmas. This study integrates theoretical frameworks with practical insights, highlighting the need for businesses to align tax amnesty participation with CSR objectives. Key themes include the role of emerging technologies, ethical decision-making, and the alignment of financial incentives with societal values."" 
 According to the news editors, the research concluded: ""By examining these dynamics, the research contributes valuable insights into how businesses can effectively manage the intersection of tax amnesty and CSR, promoting ethical practices and societal well-being."" 
 For more information on this research see: Integrating tax amnesty, CSR, and emerging technologies: Exploring ethical challenges and strategic choices. Journal of Economic Criminology, 2024,6():100107. The publisher for Journal of Economic Criminology is Elsevier. 
 A free version of this journal article is available at https://doi.org/10.1016/j.jeconc.2024.100107. 
 Our news journalists report that additional information may be obtained by contacting Ines Bouaziz Daoud, Faculty of Economics and Management of Sfax, University of Sfax, Sfax 3072, Tunisia. 
 Keywords for this news article include: University of Sfax, Sfax, Tunisia, Africa, Legal Issues, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); AMNESTY (92%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); EMERGING TECHNOLOGY (90%); JOURNALISM (90%); LAW & LEGAL SYSTEM (90%); TECHNOLOGY (90%); DATA ANALYTICS (78%); ECONOMICS (78%); FINANCIAL TECHNOLOGY (78%); NEWS REPORTING (78%); TAX LAW (78%); BUSINESS ANALYTICS (77%); COLLEGES & UNIVERSITIES (77%); DATA SCIENCE (77%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (76%); COMPANY STRATEGY (76%); CORPORATE SOCIAL RESPONSIBILITY (76%); ECONOMY & ECONOMIC INDICATORS (76%); ESG FACTORS - SOCIAL (76%); ARTIFICIAL INTELLIGENCE (74%); BLOCKCHAIN (73%); EXPERIMENTATION & RESEARCH (73%); WRITERS (73%); Legal Issues;Technology (%)
Industry: DATA ANALYTICS (78%); FINANCIAL TECHNOLOGY (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); NEWS REPORTING (78%); BUSINESS ANALYTICS (77%); COLLEGES & UNIVERSITIES (77%); DATA SCIENCE (77%); ARTIFICIAL INTELLIGENCE (74%); BLOCKCHAIN (73%); WRITERS (73%)
Geographic: TUNISIA (93%); AFRICA (79%)
Load-Date: December 17, 2024","2024 DEC 17 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx Policy and Law Daily -- Researchers detail new data in agriculture. According to news reporting out of Sfax, Tunisia, by NewsRx editors, research stated, ""This paper explores the relationship between tax amnesty programs and Corporate Social Responsibility (CSR), focusing on the ethical challenges businesses face as they navigate financial decisions and societal obligations."" 
 The news editors obtained a quote from the research from University of Sfax: ""While tax amnesty offers financial relief, it raises significant concerns about ethical behavior and transparency. The evolution of CSR into a strategic priority necessitates a careful balance between financial goals and broader societal contributions. Emerging technologies, such as artficial intelligence (AI), blockchain, and data analytics, are transforming tax compliance and CSR practices by enhancing transparency and accountability, but they also introduce new ethical dilemmas. This study integrates theoretical frameworks with practical insights, highlighting the need for businesses to align tax amnesty participation with CSR objectives. Key themes include the role of emerging technologies, ethical decision-making, and the alignment of financial incentives with societal values."" 
 According to the news editors, the research concluded: ""By examining these dynamics, the research contributes valuable insights into how businesses can effectively manage the intersection of tax amnesty and CSR, promoting ethical practices and societal well-being."" 
 For more information on this research see: Integrating tax amnesty, CSR, and emerging technologies: Exploring ethical challenges and strategic choices. Journal of Economic Criminology, 2024,6():100107. The publisher for Journal of Economic Criminology is Elsevier. 
 A free version of this journal article is available at https://doi.org/10.1016/j.jeconc.2024.100107. 
 Our news journalists report that additional information may be obtained by contacting Ines Bouaziz Daoud, Faculty of Economics and Management of Sfax, University of Sfax, Sfax 3072, Tunisia. 
 Keywords for this news article include: University of Sfax, Sfax, Tunisia, Africa, Legal Issues, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); AMNESTY (92%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); EMERGING TECHNOLOGY (90%); JOURNALISM (90%); LAW & LEGAL SYSTEM (90%); TECHNOLOGY (90%); DATA ANALYTICS (78%); ECONOMICS (78%); FINANCIAL TECHNOLOGY (78%); NEWS REPORTING (78%); TAX LAW (78%); BUSINESS ANALYTICS (77%); COLLEGES & UNIVERSITIES (77%); DATA SCIENCE (77%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (76%); COMPANY STRATEGY (76%); CORPORATE SOCIAL RESPONSIBILITY (76%); ECONOMY & ECONOMIC INDICATORS (76%); ESG FACTORS - SOCIAL (76%); ARTIFICIAL INTELLIGENCE (74%); BLOCKCHAIN (73%); EXPERIMENTATION & RESEARCH (73%); WRITERS (73%); Legal Issues;Technology (%)
Industry: DATA ANALYTICS (78%); FINANCIAL TECHNOLOGY (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); NEWS REPORTING (78%); BUSINESS ANALYTICS (77%); COLLEGES & UNIVERSITIES (77%); DATA SCIENCE (77%); ARTIFICIAL INTELLIGENCE (74%); BLOCKCHAIN (73%); WRITERS (73%)
Geographic: TUNISIA (93%); AFRICA (79%)
Load-Date: December 17, 2024",neutral,0.9271901249885559,balanced/neutral,"['transparency', 'accountability']",[],"['policy', 'law', 'compliance']",[],2,0,3,0
2024,Unknown Title,"Byline: Targeted News Service
Dateline: CAMBRIDGE, England 
Body
Cambridge Quarterly of Healthcare Ethics, a journal that says it features biology, medicine and healthcare, published research articles on the following topics in its July 2024 edition (Vol. 33, Issue 3):
* Ethics Education in Health Sciences Should Engage Contentious Social Issues: Here Is Why and How
* Hammer or Measuring Tape? Artificial Intelligence and Justice in Healthcare
* Hard Choices: How Does Injustice Affect the Ethics of Medical Aid in Dying?
* Healthy Mistrust: Medical Black Box Algorithms, Epistemic Authority, and Preemptionism
* Learning to Live with Strange Error: Beyond Trustworthiness in Artificial Intelligence Ethics
* Leveraging a Sturdy Norm: How Ethicists Really Argue
* Machine Ethics in Care: Could a Moral Avatar Enhance the Autonomy of Care-Dependent Persons?
* Misplaced Trust and Distrust: How Not to Engage with Medical Artificial Intelligence
* Naming and Describing Disability in Law and Medicine
* Reflection Machines: Supporting Effective Human Oversight Over Medical Decision Support Systems
* The Virtues of Interpretable Medical AI
* Xenotransplantation Clinical Trials and Equitable Patient Selection
The July 2024 edition of the Cambridge Quarterly of Healthcare Ethics Journal can be viewed at https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/issue/DE5B38C6BC70CCDBE7C87E312953080A. The Journal is published by Cambridge University Press.
[Category: Health Care]
MSTRUCK-8861062 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MEDICINE & HEALTH (90%); RESEARCH REPORTS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BIOETHICS (78%); CLINICAL DECISION SUPPORT (78%); MEDICAL ETHICS (78%); MEDICAL SCIENCE (78%); SOCIETAL ISSUES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMAN IN THE LOOP (76%); DECISION SUPPORT SYSTEMS (53%)
Company:  DECISION SUPPORT SYSTEMS INC (53%)
Industry: SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CLINICAL DECISION SUPPORT (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); DECISION SUPPORT SYSTEMS (53%)
Geographic: CAMBRIDGE, ENGLAND (91%); ENGLAND (59%)
Load-Date: October 6, 2024","Cambridge Quarterly of Healthcare Ethics, a journal that says it features biology, medicine and healthcare, published research articles on the following topics in its July 2024 edition (Vol. 33, Issue 3):
* Ethics Education in Health Sciences Should Engage Contentious Social Issues: Here Is Why and How
* Hammer or Measuring Tape? Artificial Intelligence and Justice in Healthcare
* Hard Choices: How Does Injustice Affect the Ethics of Medical Aid in Dying?
* Healthy Mistrust: Medical Black Box Algorithms, Epistemic Authority, and Preemptionism
* Learning to Live with Strange Error: Beyond Trustworthiness in Artificial Intelligence Ethics
* Leveraging a Sturdy Norm: How Ethicists Really Argue
* Machine Ethics in Care: Could a Moral Avatar Enhance the Autonomy of Care-Dependent Persons?
* Misplaced Trust and Distrust: How Not to Engage with Medical Artificial Intelligence
* Naming and Describing Disability in Law and Medicine
* Reflection Machines: Supporting Effective Human Oversight Over Medical Decision Support Systems
* The Virtues of Interpretable Medical AI
* Xenotransplantation Clinical Trials and Equitable Patient Selection
The July 2024 edition of the Cambridge Quarterly of Healthcare Ethics Journal can be viewed at https://www.cambridge.org/core/journals/cambridge-quarterly-of-healthcare-ethics/issue/DE5B38C6BC70CCDBE7C87E312953080A. The Journal is published by Cambridge University Press.
[Category: Health Care]
MSTRUCK-8861062 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MEDICINE & HEALTH (90%); RESEARCH REPORTS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BIOETHICS (78%); CLINICAL DECISION SUPPORT (78%); MEDICAL ETHICS (78%); MEDICAL SCIENCE (78%); SOCIETAL ISSUES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMAN IN THE LOOP (76%); DECISION SUPPORT SYSTEMS (53%)
Company:  DECISION SUPPORT SYSTEMS INC (53%)
Industry: SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CLINICAL DECISION SUPPORT (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); DECISION SUPPORT SYSTEMS (53%)
Geographic: CAMBRIDGE, ENGLAND (91%); ENGLAND (59%)
Load-Date: October 6, 2024",neutral,0.927163302898407,balanced/neutral,['autonomy'],"['virtues', 'justice', 'autonomy', 'justice']","['oversight', 'law', 'should']",[],1,4,3,0
2024,Unknown Title,"Dateline: LONDON, Nov. 19, 2024 
Body
PR NewswireIn the news release, Vault Unvails EthicsChat: AI-Driven Ethical Guidance for Modern Workplaces, issued 19-Nov-2024 by Vault Platform over PR Newswire, we are advised by the company that the headline should read ""Vault Unveils EthicsChat: AI-Driven Ethical Guidance for Modern Workplaces"" rather than as originally issued inadvertently. The complete, corrected release follows:Vault Unveils EthicsChat: AI-Driven Ethical Guidance for Modern WorkplacesLONDON, Nov. 19, 2024 /PRNewswire/ --Vault Platform, a leader in AI-driven ethics and compliance solutions and category leader in Active Integrity, proudly introducesEthicsChat, an innovative new product designed to make Ethics accessible to employees, streamline compliance queries, and enhance workplace integrity. 
EthicsChat can even be used inside Vault's apps for Slack and Microsoft Teams, offering real-time, AI-powered guidance on ethics, reporting, and resolution, right where work happens.Vault is developing EthicsChat to empower employees and managers to navigate complex ethical issues confidently, offering consistent, accessible answers to questions on workplace ethics based on the company's policies and Code of Conduct.Vault's EthicsChat includes expanding its ability to guide employees in understanding complex ethical situations, such as identifying potential Conflicts of Interest or determining whether certain behaviors and events should be reported under company policies.""EthicsChat is designed to transform an organization's code of conduct into a dynamic, real-time resource, which can be used wherever work happens, in the office or on-the-go"" says Neta Meidav, Vault CEO & Co-Founder. ""It enables employees to act with integrity in every situation and equips leadership with the information they need to identify trends and proactively manage risks.""EthicsChat is part of Vault's broader Active Integrity product suite including various mobile and AI-powered misconduct reporting channels and the Resolution Hub, collectively supporting both ethical reporting and case resolution workflow. Vault's suite of AI-driven tools positions the company at the forefront of innovation in the compliance tech space, offering scalable, flexible solutions to meet growing demands for transparency and accountability in the workplace.As Vault continues to lead in AI innovation for ethics and compliance, EthicsChat represents a significant step forward in enabling companies to meet compliance challenges while building a culture of integrity.For more information on EthicsChat and Vault's full suite of compliance tools, visitvautlplatform.comAbout Vault PlatformVault Platform is the Active Integrity platform, modernizing Speak Up programs with digital, AI-enabled tools to consolidate Speak Up, investigations, and data reporting, providing organizations with the tools they need to reduce risk, and create a culture of Active Integrity.  View original content:https://www.prnewswire.co.uk/news-releases/vault-unvails-ethicschat-ai-driven-ethical-guidance-for-modern-workplaces-302310088.html 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (99%); PRESS RELEASES (92%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); MANAGERS & SUPERVISORS (78%); MISCONDUCT (78%); NEW PRODUCTS (78%); PRODUCT INNOVATION (78%); EXECUTIVES (75%); INVESTIGATIONS (75%); REGULATORY COMPLIANCE (75%); CONFLICTS OF INTEREST (73%); TRENDS (71%); NEGATIVE MISC NEWS (70%); NEGATIVE NEWS (70%); RISK MANAGEMENT (67%); Vault-Platform (%); PDT New Products and Services (%)
Company:  MICROSOFT CORP (56%); Vault Platform
Ticker: MSFT (NASDAQ) (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE (89%); NEW PRODUCTS (78%); RISK MANAGEMENT (67%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Geographic: LONDON, ENGLAND (59%); CALIFORNIA, USA (73%); EUROPE (73%); ENGLAND (59%); UNITED KINGDOM (59%); England; United Kingdom; California; New York; Wisconsin; Texas; Israel
Load-Date: November 19, 2024","PR NewswireIn the news release, Vault Unvails EthicsChat: AI-Driven Ethical Guidance for Modern Workplaces, issued 19-Nov-2024 by Vault Platform over PR Newswire, we are advised by the company that the headline should read ""Vault Unveils EthicsChat: AI-Driven Ethical Guidance for Modern Workplaces"" rather than as originally issued inadvertently. The complete, corrected release follows:Vault Unveils EthicsChat: AI-Driven Ethical Guidance for Modern WorkplacesLONDON, Nov. 19, 2024 /PRNewswire/ --Vault Platform, a leader in AI-driven ethics and compliance solutions and category leader in Active Integrity, proudly introducesEthicsChat, an innovative new product designed to make Ethics accessible to employees, streamline compliance queries, and enhance workplace integrity. 
EthicsChat can even be used inside Vault's apps for Slack and Microsoft Teams, offering real-time, AI-powered guidance on ethics, reporting, and resolution, right where work happens.Vault is developing EthicsChat to empower employees and managers to navigate complex ethical issues confidently, offering consistent, accessible answers to questions on workplace ethics based on the company's policies and Code of Conduct.Vault's EthicsChat includes expanding its ability to guide employees in understanding complex ethical situations, such as identifying potential Conflicts of Interest or determining whether certain behaviors and events should be reported under company policies.""EthicsChat is designed to transform an organization's code of conduct into a dynamic, real-time resource, which can be used wherever work happens, in the office or on-the-go"" says Neta Meidav, Vault CEO & Co-Founder. ""It enables employees to act with integrity in every situation and equips leadership with the information they need to identify trends and proactively manage risks.""EthicsChat is part of Vault's broader Active Integrity product suite including various mobile and AI-powered misconduct reporting channels and the Resolution Hub, collectively supporting both ethical reporting and case resolution workflow. Vault's suite of AI-driven tools positions the company at the forefront of innovation in the compliance tech space, offering scalable, flexible solutions to meet growing demands for transparency and accountability in the workplace.As Vault continues to lead in AI innovation for ethics and compliance, EthicsChat represents a significant step forward in enabling companies to meet compliance challenges while building a culture of integrity.For more information on EthicsChat and Vault's full suite of compliance tools, visitvautlplatform.comAbout Vault PlatformVault Platform is the Active Integrity platform, modernizing Speak Up programs with digital, AI-enabled tools to consolidate Speak Up, investigations, and data reporting, providing organizations with the tools they need to reduce risk, and create a culture of Active Integrity.  View original content:https://www.prnewswire.co.uk/news-releases/vault-unvails-ethicschat-ai-driven-ethical-guidance-for-modern-workplaces-302310088.html 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (99%); PRESS RELEASES (92%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); MANAGERS & SUPERVISORS (78%); MISCONDUCT (78%); NEW PRODUCTS (78%); PRODUCT INNOVATION (78%); EXECUTIVES (75%); INVESTIGATIONS (75%); REGULATORY COMPLIANCE (75%); CONFLICTS OF INTEREST (73%); TRENDS (71%); NEGATIVE MISC NEWS (70%); NEGATIVE NEWS (70%); RISK MANAGEMENT (67%); Vault-Platform (%); PDT New Products and Services (%)
Company:  MICROSOFT CORP (56%); Vault Platform
Ticker: MSFT (NASDAQ) (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE (89%); NEW PRODUCTS (78%); RISK MANAGEMENT (67%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Geographic: LONDON, ENGLAND (59%); CALIFORNIA, USA (73%); EUROPE (73%); ENGLAND (59%); UNITED KINGDOM (59%); England; United Kingdom; California; New York; Wisconsin; Texas; Israel
Load-Date: November 19, 2024",neutral,0.888879656791687,balanced/neutral,"['transparency', 'accountability']",[],"['compliance', 'should', 'need to']",[],2,0,3,0
2024,Unknown Title,"Body
2024 OCT 22 (NewsRx) -- By a News Reporter-Staff News Editor at Biotech News Daily -- New research on Artificial Intelligence is the subject of a report. According to news reporting out of Lexington, Massachusetts, by NewsRx editors, research stated, ""Artificial intelligence is increasingly being used in pharmacovigilance. However, the use of artificial intelligence in pharmacovigilance raises ethical concerns related to fairness, non-discrimination, compliance, and responsibility as the central ethical principles in risk assessment and regulatory requirements."" 
 Our news journalists obtained a quote from the research from Curis Inc., ""This paper explores these concerns and provides a roadmap to how to address these challenges by considering data collection, privacy protection, transparency and accountability, model training, and explainability in artificial intelligence decision making for drug safety surveillance. A number of responsible approaches have been identified including an ethics framework and best practices to enhance artificial intelligence use in healthcare. The document also recognizes some initiatives that have demonstrated the importance of ethics in artificial intelligence pharmacovigilance. Nevertheless, the major needs mentioned in this paper are transparency, accountability, data protection, and fairness, which stress the necessity of collaboration to construct a cognitive framework aimed at integrating ethical artificial intelligence into pharmacovigilance."" 
 According to the news editors, the research concluded: ""Innovation should be balanced with ethical responsibility to enhance public health outcomes as well as patient safety."" 
 This research has been peer-reviewed. 
 For more information on this research see: Safeguarding Patients In the Ai Era: Ethics At the Forefront of Pharmacovigilance. Drug Safety, 2024. Drug Safety can be contacted at: Adis Int Ltd, 5 The Warehouse Way, Northcote 0627, Auckland, New Zealand. 
 Our news journalists report that additional information may be obtained by contacting Ashish Jain, Curis Inc., 128 Spring St, Suite 500, Lexington, MA 02421, United States. Additional authors for this research include Maribel Salas, Omar Aimer and Zahabia Adenwala. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s40264-024-01483-9. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Lexington, Massachusetts, United States, North and Central America, Artificial Intelligence, Business, Business, Curis Inc., Drugs and Therapies, Emerging Technologies, Healthcare Biotechnology Companies, Machine Learning, Curis Inc. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: DRUG SAFETY (99%); ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DRUG SAFETY REGULATION (90%); JOURNALISM (90%); NEWS REPORTING (90%); RESEARCH REPORTS (90%); SAFETY (90%); WRITERS (89%); BIOTECHNOLOGY INDUSTRY (79%); EMERGING TECHNOLOGY (79%); TECHNOLOGY (79%); BEST PRACTICES (78%); PUBLIC HEALTH (78%); BIOTECHNOLOGY & GENETIC SCIENCE (74%); MACHINE LEARNING (74%); SURVEILLANCE (73%); REGULATORY ACTIONS (71%); SAFETY, ACCIDENTS & DISASTERS (71%); PRIVACY RIGHTS (69%); Lexington;State:Massachusetts;United States;North and Central America;Artificial Intelligence;Business;Business;Curis Inc.;Drugs and Therapies;Emerging Technologies;Healthcare Biotechnology Companies;Machine Learning (%)
Company:  CURIS INC (93%)
Ticker: CRIS (NASDAQ) (93%)
Industry: NAICS325414 BIOLOGICAL PRODUCT (EXCEPT DIAGNOSTIC) MANUFACTURING (93%); SIC2836 BIOLOGICAL PRODUCTS, EXCEPT DIAGNOSTIC SUBSTANCES (93%); DRUG SAFETY (99%); PHARMACEUTICALS & BIOTECHNOLOGY (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DRUG SAFETY REGULATION (90%); INFORMATION SECURITY & PRIVACY (90%); NEWS REPORTING (90%); WRITERS (89%); BIOTECHNOLOGY INDUSTRY (79%); DATA SECURITY (76%); MACHINE LEARNING (74%)
Geographic: AUCKLAND, NEW ZEALAND (53%); MASSACHUSETTS, USA (94%); NEW ZEALAND (77%); CENTRAL AMERICA (73%)
Load-Date: October 22, 2024","2024 OCT 22 (NewsRx) -- By a News Reporter-Staff News Editor at Biotech News Daily -- New research on Artificial Intelligence is the subject of a report. According to news reporting out of Lexington, Massachusetts, by NewsRx editors, research stated, ""Artificial intelligence is increasingly being used in pharmacovigilance. However, the use of artificial intelligence in pharmacovigilance raises ethical concerns related to fairness, non-discrimination, compliance, and responsibility as the central ethical principles in risk assessment and regulatory requirements."" 
 Our news journalists obtained a quote from the research from Curis Inc., ""This paper explores these concerns and provides a roadmap to how to address these challenges by considering data collection, privacy protection, transparency and accountability, model training, and explainability in artificial intelligence decision making for drug safety surveillance. A number of responsible approaches have been identified including an ethics framework and best practices to enhance artificial intelligence use in healthcare. The document also recognizes some initiatives that have demonstrated the importance of ethics in artificial intelligence pharmacovigilance. Nevertheless, the major needs mentioned in this paper are transparency, accountability, data protection, and fairness, which stress the necessity of collaboration to construct a cognitive framework aimed at integrating ethical artificial intelligence into pharmacovigilance."" 
 According to the news editors, the research concluded: ""Innovation should be balanced with ethical responsibility to enhance public health outcomes as well as patient safety."" 
 This research has been peer-reviewed. 
 For more information on this research see: Safeguarding Patients In the Ai Era: Ethics At the Forefront of Pharmacovigilance. Drug Safety, 2024. Drug Safety can be contacted at: Adis Int Ltd, 5 The Warehouse Way, Northcote 0627, Auckland, New Zealand. 
 Our news journalists report that additional information may be obtained by contacting Ashish Jain, Curis Inc., 128 Spring St, Suite 500, Lexington, MA 02421, United States. Additional authors for this research include Maribel Salas, Omar Aimer and Zahabia Adenwala. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s40264-024-01483-9. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Lexington, Massachusetts, United States, North and Central America, Artificial Intelligence, Business, Business, Curis Inc., Drugs and Therapies, Emerging Technologies, Healthcare Biotechnology Companies, Machine Learning, Curis Inc. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: DRUG SAFETY (99%); ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DRUG SAFETY REGULATION (90%); JOURNALISM (90%); NEWS REPORTING (90%); RESEARCH REPORTS (90%); SAFETY (90%); WRITERS (89%); BIOTECHNOLOGY INDUSTRY (79%); EMERGING TECHNOLOGY (79%); TECHNOLOGY (79%); BEST PRACTICES (78%); PUBLIC HEALTH (78%); BIOTECHNOLOGY & GENETIC SCIENCE (74%); MACHINE LEARNING (74%); SURVEILLANCE (73%); REGULATORY ACTIONS (71%); SAFETY, ACCIDENTS & DISASTERS (71%); PRIVACY RIGHTS (69%); Lexington;State:Massachusetts;United States;North and Central America;Artificial Intelligence;Business;Business;Curis Inc.;Drugs and Therapies;Emerging Technologies;Healthcare Biotechnology Companies;Machine Learning (%)
Company:  CURIS INC (93%)
Ticker: CRIS (NASDAQ) (93%)
Industry: NAICS325414 BIOLOGICAL PRODUCT (EXCEPT DIAGNOSTIC) MANUFACTURING (93%); SIC2836 BIOLOGICAL PRODUCTS, EXCEPT DIAGNOSTIC SUBSTANCES (93%); DRUG SAFETY (99%); PHARMACEUTICALS & BIOTECHNOLOGY (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DRUG SAFETY REGULATION (90%); INFORMATION SECURITY & PRIVACY (90%); NEWS REPORTING (90%); WRITERS (89%); BIOTECHNOLOGY INDUSTRY (79%); DATA SECURITY (76%); MACHINE LEARNING (74%)
Geographic: AUCKLAND, NEW ZEALAND (53%); MASSACHUSETTS, USA (94%); NEW ZEALAND (77%); CENTRAL AMERICA (73%)
Load-Date: October 22, 2024",neutral,0.9042293429374695,balanced/neutral,"['privacy', 'surveillance', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security']",['fairness'],"['regulation', 'framework', 'compliance', 'should']",['machine learning'],9,1,4,1
2024,Unknown Title,"Byline: States News Service
Dateline: AMHERST, Mass. 
Body
The following information was released by the University of Massachusetts - Amherst:
UMass Amherst faculty members are encouraged to submit papers for a special session of the IEEE Global Engineering Education Conference (EDUCON) 2025 conference titled ""Generative AI and Ethical Integration in Higher Education: Navigating Innovation and Responsibility.""
The session will explore the transformative potential of Generative AI in education, with a focus on addressing critical ethical challenges such as bias, privacy, accountability, explainability and trustworthiness.
UMass doctoral student Krishna Chaitanya Rao Kathala, global engagement graduate assistant in the Office of Global Affairs and co-chair of the conference special session, invites submissions that examine best practices, challenges and strategies for integrating AI responsibly in higher education. With AI systems increasingly influencing personalized learning, admissions and assessment, Kathala says that the need for embedding ethical considerations into educational practices has never been more urgent.
Topics of interest for submissions include, but are not limited to:
The role of educators in AI-augmented learning environments
Ethical concerns around bias, fairness, and accountability in AI-driven tools
Creativity and ethical considerations in using generative AI for teaching
Challenges and opportunities in teaching AI ethics within engineering curricula
The impact of generative AI on traditional pedagogical practices
Mitigating misinformation, AI hallucinations, and deep fakes in education
The deadline for submissions is Jan. 10, 2025. Notifications of acceptance are expected by Jan. 29, with a final manuscript deadline set for Feb. 19.
EDUCON 2025, which provides a forum for academic, research and industrial collaboration on global engineering education, will be held April 22-25 in London.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: GENERATIVE AI (94%); ETHICS (92%); COLLEGES & UNIVERSITIES (91%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CONFERENCES & CONVENTIONS (89%); ENGINEERING (89%); CURRICULA (78%); DISINFORMATION & MISINFORMATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); AI HALLUCINATIONS (77%); ARTIFICIAL INTELLIGENCE (77%); BEST PRACTICES (77%); DEEPFAKE TECHNOLOGY (72%)
Company:  AI SYSTEMS (55%)
Organization: UNIVERSITY OF MASSACHUSETTS (94%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); GENERATIVE AI (94%); COLLEGES & UNIVERSITIES (91%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); ENGINEERING (89%); GRADUATE & PROFESSIONAL SCHOOLS (78%); AI HALLUCINATIONS (77%); ARTIFICIAL INTELLIGENCE (77%); DEEPFAKE TECHNOLOGY (72%)
Geographic: LONDON, ENGLAND (51%); MASSACHUSETTS, USA (92%)
Load-Date: November 19, 2024","The following information was released by the University of Massachusetts - Amherst:
UMass Amherst faculty members are encouraged to submit papers for a special session of the IEEE Global Engineering Education Conference (EDUCON) 2025 conference titled ""Generative AI and Ethical Integration in Higher Education: Navigating Innovation and Responsibility.""
The session will explore the transformative potential of Generative AI in education, with a focus on addressing critical ethical challenges such as bias, privacy, accountability, explainability and trustworthiness.
UMass doctoral student Krishna Chaitanya Rao Kathala, global engagement graduate assistant in the Office of Global Affairs and co-chair of the conference special session, invites submissions that examine best practices, challenges and strategies for integrating AI responsibly in higher education. With AI systems increasingly influencing personalized learning, admissions and assessment, Kathala says that the need for embedding ethical considerations into educational practices has never been more urgent.
Topics of interest for submissions include, but are not limited to:
The role of educators in AI-augmented learning environments
Ethical concerns around bias, fairness, and accountability in AI-driven tools
Creativity and ethical considerations in using generative AI for teaching
Challenges and opportunities in teaching AI ethics within engineering curricula
The impact of generative AI on traditional pedagogical practices
Mitigating misinformation, AI hallucinations, and deep fakes in education
The deadline for submissions is Jan. 10, 2025. Notifications of acceptance are expected by Jan. 29, with a final manuscript deadline set for Feb. 19.
EDUCON 2025, which provides a forum for academic, research and industrial collaboration on global engineering education, will be held April 22-25 in London.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: GENERATIVE AI (94%); ETHICS (92%); COLLEGES & UNIVERSITIES (91%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CONFERENCES & CONVENTIONS (89%); ENGINEERING (89%); CURRICULA (78%); DISINFORMATION & MISINFORMATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); AI HALLUCINATIONS (77%); ARTIFICIAL INTELLIGENCE (77%); BEST PRACTICES (77%); DEEPFAKE TECHNOLOGY (72%)
Company:  AI SYSTEMS (55%)
Organization: UNIVERSITY OF MASSACHUSETTS (94%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); GENERATIVE AI (94%); COLLEGES & UNIVERSITIES (91%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); ENGINEERING (89%); GRADUATE & PROFESSIONAL SCHOOLS (78%); AI HALLUCINATIONS (77%); ARTIFICIAL INTELLIGENCE (77%); DEEPFAKE TECHNOLOGY (72%)
Geographic: LONDON, ENGLAND (51%); MASSACHUSETTS, USA (92%)
Load-Date: November 19, 2024",neutral,0.7828466296195984,balanced/neutral,"['privacy', 'bias', 'fairness', 'explainability', 'accountability', 'misinformation', 'disinformation']",['fairness'],[],['generative ai'],7,1,0,1
2024,Unknown Title,"Byline: Targeted News Service
Dateline: NOTRE DAME, Indiana 
Body
The University of Notre Dame issued the following news:
The University of Notre Dame's Institute for Advanced Study is now the Institute for Ethics and the Common Good, launching its website today at ethics.nd.edu. The transformed, expanded institute will play an essential role in advancing the University-wide Ethics Initiative emerging from ""Notre Dame 2033: A Strategic Framework.""
""The world today is changing rapidly, and with those changes come a host of challenging ethical questions,"" said Wilsey Family College Professor of Philosophy Meghan Sullivan, who directs both the Institute for Ethics and the Common Good and the Ethics Initiative. ""We need a place where people can weigh these questions, discern the good, and find the inspiration to keep our most fundamental values at the center of all the decisions we make. With its deep, complementary roots of faith and reason, the University of Notre Dame can be that place.""
Building on a rich history
Founded in 2008, the Notre Dame Institute for Advanced Study (NDIAS) has worked to foster research focused on significant questions and enriched by interdisciplinary collaboration. More than 350 faculty, graduate students and undergraduates have served as NDIAS fellows, generating research and publications that advanced knowledge, inspired new undergraduate courses and opened channels of dialogue across disparate fields.
Building on this rich history, the Institute for Ethics and the Common Good (ECG) will facilitate interdisciplinary research in foundational and applied ethics, coordinate projects that cross departments and units, and support ethics-related education and public engagement efforts.
It will continue its highly competitive and successful fellowship programs for faculty, graduate students and undergraduates, creating opportunities for fellows to develop cutting-edge ethics research and deepen personal formation.
With the support of a major John Templeton Foundation grant, the institute will expand its popular Signature Course Fellowship program. This program, which in the past has supported faculty at Notre Dame in developing undergraduate ""signature courses"" focused on student flourishing, will now be open to faculty at other colleges and universities who wish to learn from Notre Dame's successful model and create similar courses to benefit students on their campuses.
Enhancing research endeavors
ECG will be the home of the new Rev. John I. Jenkins, C.S.C., Center for Virtue Ethics, recently established in honor of University President Emeritus Father Jenkins. The Jenkins Center will support preeminent scholars whose research advances human flourishing in both moral and spiritual contexts, facilitate the development of undergraduate courses exploring topics such as justice and the common good, and deepen the ethical formation of Notre Dame students and faculty. The work of the Jenkins Center will bring renewed vigor to the study of virtue ethics, continuing the long history of Catholic thought leadership in this field.
The Notre Dame-IBM Technology Ethics Lab will now be a key element of the institute. The lab promotes broad-based, far-reaching interdisciplinary research, thought and policy leadership in artificial intelligence and other technology ethics by engaging with relevant stakeholders to examine real-world challenges and provide practical models and applied solutions for ethical technology design, development, and deployment. The lab is sponsored by IBM through a 10-year, $20 million investment.
As the institute grows, it will focus attention on other pillars of applied ethics, including environmental ethics and the ethics of business and governance.
In this work, the institute and its team will strive to fully integrate intellectual and moral development, guided by the vision of Blessed Basil Moreau, founder of the Congregation of Holy Cross.
Supporting the Ethics Initiative
ECG is a signature element of the Ethics Initiative, one of several University-wide strategic efforts that will draw on expertise from multiple colleges, schools, centers and institutes to make the most meaningful contributions to questions of national and international concern.
The Ethics Initiative aims to establish Notre Dame as a premier global destination for the study of ethics, offering superb training for future generations of ethicists and moral leaders, a platform for engagement of the Catholic moral tradition with other modes of inquiry, and an opportunity to forge insights into some of the most significant ethical issues of our time.
To advance these goals, the initiative will make strategic hiring investments in key departments and area groups, grow opportunities in ethics for Notre Dame graduate students, and foster collaboration and coordination among the many departments and academic units on campus that focus on ethics issues.
""The launch of the Institute for Ethics and the Common Good is an exciting milestone for the Ethics Initiative,"" said John T. McGreevy, the Charles and Jill Fischer Provost. ""As the only formally religious institution in the Association of American Universities, Notre Dame has the capacity to make a unique and strongly needed contribution to understanding the ethical challenges we face today. The work of the institute, together with the related activities of the initiative and its many current and potential partners, will play an important role in advancing Notre Dame as a leading global Catholic research university and a powerful force for good in the world.""
Originally published by Laura Moran Walton at ethics.nd.edu on July 25, 2024.
***
Original text here: https://news.nd.edu/news/transformed-institute-for-ethics-and-the-common-good-advances-notre-dames-commitment-to-excellence-in-the-study-of-ethics/
MSTRUCK-8742307 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); COLLEGES & UNIVERSITIES (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGE STUDENTS (89%); GRADUATE & PROFESSIONAL SCHOOLS (78%); PHILOSOPHY (78%); SOCIAL SCIENCE EDUCATION (78%); UNIVERSITY ADMINISTRATION (73%); GRANTS & GIFTS (64%); FOUNDATIONS (50%)
Organization: UNIVERSITY OF NOTRE DAME (94%); INSTITUTE FOR ADVANCED STUDY (91%)
Industry: COLLEGES & UNIVERSITIES (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGE STUDENTS (89%); EDUCATIONAL SERVICES (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%)
Geographic: INDIANA, USA (79%)
Load-Date: July 25, 2024","The University of Notre Dame issued the following news:
The University of Notre Dame's Institute for Advanced Study is now the Institute for Ethics and the Common Good, launching its website today at ethics.nd.edu. The transformed, expanded institute will play an essential role in advancing the University-wide Ethics Initiative emerging from ""Notre Dame 2033: A Strategic Framework.""
""The world today is changing rapidly, and with those changes come a host of challenging ethical questions,"" said Wilsey Family College Professor of Philosophy Meghan Sullivan, who directs both the Institute for Ethics and the Common Good and the Ethics Initiative. ""We need a place where people can weigh these questions, discern the good, and find the inspiration to keep our most fundamental values at the center of all the decisions we make. With its deep, complementary roots of faith and reason, the University of Notre Dame can be that place.""
Building on a rich history
Founded in 2008, the Notre Dame Institute for Advanced Study (NDIAS) has worked to foster research focused on significant questions and enriched by interdisciplinary collaboration. More than 350 faculty, graduate students and undergraduates have served as NDIAS fellows, generating research and publications that advanced knowledge, inspired new undergraduate courses and opened channels of dialogue across disparate fields.
Building on this rich history, the Institute for Ethics and the Common Good (ECG) will facilitate interdisciplinary research in foundational and applied ethics, coordinate projects that cross departments and units, and support ethics-related education and public engagement efforts.
It will continue its highly competitive and successful fellowship programs for faculty, graduate students and undergraduates, creating opportunities for fellows to develop cutting-edge ethics research and deepen personal formation.
With the support of a major John Templeton Foundation grant, the institute will expand its popular Signature Course Fellowship program. This program, which in the past has supported faculty at Notre Dame in developing undergraduate ""signature courses"" focused on student flourishing, will now be open to faculty at other colleges and universities who wish to learn from Notre Dame's successful model and create similar courses to benefit students on their campuses.
Enhancing research endeavors
ECG will be the home of the new Rev. John I. Jenkins, C.S.C., Center for Virtue Ethics, recently established in honor of University President Emeritus Father Jenkins. The Jenkins Center will support preeminent scholars whose research advances human flourishing in both moral and spiritual contexts, facilitate the development of undergraduate courses exploring topics such as justice and the common good, and deepen the ethical formation of Notre Dame students and faculty. The work of the Jenkins Center will bring renewed vigor to the study of virtue ethics, continuing the long history of Catholic thought leadership in this field.
The Notre Dame-IBM Technology Ethics Lab will now be a key element of the institute. The lab promotes broad-based, far-reaching interdisciplinary research, thought and policy leadership in artificial intelligence and other technology ethics by engaging with relevant stakeholders to examine real-world challenges and provide practical models and applied solutions for ethical technology design, development, and deployment. The lab is sponsored by IBM through a 10-year, $20 million investment.
As the institute grows, it will focus attention on other pillars of applied ethics, including environmental ethics and the ethics of business and governance.
In this work, the institute and its team will strive to fully integrate intellectual and moral development, guided by the vision of Blessed Basil Moreau, founder of the Congregation of Holy Cross.
Supporting the Ethics Initiative
ECG is a signature element of the Ethics Initiative, one of several University-wide strategic efforts that will draw on expertise from multiple colleges, schools, centers and institutes to make the most meaningful contributions to questions of national and international concern.
The Ethics Initiative aims to establish Notre Dame as a premier global destination for the study of ethics, offering superb training for future generations of ethicists and moral leaders, a platform for engagement of the Catholic moral tradition with other modes of inquiry, and an opportunity to forge insights into some of the most significant ethical issues of our time.
To advance these goals, the initiative will make strategic hiring investments in key departments and area groups, grow opportunities in ethics for Notre Dame graduate students, and foster collaboration and coordination among the many departments and academic units on campus that focus on ethics issues.
""The launch of the Institute for Ethics and the Common Good is an exciting milestone for the Ethics Initiative,"" said John T. McGreevy, the Charles and Jill Fischer Provost. ""As the only formally religious institution in the Association of American Universities, Notre Dame has the capacity to make a unique and strongly needed contribution to understanding the ethical challenges we face today. The work of the institute, together with the related activities of the initiative and its many current and potential partners, will play an important role in advancing Notre Dame as a leading global Catholic research university and a powerful force for good in the world.""
Originally published by Laura Moran Walton at ethics.nd.edu on July 25, 2024.
***
Original text here: https://news.nd.edu/news/transformed-institute-for-ethics-and-the-common-good-advances-notre-dames-commitment-to-excellence-in-the-study-of-ethics/
MSTRUCK-8742307 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); COLLEGES & UNIVERSITIES (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGE STUDENTS (89%); GRADUATE & PROFESSIONAL SCHOOLS (78%); PHILOSOPHY (78%); SOCIAL SCIENCE EDUCATION (78%); UNIVERSITY ADMINISTRATION (73%); GRANTS & GIFTS (64%); FOUNDATIONS (50%)
Organization: UNIVERSITY OF NOTRE DAME (94%); INSTITUTE FOR ADVANCED STUDY (91%)
Industry: COLLEGES & UNIVERSITIES (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGE STUDENTS (89%); EDUCATIONAL SERVICES (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%)
Geographic: INDIANA, USA (79%)
Load-Date: July 25, 2024",neutral,0.5807738304138184,balanced/neutral,[],"['virtue ethics', 'justice', 'justice']","['policy', 'governance', 'framework']",[],0,3,3,0
2024,Unknown Title,"Highlight: A study that will be a national blueprint for the use of AI in policing, has been published thanks to help from researchers at the University of Northampton (UON).
Body
The groundbreaking research was led by Professor Marion Oswald MBE from Northumbria Law School and supported by Dr Claire Paterson-Young and Dr Michael Maher from UON’s Institute for Social Innovation and Impact (ISII) 
Claire said: “AI can be a powerful tool to police forces around the world in terms of crime prevention and detection.
“But we need to make sure it is applied in an ethical way that puts human rights at the centre of decision making and builds trust in policing rather than eroding it.
“That’s why we have worked with a group of researchers from around the UK, led by Prof Oswald, to see how the use of an independent Data Ethics Advisory Committee by West Midlands Police has transformed the understanding of how to achieve responsible AI in policing.”
Over the past five years, the West Midlands Police and Crime Commissioner (WMOPCC) and West Midlands Police (WMP) have maintained an innovative Data Ethics Committee.
This interdisciplinary body, comprised of independent experts in law, computer science, ethics, social impact, and victims’ rights, advises on the design, development, and deployment of advanced AI tools and data analytics in policing. 
The new research highlights how this model has transformed police officers' understanding of the ethical and technical implications of AI, while simultaneously ensuring that human rights are at the forefront of thinking around new technology initiatives.
Funded by the Arts and Humanities Research Council (AHRC) through its Bridging Responsible AI Divides (BRAID) programme, the research concludes that this type of independent advice can help to bridge the gap between ethical reflection, scientific rigor, and human rights considerations in law enforcement.
The study found that the Committee’s work did not impede operational policing, but rather supported it, leading to more responsible and ethical AI use. 
Assistant Chief Constable Matt Welsted from West Midlands Police said the use of powerful new technology came with significant responsibilities, adding: “This research and the recommendations made will be invaluable to helping us and other forces get this balance right and ensure that the decisions we make and the tools we use to police our communities are ethical and legitimate.”
The research, which included interviews with Committee members, police officers, data scientists, and community representatives, as well as a review of Committee documents and observations of technology in action, calls for greater community involvement in the data ethics process. 
The research team emphasises that community trust in AI policing tools can only be achieved if the voices of community representatives are respected and visibly influential. 
Professor Oswald MBE, said: “Our research underscores the importance of balancing technological advancement with ethical oversight, advocating for a structured, transparent, and inclusive approach to AI in policing, with the West Midlands Data Ethics Committee serving as a leading example.”
Graphic
AI must be applied in an ethical way that builds trust in policing rather than eroding it.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (90%); HUMAN RIGHTS (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); LAW SCHOOLS (90%); NEGATIVE NEWS (90%); DATA SCIENCE (89%); LAW ENFORCEMENT (89%); TECHNOLOGY (89%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); EXPERIMENTATION & RESEARCH (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); HUMANITIES & SOCIAL SCIENCE (78%); LAWYERS (78%); POLICE FORCES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMANITIES (73%); RESEARCH REPORTS (73%); CRIME PREVENTION (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); LAW SCHOOLS (90%); DATA SCIENCE (89%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); LAWYERS (78%); PUBLISHING (78%)
Geographic: ENGLAND (94%); UNITED KINGDOM (77%)
Load-Date: October 4, 2024","The groundbreaking research was led by Professor Marion Oswald MBE from Northumbria Law School and supported by Dr Claire Paterson-Young and Dr Michael Maher from UON’s Institute for Social Innovation and Impact (ISII) 
Claire said: “AI can be a powerful tool to police forces around the world in terms of crime prevention and detection.
“But we need to make sure it is applied in an ethical way that puts human rights at the centre of decision making and builds trust in policing rather than eroding it.
“That’s why we have worked with a group of researchers from around the UK, led by Prof Oswald, to see how the use of an independent Data Ethics Advisory Committee by West Midlands Police has transformed the understanding of how to achieve responsible AI in policing.”
Over the past five years, the West Midlands Police and Crime Commissioner (WMOPCC) and West Midlands Police (WMP) have maintained an innovative Data Ethics Committee.
This interdisciplinary body, comprised of independent experts in law, computer science, ethics, social impact, and victims’ rights, advises on the design, development, and deployment of advanced AI tools and data analytics in policing. 
The new research highlights how this model has transformed police officers' understanding of the ethical and technical implications of AI, while simultaneously ensuring that human rights are at the forefront of thinking around new technology initiatives.
Funded by the Arts and Humanities Research Council (AHRC) through its Bridging Responsible AI Divides (BRAID) programme, the research concludes that this type of independent advice can help to bridge the gap between ethical reflection, scientific rigor, and human rights considerations in law enforcement.
The study found that the Committee’s work did not impede operational policing, but rather supported it, leading to more responsible and ethical AI use. 
Assistant Chief Constable Matt Welsted from West Midlands Police said the use of powerful new technology came with significant responsibilities, adding: “This research and the recommendations made will be invaluable to helping us and other forces get this balance right and ensure that the decisions we make and the tools we use to police our communities are ethical and legitimate.”
The research, which included interviews with Committee members, police officers, data scientists, and community representatives, as well as a review of Committee documents and observations of technology in action, calls for greater community involvement in the data ethics process. 
The research team emphasises that community trust in AI policing tools can only be achieved if the voices of community representatives are respected and visibly influential. 
Professor Oswald MBE, said: “Our research underscores the importance of balancing technological advancement with ethical oversight, advocating for a structured, transparent, and inclusive approach to AI in policing, with the West Midlands Data Ethics Committee serving as a leading example.”
Graphic
AI must be applied in an ethical way that builds trust in policing rather than eroding it.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (90%); HUMAN RIGHTS (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); LAW SCHOOLS (90%); NEGATIVE NEWS (90%); DATA SCIENCE (89%); LAW ENFORCEMENT (89%); TECHNOLOGY (89%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); EXPERIMENTATION & RESEARCH (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); HUMANITIES & SOCIAL SCIENCE (78%); LAWYERS (78%); POLICE FORCES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMANITIES (73%); RESEARCH REPORTS (73%); CRIME PREVENTION (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); LAW SCHOOLS (90%); DATA SCIENCE (89%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); LAWYERS (78%); PUBLISHING (78%)
Geographic: ENGLAND (94%); UNITED KINGDOM (77%)
Load-Date: October 4, 2024",positive,0.767029881477356,balanced/neutral,['human rights'],[],"['oversight', 'law', 'must', 'need to', 'calls for']",[],1,0,5,0
2024,Unknown Title,"Byline: States News Service
Dateline: BLACKSBURG, VA 
Body
The following information was released by the Virginia Tech:
Eldardiry and her team will develop practical competencies that enable students to translate ethical principles into concrete decision-making in artificial intellingence system design.
By
Barbara L. Micale
4 Nov 2024
As artificial intelligence (AI) increasingly affects peoples' everyday lives,Hoda Eldardiry,associate professor in theDepartment of Computer Scienceand core faculty at theSanghani Center for Artificial Intelligence and Data Analytics,isconducting research in engineering and computing education that will help studentsin majors such as computer science, computer engineering, and data sciencebridge the gap between the classroom and the job site.
Recently, she receiveda$349,360grant fromtheNational Science Foundation's (NSF) Engineering Education programto support her work.
""We want to ensure thatevery student is adequately prepared to not only confront but act on the challenges that new AI technologies pose to humans and society,"" saidEldardiry.
Her team for the estimated three-year projectincludes co-principal investigatorsQin Zhu,associate professor, andDayoung Kim, assistant professor, both in the Department of Engineering Education; James Weichert, a master's degree student in computer science advised by Eldardiry; and two Ph.D. students in engineering education, Yixiang Sun advised by Zhu and Emad Ali advised by Kim.
Eldardiry said their research which includes AI ethics issues related to autonomous vehicles, privacy, and bias differs from theoretical AI ethics research because their approach is to improve AI ethics education from the perspective of industry professionals currently working in AI and AI policy.
They have already interviewed a group of these professionals to get a better sense of how they view the AI policy landscape and more crucially, what skills they need to apply their technical backgrounds to real-world problems involving the ethical use of AI. With this project, they aim to engage practicing AI engineers to better understand how they translate AI ethics principles into practical applications when designing AI systems.
""We call these skills 'translational competencies,' and this is really the heart of our research,"" Eldardiry said. ""A curriculum shaped by this research can help cultivate the competencies needed for students to apply often vague ethical principles to concrete decision-making in the development and use of AI systems.""
In reviewing current curricula, Eldardiry said, one ethical concern that arises with more and more powerful AI tools and vast amounts of data is the privacy of user data. This is especially important when AI technologies can leverage that user data to find connections or identify users in a way that humans cannot. The social media platform TikTok is a good example of this because it collects so much data about what videos you are watching and is, therefore, really good at triangulating what your interests are and perhaps more personal things like your political ideology or sexual orientation.
""When we talk about privacy in a computer science ethics class, it is brought up as a fundamental ethical principle, but then the conversation normally stops there. Our current curriculum does not go further into depth about what specific kind of privacy we want to guarantee or the technical details required to build a system that does actually preserve user privacy,"" she said. ""This is seen as an 'advanced topic' that is outside the scope of an undergraduate or even graduate ethics course, but the reality is that these details might be key when a student graduates and is in charge of using or developing an AI system.""
Another example is self-driving cars and how they should be programmed to prioritize human life. While it is easy to say that the car should avoid any harm to humans all the time, there are inevitably situations where that is not possible and the car must make a split-second decision. So what should the car be programmed to do in that case? Perhaps there is no single ""correct"" answer, but this is also not anunrealistic scenario to be talking about in an ethics class, Eldardiry said.
""Ultimately, we would like to see a paradigm shift in AI ethics education away from a hands-off approach where students are not engaging with the course material to a very hands-on approach where students are taught and expected to apply the ethical principles they learn or develop to their engineering work,"" said Eldardiry. ""These translational skills are something that future AI engineers will undoubtedly need in their toolkit and will form a growing part of their job expectations as even the development of AI programs becomes more automated.""
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); COMPUTER SCIENCE (90%); ENGINEERING (90%); FOUNDATIONS (90%); SCIENCE FUNDING (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); CURRICULA (89%); PROFESSIONAL WORKERS (89%); TECHNOLOGY (89%); CERTIFICATES, DEGREES & DIPLOMAS (78%); DATA ANALYTICS (78%); EDUCATION & TRAINING (78%); POLITICAL & SOCIAL IDEOLOGIES (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (77%); DATA SCIENCE (77%); EXPERIMENTATION & RESEARCH (77%); BUSINESS ANALYTICS (76%); COMPUTER ENGINEERING (76%); INTERNET SOCIAL NETWORKING (75%); PHOTO & VIDEO SHARING (75%); LGBTQ+ PERSONS (65%); SOCIAL MEDIA (60%)
Organization: NATIONAL SCIENCE FOUNDATION (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); COMPUTER SCIENCE (90%); ENGINEERING (90%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION SECURITY & PRIVACY (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (77%); DATA SCIENCE (77%); BUSINESS ANALYTICS (76%); COMPUTER ENGINEERING (76%); INTERNET SOCIAL NETWORKING (75%); PHOTO & VIDEO SHARING (75%); SOCIAL MEDIA (60%); AUTONOMOUS VEHICLES (50%)
Geographic: VIRGINIA, USA (79%)
Load-Date: November 5, 2024","The following information was released by the Virginia Tech:
Eldardiry and her team will develop practical competencies that enable students to translate ethical principles into concrete decision-making in artificial intellingence system design.
By
Barbara L. Micale
4 Nov 2024
As artificial intelligence (AI) increasingly affects peoples' everyday lives,Hoda Eldardiry,associate professor in theDepartment of Computer Scienceand core faculty at theSanghani Center for Artificial Intelligence and Data Analytics,isconducting research in engineering and computing education that will help studentsin majors such as computer science, computer engineering, and data sciencebridge the gap between the classroom and the job site.
Recently, she receiveda$349,360grant fromtheNational Science Foundation's (NSF) Engineering Education programto support her work.
""We want to ensure thatevery student is adequately prepared to not only confront but act on the challenges that new AI technologies pose to humans and society,"" saidEldardiry.
Her team for the estimated three-year projectincludes co-principal investigatorsQin Zhu,associate professor, andDayoung Kim, assistant professor, both in the Department of Engineering Education; James Weichert, a master's degree student in computer science advised by Eldardiry; and two Ph.D. students in engineering education, Yixiang Sun advised by Zhu and Emad Ali advised by Kim.
Eldardiry said their research which includes AI ethics issues related to autonomous vehicles, privacy, and bias differs from theoretical AI ethics research because their approach is to improve AI ethics education from the perspective of industry professionals currently working in AI and AI policy.
They have already interviewed a group of these professionals to get a better sense of how they view the AI policy landscape and more crucially, what skills they need to apply their technical backgrounds to real-world problems involving the ethical use of AI. With this project, they aim to engage practicing AI engineers to better understand how they translate AI ethics principles into practical applications when designing AI systems.
""We call these skills 'translational competencies,' and this is really the heart of our research,"" Eldardiry said. ""A curriculum shaped by this research can help cultivate the competencies needed for students to apply often vague ethical principles to concrete decision-making in the development and use of AI systems.""
In reviewing current curricula, Eldardiry said, one ethical concern that arises with more and more powerful AI tools and vast amounts of data is the privacy of user data. This is especially important when AI technologies can leverage that user data to find connections or identify users in a way that humans cannot. The social media platform TikTok is a good example of this because it collects so much data about what videos you are watching and is, therefore, really good at triangulating what your interests are and perhaps more personal things like your political ideology or sexual orientation.
""When we talk about privacy in a computer science ethics class, it is brought up as a fundamental ethical principle, but then the conversation normally stops there. Our current curriculum does not go further into depth about what specific kind of privacy we want to guarantee or the technical details required to build a system that does actually preserve user privacy,"" she said. ""This is seen as an 'advanced topic' that is outside the scope of an undergraduate or even graduate ethics course, but the reality is that these details might be key when a student graduates and is in charge of using or developing an AI system.""
Another example is self-driving cars and how they should be programmed to prioritize human life. While it is easy to say that the car should avoid any harm to humans all the time, there are inevitably situations where that is not possible and the car must make a split-second decision. So what should the car be programmed to do in that case? Perhaps there is no single ""correct"" answer, but this is also not anunrealistic scenario to be talking about in an ethics class, Eldardiry said.
""Ultimately, we would like to see a paradigm shift in AI ethics education away from a hands-off approach where students are not engaging with the course material to a very hands-on approach where students are taught and expected to apply the ethical principles they learn or develop to their engineering work,"" said Eldardiry. ""These translational skills are something that future AI engineers will undoubtedly need in their toolkit and will form a growing part of their job expectations as even the development of AI programs becomes more automated.""
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); COMPUTER SCIENCE (90%); ENGINEERING (90%); FOUNDATIONS (90%); SCIENCE FUNDING (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); CURRICULA (89%); PROFESSIONAL WORKERS (89%); TECHNOLOGY (89%); CERTIFICATES, DEGREES & DIPLOMAS (78%); DATA ANALYTICS (78%); EDUCATION & TRAINING (78%); POLITICAL & SOCIAL IDEOLOGIES (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (77%); DATA SCIENCE (77%); EXPERIMENTATION & RESEARCH (77%); BUSINESS ANALYTICS (76%); COMPUTER ENGINEERING (76%); INTERNET SOCIAL NETWORKING (75%); PHOTO & VIDEO SHARING (75%); LGBTQ+ PERSONS (65%); SOCIAL MEDIA (60%)
Organization: NATIONAL SCIENCE FOUNDATION (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); COMPUTER SCIENCE (90%); ENGINEERING (90%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION SECURITY & PRIVACY (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (77%); DATA SCIENCE (77%); BUSINESS ANALYTICS (76%); COMPUTER ENGINEERING (76%); INTERNET SOCIAL NETWORKING (75%); PHOTO & VIDEO SHARING (75%); SOCIAL MEDIA (60%); AUTONOMOUS VEHICLES (50%)
Geographic: VIRGINIA, USA (79%)
Load-Date: November 5, 2024",neutral,0.6188123822212219,balanced/neutral,"['privacy', 'bias', 'security']",[],"['regulation', 'policy', 'should', 'must', 'need to']",[],3,0,5,0
2024,Unknown Title,"Body
2024 AUG 14 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on Robotics. According to news reporting out of Florence, Italy, by NewsRx editors, research stated, ""The development of social assistive robots for supporting healthcare provision faces a lack of an ethical approach that adequately addresses the normatively relevant challenges regarding its deployment. Current ethical reflection is primarily informed by an individual-centered perspective focused on robots' implications for their end-users and thereby limited to the dyadic human-robot interaction sphere."" 
 Funders for this research include CRUE-CSIC agreement, Springer Nature, MCIN/AEI, ESF Investing in your future, European Union Horizon 2020 Programme. 
 Our news journalists obtained a quote from the research from European University Institute, ""Considering that this is tightly correlated to the restricted understanding of core ethical concepts upon which reflection stands, this paper delves into the concept of freedom from a philosophical perspective to unfold its full normative breadth for a critical assessment of technological development. By bringing to the fore the political-structural dimension of freedom and, in turn, elaborating the political dimension of technology, the undertaken philosophical approach discloses freedom as a transversal ethical concept for a normative reflection on technology. Thereby, it broadens the scope of ethical attention beyond the sphere of human-robot interaction and turns attention to the so far overlooked structural dimension of human-robot relations. Drawing on conceptions of freedom as non-domination, among others, the paper approaches social assistive robotics and reexamines the terrain of relevant issues for its development. Since freedom is one major issue upon which current concerns revolve, the undertaken analysis substantially enriches the ongoing ethical discussion on social assistive robotics' implications for human freedom."" 
 According to the news editors, the research concluded: ""In this way, this work contributes to going beyond the current individual-centered ethical perspective by laying conceptual grounds for a comprehensive ethical approach to social assistive robotics' development."" 
 This research has been peer-reviewed. 
 For more information on this research see: Social Assistive Robotics: an Ethical and Political Inquiry Through the Lens of Freedom. International Journal of Social Robotics, 2024. International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; International Journal of Social Robotics - www.springerlink.com/content/1875-4791/) 
 Our news journalists report that additional information may be obtained by contacting Julia Pareto, European University Institute, Florence Sch Transnatl Governance, Palazzo Buontalenti, Via Camillo Cavour 65, I-50129 Florence, Italy. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s12369-024-01161-x. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Florence, Italy, Europe, Emerging Technologies, Machine Learning, Nano-robot, Robot, Robotics, Technology, European University Institute. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); GOVERNMENT ETHICS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); TECHNOLOGY (90%); HUMAN MACHINE INTERACTION (89%); EUROPEAN UNION (78%); NEWS REPORTING (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (72%); COLLEGES & UNIVERSITIES (71%); Florence;Italy;Europe;Emerging Technologies;Machine Learning;Nano-robot;Robot;Robotics;Technology (%)
Organization:  EUROPEAN UNION (56%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); WRITERS (78%); COLLEGES & UNIVERSITIES (71%)
Geographic: EUROPE (91%); EUROPEAN UNION MEMBER STATES (79%); NETHERLANDS (79%)
Load-Date: August 14, 2024","2024 AUG 14 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on Robotics. According to news reporting out of Florence, Italy, by NewsRx editors, research stated, ""The development of social assistive robots for supporting healthcare provision faces a lack of an ethical approach that adequately addresses the normatively relevant challenges regarding its deployment. Current ethical reflection is primarily informed by an individual-centered perspective focused on robots' implications for their end-users and thereby limited to the dyadic human-robot interaction sphere."" 
 Funders for this research include CRUE-CSIC agreement, Springer Nature, MCIN/AEI, ESF Investing in your future, European Union Horizon 2020 Programme. 
 Our news journalists obtained a quote from the research from European University Institute, ""Considering that this is tightly correlated to the restricted understanding of core ethical concepts upon which reflection stands, this paper delves into the concept of freedom from a philosophical perspective to unfold its full normative breadth for a critical assessment of technological development. By bringing to the fore the political-structural dimension of freedom and, in turn, elaborating the political dimension of technology, the undertaken philosophical approach discloses freedom as a transversal ethical concept for a normative reflection on technology. Thereby, it broadens the scope of ethical attention beyond the sphere of human-robot interaction and turns attention to the so far overlooked structural dimension of human-robot relations. Drawing on conceptions of freedom as non-domination, among others, the paper approaches social assistive robotics and reexamines the terrain of relevant issues for its development. Since freedom is one major issue upon which current concerns revolve, the undertaken analysis substantially enriches the ongoing ethical discussion on social assistive robotics' implications for human freedom."" 
 According to the news editors, the research concluded: ""In this way, this work contributes to going beyond the current individual-centered ethical perspective by laying conceptual grounds for a comprehensive ethical approach to social assistive robotics' development."" 
 This research has been peer-reviewed. 
 For more information on this research see: Social Assistive Robotics: an Ethical and Political Inquiry Through the Lens of Freedom. International Journal of Social Robotics, 2024. International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; International Journal of Social Robotics - www.springerlink.com/content/1875-4791/) 
 Our news journalists report that additional information may be obtained by contacting Julia Pareto, European University Institute, Florence Sch Transnatl Governance, Palazzo Buontalenti, Via Camillo Cavour 65, I-50129 Florence, Italy. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s12369-024-01161-x. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Florence, Italy, Europe, Emerging Technologies, Machine Learning, Nano-robot, Robot, Robotics, Technology, European University Institute. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); GOVERNMENT ETHICS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); TECHNOLOGY (90%); HUMAN MACHINE INTERACTION (89%); EUROPEAN UNION (78%); NEWS REPORTING (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (72%); COLLEGES & UNIVERSITIES (71%); Florence;Italy;Europe;Emerging Technologies;Machine Learning;Nano-robot;Robot;Robotics;Technology (%)
Organization:  EUROPEAN UNION (56%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); WRITERS (78%); COLLEGES & UNIVERSITIES (71%)
Geographic: EUROPE (91%); EUROPEAN UNION MEMBER STATES (79%); NETHERLANDS (79%)
Load-Date: August 14, 2024",neutral,0.9273810982704163,balanced/neutral,[],[],['governance'],"['machine learning', 'robot', 'robotics']",0,0,1,3
2024,Unknown Title,"Byline: BestMediaInfo Bureau
Body
The code takes into account aspects like how to look at data, the nuances of data being used and labelling aimed at safety, accountability, and ethical practices in AI
New Delhi: IT Ministry is crafting a voluntary code of conduct and ethics for work around Artificial Intelligence (AI), and talks are on with companies and stakeholders for the same, according to a source.
The code would take into account aspects like how to look at data, the nuances of data being used, and labelling among other aspects.
The source said that the work on voluntary code of conduct and ethics for AI firms is currently on.
Amid an AI gold rush of sorts among companies, nations across the globe are stressing the importance of responsible practices related to Artificial Intelligence.
Last week, UNESCO in collaboration with the IT Ministry held a stakeholder consultation on safety and ethics in Artificial Intelligence, as India aims to craft a policy that envisions 'AI for All'.
This initiative came at a crucial moment as India embarked on its ambitious 'IndiaAI Mission' backed by over Rs 10,000 crore in funding.
Central to the mission is the safe and trusted AI pillar, which underscores the commitment to ensuring safety, accountability, and ethical practices in AI development and deployment.
By promoting indigenous frameworks, robust governance tools, and self-assessment guidelines, the IndiaAI Mission aims to empower innovators and democratise AI benefits across sectors.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); SAFETY (90%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: NEW DELHI, INDIA (79%); INDIA (91%)
Load-Date: November 19, 2024","The code takes into account aspects like how to look at data, the nuances of data being used and labelling aimed at safety, accountability, and ethical practices in AI
New Delhi: IT Ministry is crafting a voluntary code of conduct and ethics for work around Artificial Intelligence (AI), and talks are on with companies and stakeholders for the same, according to a source.
The code would take into account aspects like how to look at data, the nuances of data being used, and labelling among other aspects.
The source said that the work on voluntary code of conduct and ethics for AI firms is currently on.
Amid an AI gold rush of sorts among companies, nations across the globe are stressing the importance of responsible practices related to Artificial Intelligence.
Last week, UNESCO in collaboration with the IT Ministry held a stakeholder consultation on safety and ethics in Artificial Intelligence, as India aims to craft a policy that envisions 'AI for All'.
This initiative came at a crucial moment as India embarked on its ambitious 'IndiaAI Mission' backed by over Rs 10,000 crore in funding.
Central to the mission is the safe and trusted AI pillar, which underscores the commitment to ensuring safety, accountability, and ethical practices in AI development and deployment.
By promoting indigenous frameworks, robust governance tools, and self-assessment guidelines, the IndiaAI Mission aims to empower innovators and democratise AI benefits across sectors.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); SAFETY (90%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: NEW DELHI, INDIA (79%); INDIA (91%)
Load-Date: November 19, 2024",neutral,0.8292866945266724,balanced/neutral,"['accountability', 'safety']",[],"['policy', 'governance', 'guidelines']",[],2,0,3,0
2024,Unknown Title,"Byline: States News Service
Dateline: OXFORD, UK 
Body
The following information was released by the University of Oxford:
Researchers from the University of Oxford, University of Cambridge, University of Copenhagen, National University of Singapore, and other leading institutions have devised philosophically-grounded ethical guidelines for using Large Language Models in academic writing.
As Large Language Models (LLMs) become more prevalent and easy to access, academics across the globe are using their assistance for academic manuscript writing, in particular developing ideas and content. However, several concerns arise from their probabilistic nature relating to plagiarism, authorship attribution, and the integrity of academia as a whole. As AI tools become increasingly sophisticated, clear ethical guidelines are therefore crucial to maintaining the quality and credibility of scholarly work.
The new research, published in Nature Machine Intelligence, outlines three essential criteria that maximise the beneficial impacts of LLMs on scientific advancement and academic equity:
Human vetting and guaranteeing of accuracy and integrity
Ensuring substantial human contribution to the work
Appropriate acknowledgment and transparency of LLM use.
The authors define a template LLM Use Acknowledgement, which researchers can utilise when submitting manuscripts. This practical tool will streamline adherence to ethical standards in AI-assisted academic writing, and provide greater transparency about LLM use.
Speaking of the guidelines, co-author, Professor Julian Savulescu, of The Uehiro Oxford Institute, said: 'Large Language Models are the Pandora's Box for academic research. They could eliminate academic independence, creativity, originality and thought itself. But they could also facilitate unimaginable co-creation and productivity. These guidelines are the first steps to using LLMs responsibly and ethically in academic writing and research.'
This publication marks a crucial step in managing the relationship between human academic work and machine intelligence. By empowering researchers to leverage AI technology ethically, they aim to boost productivity and innovation while preserving academic integrity.
Co-author, Dr Brian Earp, of The Uehiro Oxford Institute, said: 'It's appropriate and necessary to be extremely cautious when faced with new technological possibilities, including the ability for human writers to co-create academic material using generative AI. This is especially true when things are scaling up and moving quickly. But ethical guidelines are not only about reducing risk; they are also about maximizing potential benefits.'
Professor Timo Minssen from the University of Copenhagen said: 'Guidance is essential in shaping the ethical use of AI in academic research, and in particular concerning the co-creation of academic articles with LLMs. Appropriate acknowledgment based on the principles of research ethics should ensure transparency, ethical integrity, and proper attribution. Ideally, this will promote a collaborative and more inclusive environment where human ingenuity and machine intelligence can enhance scholarly discourse.'
This new research presents opportunities for academic communities worldwide, and can be used across all academic disciplines.
The paper 'Guidelines for ethical use and acknowledgement of large language models in academic writing' has been published in Nature Machine Intelligence.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); LARGE LANGUAGE MODELS (90%); WRITERS (90%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); SCHOOL CHEATING (78%); GENERATIVE AI (77%); RESEARCH REPORTS (73%); PLAGIARISM (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); LARGE LANGUAGE MODELS (90%); WRITERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); GENERATIVE AI (77%)
Geographic: OXFORD, ENGLAND (89%)
Load-Date: November 13, 2024","The following information was released by the University of Oxford:
Researchers from the University of Oxford, University of Cambridge, University of Copenhagen, National University of Singapore, and other leading institutions have devised philosophically-grounded ethical guidelines for using Large Language Models in academic writing.
As Large Language Models (LLMs) become more prevalent and easy to access, academics across the globe are using their assistance for academic manuscript writing, in particular developing ideas and content. However, several concerns arise from their probabilistic nature relating to plagiarism, authorship attribution, and the integrity of academia as a whole. As AI tools become increasingly sophisticated, clear ethical guidelines are therefore crucial to maintaining the quality and credibility of scholarly work.
The new research, published in Nature Machine Intelligence, outlines three essential criteria that maximise the beneficial impacts of LLMs on scientific advancement and academic equity:
Human vetting and guaranteeing of accuracy and integrity
Ensuring substantial human contribution to the work
Appropriate acknowledgment and transparency of LLM use.
The authors define a template LLM Use Acknowledgement, which researchers can utilise when submitting manuscripts. This practical tool will streamline adherence to ethical standards in AI-assisted academic writing, and provide greater transparency about LLM use.
Speaking of the guidelines, co-author, Professor Julian Savulescu, of The Uehiro Oxford Institute, said: 'Large Language Models are the Pandora's Box for academic research. They could eliminate academic independence, creativity, originality and thought itself. But they could also facilitate unimaginable co-creation and productivity. These guidelines are the first steps to using LLMs responsibly and ethically in academic writing and research.'
This publication marks a crucial step in managing the relationship between human academic work and machine intelligence. By empowering researchers to leverage AI technology ethically, they aim to boost productivity and innovation while preserving academic integrity.
Co-author, Dr Brian Earp, of The Uehiro Oxford Institute, said: 'It's appropriate and necessary to be extremely cautious when faced with new technological possibilities, including the ability for human writers to co-create academic material using generative AI. This is especially true when things are scaling up and moving quickly. But ethical guidelines are not only about reducing risk; they are also about maximizing potential benefits.'
Professor Timo Minssen from the University of Copenhagen said: 'Guidance is essential in shaping the ethical use of AI in academic research, and in particular concerning the co-creation of academic articles with LLMs. Appropriate acknowledgment based on the principles of research ethics should ensure transparency, ethical integrity, and proper attribution. Ideally, this will promote a collaborative and more inclusive environment where human ingenuity and machine intelligence can enhance scholarly discourse.'
This new research presents opportunities for academic communities worldwide, and can be used across all academic disciplines.
The paper 'Guidelines for ethical use and acknowledgement of large language models in academic writing' has been published in Nature Machine Intelligence.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); LARGE LANGUAGE MODELS (90%); WRITERS (90%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); SCHOOL CHEATING (78%); GENERATIVE AI (77%); RESEARCH REPORTS (73%); PLAGIARISM (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); LARGE LANGUAGE MODELS (90%); WRITERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); GENERATIVE AI (77%)
Geographic: OXFORD, ENGLAND (89%)
Load-Date: November 13, 2024",neutral,0.8569886684417725,balanced/neutral,"['transparency', 'access']",['equity'],"['standards', 'guidelines', 'should']","['generative ai', 'llm']",2,1,3,2
2024,Unknown Title,"Body
59% of respondents believe AI ethical risks are not treated separately. Organizations are advised to establish separate frameworks for managing AI ethical risks. Julia Graham emphasizes the need for better understanding of AI ethical risks, while Hoe-Yeong Loke highlights the challenge of managing AI ethical risks separately.
Key Highlights:
* Organizations are urged to establish AI ethics committees and separate AI risk assessment frameworks.
* Julia Graham, CEO of Airmic, emphasizes the need for better understanding of AI ethical risks.
* Hoe-Yeong Loke, Head of Research at Airmic, highlights the challenge of managing AI ethical risks separately.
Original Press Release:
April 9 -- Airmicissued the following news release:
- Findings open debate on managing AI alongside other ethical risks
Organisations are treating the ethical risks from the use of artificial intelligence (AI) together with other ethical risks, said 59% of respondents in an Airmic survey this week. Respondents were almost evenly split as to whether they thought AI ethical risks ought to be treated separately.
As AI applications are rapidly being adopted by organisations and individuals, respondents thought it sensible to give AI ethical risks extra visibility and attention within the risk management frameworks and processes. This comes as more bodies are calling for organisations to establish AI ethics committees and separate AI risk assessment frameworks, to steer the organisations through contentious situations relating to ethics.
Julia Graham, CEO of Airmic, said: ""The ethical risks of AI are not yet well understood and additional attention could be spent understanding them, although in time, our members expect these risks to be considered alongside other ethical risks.""
Disclaimer: chart can be viewed at: https://www.airmic.com/news/press/almost-60-say-ai-ethical-risks-not-treated-separately
Hoe-Yeong Loke, Head of Research, Airmic, said: ""There is a sense among our members that 'either you are ethical or you are not' - that it may not always be practical or desirable to separate AI ethical risks from all other ethical risks faced by the organisation.""
""What this calls for is more debate on how AI ethical risks are managed. Regardless, organisations should carefully consider the implications of potentially overlapping risk management and governance structures.""
If you would like to request an interview and or have any further questions, please let me know.
We will be sharing the results of the Airmic Big Question with the press weekly.
You can also find the results here(https://www.airmic.com/news/press).
Source: Airmic
[Category: Investment Banking & Brokerage, Artificial Intelligence]
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); RISK MANAGEMENT (90%); CORPORATE GOVERNANCE (78%); EXECUTIVES (78%); PRESS RELEASES (72%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RISK MANAGEMENT (90%); BANKING & FINANCE (60%); INVESTMENT BANKING (60%)
Load-Date: April 10, 2024","59% of respondents believe AI ethical risks are not treated separately. Organizations are advised to establish separate frameworks for managing AI ethical risks. Julia Graham emphasizes the need for better understanding of AI ethical risks, while Hoe-Yeong Loke highlights the challenge of managing AI ethical risks separately.
Key Highlights:
* Organizations are urged to establish AI ethics committees and separate AI risk assessment frameworks.
* Julia Graham, CEO of Airmic, emphasizes the need for better understanding of AI ethical risks.
* Hoe-Yeong Loke, Head of Research at Airmic, highlights the challenge of managing AI ethical risks separately.
Original Press Release:
April 9 -- Airmicissued the following news release:
- Findings open debate on managing AI alongside other ethical risks
Organisations are treating the ethical risks from the use of artificial intelligence (AI) together with other ethical risks, said 59% of respondents in an Airmic survey this week. Respondents were almost evenly split as to whether they thought AI ethical risks ought to be treated separately.
As AI applications are rapidly being adopted by organisations and individuals, respondents thought it sensible to give AI ethical risks extra visibility and attention within the risk management frameworks and processes. This comes as more bodies are calling for organisations to establish AI ethics committees and separate AI risk assessment frameworks, to steer the organisations through contentious situations relating to ethics.
Julia Graham, CEO of Airmic, said: ""The ethical risks of AI are not yet well understood and additional attention could be spent understanding them, although in time, our members expect these risks to be considered alongside other ethical risks.""
Disclaimer: chart can be viewed at: https://www.airmic.com/news/press/almost-60-say-ai-ethical-risks-not-treated-separately
Hoe-Yeong Loke, Head of Research, Airmic, said: ""There is a sense among our members that 'either you are ethical or you are not' - that it may not always be practical or desirable to separate AI ethical risks from all other ethical risks faced by the organisation.""
""What this calls for is more debate on how AI ethical risks are managed. Regardless, organisations should carefully consider the implications of potentially overlapping risk management and governance structures.""
If you would like to request an interview and or have any further questions, please let me know.
We will be sharing the results of the Airmic Big Question with the press weekly.
You can also find the results here(https://www.airmic.com/news/press).
Source: Airmic
[Category: Investment Banking & Brokerage, Artificial Intelligence]
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); RISK MANAGEMENT (90%); CORPORATE GOVERNANCE (78%); EXECUTIVES (78%); PRESS RELEASES (72%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RISK MANAGEMENT (90%); BANKING & FINANCE (60%); INVESTMENT BANKING (60%)
Load-Date: April 10, 2024",neutral,0.7912777662277222,balanced/neutral,[],[],"['governance', 'should', 'calls for']",[],0,0,3,0
2024,Unknown Title,"Body
2024 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- According to news reporting based on a preprint abstract, our journalists obtained the following quote sourced from osf.io:
 “The book Ethics of Artificial Intelligence offers a solid exploration of arguments and real-world examples that enrich the ongoing debate surrounding AI ethics. With 12 insightful chapters, the book delves into pressing ethical issues, such as the enhancement of human abilities, the nature of consciousness, and questions of responsibility and accountability in various contexts where AI technology is used.
 “This work connects technology ethics with broader philosophical discussions and provides valuable perspectives on the societal implications of AI. Engaging and accessible, it can serve as an essential resource for scholars, technology-enthusiasts, policymakers, and anyone with an interest in the transformative potential of AI and its ethical dimensions.”
 This preprint has not been peer-reviewed.
 For more information on this research see: osf.io/preprints/socarxiv/27uy6/
 Keywords for this news article include: Artificial Intelligence, Emerging Technologies, Machine Learning, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); BOOK REVIEWS (90%); JOURNALISM (90%); ROBOTICS (90%); TECHNOLOGY (90%); NEWS REPORTING (78%); WRITERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (73%); Artificial Intelligence;Emerging Technologies;Machine Learning;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); BOOK REVIEWS (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (78%)
Load-Date: November 4, 2024","2024 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- According to news reporting based on a preprint abstract, our journalists obtained the following quote sourced from osf.io:
 “The book Ethics of Artificial Intelligence offers a solid exploration of arguments and real-world examples that enrich the ongoing debate surrounding AI ethics. With 12 insightful chapters, the book delves into pressing ethical issues, such as the enhancement of human abilities, the nature of consciousness, and questions of responsibility and accountability in various contexts where AI technology is used.
 “This work connects technology ethics with broader philosophical discussions and provides valuable perspectives on the societal implications of AI. Engaging and accessible, it can serve as an essential resource for scholars, technology-enthusiasts, policymakers, and anyone with an interest in the transformative potential of AI and its ethical dimensions.”
 This preprint has not been peer-reviewed.
 For more information on this research see: osf.io/preprints/socarxiv/27uy6/
 Keywords for this news article include: Artificial Intelligence, Emerging Technologies, Machine Learning, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); BOOK REVIEWS (90%); JOURNALISM (90%); ROBOTICS (90%); TECHNOLOGY (90%); NEWS REPORTING (78%); WRITERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (73%); Artificial Intelligence;Emerging Technologies;Machine Learning;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); BOOK REVIEWS (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (78%)
Load-Date: November 4, 2024",neutral,0.885493278503418,balanced/neutral,['accountability'],[],[],"['machine learning', 'robotics']",1,0,0,2
2024,Unknown Title,"Byline: EDRM - Electronic Discovery Reference ModelHon. Ralph Artigliere
Body
September 5th, 2024 ( JD Supra  - Delivered by  Newstex )
Image: Holley Robinson, EDRM.
Generative AI is rapidly transforming the landscape of legal and judicial practice, raising complex ethical questions that demand thoughtful regulation. Recognizing this, on August 29, 2024, the Florida Supreme Court took a significant step by amending the Rules Regulating the Florida Bar to address the ethical use of generative AI by lawyers. These changes mark a forward-thinking approach to managing AI's impact on the legal profession. Were these amendments necessary? Absolutely. Were they implemented effectively? Yes. This article explores why these changes are crucial and what every lawyer needs to understand about them.
The Rise of Generative AI Power in Legal Workflow
Generative AI is more than just a new trend; it's a transformative technology with profound implications for legal practice. AI is not new to lawyers or the support systems and vendors that assist in managing their practices and tasks, but generative AI represents a giant step forward, bringing both opportunities and challenges.
Unlike traditional AI, which identifies patterns and makes decisions based on existing data, generative AI uses advanced machine learning to create original content, such as text and images. This technology has transformative potential in legal practice, where vast amounts of data require careful management, analysis, and the precise application of rules and judgment. Generative AI can streamline tasks like drafting documents and conducting research, enhancing both efficiency and decision-making processes.
Risks and Ethical Concerns
However, these benefits come with risks. Generative AI can produce biased or misleading content, potentially affecting case outcomes. Using these products without careful attention to terms of use regarding information provided to the platform can result in breaching client confidentiality. The legal industry is seeing a surge in AI-driven tools, ranging from comprehensive platforms to accessible models like OpenAI's ChatGPT. While these tools promise increased efficiency, their misuse-such as drafting legal briefs without verifying sources-underscores the necessity for proper understanding and ethical use. If an AI tool incorrectly cites case law or leaks confidential client information, the consequences could be severe for both the lawyer and their client.
Given the rapid development of this technology and its significant impact on legal practice, responsible regulation is essential. Regulatory bodies must craft guidelines that protect against risks without stifling innovation, striking a balance that allows lawyers to leverage AI effectively and ethically. Recognizing these opportunities and risks, The Florida Bar proposed, and the Florida Supreme Court adopted, amendments that reflect this measured approach, guiding legal professionals in navigating the evolving landscape of AI in their practice.
Florida is Taking a Leading Role in AI
Like many state bar associations and courts, The Florida Bar and the Florida Supreme Court are understandably monitoring the rise in the use of generative AI products by lawyers and judges. Earlier this year, The Florida Bar released  Ethics Opinion 24-1 ('Opinion 24-1') regarding the use of generative artificial intelligence ('AI') in the practice of law. Opinion 24-1 is based on existing universal ethical rules and standards, which the opinion recognized and applied to current issues with generative AI. I thought that effort was a good step for Florida lawyers and one that would be helpful for other jurisdictions and Bar associations looking to issue guidance. See Florida's New Advisory Ethics Opinion on Generative AI Hits the Mark found here.
Ethics Opinions like Ethics Opinion 24-1 are advisory and not binding. Changing the ethical rules is another matter.
The Hon. Judge Ralph Artigliere (ret).
Ethics Opinions like Ethics Opinion 24-1 are advisory and not binding. Changing the ethical rules is another matter. The rules establish ethical standards that lawyers must adhere to, ensuring they maintain integrity, competence, and professionalism in their practice. Rules of ethics shape professional conduct and responsibilities of lawyers to each other, their clients, the public, and the system of law. They also have a disciplinary component to ensure compliance and maintain the integrity of the legal profession. Accordingly, changing the rules will have a greater impact on the overall practice environment and should be adopted with careful consideration.
In the matter of technological innovation, undue or excessive regulation can stifle innovation and growth. The dizzying change brought about by the emergence of generative AI since November of 2022 poses challenges for regulation of the profession of law. Leaders in state bar associations and courts must adapt professionalism standards to the evolving landscape. At the same time, they want to ensure that lawyers have access to tools that make their practices more efficient and allow for sound judgment in methodology and workflow. The key is to keep the rules fresh and relevant with only necessary and measured change. In my opinion that is exactly what The Florida Court did.
The Ethical Rule Amendments
The Florida Bar petitioned the Florida Supreme Court proposing amendments to Chapter 4 of the Rules Regulating The Florida Bar, the ethical rules governing Florida lawyers. Among the proposals were changes to the rules and comments on lawyer responsibilities when using generative AI. The Florida Bar's Board of Governors approved the proposed amendments, and the Bar published the proposed amendments for comment in The Florida Bar News. No comments were received. All of the proposed changes involving Generative AI were adopted by the Court in a unanimous opinion, IN RE: AMENDMENTS TO RULES REGULATING THE FLORIDA BAR - CHAPTER 4, 2024 Fla. LEXIS 1373 (Fla. August 29, 2024) also available  here. The amendments are effective October 28, 2024.
All of the proposed changes involving Generative AI were adopted by the Court in a unanimous opinion, IN RE: AMENDMENTS TO RULES REGULATING THE FLORIDA BAR - CHAPTER 4, 2024 Fla. LEXIS 1373 (Fla. August 29, 2024) also available  here.The Hon. Judge Ralph Artigliere (ret).
In addition to various grammatical changes, the Court amended the Comments to rules 4-1.1, 4-1.6, 4-5.1, and 4-5.3, adding a warning about the necessity to take care in using generative artificial intelligence. The changes were made to comments in the following rules with the new language underlined below:
Comment to RULE 4-1.1 COMPETENCE:
Maintaining Competence
To maintain the requisite knowledge and skill, a lawyer should keep abreast of changes in the law and its practice, engage in continuing study and education, including an understanding of the benefits and risks associated with the use of technology, including generative artificial intelligence, and comply with all continuing legal education requirements to which the lawyer is subject.
Comment to RULE 4-1.6. CONFIDENTIALITY OF INFORMATION:
Acting Competently to Preserve Confidentiality
Paragraph (e) requires a lawyer to act competently to safeguard information relating to the representation of a client against unauthorized access by third parties and against inadvertent or unauthorized disclosure by the lawyer or other persons who are participating in the representation of the client or who are subject to the lawyer's supervision. See rules 4-1.1, 4-5.1 and 4-5.3. For example, a lawyer should be aware that generative artificial intelligence may create risks to the lawyer's duty of confidentiality. .
Comment to: RULE 4-5.1. RESPONSIBILITIES OF PARTNERS, MANAGERS, AND SUPERVISORY LAWYERS:
Subdivision (a) requires lawyers with managerial authority within a firm to make reasonable efforts to establish internal policies and procedures designed to provide reasonable assurance that all lawyers in the firm will conform to the Rules of Professional Conduct. Such policies and procedures include those designed to detect and resolve conflicts of interest, identify dates by which actions must be taken in pending matters, account for client funds and property, consider safeguards for the firm's use of technologies such as generative artificial intelligence, and ensure that inexperienced lawyers are properly supervised.
Comment to: RULE 4-5.3. RESPONSIBILITIES REGARDING NONLAWYER ASSISTANTS:
Lawyers generally employ assistants in their practice, including secretaries, investigators, law student interns, and paraprofessionals such as paralegals and legal assistants. Such assistants, whether employees or independent contractors, act for the lawyer in rendition of the lawyer's professional services. A lawyer must give such assistants appropriate instruction and supervision concerning the ethical aspects of their employment, particularly regarding the obligation not to disclose information relating to representation of the client. A lawyer should also consider safeguards when assistants use technologies such as generative artificial intelligence. .
Nonlawyers Outside the Firm
A lawyer may use nonlawyers outside the firm to assist the lawyer in rendering legal services to the client. Examples include the retention of an investigative or paraprofessional service, hiring a document management company to create and maintain a database for complex litigation, sending client documents to a third party for printing or scanning, using generative artificial intelligence, and using an Internet-based service to store client information. When using these services outside the firm, a lawyer must make reasonable efforts to ensure that the services are provided in a manner that is compatible with the lawyer's professional obligations. .
These changes underscore the need for continuous adaptation and vigilance as the legal community navigates the evolving challenges posed by new technologies.
The Impact of Amending Ethical Rules
The Florida Bar and the Court took a forward-thinking but measured approach to Generative AI. Especially in the professional world, undue hype and carelessly using tools with potential down issues like hallucinations, bias, and data insecurity are dangers to lawyers, their clients, and the courts. But careful and effective use is possible, the tools are improving all the time, and there is no way the AI advantage is a passing fad. For those reasons, it is important that regulation of use of generative AI be targeted and measured. Ethical rules should highlight the responsibility without throwing a wet blanket on the fire of learning and progress. The changes made by the Florida Court are right in line with what is needed.
Hopefully, amendments like this will spur a discussion in the legal community and raise awareness of the benefits as well as the risks of new technology. Likewise, lawyers should understand and comment when necessary on the regulations that affect them and their profession. Stay informed about technological advancements and engage in discussions about ethical standards. Dialogue is good for all of us.
Were the New Rules Necessary?
Some will say that the amendments specifically mentioning generative AI were not needed as they are covered by existing rules, including the Comment to Rule 4-1.1 requiring lawyers to be competent in technology. Yes, the existing rules already require the competence, diligence, and responsibilities that use of other technologies already in widespread use. Careless or uninformed use of Generative AI is no different from cloud computing or use of other products without confidentiality safeguards. However, since generative AI is still in its infancy, lawyers are still making mistakes despite the current rules, previous ethical guidance, and widespread coverage of missteps.
The rule changes made by Florida are in the comments, not the rules themselves. There is no downside to adding the careful wording in the comments as the Court did here, and hopefully publicizing and enforcing these rule changes will broaden the understanding of the potential consequences of careless use of technology tools. Whether the new language is needed to clarify and enforce the rules is probably less important than the value of informing The Bar of their ethical responsibilities as to generative AI.
CONCLUSION
I applaud the Florida Bar Association and Supreme Court for their approach to a growing problem existing in the wake of the Generative AI juggernaut: lawyer apathy, ignorance, or abuse of a valuable tool with a tremendous upside but the potential for harm if not carefully and ethically employed in law practice. Measured steps in ethical rules and guidance at this early stage of development of the technology will allow progress to occur with guidance and guardrails that keep lawyer use within safe ethical bounds.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: GENERATIVE AI (94%); ETHICS (91%); LAW & LEGAL SYSTEM (90%); LAWYERS (90%); LEGAL SERVICES (90%); ARTIFICIAL INTELLIGENCE (89%); GOVERNMENT BODIES & OFFICES (89%); LAW COURTS & TRIBUNALS (89%); PROFESSIONAL WORKERS (89%); SUPREME COURTS (89%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CHATBOTS (78%); EMERGING TECHNOLOGY (78%); AGENCY RULEMAKING (77%); JUDGES (77%); TRENDS (76%); MACHINE LEARNING (73%); BUSINESS & PROFESSIONAL ASSOCIATIONS (70%); ASSOCIATIONS & ORGANIZATIONS (50%)
Organization: FLORIDA SUPREME COURT (58%)
Industry: GENERATIVE AI (94%); LAWYERS (90%); LEGAL SERVICES (90%); ARTIFICIAL INTELLIGENCE (89%); DIGITAL RIGHTS MANAGEMENT (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CHATBOTS (78%); MACHINE LEARNING (73%)
Geographic: FLORIDA, USA (97%)
Load-Date: September 5, 2024","September 5th, 2024 ( JD Supra  - Delivered by  Newstex )
Image: Holley Robinson, EDRM.
Generative AI is rapidly transforming the landscape of legal and judicial practice, raising complex ethical questions that demand thoughtful regulation. Recognizing this, on August 29, 2024, the Florida Supreme Court took a significant step by amending the Rules Regulating the Florida Bar to address the ethical use of generative AI by lawyers. These changes mark a forward-thinking approach to managing AI's impact on the legal profession. Were these amendments necessary? Absolutely. Were they implemented effectively? Yes. This article explores why these changes are crucial and what every lawyer needs to understand about them.
The Rise of Generative AI Power in Legal Workflow
Generative AI is more than just a new trend; it's a transformative technology with profound implications for legal practice. AI is not new to lawyers or the support systems and vendors that assist in managing their practices and tasks, but generative AI represents a giant step forward, bringing both opportunities and challenges.
Unlike traditional AI, which identifies patterns and makes decisions based on existing data, generative AI uses advanced machine learning to create original content, such as text and images. This technology has transformative potential in legal practice, where vast amounts of data require careful management, analysis, and the precise application of rules and judgment. Generative AI can streamline tasks like drafting documents and conducting research, enhancing both efficiency and decision-making processes.
Risks and Ethical Concerns
However, these benefits come with risks. Generative AI can produce biased or misleading content, potentially affecting case outcomes. Using these products without careful attention to terms of use regarding information provided to the platform can result in breaching client confidentiality. The legal industry is seeing a surge in AI-driven tools, ranging from comprehensive platforms to accessible models like OpenAI's ChatGPT. While these tools promise increased efficiency, their misuse-such as drafting legal briefs without verifying sources-underscores the necessity for proper understanding and ethical use. If an AI tool incorrectly cites case law or leaks confidential client information, the consequences could be severe for both the lawyer and their client.
Given the rapid development of this technology and its significant impact on legal practice, responsible regulation is essential. Regulatory bodies must craft guidelines that protect against risks without stifling innovation, striking a balance that allows lawyers to leverage AI effectively and ethically. Recognizing these opportunities and risks, The Florida Bar proposed, and the Florida Supreme Court adopted, amendments that reflect this measured approach, guiding legal professionals in navigating the evolving landscape of AI in their practice.
Florida is Taking a Leading Role in AI
Like many state bar associations and courts, The Florida Bar and the Florida Supreme Court are understandably monitoring the rise in the use of generative AI products by lawyers and judges. Earlier this year, The Florida Bar released  Ethics Opinion 24-1 ('Opinion 24-1') regarding the use of generative artificial intelligence ('AI') in the practice of law. Opinion 24-1 is based on existing universal ethical rules and standards, which the opinion recognized and applied to current issues with generative AI. I thought that effort was a good step for Florida lawyers and one that would be helpful for other jurisdictions and Bar associations looking to issue guidance. See Florida's New Advisory Ethics Opinion on Generative AI Hits the Mark found here.
Ethics Opinions like Ethics Opinion 24-1 are advisory and not binding. Changing the ethical rules is another matter.
The Hon. Judge Ralph Artigliere (ret).
Ethics Opinions like Ethics Opinion 24-1 are advisory and not binding. Changing the ethical rules is another matter. The rules establish ethical standards that lawyers must adhere to, ensuring they maintain integrity, competence, and professionalism in their practice. Rules of ethics shape professional conduct and responsibilities of lawyers to each other, their clients, the public, and the system of law. They also have a disciplinary component to ensure compliance and maintain the integrity of the legal profession. Accordingly, changing the rules will have a greater impact on the overall practice environment and should be adopted with careful consideration.
In the matter of technological innovation, undue or excessive regulation can stifle innovation and growth. The dizzying change brought about by the emergence of generative AI since November of 2022 poses challenges for regulation of the profession of law. Leaders in state bar associations and courts must adapt professionalism standards to the evolving landscape. At the same time, they want to ensure that lawyers have access to tools that make their practices more efficient and allow for sound judgment in methodology and workflow. The key is to keep the rules fresh and relevant with only necessary and measured change. In my opinion that is exactly what The Florida Court did.
The Ethical Rule Amendments
The Florida Bar petitioned the Florida Supreme Court proposing amendments to Chapter 4 of the Rules Regulating The Florida Bar, the ethical rules governing Florida lawyers. Among the proposals were changes to the rules and comments on lawyer responsibilities when using generative AI. The Florida Bar's Board of Governors approved the proposed amendments, and the Bar published the proposed amendments for comment in The Florida Bar News. No comments were received. All of the proposed changes involving Generative AI were adopted by the Court in a unanimous opinion, IN RE: AMENDMENTS TO RULES REGULATING THE FLORIDA BAR - CHAPTER 4, 2024 Fla. LEXIS 1373 (Fla. August 29, 2024) also available  here. The amendments are effective October 28, 2024.
All of the proposed changes involving Generative AI were adopted by the Court in a unanimous opinion, IN RE: AMENDMENTS TO RULES REGULATING THE FLORIDA BAR - CHAPTER 4, 2024 Fla. LEXIS 1373 (Fla. August 29, 2024) also available  here.The Hon. Judge Ralph Artigliere (ret).
In addition to various grammatical changes, the Court amended the Comments to rules 4-1.1, 4-1.6, 4-5.1, and 4-5.3, adding a warning about the necessity to take care in using generative artificial intelligence. The changes were made to comments in the following rules with the new language underlined below:
Comment to RULE 4-1.1 COMPETENCE:
Maintaining Competence
To maintain the requisite knowledge and skill, a lawyer should keep abreast of changes in the law and its practice, engage in continuing study and education, including an understanding of the benefits and risks associated with the use of technology, including generative artificial intelligence, and comply with all continuing legal education requirements to which the lawyer is subject.
Comment to RULE 4-1.6. CONFIDENTIALITY OF INFORMATION:
Acting Competently to Preserve Confidentiality
Paragraph (e) requires a lawyer to act competently to safeguard information relating to the representation of a client against unauthorized access by third parties and against inadvertent or unauthorized disclosure by the lawyer or other persons who are participating in the representation of the client or who are subject to the lawyer's supervision. See rules 4-1.1, 4-5.1 and 4-5.3. For example, a lawyer should be aware that generative artificial intelligence may create risks to the lawyer's duty of confidentiality. .
Comment to: RULE 4-5.1. RESPONSIBILITIES OF PARTNERS, MANAGERS, AND SUPERVISORY LAWYERS:
Subdivision (a) requires lawyers with managerial authority within a firm to make reasonable efforts to establish internal policies and procedures designed to provide reasonable assurance that all lawyers in the firm will conform to the Rules of Professional Conduct. Such policies and procedures include those designed to detect and resolve conflicts of interest, identify dates by which actions must be taken in pending matters, account for client funds and property, consider safeguards for the firm's use of technologies such as generative artificial intelligence, and ensure that inexperienced lawyers are properly supervised.
Comment to: RULE 4-5.3. RESPONSIBILITIES REGARDING NONLAWYER ASSISTANTS:
Lawyers generally employ assistants in their practice, including secretaries, investigators, law student interns, and paraprofessionals such as paralegals and legal assistants. Such assistants, whether employees or independent contractors, act for the lawyer in rendition of the lawyer's professional services. A lawyer must give such assistants appropriate instruction and supervision concerning the ethical aspects of their employment, particularly regarding the obligation not to disclose information relating to representation of the client. A lawyer should also consider safeguards when assistants use technologies such as generative artificial intelligence. .
Nonlawyers Outside the Firm
A lawyer may use nonlawyers outside the firm to assist the lawyer in rendering legal services to the client. Examples include the retention of an investigative or paraprofessional service, hiring a document management company to create and maintain a database for complex litigation, sending client documents to a third party for printing or scanning, using generative artificial intelligence, and using an Internet-based service to store client information. When using these services outside the firm, a lawyer must make reasonable efforts to ensure that the services are provided in a manner that is compatible with the lawyer's professional obligations. .
These changes underscore the need for continuous adaptation and vigilance as the legal community navigates the evolving challenges posed by new technologies.
The Impact of Amending Ethical Rules
The Florida Bar and the Court took a forward-thinking but measured approach to Generative AI. Especially in the professional world, undue hype and carelessly using tools with potential down issues like hallucinations, bias, and data insecurity are dangers to lawyers, their clients, and the courts. But careful and effective use is possible, the tools are improving all the time, and there is no way the AI advantage is a passing fad. For those reasons, it is important that regulation of use of generative AI be targeted and measured. Ethical rules should highlight the responsibility without throwing a wet blanket on the fire of learning and progress. The changes made by the Florida Court are right in line with what is needed.
Hopefully, amendments like this will spur a discussion in the legal community and raise awareness of the benefits as well as the risks of new technology. Likewise, lawyers should understand and comment when necessary on the regulations that affect them and their profession. Stay informed about technological advancements and engage in discussions about ethical standards. Dialogue is good for all of us.
Were the New Rules Necessary?
Some will say that the amendments specifically mentioning generative AI were not needed as they are covered by existing rules, including the Comment to Rule 4-1.1 requiring lawyers to be competent in technology. Yes, the existing rules already require the competence, diligence, and responsibilities that use of other technologies already in widespread use. Careless or uninformed use of Generative AI is no different from cloud computing or use of other products without confidentiality safeguards. However, since generative AI is still in its infancy, lawyers are still making mistakes despite the current rules, previous ethical guidance, and widespread coverage of missteps.
The rule changes made by Florida are in the comments, not the rules themselves. There is no downside to adding the careful wording in the comments as the Court did here, and hopefully publicizing and enforcing these rule changes will broaden the understanding of the potential consequences of careless use of technology tools. Whether the new language is needed to clarify and enforce the rules is probably less important than the value of informing The Bar of their ethical responsibilities as to generative AI.
CONCLUSION
I applaud the Florida Bar Association and Supreme Court for their approach to a growing problem existing in the wake of the Generative AI juggernaut: lawyer apathy, ignorance, or abuse of a valuable tool with a tremendous upside but the potential for harm if not carefully and ethically employed in law practice. Measured steps in ethical rules and guidance at this early stage of development of the technology will allow progress to occur with guidance and guardrails that keep lawyer use within safe ethical bounds.
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: GENERATIVE AI (94%); ETHICS (91%); LAW & LEGAL SYSTEM (90%); LAWYERS (90%); LEGAL SERVICES (90%); ARTIFICIAL INTELLIGENCE (89%); GOVERNMENT BODIES & OFFICES (89%); LAW COURTS & TRIBUNALS (89%); PROFESSIONAL WORKERS (89%); SUPREME COURTS (89%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CHATBOTS (78%); EMERGING TECHNOLOGY (78%); AGENCY RULEMAKING (77%); JUDGES (77%); TRENDS (76%); MACHINE LEARNING (73%); BUSINESS & PROFESSIONAL ASSOCIATIONS (70%); ASSOCIATIONS & ORGANIZATIONS (50%)
Organization: FLORIDA SUPREME COURT (58%)
Industry: GENERATIVE AI (94%); LAWYERS (90%); LEGAL SERVICES (90%); ARTIFICIAL INTELLIGENCE (89%); DIGITAL RIGHTS MANAGEMENT (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CHATBOTS (78%); MACHINE LEARNING (73%)
Geographic: FLORIDA, USA (97%)
Load-Date: September 5, 2024",neutral,0.7292534112930298,balanced/neutral,"['bias', 'agency', 'access']",[],"['regulation', 'standards', 'guidelines', 'law', 'compliance', 'should', 'must']","['machine learning', 'generative ai', 'chatgpt']",3,0,7,3
2024,Unknown Title,"Body
2024 DEC 06 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx COVID-19 Daily -- Investigators publish new report on COVID-19. According to news originating from Fitchburg, Massachusetts, by NewsRx correspondents, research stated, ""This case study explores the ethical dimensions of social media communication during the COVID-19 pandemic, focusing on its dual role in disseminating both accurate health information and misinformation."" 
 The news correspondents obtained a quote from the research from Fitchburg State University: ""As the pandemic escalated, many turned to social platforms for updates, resulting in widespread misinformation that generated public confusion, anxiety, and vaccine hesitancy. The study highlights the critical responsibilities of health professionals, social media platforms, and public health organizations in ensuring accurate information dissemination while actively combating misinformation. It emphasizes the need for ethical communication strategies focused on integrity, transparency, and accountability."" 
 According to the news reporters, the research concluded: ""Additionally, it proposes practical solutions, such as automated fact-checking through artificial intelligence algorithms, human monitoring, and collaborative educational campaigns, to enhance the reliability of health information shared on social media. The findings aim to inform best practices for ethical digital communication in future health crises, fostering public trust and improving health outcomes."" 
 For more information on this research see: Ethical Social Media Communication during the COVID-19 Pandemic: A Case Study. International Journal of Health Sciences and Research, 2024,14(11). The publisher for International Journal of Health Sciences and Research is Galore Knowledge Publication Pvt. Ltd. 
 A free version of this journal article is available at https://doi.org/10.52403/ijhsr.20241128. 
 Our news editors report that more information may be obtained by contacting Anthony Vincent Razzano, School of Arts and Sciences, Fitchburg State University, Fitchburg, Massachusetts, United States. 
 Keywords for this news article include: Fitchburg State University, Fitchburg, Massachusetts, United States, North and Central America, COVID-19, Coronavirus, Epidemiology, Health and Medicine, Pandemic, RNA Viruses, SARS-CoV-2, Severe Acute Respiratory Syndrome Coronavirus 2, Social Media, Viral, Virology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: EPIDEMICS (96%); COVID CORONAVIRUS (94%); COVID-19 CORONAVIRUS (94%); PANDEMICS (91%); CASE STUDIES (90%); DISINFORMATION & MISINFORMATION (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); HEALTH CARE INFORMATION (90%); INFECTIOUS DISEASE (90%); INVESTIGATIONS (90%); PUBLIC HEALTH (90%); SOCIAL MEDIA (90%); COLLEGES & UNIVERSITIES (89%); CORONAVIRUSES (89%); EPIDEMIOLOGY (89%); MEDICAL SCIENCE (89%); MEDICINE & HEALTH (89%); VIRUSES (89%); HEALTH MISINFORMATION (79%); RESPIRATORY DISORDERS & INJURIES (79%); SARS (79%); VIROLOGY (79%); ZOONOTIC DISEASES (79%); FACT CHECKING (78%); JOURNALISM (78%); MICROBIOLOGY (78%); NEGATIVE NEWS (78%); PUBLIC HEALTH ADMINISTRATION (78%); VACCINES (74%); HEALTH CARE PROFESSIONALS (73%); PROFESSIONAL WORKERS (73%); ARTS & HUMANITIES EDUCATION (71%); ASSOCIATIONS & ORGANIZATIONS (69%); ARTIFICIAL INTELLIGENCE (67%); COVID-19;Coronavirus;Epidemiology;Health and Medicine;Pandemic;RNA Viruses;SARS-CoV-2;Severe Acute Respiratory Syndrome Coronavirus 2;Social Media;Viral;Virology (%)
Industry: HEALTH CARE INFORMATION (90%); SOCIAL MEDIA (90%); COLLEGES & UNIVERSITIES (89%); EPIDEMIOLOGY (89%); HEALTH MISINFORMATION (79%); VIROLOGY (79%); PUBLISHING (78%); VACCINES (74%); HEALTH CARE PROFESSIONALS (73%); ARTIFICIAL INTELLIGENCE (67%)
Geographic: MASSACHUSETTS, USA (93%); CENTRAL AMERICA (79%)
Load-Date: December 6, 2024","2024 DEC 06 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx COVID-19 Daily -- Investigators publish new report on COVID-19. According to news originating from Fitchburg, Massachusetts, by NewsRx correspondents, research stated, ""This case study explores the ethical dimensions of social media communication during the COVID-19 pandemic, focusing on its dual role in disseminating both accurate health information and misinformation."" 
 The news correspondents obtained a quote from the research from Fitchburg State University: ""As the pandemic escalated, many turned to social platforms for updates, resulting in widespread misinformation that generated public confusion, anxiety, and vaccine hesitancy. The study highlights the critical responsibilities of health professionals, social media platforms, and public health organizations in ensuring accurate information dissemination while actively combating misinformation. It emphasizes the need for ethical communication strategies focused on integrity, transparency, and accountability."" 
 According to the news reporters, the research concluded: ""Additionally, it proposes practical solutions, such as automated fact-checking through artificial intelligence algorithms, human monitoring, and collaborative educational campaigns, to enhance the reliability of health information shared on social media. The findings aim to inform best practices for ethical digital communication in future health crises, fostering public trust and improving health outcomes."" 
 For more information on this research see: Ethical Social Media Communication during the COVID-19 Pandemic: A Case Study. International Journal of Health Sciences and Research, 2024,14(11). The publisher for International Journal of Health Sciences and Research is Galore Knowledge Publication Pvt. Ltd. 
 A free version of this journal article is available at https://doi.org/10.52403/ijhsr.20241128. 
 Our news editors report that more information may be obtained by contacting Anthony Vincent Razzano, School of Arts and Sciences, Fitchburg State University, Fitchburg, Massachusetts, United States. 
 Keywords for this news article include: Fitchburg State University, Fitchburg, Massachusetts, United States, North and Central America, COVID-19, Coronavirus, Epidemiology, Health and Medicine, Pandemic, RNA Viruses, SARS-CoV-2, Severe Acute Respiratory Syndrome Coronavirus 2, Social Media, Viral, Virology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: EPIDEMICS (96%); COVID CORONAVIRUS (94%); COVID-19 CORONAVIRUS (94%); PANDEMICS (91%); CASE STUDIES (90%); DISINFORMATION & MISINFORMATION (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); HEALTH CARE INFORMATION (90%); INFECTIOUS DISEASE (90%); INVESTIGATIONS (90%); PUBLIC HEALTH (90%); SOCIAL MEDIA (90%); COLLEGES & UNIVERSITIES (89%); CORONAVIRUSES (89%); EPIDEMIOLOGY (89%); MEDICAL SCIENCE (89%); MEDICINE & HEALTH (89%); VIRUSES (89%); HEALTH MISINFORMATION (79%); RESPIRATORY DISORDERS & INJURIES (79%); SARS (79%); VIROLOGY (79%); ZOONOTIC DISEASES (79%); FACT CHECKING (78%); JOURNALISM (78%); MICROBIOLOGY (78%); NEGATIVE NEWS (78%); PUBLIC HEALTH ADMINISTRATION (78%); VACCINES (74%); HEALTH CARE PROFESSIONALS (73%); PROFESSIONAL WORKERS (73%); ARTS & HUMANITIES EDUCATION (71%); ASSOCIATIONS & ORGANIZATIONS (69%); ARTIFICIAL INTELLIGENCE (67%); COVID-19;Coronavirus;Epidemiology;Health and Medicine;Pandemic;RNA Viruses;SARS-CoV-2;Severe Acute Respiratory Syndrome Coronavirus 2;Social Media;Viral;Virology (%)
Industry: HEALTH CARE INFORMATION (90%); SOCIAL MEDIA (90%); COLLEGES & UNIVERSITIES (89%); EPIDEMIOLOGY (89%); HEALTH MISINFORMATION (79%); VIROLOGY (79%); PUBLISHING (78%); VACCINES (74%); HEALTH CARE PROFESSIONALS (73%); ARTIFICIAL INTELLIGENCE (67%)
Geographic: MASSACHUSETTS, USA (93%); CENTRAL AMERICA (79%)
Load-Date: December 6, 2024",neutral,0.9426640272140503,balanced/neutral,"['transparency', 'accountability', 'misinformation', 'disinformation']",[],[],[],4,0,0,0
2024,Unknown Title,"Body
2024 DEC 10 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting originating from Lubeck, Germany, by NewsRx correspondents, research stated, ""We critique demands in artificial intelligence and technology development for bridging the so-called principles-to-practice gap that are voiced for instrumental reasons, such as accelerating adoption or creating trust, via clearly actionable ethical rules or via outsourced guidance offered by ethics 'experts.' We contend that these views are prone to amount to a simple reconfiguration of technical implementation."" 
 Our news reporters obtained a quote from the research from University of Lubeck: ""We support inclusive and philosophically grounded ethical reflection as key to bridging the gap. However, we acknowledge that this requires assistance, e.g., in the form of platform structures as part of ecosystem governance. Such platforms should facilitate inclusive discourse to disaggregate ethical principles on different levels of abstraction, and contextual framings, as well as support the considerable interdisciplinary work for unpacking them. Translating ethical principles into practice involves indispensable collaborative processes of (self-)reflection, including those with epistemic privilege on the relevant subject matter."" 
 According to the news editors, the research concluded: ""We propose that ecosystems should provide the corresponding infrastructure."" 
 For more information on this research see: A systemic perspective on bridging the principles-to-practice gap in creating ethical artificial intelligence solutions - a critique of dominant narratives and proposal for a collaborative way forward. Journal of Responsible Innovation, 2024,11(1). The publisher for Journal of Responsible Innovation is Taylor & Francis Group. 
 A free version of this journal article is available at https://doi.org/10.1080/23299460.2024.2431350. 
 Our news journalists report that more information may be obtained by contacting Christian Herzog, Ethical Innovation Hub, University of Lubeck, Lubeck, Germany. Additional authors for this research include Sabrina Blank. 
 Keywords for this news article include: University of Lubeck, Lubeck, Germany, Europe, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (79%); NEWS REPORTING (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  TAYLOR & FRANCIS GROUP LTD (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (78%)
Geographic: GERMANY (90%); EUROPE (58%)
Load-Date: December 10, 2024","2024 DEC 10 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting originating from Lubeck, Germany, by NewsRx correspondents, research stated, ""We critique demands in artificial intelligence and technology development for bridging the so-called principles-to-practice gap that are voiced for instrumental reasons, such as accelerating adoption or creating trust, via clearly actionable ethical rules or via outsourced guidance offered by ethics 'experts.' We contend that these views are prone to amount to a simple reconfiguration of technical implementation."" 
 Our news reporters obtained a quote from the research from University of Lubeck: ""We support inclusive and philosophically grounded ethical reflection as key to bridging the gap. However, we acknowledge that this requires assistance, e.g., in the form of platform structures as part of ecosystem governance. Such platforms should facilitate inclusive discourse to disaggregate ethical principles on different levels of abstraction, and contextual framings, as well as support the considerable interdisciplinary work for unpacking them. Translating ethical principles into practice involves indispensable collaborative processes of (self-)reflection, including those with epistemic privilege on the relevant subject matter."" 
 According to the news editors, the research concluded: ""We propose that ecosystems should provide the corresponding infrastructure."" 
 For more information on this research see: A systemic perspective on bridging the principles-to-practice gap in creating ethical artificial intelligence solutions - a critique of dominant narratives and proposal for a collaborative way forward. Journal of Responsible Innovation, 2024,11(1). The publisher for Journal of Responsible Innovation is Taylor & Francis Group. 
 A free version of this journal article is available at https://doi.org/10.1080/23299460.2024.2431350. 
 Our news journalists report that more information may be obtained by contacting Christian Herzog, Ethical Innovation Hub, University of Lubeck, Lubeck, Germany. Additional authors for this research include Sabrina Blank. 
 Keywords for this news article include: University of Lubeck, Lubeck, Germany, Europe, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (79%); NEWS REPORTING (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  TAYLOR & FRANCIS GROUP LTD (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (78%)
Geographic: GERMANY (90%); EUROPE (58%)
Load-Date: December 10, 2024",neutral,0.9298065900802612,balanced/neutral,[],[],"['governance', 'should', 'propose']","['machine learning', 'robotics']",0,0,3,2
2024,Unknown Title,"Byline: The Peninsula Newspaper
Body
Doha, Qatar: The Excellence Center for Training and Consultancy at the Doha Institute for Graduate Studies DI organized, on Sunday, November 24, 2024, a seminar titled 'Cybersecurity and the Contemporary Challenges in Facing Cyber Intrusions: Practices and Ethics' in collaboration with the Kindi Center for Computing Research at Qatar University.
The event featured the participation of HE Dr Ahmed Bin Hamad AlMohanadi, Shura Council Member, and the attendance of HE Brigadier General Abdelrahman Al Sulaiti, President of the Police Academy, Dr. Abdelwahab ElAffendi, President of the DI, Dr Ayhab Saad, Dean of the School of Economics, Administration and Public Policy, Dr Amal Gazal, Dean of the School of Social Sciences and Humanities, with a number of leaders, academics and researchers.
In her opening remarks, Amal Al-Subaie, Manager of the Development and Initiatives Section at the Excellence Center, emphasized the growing cybersecurity threats globally. She highlighted the importance of raising societal and institutional awareness of these risks and the need for additional measures to ensure comprehensive protection against cyber threats.
Dr. Devren Unal, speaking on behalf of the Director of the Qatar Mobility Innovations Center (QMIC) and the KINDI Center for Computing Research, expressed his pleasure in cooperating with the Excellence Center to organize the seminar. He underscored the significance of cybersecurity in today's world and its challenges.
The seminar, moderated by Dr. Fadi Zaraket, Head of the Arab Digital Social Research Unit at the Arab Center for Research and Policy Studies, featured five key presentations. HE Dr. Ahmed bin Hamad Al-Mohannadi discussed ""Digital Transformation and Integrating Digital Technology in All Business Fields: Cloud Computing as a Model,"" highlighting the rapid evolution of artificial intelligence (AI) and its impact on daily life. He emphasized AI's benefits and risks and called for its positive utilization.
Dr. Rateb Al-Jabbar, a researcher in AI and cybersecurity at the KINDI Center, presented ""Generative AI: Cyber Risks and Ethical Challenges."" He explored generative AI's economic impact and ethical challenges, including privacy violations, legal accountability, model bias, and influence on employment.
Dr. Mohamed Al-Durani, Professor of Critical Security Studies at the Doha Institute, addressed global and regional cybersecurity challenges. He stressed the significant impacts of cyber threats on infrastructure, discussing ""ethical hacking"" and methods hackers use to infiltrate institutional systems.
Professor Dhiab Al-Badaina spoke about cyber defense and cyber-attacks using AI. He highlighted AI's dual role in defense and attack, ethical concerns over misuse, privacy fears, and regulatory gaps. Al-Badaina posed the question: Can AI take on the role of cybersecurity?
In the final presentation, Dr. Bashir bin Issa Al-Shirawi focused on ""Adhering to Ethical Principles in Developing Cybersecurity Strategies."" He elaborated on the ethical framework in cybersecurity, emphasizing core values such as integrity, accountability, privacy, justice, and diligence.
The seminar holds prominence in a world that is witnessing rapid digital transformations by the minute, where the internet plays a crucial role in social and economic development, improving quality of life, fostering innovation, and opening new opportunities across various sectors. However, cyberattacks targeting both public and private institutions have increased significantly, threatening national and economic security. These threats go beyond traditional breaches, encompassing attacks on personal data, critical infrastructure disruptions, and sensitive information leaks. This situation places growing pressure on governments and international institutions to address these challenges and enhance their ability to protect digital networks and systems.
Peninsula - Image
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1059
Subject: RESEARCH INSTITUTES (91%); CYBERATTACKS (90%); CYBERCRIME (90%); NEGATIVE TECHNOLOGY NEWS (90%); SOCIAL SCIENCES (90%); UNIVERSITY ADMINISTRATION (90%); COMPUTATIONAL RESEARCH (89%); COMPUTER SCIENCE (89%); ETHICS (89%); HACKING (89%); PUBLIC POLICY (89%); BUSINESS EDUCATION (78%); BUSINESS NEWS (78%); COMPUTER CRIME (78%); ECONOMICS (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); HUMANITIES & SOCIAL SCIENCE (78%); NEGATIVE NEWS (78%); PRIVACY RIGHTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); SOCIAL SCIENCE EDUCATION (76%); CRIME, LAW ENFORCEMENT & CORRECTIONS (75%); LAW ENFORCEMENT TRAINING (73%); ARTIFICIAL INTELLIGENCE (68%); GENERATIVE AI (68%); INVASION OF PRIVACY (60%)
Industry: CYBERATTACKS (90%); CYBERCRIME (90%); CYBERSECURITY (90%); INFORMATION SECURITY & PRIVACY (90%); COMPUTATIONAL RESEARCH (89%); COMPUTER SCIENCE (89%); HACKING (89%); COMPUTER CRIME (78%); CONSULTING SERVICES (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); COLLEGE & UNIVERSITY PROFESSORS (76%); LAW ENFORCEMENT TRAINING (73%); CLOUD COMPUTING (72%); ARTIFICIAL INTELLIGENCE (68%); GENERATIVE AI (68%)
Geographic: DOHA, QATAR (91%); QATAR (92%)
Load-Date: November 25, 2024","Doha, Qatar: The Excellence Center for Training and Consultancy at the Doha Institute for Graduate Studies DI organized, on Sunday, November 24, 2024, a seminar titled 'Cybersecurity and the Contemporary Challenges in Facing Cyber Intrusions: Practices and Ethics' in collaboration with the Kindi Center for Computing Research at Qatar University.
The event featured the participation of HE Dr Ahmed Bin Hamad AlMohanadi, Shura Council Member, and the attendance of HE Brigadier General Abdelrahman Al Sulaiti, President of the Police Academy, Dr. Abdelwahab ElAffendi, President of the DI, Dr Ayhab Saad, Dean of the School of Economics, Administration and Public Policy, Dr Amal Gazal, Dean of the School of Social Sciences and Humanities, with a number of leaders, academics and researchers.
In her opening remarks, Amal Al-Subaie, Manager of the Development and Initiatives Section at the Excellence Center, emphasized the growing cybersecurity threats globally. She highlighted the importance of raising societal and institutional awareness of these risks and the need for additional measures to ensure comprehensive protection against cyber threats.
Dr. Devren Unal, speaking on behalf of the Director of the Qatar Mobility Innovations Center (QMIC) and the KINDI Center for Computing Research, expressed his pleasure in cooperating with the Excellence Center to organize the seminar. He underscored the significance of cybersecurity in today's world and its challenges.
The seminar, moderated by Dr. Fadi Zaraket, Head of the Arab Digital Social Research Unit at the Arab Center for Research and Policy Studies, featured five key presentations. HE Dr. Ahmed bin Hamad Al-Mohannadi discussed ""Digital Transformation and Integrating Digital Technology in All Business Fields: Cloud Computing as a Model,"" highlighting the rapid evolution of artificial intelligence (AI) and its impact on daily life. He emphasized AI's benefits and risks and called for its positive utilization.
Dr. Rateb Al-Jabbar, a researcher in AI and cybersecurity at the KINDI Center, presented ""Generative AI: Cyber Risks and Ethical Challenges."" He explored generative AI's economic impact and ethical challenges, including privacy violations, legal accountability, model bias, and influence on employment.
Dr. Mohamed Al-Durani, Professor of Critical Security Studies at the Doha Institute, addressed global and regional cybersecurity challenges. He stressed the significant impacts of cyber threats on infrastructure, discussing ""ethical hacking"" and methods hackers use to infiltrate institutional systems.
Professor Dhiab Al-Badaina spoke about cyber defense and cyber-attacks using AI. He highlighted AI's dual role in defense and attack, ethical concerns over misuse, privacy fears, and regulatory gaps. Al-Badaina posed the question: Can AI take on the role of cybersecurity?
In the final presentation, Dr. Bashir bin Issa Al-Shirawi focused on ""Adhering to Ethical Principles in Developing Cybersecurity Strategies."" He elaborated on the ethical framework in cybersecurity, emphasizing core values such as integrity, accountability, privacy, justice, and diligence.
The seminar holds prominence in a world that is witnessing rapid digital transformations by the minute, where the internet plays a crucial role in social and economic development, improving quality of life, fostering innovation, and opening new opportunities across various sectors. However, cyberattacks targeting both public and private institutions have increased significantly, threatening national and economic security. These threats go beyond traditional breaches, encompassing attacks on personal data, critical infrastructure disruptions, and sensitive information leaks. This situation places growing pressure on governments and international institutions to address these challenges and enhance their ability to protect digital networks and systems.
Peninsula - Image
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1059
Subject: RESEARCH INSTITUTES (91%); CYBERATTACKS (90%); CYBERCRIME (90%); NEGATIVE TECHNOLOGY NEWS (90%); SOCIAL SCIENCES (90%); UNIVERSITY ADMINISTRATION (90%); COMPUTATIONAL RESEARCH (89%); COMPUTER SCIENCE (89%); ETHICS (89%); HACKING (89%); PUBLIC POLICY (89%); BUSINESS EDUCATION (78%); BUSINESS NEWS (78%); COMPUTER CRIME (78%); ECONOMICS (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); HUMANITIES & SOCIAL SCIENCE (78%); NEGATIVE NEWS (78%); PRIVACY RIGHTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); SOCIAL SCIENCE EDUCATION (76%); CRIME, LAW ENFORCEMENT & CORRECTIONS (75%); LAW ENFORCEMENT TRAINING (73%); ARTIFICIAL INTELLIGENCE (68%); GENERATIVE AI (68%); INVASION OF PRIVACY (60%)
Industry: CYBERATTACKS (90%); CYBERCRIME (90%); CYBERSECURITY (90%); INFORMATION SECURITY & PRIVACY (90%); COMPUTATIONAL RESEARCH (89%); COMPUTER SCIENCE (89%); HACKING (89%); COMPUTER CRIME (78%); CONSULTING SERVICES (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); COLLEGE & UNIVERSITY PROFESSORS (76%); LAW ENFORCEMENT TRAINING (73%); CLOUD COMPUTING (72%); ARTIFICIAL INTELLIGENCE (68%); GENERATIVE AI (68%)
Geographic: DOHA, QATAR (91%); QATAR (92%)
Load-Date: November 25, 2024",neutral,0.854145884513855,balanced/neutral,"['privacy', 'bias', 'accountability', 'security']","['justice', 'justice']","['policy', 'framework', 'law']",['generative ai'],4,2,3,1
2024,Unknown Title,"Body
       <p>We are heading towards a society in which <strong>artificial intelligence will become more and more intertwined with our social fabric</strong>. <strong>People and machines will increasingly intersect with each other</strong> to the point where the line that separates us today will become thinner and thinner...invisible......</p><p>This being the case, we must consider not only what AI can do, but above all how it should be done. In other words, <strong>introducing ethics into the AI that will surround us will be not only a good complement, but fundamental.</strong></p><p>This means that we will need to integrate ethical values into all stages of AI development. What does this idea imply?
 That it <strong>is not just a matter of avoiding the misuse of AI, but above all of consciously adopting moral principles to guide both the creation and application of these technologies</strong>. But: how do we ensure that AI acts in the best interests of humanity? And who decides what is 'best interests'?</p><p>Here, some will say, regulation....siempre....regulation comes into play. Our social lifeline... the thing is that<strong> regulation applied to AI can also limit innovation</strong>. By placing too many restrictions, we could stall technological progress that could solve some of humanity's most pressing problems. The key is to find a balance between innovation and ethical regulation, but is that balance really achievable?</p><p>As a society, <strong>we must be both the creators and custodians of the technology that will define the future</strong>. To that end, I envision a future where every AI developer has to take a 'technological Hippocratic' oath before writing a line of code. Not just ""thou shalt do no harm,"" but ""thou shalt not program harm."" </p><p>This commitment would not only emphasize the importance of integrity in technology, but could transform AI development into <strong>a practice as mindful and ethically guided as medicine</strong>. In this scenario, ethics would become as crucial a pillar as technological innovation, a balance that could ensure a future in which artificial intelligence amplifies the best of humanity without replicating its past mistakes made by companies like Google, Twitter, Amazon, Facebook and the like....</p>       
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); EMERGING TECHNOLOGY (78%); PRODUCT INNOVATION (68%); economia (%)
Company:  GOOGLE LLC (52%);  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (52%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%)
Load-Date: November 6, 2024","<p>We are heading towards a society in which <strong>artificial intelligence will become more and more intertwined with our social fabric</strong>. <strong>People and machines will increasingly intersect with each other</strong> to the point where the line that separates us today will become thinner and thinner...invisible......</p><p>This being the case, we must consider not only what AI can do, but above all how it should be done. In other words, <strong>introducing ethics into the AI that will surround us will be not only a good complement, but fundamental.</strong></p><p>This means that we will need to integrate ethical values into all stages of AI development. What does this idea imply?
 That it <strong>is not just a matter of avoiding the misuse of AI, but above all of consciously adopting moral principles to guide both the creation and application of these technologies</strong>. But: how do we ensure that AI acts in the best interests of humanity? And who decides what is 'best interests'?</p><p>Here, some will say, regulation....siempre....regulation comes into play. Our social lifeline... the thing is that<strong> regulation applied to AI can also limit innovation</strong>. By placing too many restrictions, we could stall technological progress that could solve some of humanity's most pressing problems. The key is to find a balance between innovation and ethical regulation, but is that balance really achievable?</p><p>As a society, <strong>we must be both the creators and custodians of the technology that will define the future</strong>. To that end, I envision a future where every AI developer has to take a 'technological Hippocratic' oath before writing a line of code. Not just ""thou shalt do no harm,"" but ""thou shalt not program harm."" </p><p>This commitment would not only emphasize the importance of integrity in technology, but could transform AI development into <strong>a practice as mindful and ethically guided as medicine</strong>. In this scenario, ethics would become as crucial a pillar as technological innovation, a balance that could ensure a future in which artificial intelligence amplifies the best of humanity without replicating its past mistakes made by companies like Google, Twitter, Amazon, Facebook and the like....</p>       
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); EMERGING TECHNOLOGY (78%); PRODUCT INNOVATION (68%); economia (%)
Company:  GOOGLE LLC (52%);  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (52%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%)
Load-Date: November 6, 2024",neutral,0.7382552623748779,balanced/neutral,[],[],"['regulation', 'policy', 'should', 'must', 'need to']",[],0,0,5,0
2024,Unknown Title,"Body
United Nations Education, Scientific and Cultural Organization (UNESCO) South Asia Regional Office, in collaboration with the Ministry of Electronics and Information Technology (MeitY), Government of India, hosted the National Stakeholder Workshop on Safe, Trusted and Ethical AI at the Taj Palace Hotel, New Delhi.
The event was held at a crucial juncture, following the Government of India's recent approval of the IndiaAI Mission, which has been allocated more than Rs 10,000 crore, marking a significant step towards bolstering India's AI ecosystem. The workshop provided a platform for critical discussions intended at integrating safe, trusted and ethical AI considerations into the national and state-level AI strategies and programmes, ensuring that the deployment of AI technologies aligns with public welfare and adheres to international norms and standards.
The Workshop featured participation from senior level officials from various Central Line Ministries, State Governments, NITI Aayog and Industry partners such as NASSCOM, ensuring a broad representation of perspectives. Extensive dialogue on the concept of safe and trusted AI, its ethical implications and the societal impact of AI technologies were deliberated upon through panel discussions with breakout group sessions on India harnessing ethical implementation of AI.
The inaugural session was graced by eminent dignitaries -Prof Ajay Kumar Sood, Principal Scientific Adviser to the Government of India; Shri Abhishek Singh, Additional Secretary, MeitY; Mr Tim Curtis, Director, UNESCO South Asia Regional Office and Ms Gabriela Ramos, UNESCO Assistant Director General for Social and Human Sciences.
The Workshop was also attended by Ms Debjani Ghosh, President NASSCOM; Shri Prakash Kumar, CEO at Wadhwani Centre for Government Digital Transformation; Mr James Wright, Programme Specialist, Section for Bioethics and the Ethics of Science and Technology, UNESCO Headquarters; Mr Joe Hironaka, Regional Advisor for Communication and Information, UNESCO Regional Office, Bangkok; Mr Jian Xi Teng, Programme Specialist, Education, UNESCO South Asia Regional Office and Ms Eunsong Kim, Programme Specialist, UNESCO South Asia Regional Office.
In his inaugural address, Prof Ajay Kumar Sood, PSA said, As AI raises concerns on ethics and its societal implications, India aims to adopt a balanced approach on AI. India has launched several initiatives including, the India AI mission to foster the development and adoption of AI. Globally, UNESCO has played a commendable role in promoting ethics of AI across the world and getting UNESCO Member States to support the UNESCO Recommendation on Ethics of AI is a great example.
Shri Abhishek Singh, Additional Secretary, MeitY elucidated, When it comes to the use of the word ethics, we prefer to define it in terms of building a safe and trusted AI which will not result in user harm; which will result in ensuring a framework that will promote innovation and that will restrict the risks that are related to AI.
The AI is expected to add nearly $500 billion to India's GDP by 2025, driven by advancements in various sectors such as healthcare, financial services, and telecommunications. To support this vision, MeitY has been entrusted with the responsibility of leading the IndiaAI Mission. This mission is set to further catalyze technological self-reliance across the nation through its key components, including the IndiaAI Compute Capacity, IndiaAI Innovation Centre (IAIC), IndiaAI Datasets Platform, IndiaAI Application Development Initiative, IndiaAI FutureSkills, IndiaAI Startup Financing, and Safe & Trusted AI.
The workshop's comprehensive agenda included sessions on AI fundamentals, Ethical Dimensions of AI, UNESCO's Role in AI ethics and the current AI policy landscape in India.By collectively enhancing understanding and preparing for challenges and opportunities presented by AI. The workshop aimed to establish a foundation for informed policy development that promotes equitable and sustainable AI adoption nationwide.
AI has immense potential to contribute in achieving the Sustainable Development Goals (SDGs); it also poses significant ethical and practical risks if deployed without proper frameworks ensuring ethical development and use. UNESCO aims to support the Indian government in integrating ethical considerations into the national and state-level AI strategies and programmes, ensuring that the deployment of AI technologies aligns with and adheres to international norms and standards outlined in the UNESCO Recommendation on the Ethics of Artificial Intelligence, Mr Tim Curtis, UNESCO Representative to India and the Director of UNESCO South Asia Regional Office said in his remarks.
As a panellist on the discussion on AI in India: Policy and Practice, NASSCOM President, Ms Debjani Ghosh opined, First, humans need to adhere to ethical standards, and then extend those principles to AI. Ethics is about equity and inclusion; we cannot afford a closed sytem where only a few companies control AI.
The 'Recommendation on the Ethics of Artificial Intelligence' was unanimously adopted in November 2021 by all 193 UNESCO Member States and is the first international standard setting instrument on the ethics of AI. The protection of human rights and dignity is the cornerstone of the Recommendation. This is largely based on fundamental principles such as transparency and fairness as well as to ensure the critical role of human oversight in maintaining checks in AI systems.
UNESCO is working with the Ministry of Electronics and IT, Government of India, to ensure that the core values and principles of the Global Recommendation is translated into concrete policy action with respect to data governance, environment and ecosystems, gender, education and research, and health and social wellbeing, among many other spheres.
(Press Information Bureau, Government of India)
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); TECHNOLOGY (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); GOVERNMENT ADVISORS & MINISTERS (79%); ALLIANCES & PARTNERSHIPS (78%); ASSOCIATIONS & ORGANIZATIONS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT BODIES & OFFICES (78%); REGIONAL & LOCAL GOVERNMENTS (78%); APPROVALS (73%); HUMANITIES & SOCIAL SCIENCE (73%); BIOETHICS (72%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); BANKING & FINANCE (73%); TELECOMMUNICATIONS (73%); HOTELS & MOTELS (57%)
Person: JAMES F WRIGHT (50%)
Geographic: BANGKOK, THAILAND (79%); NEW DELHI, INDIA (79%); INDIA (99%); ASIA (94%); SOUTHERN ASIA (94%)
Load-Date: June 7, 2024","United Nations Education, Scientific and Cultural Organization (UNESCO) South Asia Regional Office, in collaboration with the Ministry of Electronics and Information Technology (MeitY), Government of India, hosted the National Stakeholder Workshop on Safe, Trusted and Ethical AI at the Taj Palace Hotel, New Delhi.
The event was held at a crucial juncture, following the Government of India's recent approval of the IndiaAI Mission, which has been allocated more than Rs 10,000 crore, marking a significant step towards bolstering India's AI ecosystem. The workshop provided a platform for critical discussions intended at integrating safe, trusted and ethical AI considerations into the national and state-level AI strategies and programmes, ensuring that the deployment of AI technologies aligns with public welfare and adheres to international norms and standards.
The Workshop featured participation from senior level officials from various Central Line Ministries, State Governments, NITI Aayog and Industry partners such as NASSCOM, ensuring a broad representation of perspectives. Extensive dialogue on the concept of safe and trusted AI, its ethical implications and the societal impact of AI technologies were deliberated upon through panel discussions with breakout group sessions on India harnessing ethical implementation of AI.
The inaugural session was graced by eminent dignitaries -Prof Ajay Kumar Sood, Principal Scientific Adviser to the Government of India; Shri Abhishek Singh, Additional Secretary, MeitY; Mr Tim Curtis, Director, UNESCO South Asia Regional Office and Ms Gabriela Ramos, UNESCO Assistant Director General for Social and Human Sciences.
The Workshop was also attended by Ms Debjani Ghosh, President NASSCOM; Shri Prakash Kumar, CEO at Wadhwani Centre for Government Digital Transformation; Mr James Wright, Programme Specialist, Section for Bioethics and the Ethics of Science and Technology, UNESCO Headquarters; Mr Joe Hironaka, Regional Advisor for Communication and Information, UNESCO Regional Office, Bangkok; Mr Jian Xi Teng, Programme Specialist, Education, UNESCO South Asia Regional Office and Ms Eunsong Kim, Programme Specialist, UNESCO South Asia Regional Office.
In his inaugural address, Prof Ajay Kumar Sood, PSA said, As AI raises concerns on ethics and its societal implications, India aims to adopt a balanced approach on AI. India has launched several initiatives including, the India AI mission to foster the development and adoption of AI. Globally, UNESCO has played a commendable role in promoting ethics of AI across the world and getting UNESCO Member States to support the UNESCO Recommendation on Ethics of AI is a great example.
Shri Abhishek Singh, Additional Secretary, MeitY elucidated, When it comes to the use of the word ethics, we prefer to define it in terms of building a safe and trusted AI which will not result in user harm; which will result in ensuring a framework that will promote innovation and that will restrict the risks that are related to AI.
The AI is expected to add nearly $500 billion to India's GDP by 2025, driven by advancements in various sectors such as healthcare, financial services, and telecommunications. To support this vision, MeitY has been entrusted with the responsibility of leading the IndiaAI Mission. This mission is set to further catalyze technological self-reliance across the nation through its key components, including the IndiaAI Compute Capacity, IndiaAI Innovation Centre (IAIC), IndiaAI Datasets Platform, IndiaAI Application Development Initiative, IndiaAI FutureSkills, IndiaAI Startup Financing, and Safe & Trusted AI.
The workshop's comprehensive agenda included sessions on AI fundamentals, Ethical Dimensions of AI, UNESCO's Role in AI ethics and the current AI policy landscape in India.By collectively enhancing understanding and preparing for challenges and opportunities presented by AI. The workshop aimed to establish a foundation for informed policy development that promotes equitable and sustainable AI adoption nationwide.
AI has immense potential to contribute in achieving the Sustainable Development Goals (SDGs); it also poses significant ethical and practical risks if deployed without proper frameworks ensuring ethical development and use. UNESCO aims to support the Indian government in integrating ethical considerations into the national and state-level AI strategies and programmes, ensuring that the deployment of AI technologies aligns with and adheres to international norms and standards outlined in the UNESCO Recommendation on the Ethics of Artificial Intelligence, Mr Tim Curtis, UNESCO Representative to India and the Director of UNESCO South Asia Regional Office said in his remarks.
As a panellist on the discussion on AI in India: Policy and Practice, NASSCOM President, Ms Debjani Ghosh opined, First, humans need to adhere to ethical standards, and then extend those principles to AI. Ethics is about equity and inclusion; we cannot afford a closed sytem where only a few companies control AI.
The 'Recommendation on the Ethics of Artificial Intelligence' was unanimously adopted in November 2021 by all 193 UNESCO Member States and is the first international standard setting instrument on the ethics of AI. The protection of human rights and dignity is the cornerstone of the Recommendation. This is largely based on fundamental principles such as transparency and fairness as well as to ensure the critical role of human oversight in maintaining checks in AI systems.
UNESCO is working with the Ministry of Electronics and IT, Government of India, to ensure that the core values and principles of the Global Recommendation is translated into concrete policy action with respect to data governance, environment and ecosystems, gender, education and research, and health and social wellbeing, among many other spheres.
(Press Information Bureau, Government of India)
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); TECHNOLOGY (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); GOVERNMENT ADVISORS & MINISTERS (79%); ALLIANCES & PARTNERSHIPS (78%); ASSOCIATIONS & ORGANIZATIONS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT BODIES & OFFICES (78%); REGIONAL & LOCAL GOVERNMENTS (78%); APPROVALS (73%); HUMANITIES & SOCIAL SCIENCE (73%); BIOETHICS (72%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); BANKING & FINANCE (73%); TELECOMMUNICATIONS (73%); HOTELS & MOTELS (57%)
Person: JAMES F WRIGHT (50%)
Geographic: BANGKOK, THAILAND (79%); NEW DELHI, INDIA (79%); INDIA (99%); ASIA (94%); SOUTHERN ASIA (94%)
Load-Date: June 7, 2024",neutral,0.676315426826477,balanced/neutral,"['fairness', 'transparency', 'human rights']","['fairness', 'equity', 'dignity']","['policy', 'governance', 'oversight', 'standards', 'framework', 'need to']",[],3,3,6,0
2024,Unknown Title,"Body
2024 NOV 05 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators discuss new findings in artificial intelligence. According to news reporting out of Tehran, Iran, by NewsRx editors, research stated, ""There are whispers about whether or not Artificial Intelligence (AI) will become more powerful in the field of competition with the human resources of organizations."" 
 The news journalists obtained a quote from the research from Islamic Azad University: ""The main problem for organizations to use AI is the mental ambiguity of their organizational resources about this intelligence in the field of professional ethics. The use of AI in business requires a manager who is familiar with AI issues. Unfortunately, many human resource managers still think AI is a myth, have unscientific and somewhat imaginative expectations, and do not know what transformation AI can bring to their business. This study uses a qualitative meta-analysis method to explore and synthesize existing literature on the role of organizational human ethics based on AI management. Based on the findings of the research, the components of AI management based on professional ethics as a commitment to ethics, ability to explain, fairness, robustness, transparency, privacy protection, international cooperation of use, awareness, use of good data hygiene, use of good data collection, were identified. Controlling users and reducing the algorithmic bias of AI has no place among human intelligence and can only be defined as a helper and not a substitute for humans and the humanity of human resources of organizations."" 
 According to the news reporters, the research concluded: ""If in planning the development of AI, human and ethical issues are considered together, organizations can hope to realize the dream of ethical and entrepreneurial AI."" 
 For more information on this research see: Artificial Intelligence Ethics in Organizational Human Resources Management. International Journal of Management, Accounting and Economics, 2024,11(7):930-950. The publisher for International Journal of Management, Accounting and Economics is Mashhad: Behzad Hassannezhad Kashani. 
 A free version of this journal article is available at https://doi.org/10.5281/zenodo.12752414. 
 Our news editors report that additional information may be obtained by contacting Behnoush Jovari, Department of Public Management, Central Tehran Branch, Islamic Azad University, Tehran, Iran. 
 Keywords for this news article include: Islamic Azad University, Tehran, Iran, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (92%); HUMAN RESOURCES (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); HUMAN RESOURCES & PERSONNEL MANAGEMENT (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); MANAGERS & SUPERVISORS (90%); MUSLIMS & ISLAM (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RELIGION (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); NEWS REPORTING (78%); INTELLIGENCE & COGNITION (75%); EMERGING TECHNOLOGY (74%); ENTREPRENEURSHIP (74%); TECHNOLOGY (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); INTERNATIONAL RELATIONS (67%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  RESOURCE MANAGEMENT INTERNATIONAL INC (58%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); INFORMATION SECURITY & PRIVACY (70%)
Geographic: TEHRAN, IRAN (90%); MASHHAD, IRAN (58%); ASIA (78%)
Load-Date: November 5, 2024","2024 NOV 05 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators discuss new findings in artificial intelligence. According to news reporting out of Tehran, Iran, by NewsRx editors, research stated, ""There are whispers about whether or not Artificial Intelligence (AI) will become more powerful in the field of competition with the human resources of organizations."" 
 The news journalists obtained a quote from the research from Islamic Azad University: ""The main problem for organizations to use AI is the mental ambiguity of their organizational resources about this intelligence in the field of professional ethics. The use of AI in business requires a manager who is familiar with AI issues. Unfortunately, many human resource managers still think AI is a myth, have unscientific and somewhat imaginative expectations, and do not know what transformation AI can bring to their business. This study uses a qualitative meta-analysis method to explore and synthesize existing literature on the role of organizational human ethics based on AI management. Based on the findings of the research, the components of AI management based on professional ethics as a commitment to ethics, ability to explain, fairness, robustness, transparency, privacy protection, international cooperation of use, awareness, use of good data hygiene, use of good data collection, were identified. Controlling users and reducing the algorithmic bias of AI has no place among human intelligence and can only be defined as a helper and not a substitute for humans and the humanity of human resources of organizations."" 
 According to the news reporters, the research concluded: ""If in planning the development of AI, human and ethical issues are considered together, organizations can hope to realize the dream of ethical and entrepreneurial AI."" 
 For more information on this research see: Artificial Intelligence Ethics in Organizational Human Resources Management. International Journal of Management, Accounting and Economics, 2024,11(7):930-950. The publisher for International Journal of Management, Accounting and Economics is Mashhad: Behzad Hassannezhad Kashani. 
 A free version of this journal article is available at https://doi.org/10.5281/zenodo.12752414. 
 Our news editors report that additional information may be obtained by contacting Behnoush Jovari, Department of Public Management, Central Tehran Branch, Islamic Azad University, Tehran, Iran. 
 Keywords for this news article include: Islamic Azad University, Tehran, Iran, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (92%); HUMAN RESOURCES (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); HUMAN RESOURCES & PERSONNEL MANAGEMENT (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); MANAGERS & SUPERVISORS (90%); MUSLIMS & ISLAM (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RELIGION (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); NEWS REPORTING (78%); INTELLIGENCE & COGNITION (75%); EMERGING TECHNOLOGY (74%); ENTREPRENEURSHIP (74%); TECHNOLOGY (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); INTERNATIONAL RELATIONS (67%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  RESOURCE MANAGEMENT INTERNATIONAL INC (58%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); INFORMATION SECURITY & PRIVACY (70%)
Geographic: TEHRAN, IRAN (90%); MASHHAD, IRAN (58%); ASIA (78%)
Load-Date: November 5, 2024",neutral,0.9324007630348206,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'security']",['fairness'],[],"['machine learning', 'robotics']",5,1,0,2
2024,Unknown Title,"Body
Link to Story
Readers' Favorite announces the review of the Non-Fiction - Business/Finance book ""Navigating Ethical Leadership in the Age of AI"" by Annette Bühler, currently available at .
Readers' Favorite is one of the largest book review and award contest sites on the Internet. They have earned the respect of renowned publishers like Random House, Simon & Schuster, and Harper Collins, and have received the ""Best Websites for Authors"" and ""Honoring Excellence"" awards from the Association of Independent Authors. They are also fully accredited by the BBB (A+ rating), which is a rarity among Book Review and Book Award Contest companies.
""Reviewed By Asher Syed for Readers' Favorite
Annette Bühler's Navigating Ethical Leadership in the Age of AI: The Ethic Pocketknife covers the roles of ethical leadership as AI technologies take off. Bühler emphasizes how important it is to incorporate ethical frameworks-deontological, teleological, and virtue ethics-into leadership work to avoid any ethical hitches with AI, like data privacy, bias, and transparency. Bühler gives us the ""Ethic Pocketknife,"" a toolkit to help leaders add ethical considerations to their decision-making. Her toolkit includes sections like the Integrity Blade and Fairness File, which help make sure decisions are in line with human values and society. Bühler shows us its application by including case studies in sectors like healthcare and fintech, drawing out continuous improvement, stakeholder engagement, and the balance between technological progress and ethical standards.
""Ethical sensitivity means recognizing the broader implications of our actions and striving to do what is right, even when it's not the easiest path."" Annette Bühler has done an excellent job of writing clear and well-structured arguments logically in Navigating Ethical Leadership in the Age of AI, breaking the work down into organized sections, distinct definitions, and in a style that is both professional and wonderfully accessible. Bühler amplifies this for readers by giving actionable insight that can be applied to businesses in almost any sector. I really appreciate the practical tools she spells out for us, the key piece being the Ethic Pocketknife. It's quite an innovative concept when you think about the handiness of a pocketknife, and I loved that the different tools that flip out of it are symbolic of Bühler's components. I'm partial to the Collaboration Corkscrew; you'll have to find out for yourself what that means. Overall, this is a fantastic, progressive, and forward-thinking guide that should be required reading for leaders, and leaders in the making.""
You can learn more about Annette Bühler and ""Navigating Ethical Leadership in the Age of AI"" at where you can read reviews and the author's biography, as well as connect with the author directly or through their website and social media pages.
MENAFN25102024003238003268ID1108819611
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); BOOK REVIEWS (90%); PRESS RELEASES (90%); WRITERS (90%); TECHNOLOGY (89%); BIOGRAPHICAL LITERATURE (78%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); CASE STUDIES (77%); ACCREDITATION (75%); QUALITY CONTROL (75%); BETTER BUSINESS BUREAUS (73%); PROFILES & BIOGRAPHIES (73%); SOCIAL MEDIA (72%)
Company:  SIMON & SCHUSTER INC (57%);  BEST INC (57%)
Ticker: BEST (NYSE) (57%)
Industry: NAICS513130 BOOK PUBLISHERS (57%); SIC2731 BOOKS: PUBLISHING, OR PUBLISHING & PRINTING (57%); SIC5999 MISCELLANEOUS RETAIL STORES, NEC (57%); BOOK REVIEWS (90%); WRITERS (90%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); PUBLISHING (78%); INTERNET & WWW (77%); WEBSITES (77%); SOCIAL MEDIA (72%); INFORMATION SECURITY & PRIVACY (67%)
Load-Date: March 5, 2025","Link to Story
Readers' Favorite announces the review of the Non-Fiction - Business/Finance book ""Navigating Ethical Leadership in the Age of AI"" by Annette Bühler, currently available at .
Readers' Favorite is one of the largest book review and award contest sites on the Internet. They have earned the respect of renowned publishers like Random House, Simon & Schuster, and Harper Collins, and have received the ""Best Websites for Authors"" and ""Honoring Excellence"" awards from the Association of Independent Authors. They are also fully accredited by the BBB (A+ rating), which is a rarity among Book Review and Book Award Contest companies.
""Reviewed By Asher Syed for Readers' Favorite
Annette Bühler's Navigating Ethical Leadership in the Age of AI: The Ethic Pocketknife covers the roles of ethical leadership as AI technologies take off. Bühler emphasizes how important it is to incorporate ethical frameworks-deontological, teleological, and virtue ethics-into leadership work to avoid any ethical hitches with AI, like data privacy, bias, and transparency. Bühler gives us the ""Ethic Pocketknife,"" a toolkit to help leaders add ethical considerations to their decision-making. Her toolkit includes sections like the Integrity Blade and Fairness File, which help make sure decisions are in line with human values and society. Bühler shows us its application by including case studies in sectors like healthcare and fintech, drawing out continuous improvement, stakeholder engagement, and the balance between technological progress and ethical standards.
""Ethical sensitivity means recognizing the broader implications of our actions and striving to do what is right, even when it's not the easiest path."" Annette Bühler has done an excellent job of writing clear and well-structured arguments logically in Navigating Ethical Leadership in the Age of AI, breaking the work down into organized sections, distinct definitions, and in a style that is both professional and wonderfully accessible. Bühler amplifies this for readers by giving actionable insight that can be applied to businesses in almost any sector. I really appreciate the practical tools she spells out for us, the key piece being the Ethic Pocketknife. It's quite an innovative concept when you think about the handiness of a pocketknife, and I loved that the different tools that flip out of it are symbolic of Bühler's components. I'm partial to the Collaboration Corkscrew; you'll have to find out for yourself what that means. Overall, this is a fantastic, progressive, and forward-thinking guide that should be required reading for leaders, and leaders in the making.""
You can learn more about Annette Bühler and ""Navigating Ethical Leadership in the Age of AI"" at where you can read reviews and the author's biography, as well as connect with the author directly or through their website and social media pages.
MENAFN25102024003238003268ID1108819611
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); BOOK REVIEWS (90%); PRESS RELEASES (90%); WRITERS (90%); TECHNOLOGY (89%); BIOGRAPHICAL LITERATURE (78%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); CASE STUDIES (77%); ACCREDITATION (75%); QUALITY CONTROL (75%); BETTER BUSINESS BUREAUS (73%); PROFILES & BIOGRAPHIES (73%); SOCIAL MEDIA (72%)
Company:  SIMON & SCHUSTER INC (57%);  BEST INC (57%)
Ticker: BEST (NYSE) (57%)
Industry: NAICS513130 BOOK PUBLISHERS (57%); SIC2731 BOOKS: PUBLISHING, OR PUBLISHING & PRINTING (57%); SIC5999 MISCELLANEOUS RETAIL STORES, NEC (57%); BOOK REVIEWS (90%); WRITERS (90%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); PUBLISHING (78%); INTERNET & WWW (77%); WEBSITES (77%); SOCIAL MEDIA (72%); INFORMATION SECURITY & PRIVACY (67%)
Load-Date: March 5, 2025",positive,0.5249064564704895,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'security']","['deontological', 'virtue ethics', 'fairness']","['standards', 'should']",[],5,3,2,0
2024,Unknown Title,"Byline: Jack O'Neill
Body
Artificial Intelligence, especially generative AI, is no longer the stuff of science fiction - it's here, it's powerful, and it's transforming every facet of our lives. From healthcare and finance to environmental management and entertainment, its influence is per­vasive. But here's the catch: while AI holds immense promise, it also poses significant risks if not guided by strong ethical principles.
Australian business stands at a crossroads. Will we harness AI responsibly to benefit all, or will we let it run mostly unchecked, risking societal harm and eroding public trust?
The high stakes of ignoring AI ethics
Imagine a future where AI systems make decisions that unfairly discriminate, invade privacy, or operate without accountability. Without ethical oversight, this isn't a dystopian fantasy -  but a looming reality. Missteps in AI can lead to public backlash, legal troubles, and long-term damage to brand reputations. Some 58 per cent of Australians are concerned about privacy and security issues with AI accessing their personal data; they need transparency, according to Dentsu's Data Consciousness Project. Companies that ignore these demands risk losing customer loyalty and market share.
Experts, including two of the three ""godfathers"" of modern AI, Geoffrey Hinton and Yoshua Bengio, believe society isn't putting enough of a priority on the risks of AI misuse, focusing instead on pushing the boundaries of innovation whatever the cost to society.
But we can't ignore the risk to society. We need to be able to understand and address how AI can falter, in three pivotal ways.
First, it's only as good as the data we feed it. If that data is biased, unrepresentative, or flawed, the AI's decisions will mirror those imperfections - sometimes with serious repercussions. This year New York City council's new AI chatbot designed to help businesses navigate regulations went awry due to flawed training data. Instead of promoting compliance, it advised companies to ignore legal requirements, essentially telling them to break the law. This was due to  incomplete data that failed to  cover the complex legal landscape.
Second, AI ""hallucinations"" occur when systems generate outputs that are false, misleading, or downright nonsensical, yet present them as accurate, leading to misinformation and eroding trust. In April, Elon Musk's AI chatbot Grok hallucinated publicly and accused NBA start Klay Thompson of going on a vandalism spree in California. To be clear, he did no such thing. It was pointed out that Grok likely confused a common basketball term in which players are said to be throwing ""bricks"" - when they take an air ball shot that doesn't hit the rim - with vandalism.
Third, as AI becomes more sophisticated, there's a danger that humans might over-rely on it, removing responsibility to think critically and make informed judgments. This complacency can allow errors to go unchecked and ethical oversights to multiply, undermining the very benefits AI seeks to provide. Famously in 2023, a lawyer at Levidow, Levidow & Oberman relied on ChatGPT to research precedents for a case. But at least six of the cases submitted in the brief didn't exist. The result was a fine for the business and the case being thrown out, leading to significant brand damage to the firm.
The importance of having human oversight
To prevent AI systems from making flawed decisions that could lead to financial troubles or damage reputations, businesses must implement rigorous data management and ethical practices. This means ensuring all training data is accurate and truly representative of Australia's diverse population - regularly auditing datasets for ­biases and inaccuracies.
Ethical data sourcing is just as crucial: collect data responsibly, respect privacy laws, obtain necessary consent, and avoid perpetuating stereotypes or discrimination. Moreover, involving diverse teams in AI development brings varied perspectives, helping to spot biases that homogeneous groups might overlook. By prioritising data integrity and ethics, companies can safeguard against the pitfalls of flawed or biased training data.
We need to maintain a level of human oversight and human verification mechanisms, aligning with best practice policies laid out by the federal government to ­ensure we're not missing critical decision-making processes.
Continuous staff training about AI limitations and the importance of critical thinking is essential, emphasising that AI is a tool to aid, not replace, human judgment. By fostering a culture of scepticism and verification, Australian businesses can avoid AI errors and maintain trust with their stakeholders.
Call to action: Embrace ethical AI or risk being left behind
The race for AI advancement is on, but without ethics or guardrails, it's a race to the bottom. Companies that ignore ethical principles may gain short-term advantages but will ultimately face backlash - from consumers, regulators, and society at large.
AI systems must operate in alignment with human values. Brands must put people and community above the short-term advantages and focus on driving AI innovation within an ethical framework. This is the only way AI can drive positive results for people, society and business.
Jack O'Neill is client partner at Merkle, a Dentsu company.
Notes
Document links may not lead to an active page. Page maintenance is at the discretion of the publisher.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: The Australian
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); VANDALISM (78%); BRANDING (77%); DISCRIMINATION (77%); PRIVACY RIGHTS (76%); CITY GOVERNMENT (71%); INVASION OF PRIVACY (71%); BASKETBALL (63%); DISINFORMATION & MISINFORMATION (63%); CITIES (57%); ENVIRONMENT & NATURAL RESOURCES (57%); decision-making processes (%); positive results (%); United States of America (%); backlash-from consumers (%); vandalism spree (%); security issues (%); North America (%); Oceania (%); Klay Thompson (%); air ball shot (%); Levidow, Levidow & Oberman (%); science fiction-it (%); eroding trust (%); America (%); training data (%); federal government (%); Ethical data sourcing (%); market share (%); rigorous data management (%); New York (%); human judgment (%); City council (%); Geoffrey Hinton (%); Australia and New Zealand (%); client partner (%); prioritising data integrity (%); losing customer loyalty (%); human values (%); Australian businesses (%); California (%); respect privacy laws (%); Continuous staff training (%); research precedents (%); practice policies (%); ethical principles (%); human oversight (%); Northern America (%); human verification mechanisms (%); looming reality (%); immense promise (%); Elon Musk (%); Australia (%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); INFORMATION SECURITY & PRIVACY (78%); BRANDING (77%); MARKET SHARE (72%)
Person: KLAY THOMPSON (88%); ELON MUSK (72%)
Geographic: NEW YORK, NY, USA (78%); CALIFORNIA, USA (92%); NEW YORK, USA (90%); AUSTRALIA (93%); UNITED STATES (93%); AUSTRALIA & NEW ZEALAND (79%); NEW ZEALAND (79%); NORTH AMERICA (79%); OCEANIA (73%)
Load-Date: November 17, 2024","Artificial Intelligence, especially generative AI, is no longer the stuff of science fiction - it's here, it's powerful, and it's transforming every facet of our lives. From healthcare and finance to environmental management and entertainment, its influence is per­vasive. But here's the catch: while AI holds immense promise, it also poses significant risks if not guided by strong ethical principles.
Australian business stands at a crossroads. Will we harness AI responsibly to benefit all, or will we let it run mostly unchecked, risking societal harm and eroding public trust?
The high stakes of ignoring AI ethics
Imagine a future where AI systems make decisions that unfairly discriminate, invade privacy, or operate without accountability. Without ethical oversight, this isn't a dystopian fantasy -  but a looming reality. Missteps in AI can lead to public backlash, legal troubles, and long-term damage to brand reputations. Some 58 per cent of Australians are concerned about privacy and security issues with AI accessing their personal data; they need transparency, according to Dentsu's Data Consciousness Project. Companies that ignore these demands risk losing customer loyalty and market share.
Experts, including two of the three ""godfathers"" of modern AI, Geoffrey Hinton and Yoshua Bengio, believe society isn't putting enough of a priority on the risks of AI misuse, focusing instead on pushing the boundaries of innovation whatever the cost to society.
But we can't ignore the risk to society. We need to be able to understand and address how AI can falter, in three pivotal ways.
First, it's only as good as the data we feed it. If that data is biased, unrepresentative, or flawed, the AI's decisions will mirror those imperfections - sometimes with serious repercussions. This year New York City council's new AI chatbot designed to help businesses navigate regulations went awry due to flawed training data. Instead of promoting compliance, it advised companies to ignore legal requirements, essentially telling them to break the law. This was due to  incomplete data that failed to  cover the complex legal landscape.
Second, AI ""hallucinations"" occur when systems generate outputs that are false, misleading, or downright nonsensical, yet present them as accurate, leading to misinformation and eroding trust. In April, Elon Musk's AI chatbot Grok hallucinated publicly and accused NBA start Klay Thompson of going on a vandalism spree in California. To be clear, he did no such thing. It was pointed out that Grok likely confused a common basketball term in which players are said to be throwing ""bricks"" - when they take an air ball shot that doesn't hit the rim - with vandalism.
Third, as AI becomes more sophisticated, there's a danger that humans might over-rely on it, removing responsibility to think critically and make informed judgments. This complacency can allow errors to go unchecked and ethical oversights to multiply, undermining the very benefits AI seeks to provide. Famously in 2023, a lawyer at Levidow, Levidow & Oberman relied on ChatGPT to research precedents for a case. But at least six of the cases submitted in the brief didn't exist. The result was a fine for the business and the case being thrown out, leading to significant brand damage to the firm.
The importance of having human oversight
To prevent AI systems from making flawed decisions that could lead to financial troubles or damage reputations, businesses must implement rigorous data management and ethical practices. This means ensuring all training data is accurate and truly representative of Australia's diverse population - regularly auditing datasets for ­biases and inaccuracies.
Ethical data sourcing is just as crucial: collect data responsibly, respect privacy laws, obtain necessary consent, and avoid perpetuating stereotypes or discrimination. Moreover, involving diverse teams in AI development brings varied perspectives, helping to spot biases that homogeneous groups might overlook. By prioritising data integrity and ethics, companies can safeguard against the pitfalls of flawed or biased training data.
We need to maintain a level of human oversight and human verification mechanisms, aligning with best practice policies laid out by the federal government to ­ensure we're not missing critical decision-making processes.
Continuous staff training about AI limitations and the importance of critical thinking is essential, emphasising that AI is a tool to aid, not replace, human judgment. By fostering a culture of scepticism and verification, Australian businesses can avoid AI errors and maintain trust with their stakeholders.
Call to action: Embrace ethical AI or risk being left behind
The race for AI advancement is on, but without ethics or guardrails, it's a race to the bottom. Companies that ignore ethical principles may gain short-term advantages but will ultimately face backlash - from consumers, regulators, and society at large.
AI systems must operate in alignment with human values. Brands must put people and community above the short-term advantages and focus on driving AI innovation within an ethical framework. This is the only way AI can drive positive results for people, society and business.
Jack O'Neill is client partner at Merkle, a Dentsu company.
Notes
Document links may not lead to an active page. Page maintenance is at the discretion of the publisher.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: The Australian
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); VANDALISM (78%); BRANDING (77%); DISCRIMINATION (77%); PRIVACY RIGHTS (76%); CITY GOVERNMENT (71%); INVASION OF PRIVACY (71%); BASKETBALL (63%); DISINFORMATION & MISINFORMATION (63%); CITIES (57%); ENVIRONMENT & NATURAL RESOURCES (57%); decision-making processes (%); positive results (%); United States of America (%); backlash-from consumers (%); vandalism spree (%); security issues (%); North America (%); Oceania (%); Klay Thompson (%); air ball shot (%); Levidow, Levidow & Oberman (%); science fiction-it (%); eroding trust (%); America (%); training data (%); federal government (%); Ethical data sourcing (%); market share (%); rigorous data management (%); New York (%); human judgment (%); City council (%); Geoffrey Hinton (%); Australia and New Zealand (%); client partner (%); prioritising data integrity (%); losing customer loyalty (%); human values (%); Australian businesses (%); California (%); respect privacy laws (%); Continuous staff training (%); research precedents (%); practice policies (%); ethical principles (%); human oversight (%); Northern America (%); human verification mechanisms (%); looming reality (%); immense promise (%); Elon Musk (%); Australia (%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); INFORMATION SECURITY & PRIVACY (78%); BRANDING (77%); MARKET SHARE (72%)
Person: KLAY THOMPSON (88%); ELON MUSK (72%)
Geographic: NEW YORK, NY, USA (78%); CALIFORNIA, USA (92%); NEW YORK, USA (90%); AUSTRALIA (93%); UNITED STATES (93%); AUSTRALIA & NEW ZEALAND (79%); NEW ZEALAND (79%); NORTH AMERICA (79%); OCEANIA (73%)
Load-Date: November 17, 2024",neutral,0.5585551261901855,balanced/neutral,"['privacy', 'discrimination', 'transparency', 'accountability', 'security', 'consent', 'misinformation', 'disinformation']",[],"['oversight', 'framework', 'law', 'compliance', 'must', 'need to']","['generative ai', 'chatgpt']",8,0,6,2
2024,Unknown Title,"Body
ABSTRACT
Understanding DealStats: What You Need to Know (FREE WEBINAR), December 11, 10:00 a.m.-11:15 a.m. PT/1:00 p.m.-2:15 p.m. ET. Featuring: Adam Manson (Business Valuation Resources) and Oday Merhi (Business Valuation Resources). CPE credits: 1.5.
FULL TEXT
 Understanding DealStats: What You Need to Know (FREE WEBINAR) , December 11, 10:00 a.m.-11:15 a.m. PT/1:00 p.m.-2:15 p.m. ET. Featuring: Adam Manson (Business Valuation Resources) and Oday Merhi (Business Valuation Resources). CPE credits: 1.5.
Are you aware of the newest enhancements to DealStats? The speakers will cover them and include a background on the resource, such as the data sources DealStats uses, how the data are reviewed and vetted, and what benefits the database can provide.
 Ethical Issues in Business Valuation—December 2024 , December 12, 10:00 a.m.-11:40 a.m. PT/1:00 p.m.-2:40 p.m. ET. Featuring: R. James Alerding (Alerding Consulting) and John Barrett Jr. (Barrett Valuation Services Inc.). CPE credits: 2.0.
The speakers will cover a broad range of ethical topics, from review of BV standards relating to ethics to examples of ethical issues in practice, as well as a section discussing ethical issues relating to artificial intelligence (AI).
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (92%); BUSINESS ETHICS (78%); ARTIFICIAL INTELLIGENCE ETHICS (74%); ARTIFICIAL INTELLIGENCE (65%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (74%); ARTIFICIAL INTELLIGENCE (65%)
Load-Date: December 12, 2024","ABSTRACT
Understanding DealStats: What You Need to Know (FREE WEBINAR), December 11, 10:00 a.m.-11:15 a.m. PT/1:00 p.m.-2:15 p.m. ET. Featuring: Adam Manson (Business Valuation Resources) and Oday Merhi (Business Valuation Resources). CPE credits: 1.5.
FULL TEXT
 Understanding DealStats: What You Need to Know (FREE WEBINAR) , December 11, 10:00 a.m.-11:15 a.m. PT/1:00 p.m.-2:15 p.m. ET. Featuring: Adam Manson (Business Valuation Resources) and Oday Merhi (Business Valuation Resources). CPE credits: 1.5.
Are you aware of the newest enhancements to DealStats? The speakers will cover them and include a background on the resource, such as the data sources DealStats uses, how the data are reviewed and vetted, and what benefits the database can provide.
 Ethical Issues in Business Valuation—December 2024 , December 12, 10:00 a.m.-11:40 a.m. PT/1:00 p.m.-2:40 p.m. ET. Featuring: R. James Alerding (Alerding Consulting) and John Barrett Jr. (Barrett Valuation Services Inc.). CPE credits: 2.0.
The speakers will cover a broad range of ethical topics, from review of BV standards relating to ethics to examples of ethical issues in practice, as well as a section discussing ethical issues relating to artificial intelligence (AI).
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (92%); BUSINESS ETHICS (78%); ARTIFICIAL INTELLIGENCE ETHICS (74%); ARTIFICIAL INTELLIGENCE (65%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (74%); ARTIFICIAL INTELLIGENCE (65%)
Load-Date: December 12, 2024",neutral,0.9069529175758362,balanced/neutral,[],[],"['standards', 'need to']",[],0,0,2,0
2024,Unknown Title,"Byline: States News Service
Dateline: GARRISON, NY 
Body
The following information was released by the Hastings Center:
The Hastings Center is pleased to announce the election of the 2024 fellows. Hastings Center fellows are a group of about 300 individuals of outstanding accomplishment whose work has informed scholarship and public understanding of complex ethical issues in health, health care, science, and technology.
""Our new fellows are leaders in a wide range of areas of global importance, including ethical issues in infectious disease outbreaks, AI in health, neuroscience, reproductive rights, genetics and race, and disability,"" said Hastings Center President Vardit Ravitsky. ""I welcome them and look forward to working with them.""
""We are proud to announce this dynamic slate of Hastings Center fellows,"" said Michele Goodwin, the chair of the Fellow's Council, who is Linda D. and Timothy J. O'Neill Professor of Constitutional Law and Global Health Policy at Georgetown Law School. ""These individuals are thought leaders whose research, scholarship, and policy advocacy have shaped the bioethics and health fields in tremendous, impactful ways.Theircontributions in policy and academic discourses offer urgentlyneeded pathways forward for tackling the most challenging health related conundrums. We are honored to recognize them and their election to this esteemed fellowship.""
The 2024 Hastings Center fellows are:
Carl Coleman, JD, is Associate Dean for Graduate Programs and Professor of Law at Seton Hall Law. He specializes in the legal, ethical, and public policy implications of medical treatment, research, and public health. He served as Bioethics and Law Adviser at the World Health Organization from 2006 to 2007 and has continued to work closely with WHO's Global Health Ethics team. In addition, he is the lead author of numerous WHO guidance documents on topics such as ethical issues in infectious disease outbreaks, tuberculosis care and control, and clinical trials oversight. From 2010 to 2013, he was a member of the Secretary's Advisory Committee on Human Research Protections, which is charged with providing expert advice to the Office for Human Research Protections of the U.S. Department of Health and Human Services. Prior to joining the Seton Hall faculty, he served as Executive Director of the New York State Task Force on Life and the Law, supporting the Task Force's work in the areas of end-of-life decision-making, assisted reproductive technologies, and genetic testing and screening. Carl H. Coleman Seton Hall Law School
Jennifer L. Gibson, PhD, is the Sun Life Financial Chair in Bioethics andDirector of the University of Toronto Joint Centre for Bioethics (JCB) and an associate professor in the Division of Clinical Public Health and the Institute of Health Policy, Management, and Evaluation of the Dalla Lana School of Public Health. She is a health policy ethics scholar whose research, teaching, and policy work focuses on ethical issues in contemporary health institutions and systems. She has advised governments and policymakers on issues such as medical assistance in dying, public health emergencies, health technology assessment, drug funding and supply, and resource allocation. From 2020 to 2022, she created and co-chaired the Ontario Covid-19 Bioethics Table and served as bioethics advisor to several planning tables of the Ontario Ministry of Health. In 2018, she founded the JCB's Ethics and AI for Good Health Program, which explores and engages inethics and governance issues associated with AI in health care and public health through research and training initiatives.In addition, she is a member of the WHO Expert Group on Ethics and Governance of AI for Health and recently completed a three-year ministerial appointment as Vice-Chair of the Ontario Health Data Council. Her research and policy interests are increasingly turning toward the ethics in and of wicked problems, including problems involving convergent existential risk and their implications for health and a sustainable future for all. https://jcb.utoronto.ca/people/our-team/jennifer-gibson/
James Giordano, PhD, DPhil, is the Pellegrino Center Professor in the Departments of Neurology and Biochemistry and Chief of the Neuroethics Studies Program at Georgetown University Medical Center. He is senior bioethicist of the Defense Medical Ethics Center and adjunct professor of Psychiatry at the Uniformed Services University of Health Sciences; Distinguished Visiting Professor of Health Promotions, Technology and Ethics at the Coburg University of Applied Sciences in Germany; Stockdale Fellow in Science, Technology, and Ethics at the United States Naval Academy; Senior Science Advisory Fellow of the Strategic Multilayer Assessment Branch of the Joint Staff, Pentagon; and Chair Emeritus of the IEEE Brain Initiative Project on Neurotechnology and Ethics. Previously, he was Fellow and Task Leader of the Neuroethics Study Section of the European Union Human Brain Project. He is an elected member of the U.S. Department of Health and Human Services Secretary's Advisory Committee; Fulbright Professor of Neuroscience and the European Academy of Science and Arts Neuroethics at the Ludwig Maximilians University in Munich; and Associate Fellow of the Oxford Centre for Neuroethics. He is an elected founding member of the Neuroethics, Legal, and Social Issues Advisory Panel of the U.S. Defense Advanced Research Projects Agency (DARPA), an elected member of the European Academy of Science and Arts; and an Overseas Fellow of the Royal Society of Medicine in the U.K. https://gufaculty360.georgetown.edu/s/contact/00336000014Tm4oAAC/james-giordano-phd
Elizabeth Heitman, PhD, is a professor at the University of Texas Southwestern Medical Center in the Department of Psychiatry's Division of Ethics and the Program in Ethics in Science and Medicine, with secondary appointments in the Department of Applied Clinical Research and the O'Donnell School of Public Health. Her work focuses on cultural aspects of ethics in clinical medicine, biomedical science, and public health, particularly international standards of research ethics and education in the responsible conduct of research. She co-directs two National Institutes of Health-sponsored collaborative research ethics education programs in Mozambique and Peru, and is the co-editor of four ethics texts, most recently Race and Research: Perspectives on Minority Participation in Health Studies (American Public Health Association, 2024). As a national associate and report author for the National Academy of Sciences, she has trained her expertise in the ethics of technology assessment on technologies with public health impact: bioterrorism countermeasures using animal models, gene drive technology, and research with dual use potential. In 2023, she was named as a Fellow of the American Association for the Advancement of Science. Elizabeth Heitman, Ph.D. Faculty Profile UT Southwestern
D. Micah Hester, PhD, HEC-C, is the Chair of the Department of Medical Humanities and Bioethics and Professor of Medical Humanities and Pediatrics at University of Arkansas for Medical Sciences, as well as clinical ethicist at Arkansas Children's Hospital and research ethics consultant for the UAMS Translational Research Institute. He was trained in philosophy with a focus on American pragmatism and is recognized as a leader in ""pragmatic bioethics."" He has written extensively on the ethics of patient-professional relationships (Community as Healing, Rowmanand Littlefield, 2001) and end-of-life issues (End-of-life Care and Pragmatic Decision Making, Cambridge University Press, 2010]. In both these texts, he argues for a pragmatic and narrative approach to bioethical considerations, which are the bases of much of his scholarly work. His two books on ethics committees and ethics consultationEthics By Committee (Rowman and Littlefield, 2008) and Guidance for Ethics Committees (Cambridge University Press, 2012, with a second edition in 2022) are widely used textbooks. D. Micah Hester, Ph.D. | UAMS Department of Medical Humanities and Bioethics
Judy Illes, CM, PhD, is a professor of neurology, Distinguished University Scholar, and Distinguished Professor in Neuroethics at the University of British Columbia. She is director of Neuroethics Canada and faculty in the Centre for Brain Health and at the Vancouver Coastal Health Research Institute. In addition, she holds associate appointments in Population and Public Health and in Journalism at UBC and in the Department of Computer Science and Engineering at the University of Washington in Seattle. Dr. Illes is a pioneer in the field of neuroethics. Her research, teaching, and outreach initiatives are devoted to ethical, legal, social and policy challenges at the intersection of the brain sciences and biomedical ethics. She has made groundbreakingcontributions to neuroethical thinking for neuroscience discovery and clinical translation across the life span, and to entrepreneurship and the commercialization of health care. Dr. Illes has held many leadership positions. She serves as Chair of the International Brain Initiative, co-Lead of the Canadian Brain Research Strategy, expert consultant to UNESCO and WHO on the ethics of neurotechnology, as the expert advisor to EuroBioImaging, and as a member of the Ethics, Law and Humanities Committee of the American Academy of Neurology. Most recently, she became Vice Chair of the newly incorporated Bioethics Council for Canada. She held the Canada Research Chair in Neuroethics from 2007 to 2021.In 2017,Dr. Illes was awarded the Order of Canada, the country's highest recognition of its citizens. Neuroethics Canada University of British Columbia
Michelle N. Meyer, PhD, JD, HEC-C, is the Chief Bioethics Officer at Geisinger, an integrated, nonprofit health system in Pennsylvania, and associate professor and Chair of the Department of Bioethics and Decision Sciences at Geisinger College of Health Sciences. In addition to conducting normative ethics scholarship and empirical legal research, she uses survey experiments and qualitative methods of investigating judgments and decision-making related to science, innovation, and health. She is also faculty codirector of Geisinger's Behavioral Insights Team, which designs, implements, and uses large field experiments to rigorously evaluate behavioral science-informed provider and patient-facing interventions that aim to make healthy choices easier. Her work has appeared in leading journals of bioethics, law, science, and medicine, as well as in the New York Times, Slate, Wired, and the Los Angeles Times. Her research has been funded by the National Institutes of Health, the U.S. Food and Drug Administration, the National Science Foundation, the National Bureau of Economic Research (NBER) Roybal Center for Behavior Change in Health, the Russell Sage Foundation, and the Robert Wood Johnson Foundation, and covered by Science, The Economist, and many other leading media outlets around the world. Michelle N. Meyer About
Stuart Rennie, PhD, is a professor in social medicine at the University of North Carolina School of Medicine Center of Bioethics. His current work focuses on research ethics, public health ethics, and medical ethics, particularly in the context of the developing world. He was co-principal investigator of two National Institutes of Health/Fogarty International Center bioethics educational projects, in the Central Francophone Africa (Building Bioethics Capacity and Justice in Health) and South Africa (Advancing Research Ethics in Southern Africa). He was also co-principal investigator of a NIH-funded research project on the social and ethical implications of HIV cure research and is part of the ethics program of UNC's Center for AIDS Research. He is currently co-principal investigator of two NIH-funded collaborative projects with Stellenbosch University in South Africa: a PhD program in research ethics and a project entitled Research for Ethical Data Science in sub-Saharan Africa. With support of the NIH and in collaboration with the Pacific Institute of Research and Evaluation, he has conducted research on the responsible conduct of HIV-related research among adolescents in western Kenya. Stuart Rennie | UNC Center for Bioethics
Charmaine DM Royal, PhD,is the Robert O. Keohane Professor of African and African American Studies, Biology, Global Health, and Family Medicine and Community Health at Duke University. She is also a senior fellow at the Kenan Institute for Ethics and a faculty associate at the Trent Center for Bioethics, Humanities and History of Medicine. She directs the Duke Center on Genomics, Race, Identity, Difference and the Duke Center for Truth, Racial Healing and Transformation. She is a human geneticist and bioethicist whose global research and scholarly pursuits span ethical, social, scientific, clinical, and policy implications of human genetics and genomics. She focuses primarily on issues at the intersection of genetics and ""race,"" with a twofold goal of 1) dispelling notions of the validity of biological human races and racial hierarchies and 2) dismantling intellectual and institutional structures that are based on those false notions. Her empirical and normative work has been published in a wide range of journals covering the life sciences, medicine, social sciences, and humanities. She has served on numerous national and international advisory boards and committees for government agencies, professional organizations, research initiatives, not-for-profit entities, and
corporations.https://scholars.duke.edu/person/charmaine.royal
Jason L. Schwartz, PhD, MBE, is an associate professor in the Department of Health Policy and Management at the Yale School of Public Health and the Section of the History of Medicine at the Yale School of Medicine. His research examines vaccines and vaccination policy, decision-making in medical regulation and public health policy, and the structure and function of scientific expert advice to the government. The overall focus of his work is on the ways in which evidence is translated into regulation and policy in medicine and public health and the role of values and value judgments in those activities. His research has been published in leading journals of medicine, health policy, public health, bioethics, and related fields. During the Covid-19 pandemic, he served as an advisor to the State of Connecticut, colleges and universities, K-12 schools, and other organizations regarding their Covid policies. His research, analysis, and perspectives have been featured in the New York Times, Washington Post,CNN, NPR, BBC, and elsewhere. http://jschwartz.yale.edu
Margaret ""Gretchen"" Schwarze, MD, MPP, is the Morgridge Professor of Vascular Surgery and a professor in the Departments of Surgery and Medical History and Bioethics at the University of Wisconsin. She is a practicing vascular surgeon and health services researcher who also directs the hospital ethics committee. Her research interests focus on informed consent, high-stakes decisions, and end-of-life care for older patients with complex illnesses. With her research, she aims to improve communication between older patients and their surgeons so that patients can avoid unwanted treatment and make decisions that align with their values, preferences, and goals. She is an alumna of the Greenwall Faculty Scholar and the Cambia Foundation Sojourns Scholar programs. She is currently funded by the National Institute on Aging. https://patientpreferences.org/
Holly Tabor, PhD, is the Director of the Stanford Center for Biomedical Ethics. She is a professor in the Department of Medicine at Stanford University and by courtesy with the Departments of Pediatrics and Epidemiology and Population Health. She is a globally recognized expert on the ethical issues surrounding health care and research for patients with disabilities, especially intellectual and developmental disability, and on the ethical, legal, and social issues in genetics. Her research has shed light on the benefits and risks of participating in genomic research, particularly of rare and undiagnosed diseases. She is editor-in-chief of the American Journal of Bioethical Empirical Research. In 2022, she received the Stanford School of Medicine Henry J. Kaiser Award for Excellence in Preclinical Teaching and the Stanford Faculty Women's Forum Allyship Award, specifically for her advocacy for trainees and faculty with disabilities. https://med.stanford.edu/profiles/holly-tabor
Katie Watson, JD, is a professor at the Northwestern Feinberg School of Medicine, teaching medical ethics, humanities, and law to medical students and students in the master's program in medical humanities and bioethics. Before becoming an academic she clerked in the federal judiciary, worked as an appellate public defender for death row inmates, practiced poverty law at Legal Aid of Chicago, and practiced health law at the firm of Ross and Hardies. In 2017-2018, she left the Feinberg School of Medicine faculty part-time to serve as senior counsel for the ACLU-IL Women's and Reproductive Rights project. In bioethics Watson is best known for her scholarship in abortion ethics, practice, and law. She is the author of Scarlet A: The Ethics, Law, and Politics of Ordinary Abortion(Oxford University Press, 2018).Her articles on these topics have appeared in publications including JAMA, the New England Journal of Medicine, the Lancet, the American Journal of Bioethics (AJOB), and The New Yorker, and when abortion is in the news she is regularly interviewed and quoted in media outlets including CNN, the Washington Post, and the New York Times. She has been a member of the Northwestern Memorial Hospital Ethics Committee for over 15 years, and she is currently a Board member of the Midwest Access Coalition and a member of the ethics committee of the International Federation of Gynecology and Obstetrics (FIGO).
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); LAW SCHOOLS (90%); MEDICAL SCIENCE (90%); PUBLIC HEALTH (90%); PUBLIC HEALTH ADMINISTRATION (90%); PUBLIC POLICY (90%); BIOETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); DISEASES & DISORDERS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE POLICY (89%); HEALTH CARE REGULATION & POLICY (89%); INFECTIOUS DISEASE (89%); STUDENT EXPENSES & FINANCING (89%); TEACHING & TEACHERS (88%); GOVERNMENT DEPARTMENTS & AUTHORITIES (79%); MEDICAID (79%); EMPLOYMENT HISTORY (78%); INTERNATIONAL ORGANIZATIONS & BODIES (78%); COLLEGES & UNIVERSITIES (77%); HEALTH DEPARTMENTS (77%); RESEARCH INSTITUTES (77%); SOCIAL SERVICES DEPARTMENTS (77%); BIOTECHNOLOGY & GENETIC SCIENCE (76%); COMMUNICABLE DISEASE CONTROL (76%); EXECUTIVES (76%); GENETIC SCREENING (76%); INTERNATIONAL GOVERNMENTAL ORGANIZATIONS (76%); REPRODUCTIVE RIGHTS (75%); UNITED NATIONS INSTITUTIONS (74%); LAWYERS (73%); ASSOCIATIONS & ORGANIZATIONS (72%); MEDICAL TREATMENTS & PROCEDURES (72%); NEUROSCIENCE (72%); DEATH & DYING (71%); REPRODUCTIVE TECHNOLOGY (71%); TUBERCULOSIS (71%); END OF LIFE DECISIONS (50%)
Company:  SUN LIFE FINANCIAL INC (51%)
Organization: HASTINGS CENTER (94%); WORLD HEALTH ORGANIZATION (54%)
Ticker: SLF (TSX) (51%); SLF (NYSE) (51%)
Industry: NAICS524113 DIRECT LIFE INSURANCE CARRIERS (51%); SIC6311 LIFE INSURANCE (51%); LAW SCHOOLS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE POLICY (89%); HEALTH CARE REGULATION & POLICY (89%); MEDICAID (79%); COLLEGES & UNIVERSITIES (77%); HEALTH CARE (77%); HEALTH DEPARTMENTS (77%); LAWYERS (73%); REPRODUCTIVE TECHNOLOGY (71%)
Geographic: NEW YORK, USA (79%); ONTARIO, CANADA (58%)
Load-Date: December 6, 2024","The following information was released by the Hastings Center:
The Hastings Center is pleased to announce the election of the 2024 fellows. Hastings Center fellows are a group of about 300 individuals of outstanding accomplishment whose work has informed scholarship and public understanding of complex ethical issues in health, health care, science, and technology.
""Our new fellows are leaders in a wide range of areas of global importance, including ethical issues in infectious disease outbreaks, AI in health, neuroscience, reproductive rights, genetics and race, and disability,"" said Hastings Center President Vardit Ravitsky. ""I welcome them and look forward to working with them.""
""We are proud to announce this dynamic slate of Hastings Center fellows,"" said Michele Goodwin, the chair of the Fellow's Council, who is Linda D. and Timothy J. O'Neill Professor of Constitutional Law and Global Health Policy at Georgetown Law School. ""These individuals are thought leaders whose research, scholarship, and policy advocacy have shaped the bioethics and health fields in tremendous, impactful ways.Theircontributions in policy and academic discourses offer urgentlyneeded pathways forward for tackling the most challenging health related conundrums. We are honored to recognize them and their election to this esteemed fellowship.""
The 2024 Hastings Center fellows are:
Carl Coleman, JD, is Associate Dean for Graduate Programs and Professor of Law at Seton Hall Law. He specializes in the legal, ethical, and public policy implications of medical treatment, research, and public health. He served as Bioethics and Law Adviser at the World Health Organization from 2006 to 2007 and has continued to work closely with WHO's Global Health Ethics team. In addition, he is the lead author of numerous WHO guidance documents on topics such as ethical issues in infectious disease outbreaks, tuberculosis care and control, and clinical trials oversight. From 2010 to 2013, he was a member of the Secretary's Advisory Committee on Human Research Protections, which is charged with providing expert advice to the Office for Human Research Protections of the U.S. Department of Health and Human Services. Prior to joining the Seton Hall faculty, he served as Executive Director of the New York State Task Force on Life and the Law, supporting the Task Force's work in the areas of end-of-life decision-making, assisted reproductive technologies, and genetic testing and screening. Carl H. Coleman Seton Hall Law School
Jennifer L. Gibson, PhD, is the Sun Life Financial Chair in Bioethics andDirector of the University of Toronto Joint Centre for Bioethics (JCB) and an associate professor in the Division of Clinical Public Health and the Institute of Health Policy, Management, and Evaluation of the Dalla Lana School of Public Health. She is a health policy ethics scholar whose research, teaching, and policy work focuses on ethical issues in contemporary health institutions and systems. She has advised governments and policymakers on issues such as medical assistance in dying, public health emergencies, health technology assessment, drug funding and supply, and resource allocation. From 2020 to 2022, she created and co-chaired the Ontario Covid-19 Bioethics Table and served as bioethics advisor to several planning tables of the Ontario Ministry of Health. In 2018, she founded the JCB's Ethics and AI for Good Health Program, which explores and engages inethics and governance issues associated with AI in health care and public health through research and training initiatives.In addition, she is a member of the WHO Expert Group on Ethics and Governance of AI for Health and recently completed a three-year ministerial appointment as Vice-Chair of the Ontario Health Data Council. Her research and policy interests are increasingly turning toward the ethics in and of wicked problems, including problems involving convergent existential risk and their implications for health and a sustainable future for all. https://jcb.utoronto.ca/people/our-team/jennifer-gibson/
James Giordano, PhD, DPhil, is the Pellegrino Center Professor in the Departments of Neurology and Biochemistry and Chief of the Neuroethics Studies Program at Georgetown University Medical Center. He is senior bioethicist of the Defense Medical Ethics Center and adjunct professor of Psychiatry at the Uniformed Services University of Health Sciences; Distinguished Visiting Professor of Health Promotions, Technology and Ethics at the Coburg University of Applied Sciences in Germany; Stockdale Fellow in Science, Technology, and Ethics at the United States Naval Academy; Senior Science Advisory Fellow of the Strategic Multilayer Assessment Branch of the Joint Staff, Pentagon; and Chair Emeritus of the IEEE Brain Initiative Project on Neurotechnology and Ethics. Previously, he was Fellow and Task Leader of the Neuroethics Study Section of the European Union Human Brain Project. He is an elected member of the U.S. Department of Health and Human Services Secretary's Advisory Committee; Fulbright Professor of Neuroscience and the European Academy of Science and Arts Neuroethics at the Ludwig Maximilians University in Munich; and Associate Fellow of the Oxford Centre for Neuroethics. He is an elected founding member of the Neuroethics, Legal, and Social Issues Advisory Panel of the U.S. Defense Advanced Research Projects Agency (DARPA), an elected member of the European Academy of Science and Arts; and an Overseas Fellow of the Royal Society of Medicine in the U.K. https://gufaculty360.georgetown.edu/s/contact/00336000014Tm4oAAC/james-giordano-phd
Elizabeth Heitman, PhD, is a professor at the University of Texas Southwestern Medical Center in the Department of Psychiatry's Division of Ethics and the Program in Ethics in Science and Medicine, with secondary appointments in the Department of Applied Clinical Research and the O'Donnell School of Public Health. Her work focuses on cultural aspects of ethics in clinical medicine, biomedical science, and public health, particularly international standards of research ethics and education in the responsible conduct of research. She co-directs two National Institutes of Health-sponsored collaborative research ethics education programs in Mozambique and Peru, and is the co-editor of four ethics texts, most recently Race and Research: Perspectives on Minority Participation in Health Studies (American Public Health Association, 2024). As a national associate and report author for the National Academy of Sciences, she has trained her expertise in the ethics of technology assessment on technologies with public health impact: bioterrorism countermeasures using animal models, gene drive technology, and research with dual use potential. In 2023, she was named as a Fellow of the American Association for the Advancement of Science. Elizabeth Heitman, Ph.D. Faculty Profile UT Southwestern
D. Micah Hester, PhD, HEC-C, is the Chair of the Department of Medical Humanities and Bioethics and Professor of Medical Humanities and Pediatrics at University of Arkansas for Medical Sciences, as well as clinical ethicist at Arkansas Children's Hospital and research ethics consultant for the UAMS Translational Research Institute. He was trained in philosophy with a focus on American pragmatism and is recognized as a leader in ""pragmatic bioethics."" He has written extensively on the ethics of patient-professional relationships (Community as Healing, Rowmanand Littlefield, 2001) and end-of-life issues (End-of-life Care and Pragmatic Decision Making, Cambridge University Press, 2010]. In both these texts, he argues for a pragmatic and narrative approach to bioethical considerations, which are the bases of much of his scholarly work. His two books on ethics committees and ethics consultationEthics By Committee (Rowman and Littlefield, 2008) and Guidance for Ethics Committees (Cambridge University Press, 2012, with a second edition in 2022) are widely used textbooks. D. Micah Hester, Ph.D. | UAMS Department of Medical Humanities and Bioethics
Judy Illes, CM, PhD, is a professor of neurology, Distinguished University Scholar, and Distinguished Professor in Neuroethics at the University of British Columbia. She is director of Neuroethics Canada and faculty in the Centre for Brain Health and at the Vancouver Coastal Health Research Institute. In addition, she holds associate appointments in Population and Public Health and in Journalism at UBC and in the Department of Computer Science and Engineering at the University of Washington in Seattle. Dr. Illes is a pioneer in the field of neuroethics. Her research, teaching, and outreach initiatives are devoted to ethical, legal, social and policy challenges at the intersection of the brain sciences and biomedical ethics. She has made groundbreakingcontributions to neuroethical thinking for neuroscience discovery and clinical translation across the life span, and to entrepreneurship and the commercialization of health care. Dr. Illes has held many leadership positions. She serves as Chair of the International Brain Initiative, co-Lead of the Canadian Brain Research Strategy, expert consultant to UNESCO and WHO on the ethics of neurotechnology, as the expert advisor to EuroBioImaging, and as a member of the Ethics, Law and Humanities Committee of the American Academy of Neurology. Most recently, she became Vice Chair of the newly incorporated Bioethics Council for Canada. She held the Canada Research Chair in Neuroethics from 2007 to 2021.In 2017,Dr. Illes was awarded the Order of Canada, the country's highest recognition of its citizens. Neuroethics Canada University of British Columbia
Michelle N. Meyer, PhD, JD, HEC-C, is the Chief Bioethics Officer at Geisinger, an integrated, nonprofit health system in Pennsylvania, and associate professor and Chair of the Department of Bioethics and Decision Sciences at Geisinger College of Health Sciences. In addition to conducting normative ethics scholarship and empirical legal research, she uses survey experiments and qualitative methods of investigating judgments and decision-making related to science, innovation, and health. She is also faculty codirector of Geisinger's Behavioral Insights Team, which designs, implements, and uses large field experiments to rigorously evaluate behavioral science-informed provider and patient-facing interventions that aim to make healthy choices easier. Her work has appeared in leading journals of bioethics, law, science, and medicine, as well as in the New York Times, Slate, Wired, and the Los Angeles Times. Her research has been funded by the National Institutes of Health, the U.S. Food and Drug Administration, the National Science Foundation, the National Bureau of Economic Research (NBER) Roybal Center for Behavior Change in Health, the Russell Sage Foundation, and the Robert Wood Johnson Foundation, and covered by Science, The Economist, and many other leading media outlets around the world. Michelle N. Meyer About
Stuart Rennie, PhD, is a professor in social medicine at the University of North Carolina School of Medicine Center of Bioethics. His current work focuses on research ethics, public health ethics, and medical ethics, particularly in the context of the developing world. He was co-principal investigator of two National Institutes of Health/Fogarty International Center bioethics educational projects, in the Central Francophone Africa (Building Bioethics Capacity and Justice in Health) and South Africa (Advancing Research Ethics in Southern Africa). He was also co-principal investigator of a NIH-funded research project on the social and ethical implications of HIV cure research and is part of the ethics program of UNC's Center for AIDS Research. He is currently co-principal investigator of two NIH-funded collaborative projects with Stellenbosch University in South Africa: a PhD program in research ethics and a project entitled Research for Ethical Data Science in sub-Saharan Africa. With support of the NIH and in collaboration with the Pacific Institute of Research and Evaluation, he has conducted research on the responsible conduct of HIV-related research among adolescents in western Kenya. Stuart Rennie | UNC Center for Bioethics
Charmaine DM Royal, PhD,is the Robert O. Keohane Professor of African and African American Studies, Biology, Global Health, and Family Medicine and Community Health at Duke University. She is also a senior fellow at the Kenan Institute for Ethics and a faculty associate at the Trent Center for Bioethics, Humanities and History of Medicine. She directs the Duke Center on Genomics, Race, Identity, Difference and the Duke Center for Truth, Racial Healing and Transformation. She is a human geneticist and bioethicist whose global research and scholarly pursuits span ethical, social, scientific, clinical, and policy implications of human genetics and genomics. She focuses primarily on issues at the intersection of genetics and ""race,"" with a twofold goal of 1) dispelling notions of the validity of biological human races and racial hierarchies and 2) dismantling intellectual and institutional structures that are based on those false notions. Her empirical and normative work has been published in a wide range of journals covering the life sciences, medicine, social sciences, and humanities. She has served on numerous national and international advisory boards and committees for government agencies, professional organizations, research initiatives, not-for-profit entities, and
corporations.https://scholars.duke.edu/person/charmaine.royal
Jason L. Schwartz, PhD, MBE, is an associate professor in the Department of Health Policy and Management at the Yale School of Public Health and the Section of the History of Medicine at the Yale School of Medicine. His research examines vaccines and vaccination policy, decision-making in medical regulation and public health policy, and the structure and function of scientific expert advice to the government. The overall focus of his work is on the ways in which evidence is translated into regulation and policy in medicine and public health and the role of values and value judgments in those activities. His research has been published in leading journals of medicine, health policy, public health, bioethics, and related fields. During the Covid-19 pandemic, he served as an advisor to the State of Connecticut, colleges and universities, K-12 schools, and other organizations regarding their Covid policies. His research, analysis, and perspectives have been featured in the New York Times, Washington Post,CNN, NPR, BBC, and elsewhere. http://jschwartz.yale.edu
Margaret ""Gretchen"" Schwarze, MD, MPP, is the Morgridge Professor of Vascular Surgery and a professor in the Departments of Surgery and Medical History and Bioethics at the University of Wisconsin. She is a practicing vascular surgeon and health services researcher who also directs the hospital ethics committee. Her research interests focus on informed consent, high-stakes decisions, and end-of-life care for older patients with complex illnesses. With her research, she aims to improve communication between older patients and their surgeons so that patients can avoid unwanted treatment and make decisions that align with their values, preferences, and goals. She is an alumna of the Greenwall Faculty Scholar and the Cambia Foundation Sojourns Scholar programs. She is currently funded by the National Institute on Aging. https://patientpreferences.org/
Holly Tabor, PhD, is the Director of the Stanford Center for Biomedical Ethics. She is a professor in the Department of Medicine at Stanford University and by courtesy with the Departments of Pediatrics and Epidemiology and Population Health. She is a globally recognized expert on the ethical issues surrounding health care and research for patients with disabilities, especially intellectual and developmental disability, and on the ethical, legal, and social issues in genetics. Her research has shed light on the benefits and risks of participating in genomic research, particularly of rare and undiagnosed diseases. She is editor-in-chief of the American Journal of Bioethical Empirical Research. In 2022, she received the Stanford School of Medicine Henry J. Kaiser Award for Excellence in Preclinical Teaching and the Stanford Faculty Women's Forum Allyship Award, specifically for her advocacy for trainees and faculty with disabilities. https://med.stanford.edu/profiles/holly-tabor
Katie Watson, JD, is a professor at the Northwestern Feinberg School of Medicine, teaching medical ethics, humanities, and law to medical students and students in the master's program in medical humanities and bioethics. Before becoming an academic she clerked in the federal judiciary, worked as an appellate public defender for death row inmates, practiced poverty law at Legal Aid of Chicago, and practiced health law at the firm of Ross and Hardies. In 2017-2018, she left the Feinberg School of Medicine faculty part-time to serve as senior counsel for the ACLU-IL Women's and Reproductive Rights project. In bioethics Watson is best known for her scholarship in abortion ethics, practice, and law. She is the author of Scarlet A: The Ethics, Law, and Politics of Ordinary Abortion(Oxford University Press, 2018).Her articles on these topics have appeared in publications including JAMA, the New England Journal of Medicine, the Lancet, the American Journal of Bioethics (AJOB), and The New Yorker, and when abortion is in the news she is regularly interviewed and quoted in media outlets including CNN, the Washington Post, and the New York Times. She has been a member of the Northwestern Memorial Hospital Ethics Committee for over 15 years, and she is currently a Board member of the Midwest Access Coalition and a member of the ethics committee of the International Federation of Gynecology and Obstetrics (FIGO).
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); LAW SCHOOLS (90%); MEDICAL SCIENCE (90%); PUBLIC HEALTH (90%); PUBLIC HEALTH ADMINISTRATION (90%); PUBLIC POLICY (90%); BIOETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); DISEASES & DISORDERS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE POLICY (89%); HEALTH CARE REGULATION & POLICY (89%); INFECTIOUS DISEASE (89%); STUDENT EXPENSES & FINANCING (89%); TEACHING & TEACHERS (88%); GOVERNMENT DEPARTMENTS & AUTHORITIES (79%); MEDICAID (79%); EMPLOYMENT HISTORY (78%); INTERNATIONAL ORGANIZATIONS & BODIES (78%); COLLEGES & UNIVERSITIES (77%); HEALTH DEPARTMENTS (77%); RESEARCH INSTITUTES (77%); SOCIAL SERVICES DEPARTMENTS (77%); BIOTECHNOLOGY & GENETIC SCIENCE (76%); COMMUNICABLE DISEASE CONTROL (76%); EXECUTIVES (76%); GENETIC SCREENING (76%); INTERNATIONAL GOVERNMENTAL ORGANIZATIONS (76%); REPRODUCTIVE RIGHTS (75%); UNITED NATIONS INSTITUTIONS (74%); LAWYERS (73%); ASSOCIATIONS & ORGANIZATIONS (72%); MEDICAL TREATMENTS & PROCEDURES (72%); NEUROSCIENCE (72%); DEATH & DYING (71%); REPRODUCTIVE TECHNOLOGY (71%); TUBERCULOSIS (71%); END OF LIFE DECISIONS (50%)
Company:  SUN LIFE FINANCIAL INC (51%)
Organization: HASTINGS CENTER (94%); WORLD HEALTH ORGANIZATION (54%)
Ticker: SLF (TSX) (51%); SLF (NYSE) (51%)
Industry: NAICS524113 DIRECT LIFE INSURANCE CARRIERS (51%); SIC6311 LIFE INSURANCE (51%); LAW SCHOOLS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE POLICY (89%); HEALTH CARE REGULATION & POLICY (89%); MEDICAID (79%); COLLEGES & UNIVERSITIES (77%); HEALTH CARE (77%); HEALTH DEPARTMENTS (77%); LAWYERS (73%); REPRODUCTIVE TECHNOLOGY (71%)
Geographic: NEW YORK, USA (79%); ONTARIO, CANADA (58%)
Load-Date: December 6, 2024",positive,0.8539347052574158,balanced/neutral,"['agency', 'consent', 'access']","['justice', 'justice']","['regulation', 'policy', 'governance', 'oversight', 'standards', 'law']",[],3,2,6,0
2024,Unknown Title,"Body
Elon Musk has backed Poornima Ramarao’s claims of foul play in the mysterious death of her son, Suchir Balaji, in San Francisco on Nov 26. The mother of the PIO tech researcher and ex-OpenAI staffer has called for an FBI probe, arguing evidence uncovered through a private autopsy and investigation casts doubt on police’s conclusion of suicide.  Musk, who co-founded OpenAI and later parted ways with the company, tweeted, “This doesn’t seem like a suicide.”  The whistleblower was known for his critical stance on AI practices. 
In Oct, he shared with NYT concerns about copyright violations by AI firms. After quitting OpenAI due to ethical differences, he turned a key figure in NYT’s copyright case against the firm.TNNPoornima Ramarao shared her concerns, writing, “Suchir’s apartment was ransacked, sign of struggle in the bathroom and looks like someone hit him in bathroom based on blood spots. It’s a cold-blooded mu*d*r declared by authorities as suicide. Lobbying in SF city doesn’t stop us from getting justices. We demand FBI investigation.” Following Musk’s comments, Ramarao reached out to him, asking for further assistance in the case. The tragedy has prompted prominent AI ethics advocates and creators to demand a full and transparent investigation, alongside stronger protections for individuals who raise ethical concerns within the tech industry.  Balaji was found dead in his San Francisco apartment on Nov 26. Police ruled his death a suicide, citing CCTV footage that showed he was alone at the time. TNN
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: COPYRIGHT (90%); CRIMINAL INVESTIGATIONS (90%); DEATH & DYING (90%); ETHICS (90%); HOMICIDE (90%); INVESTIGATIONS (90%); LAW ENFORCEMENT (90%); NEGATIVE BUSINESS NEWS (90%); NEGATIVE NEWS (90%); SUICIDE (90%); AUTOPSIES (78%); LOBBYING (78%); FEDERAL INVESTIGATIONS (77%); WHISTLEBLOWERS (77%); ARTIFICIAL INTELLIGENCE ETHICS (75%); COPYRIGHT INFRINGEMENT (73%); TECHNOLOGY (73%)
Industry: INFORMATION TECHNOLOGY INDUSTRY (77%); ARTIFICIAL INTELLIGENCE ETHICS (75%)
Person: ELON MUSK (79%)
Geographic: SAN FRANCISCO, CA, USA (90%); CALIFORNIA, USA (78%)
Load-Date: December 29, 2024","Elon Musk has backed Poornima Ramarao’s claims of foul play in the mysterious death of her son, Suchir Balaji, in San Francisco on Nov 26. The mother of the PIO tech researcher and ex-OpenAI staffer has called for an FBI probe, arguing evidence uncovered through a private autopsy and investigation casts doubt on police’s conclusion of suicide.  Musk, who co-founded OpenAI and later parted ways with the company, tweeted, “This doesn’t seem like a suicide.”  The whistleblower was known for his critical stance on AI practices. 
In Oct, he shared with NYT concerns about copyright violations by AI firms. After quitting OpenAI due to ethical differences, he turned a key figure in NYT’s copyright case against the firm.TNNPoornima Ramarao shared her concerns, writing, “Suchir’s apartment was ransacked, sign of struggle in the bathroom and looks like someone hit him in bathroom based on blood spots. It’s a cold-blooded mu*d*r declared by authorities as suicide. Lobbying in SF city doesn’t stop us from getting justices. We demand FBI investigation.” Following Musk’s comments, Ramarao reached out to him, asking for further assistance in the case. The tragedy has prompted prominent AI ethics advocates and creators to demand a full and transparent investigation, alongside stronger protections for individuals who raise ethical concerns within the tech industry.  Balaji was found dead in his San Francisco apartment on Nov 26. Police ruled his death a suicide, citing CCTV footage that showed he was alone at the time. TNN
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: COPYRIGHT (90%); CRIMINAL INVESTIGATIONS (90%); DEATH & DYING (90%); ETHICS (90%); HOMICIDE (90%); INVESTIGATIONS (90%); LAW ENFORCEMENT (90%); NEGATIVE BUSINESS NEWS (90%); NEGATIVE NEWS (90%); SUICIDE (90%); AUTOPSIES (78%); LOBBYING (78%); FEDERAL INVESTIGATIONS (77%); WHISTLEBLOWERS (77%); ARTIFICIAL INTELLIGENCE ETHICS (75%); COPYRIGHT INFRINGEMENT (73%); TECHNOLOGY (73%)
Industry: INFORMATION TECHNOLOGY INDUSTRY (77%); ARTIFICIAL INTELLIGENCE ETHICS (75%)
Person: ELON MUSK (79%)
Geographic: SAN FRANCISCO, CA, USA (90%); CALIFORNIA, USA (78%)
Load-Date: December 29, 2024",neutral,0.6108266711235046,balanced/neutral,[],[],['law'],[],0,0,1,0
2024,Unknown Title,"Highlight: The ethical and regulatory challenges associated with developments in biomedicine, health and AI are set to intensify, writes the director of the Nuffield Council on Bioethics
Body
Every day, people across the world face situations where they need to make a decision. More often than not, no choice that is available will be perfect. Instead, there is a need to balance trade-offs and prioritise what matters most.     
If you are a policymaker, the decisions you face can be monumental. Developments in biomedical technologies may offer you, in part, a way to tackle some of the most pressing health and wider societal issues in the world today. Yet in doing so, they will often raise profound risks and benefits for the people, communities and populations that need support.    
Ethical challenges thrive in the world of complexity, where there is no obvious right and wrong. Becoming aware of these and being unafraid to explore and discuss them can help ensure policies reflect public values, that regulation is proportionate and diverse interests are balanced. In short, being ethically aware helps policymakers get closer to making choices that result in a better and more equitable experience for all. Why then, is ethical evidence so often overlooked?   
I believe a main reason is an assumption of lengthy ethical considerations being a block to scientific progress. While is it true that ethical assessment takes time, I would argue this is an investment and, when well utilised, ethics is an enabler of innovation. A clear example of this can be found in the Human Fertilisation and Embryology Authority - the regulator of assisted reproduction and research on human gametes and human embryos. It is the proportionate, ethically informed regulation the HFEA provides that helps the UK to attract some of the most talented scientists.     
""Any government wanting to harness the potential of science and technology will need to anticipate and respond to the ethical challenges presented by them"" 
The ethical and regulatory challenges associated with developments in biomedicine, health and AI are set to intensify. Indeed, we are increasingly seeing situations where science has outpaced regulation. Any government wanting to harness the potential of science and technology will need to anticipate and respond to the ethical challenges presented by them. And I believe the bioethics sector, including organisations such as the Nuffield Council on Bioethics, must step forward to help better equip policymakers with the tools they need to navigate this complex ethical terrain successfully.    
To achieve this, we are enhancing our ability to anticipate disruptive developments and technologies. This will ensure we have a strong grasp on acute issues so we can give policymakers the advice they need now, as well as an understanding of what is coming, so we can present them with information they are not yet aware of but would benefit to be. This is how ethical considerations can become part of a short- and longer-term view. Indeed, this is how ethics will become both an agenda response and an agenda setting item.    
Another component of the answer resides in how we present ethical advice. By embracing a new, modular approach to research where we break down large topics into a series of questions and then publish our advice one question at a time, I believe we will deliver robust evidence in a more succinct and timely way.    
And finally, we must better connect civil servants and government with the UK bioethics sector. For by having a joined-up network of active bioethicists' and our nation's decision makers, we will support ethical counsel being more easily accessed and utilised as an integral part of the policy development process. This is what will ensure we are in a stronger position to codesign future-proofed solutions. And it is only by working effectively together that we will be able to place ethics at the centre of decisions about biomedicine and health, so we all benefit.   
Danielle Hamm is director of the Nuffield Council on Bioethics 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (95%); BIOETHICS (90%); BIOMEDICINE (90%); PUBLIC POLICY (90%); TECHNOLOGY (89%); REPRODUCTIVE TECHNOLOGY (86%); ASSOCIATIONS & ORGANIZATIONS (78%); EMERGING TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); HUMAN SUBJECTS (78%); MEDICAL TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); REPRODUCTIVE MEDICINE (76%); SOCIETAL ISSUES (73%); DISRUPTIVE INNOVATION (71%)
Organization: NUFFIELD COUNCIL ON BIOETHICS (59%)
Industry: BIOMEDICINE (90%); REPRODUCTIVE TECHNOLOGY (86%); MEDICAL TECHNOLOGY (78%); REPRODUCTIVE MEDICINE (76%)
Geographic: UNITED KINGDOM (78%)
Load-Date: April 29, 2024","Every day, people across the world face situations where they need to make a decision. More often than not, no choice that is available will be perfect. Instead, there is a need to balance trade-offs and prioritise what matters most.     
If you are a policymaker, the decisions you face can be monumental. Developments in biomedical technologies may offer you, in part, a way to tackle some of the most pressing health and wider societal issues in the world today. Yet in doing so, they will often raise profound risks and benefits for the people, communities and populations that need support.    
Ethical challenges thrive in the world of complexity, where there is no obvious right and wrong. Becoming aware of these and being unafraid to explore and discuss them can help ensure policies reflect public values, that regulation is proportionate and diverse interests are balanced. In short, being ethically aware helps policymakers get closer to making choices that result in a better and more equitable experience for all. Why then, is ethical evidence so often overlooked?   
I believe a main reason is an assumption of lengthy ethical considerations being a block to scientific progress. While is it true that ethical assessment takes time, I would argue this is an investment and, when well utilised, ethics is an enabler of innovation. A clear example of this can be found in the Human Fertilisation and Embryology Authority - the regulator of assisted reproduction and research on human gametes and human embryos. It is the proportionate, ethically informed regulation the HFEA provides that helps the UK to attract some of the most talented scientists.     
""Any government wanting to harness the potential of science and technology will need to anticipate and respond to the ethical challenges presented by them"" 
The ethical and regulatory challenges associated with developments in biomedicine, health and AI are set to intensify. Indeed, we are increasingly seeing situations where science has outpaced regulation. Any government wanting to harness the potential of science and technology will need to anticipate and respond to the ethical challenges presented by them. And I believe the bioethics sector, including organisations such as the Nuffield Council on Bioethics, must step forward to help better equip policymakers with the tools they need to navigate this complex ethical terrain successfully.    
To achieve this, we are enhancing our ability to anticipate disruptive developments and technologies. This will ensure we have a strong grasp on acute issues so we can give policymakers the advice they need now, as well as an understanding of what is coming, so we can present them with information they are not yet aware of but would benefit to be. This is how ethical considerations can become part of a short- and longer-term view. Indeed, this is how ethics will become both an agenda response and an agenda setting item.    
Another component of the answer resides in how we present ethical advice. By embracing a new, modular approach to research where we break down large topics into a series of questions and then publish our advice one question at a time, I believe we will deliver robust evidence in a more succinct and timely way.    
And finally, we must better connect civil servants and government with the UK bioethics sector. For by having a joined-up network of active bioethicists' and our nation's decision makers, we will support ethical counsel being more easily accessed and utilised as an integral part of the policy development process. This is what will ensure we are in a stronger position to codesign future-proofed solutions. And it is only by working effectively together that we will be able to place ethics at the centre of decisions about biomedicine and health, so we all benefit.   
Danielle Hamm is director of the Nuffield Council on Bioethics 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (95%); BIOETHICS (90%); BIOMEDICINE (90%); PUBLIC POLICY (90%); TECHNOLOGY (89%); REPRODUCTIVE TECHNOLOGY (86%); ASSOCIATIONS & ORGANIZATIONS (78%); EMERGING TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); HUMAN SUBJECTS (78%); MEDICAL TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); REPRODUCTIVE MEDICINE (76%); SOCIETAL ISSUES (73%); DISRUPTIVE INNOVATION (71%)
Organization: NUFFIELD COUNCIL ON BIOETHICS (59%)
Industry: BIOMEDICINE (90%); REPRODUCTIVE TECHNOLOGY (86%); MEDICAL TECHNOLOGY (78%); REPRODUCTIVE MEDICINE (76%)
Geographic: UNITED KINGDOM (78%)
Load-Date: April 29, 2024",neutral,0.6219097971916199,balanced/neutral,[],[],"['regulation', 'policy', 'must', 'need to']",[],0,0,4,0
2024,Unknown Title,"Body
Artificial intelligence is transforming how companies across industry sectors and geographies govern data. This means that updating data governance frameworks to reflect AI integration is critical for business success and adherence to regulatory requirements. With AI becoming intertwined with data-driven processes, ensuring rigorous standards when it comes to data quality, ethical usage, and privacy protection are non-negotiable.
Given how AI is reliant on large datasets, putting in place comprehensive data governance practices should be an essential starting point.
 AI models need high-quality, well-labelled data to deliver accurate outcomes,  says Petrus Keyter, data governance consultant at PBT Group. Ensuring data accuracy, completeness, and consistency is vital, as any degradation in quality can undermine AI performance. 
To address these needs, data governance frameworks must evolve to include processes for ongoing data validation, quality checks, and error correction.The ethical challenges of AI integration also play a significant role in shaping data governance. AI s capacity for complex decision-making raises concerns when it comes to bias and fairness.Compliance with regulation
 Data governance must include ethical guidelines to prevent unintended biases. Compliance with regulations like POPIA and GDPR is also critical to ensure transparency and accountability in AI s decision-making processes,  adds Keyter. Regular audits and stringent data usage protocols can help companies align their AI practices both with legal standards as well as customers  expectations.  
Additionally, data security and privacy are also vital considerations.AI models often handle sensitive data, increasing the risk of data breaches, unauthorised access, and misuse.
 Implementing a detailed security framework in this regard is essential,  Keyter emphasises. Data encryption, access control, and anonymisation are necessary to protect sensitive information and maintain trust. 
The unique requirements of AI
Creating an AI-compatible data governance framework means going beyond traditional data management practices.Data quality standards must be even higher, as AI applications require clean, consistent data for optimal performance.
 AI systems benefit from real-time data quality monitoring. Data drift detection tools help maintain these standards over time,  says Keyter. Regular assessments ensure that AI systems rely on accurate and relevant data, a foundational element of successful AI integration.  
Another important consideration is understanding the full journey of data, including its origination and lineage.AI transparencyFor AI to function transparently and accountably, companies must track the data flow from its source to its transformation and eventual use in AI applications.
 This transparency is crucial for regulatory compliance and troubleshooting. Data lineage tools allow us to trace issues back to their source, making adjustments easier and enhancing the reliability of AI-driven outcomes. 
AI also introduces the need to actively address biases in data.Without careful oversight, AI models can perpetuate existing biases in their training data, leading to unfair results.
 Data governance frameworks must incorporate checks for bias, ensuring fair and ethical AI use,  says Keyter. Through regular data audits and diverse data sampling, businesses can reduce biases and create more balanced AI models. 
Privacy-by-designThe sensitive nature of data often used in AI means that privacy protocols must be especially stringent.Privacy-by-design is an absolute necessity in this regard. Role-based access controls, anonymisation techniques, and encryption are essential for safeguarding data integrity and aligning with privacy regulations.
Putting in place a comprehensive data governance framework that takes the above into consideration is key to unlocking the full potential of AI while mitigating risks around data quality, ethics, and security.
 As AI continues to evolve, data governance frameworks must keep pace, ensuring that data integrity, accountability, and privacy are upheld.  By integrating these principles, businesses can leverage AI responsibly, creating impactful and ethical solutions that drive meaningful insights and decision-making,  concludes Keyter.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ETHICS (90%); REGULATORY ACTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); QUALITY CONTROL (89%); DATA BREACHES (78%); NEGATIVE BUSINESS NEWS (78%); REGULATORY COMPLIANCE (77%); ENCRYPTION (73%); CRYPTOLOGY (71%); UNCONSCIOUS BIAS (67%); NEGATIVE TECHNOLOGY NEWS (50%); PBT Group (%); data governance (%); AI (%); Petrus Keyter (%)
Industry: DATA GOVERNANCE & STEWARDSHIP (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); DATA PRIVACY (90%); INFORMATION SECURITY & PRIVACY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); DATA SECURITY (89%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); DATA BREACHES (78%); BIG DATA (73%); ENCRYPTION (73%); CRYPTOLOGY (71%)
Load-Date: December 27, 2024","Artificial intelligence is transforming how companies across industry sectors and geographies govern data. This means that updating data governance frameworks to reflect AI integration is critical for business success and adherence to regulatory requirements. With AI becoming intertwined with data-driven processes, ensuring rigorous standards when it comes to data quality, ethical usage, and privacy protection are non-negotiable.
Given how AI is reliant on large datasets, putting in place comprehensive data governance practices should be an essential starting point.
 AI models need high-quality, well-labelled data to deliver accurate outcomes,  says Petrus Keyter, data governance consultant at PBT Group. Ensuring data accuracy, completeness, and consistency is vital, as any degradation in quality can undermine AI performance. 
To address these needs, data governance frameworks must evolve to include processes for ongoing data validation, quality checks, and error correction.The ethical challenges of AI integration also play a significant role in shaping data governance. AI s capacity for complex decision-making raises concerns when it comes to bias and fairness.Compliance with regulation
 Data governance must include ethical guidelines to prevent unintended biases. Compliance with regulations like POPIA and GDPR is also critical to ensure transparency and accountability in AI s decision-making processes,  adds Keyter. Regular audits and stringent data usage protocols can help companies align their AI practices both with legal standards as well as customers  expectations.  
Additionally, data security and privacy are also vital considerations.AI models often handle sensitive data, increasing the risk of data breaches, unauthorised access, and misuse.
 Implementing a detailed security framework in this regard is essential,  Keyter emphasises. Data encryption, access control, and anonymisation are necessary to protect sensitive information and maintain trust. 
The unique requirements of AI
Creating an AI-compatible data governance framework means going beyond traditional data management practices.Data quality standards must be even higher, as AI applications require clean, consistent data for optimal performance.
 AI systems benefit from real-time data quality monitoring. Data drift detection tools help maintain these standards over time,  says Keyter. Regular assessments ensure that AI systems rely on accurate and relevant data, a foundational element of successful AI integration.  
Another important consideration is understanding the full journey of data, including its origination and lineage.AI transparencyFor AI to function transparently and accountably, companies must track the data flow from its source to its transformation and eventual use in AI applications.
 This transparency is crucial for regulatory compliance and troubleshooting. Data lineage tools allow us to trace issues back to their source, making adjustments easier and enhancing the reliability of AI-driven outcomes. 
AI also introduces the need to actively address biases in data.Without careful oversight, AI models can perpetuate existing biases in their training data, leading to unfair results.
 Data governance frameworks must incorporate checks for bias, ensuring fair and ethical AI use,  says Keyter. Through regular data audits and diverse data sampling, businesses can reduce biases and create more balanced AI models. 
Privacy-by-designThe sensitive nature of data often used in AI means that privacy protocols must be especially stringent.Privacy-by-design is an absolute necessity in this regard. Role-based access controls, anonymisation techniques, and encryption are essential for safeguarding data integrity and aligning with privacy regulations.
Putting in place a comprehensive data governance framework that takes the above into consideration is key to unlocking the full potential of AI while mitigating risks around data quality, ethics, and security.
 As AI continues to evolve, data governance frameworks must keep pace, ensuring that data integrity, accountability, and privacy are upheld.  By integrating these principles, businesses can leverage AI responsibly, creating impactful and ethical solutions that drive meaningful insights and decision-making,  concludes Keyter.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ETHICS (90%); REGULATORY ACTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); QUALITY CONTROL (89%); DATA BREACHES (78%); NEGATIVE BUSINESS NEWS (78%); REGULATORY COMPLIANCE (77%); ENCRYPTION (73%); CRYPTOLOGY (71%); UNCONSCIOUS BIAS (67%); NEGATIVE TECHNOLOGY NEWS (50%); PBT Group (%); data governance (%); AI (%); Petrus Keyter (%)
Industry: DATA GOVERNANCE & STEWARDSHIP (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); DATA PRIVACY (90%); INFORMATION SECURITY & PRIVACY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); DATA SECURITY (89%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); DATA BREACHES (78%); BIG DATA (73%); ENCRYPTION (73%); CRYPTOLOGY (71%)
Load-Date: December 27, 2024",neutral,0.5614877343177795,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'security', 'access']",['fairness'],"['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'framework', 'compliance', 'should', 'must', 'need to']",[],7,1,11,0
2024,Unknown Title,"Byline: Thomas Fox - Compliance Evangelist
Body
December 18th, 2024 ( JD Supra  - Delivered by  Newstex )
Business Integrity Innovations is brought to you by the Center for International Private Enterprise (CIPE) and the Compliance Podcast Network (CPN). This podcast is inspired by Ethics 1st - a multi-stakeholder initiative led by CIPE, that is creating pathways for accountable and sustainable investment in Africa. Companies can standardize their business practices, develop sound corporate governance systems, and demonstrate their commitment to compliance and business ethics using Ethics Seemore+
Business Integrity Innovations is brought to you by the Center for International Private Enterprise (CIPE) and the Compliance Podcast Network (CPN). This podcast is inspired by Ethics 1st - a multi-stakeholder initiative led by CIPE, that is creating pathways for accountable and sustainable investment in Africa. Companies can standardize their business practices, develop sound corporate governance systems, and demonstrate their commitment to compliance and business ethics using Ethics 1st.
In this episode, Tom and Lola are joined by Pana Ratanabanangkoon, who has over 30 years of experience in the energy industry and a key figure in the anti-corruption movement. Pana shares his journey from working with Shell in various countries to leading the Thai Collective Action Against Corruption (Thai CAC). He details the evolution of Thai CAC, highlighting its significant growth and innovative strategies in collective action, certification processes, and compliance. Pana also discusses the establishment of the International Collective Action Network (ICANN) to support similar initiatives globally. The conversation delves into the challenges and motivations driving anti-corruption efforts in the private sector and explores future trends, including the potential role of AI in enhancing compliance programs.
Key Highlights:
Pana's Professional Background
Role in Anti-Corruption Efforts
Evolution of Thai CAC
Challenges and Experiences
Future of Anti-Corruption Initiatives
Business Solutions to Corruption Seeless-
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: ETHICS (91%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); CORPORATE GOVERNANCE (90%); CORRUPTION (90%); ANTI-CORRUPTION (89%); ENERGY & UTILITY REGULATORY COMPLIANCE (77%); ESG FACTORS - GOVERNANCE (76%); EMPLOYMENT HISTORY (72%); GREEN FINANCE (71%); SUSTAINABLE INVESTING (71%); TRENDS (70%)
Company:  INTERNET CORP FOR ASSIGNED NAMES & NUMBERS (52%)
Industry: PODCASTING (91%); ENERGY & UTILITY REGULATORY COMPLIANCE (77%); ELECTRIC POWER INDUSTRY (73%); GREEN FINANCE (71%); SUSTAINABLE INVESTING (71%)
Geographic: AFRICA (88%)
Load-Date: December 19, 2024","December 18th, 2024 ( JD Supra  - Delivered by  Newstex )
Business Integrity Innovations is brought to you by the Center for International Private Enterprise (CIPE) and the Compliance Podcast Network (CPN). This podcast is inspired by Ethics 1st - a multi-stakeholder initiative led by CIPE, that is creating pathways for accountable and sustainable investment in Africa. Companies can standardize their business practices, develop sound corporate governance systems, and demonstrate their commitment to compliance and business ethics using Ethics Seemore+
Business Integrity Innovations is brought to you by the Center for International Private Enterprise (CIPE) and the Compliance Podcast Network (CPN). This podcast is inspired by Ethics 1st - a multi-stakeholder initiative led by CIPE, that is creating pathways for accountable and sustainable investment in Africa. Companies can standardize their business practices, develop sound corporate governance systems, and demonstrate their commitment to compliance and business ethics using Ethics 1st.
In this episode, Tom and Lola are joined by Pana Ratanabanangkoon, who has over 30 years of experience in the energy industry and a key figure in the anti-corruption movement. Pana shares his journey from working with Shell in various countries to leading the Thai Collective Action Against Corruption (Thai CAC). He details the evolution of Thai CAC, highlighting its significant growth and innovative strategies in collective action, certification processes, and compliance. Pana also discusses the establishment of the International Collective Action Network (ICANN) to support similar initiatives globally. The conversation delves into the challenges and motivations driving anti-corruption efforts in the private sector and explores future trends, including the potential role of AI in enhancing compliance programs.
Key Highlights:
Pana's Professional Background
Role in Anti-Corruption Efforts
Evolution of Thai CAC
Challenges and Experiences
Future of Anti-Corruption Initiatives
Business Solutions to Corruption Seeless-
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: ETHICS (91%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); CORPORATE GOVERNANCE (90%); CORRUPTION (90%); ANTI-CORRUPTION (89%); ENERGY & UTILITY REGULATORY COMPLIANCE (77%); ESG FACTORS - GOVERNANCE (76%); EMPLOYMENT HISTORY (72%); GREEN FINANCE (71%); SUSTAINABLE INVESTING (71%); TRENDS (70%)
Company:  INTERNET CORP FOR ASSIGNED NAMES & NUMBERS (52%)
Industry: PODCASTING (91%); ENERGY & UTILITY REGULATORY COMPLIANCE (77%); ELECTRIC POWER INDUSTRY (73%); GREEN FINANCE (71%); SUSTAINABLE INVESTING (71%)
Geographic: AFRICA (88%)
Load-Date: December 19, 2024",neutral,0.7546238303184509,balanced/neutral,[],[],"['governance', 'compliance', 'certification', 'should']",[],0,0,4,0
2024,Unknown Title,"Body
Link to Story
Readers' Favorite announces the review of the Non-Fiction - Business/Finance book ""Navigating Ethical Leadership in the Age of AI"" by Annette Bühler, currently available at .
Readers' Favorite is one of the largest book review and award contest sites on the Internet. They have earned the respect of renowned publishers like Random House, Simon & Schuster, and Harper Collins, and have received the ""Best Websites for Authors"" and ""Honoring Excellence"" awards from the Association of Independent Authors. They are also fully accredited by the BBB (A+ rating), which is a rarity among Book Review and Book Award Contest companies.
""Reviewed By Asher Syed for Readers' Favorite
Annette Bühler's Navigating Ethical Leadership in the Age of AI: The Ethic Pocketknife covers the roles of ethical leadership as AI technologies take off. Bühler emphasizes how important it is to incorporate ethical frameworks-deontological, teleological, and virtue ethics-into leadership work to avoid any ethical hitches with AI, like data privacy, bias, and transparency. Bühler gives us the ""Ethic Pocketknife,"" a toolkit to help leaders add ethical considerations to their decision-making. Her toolkit includes sections like the Integrity Blade and Fairness File, which help make sure decisions are in line with human values and society. Bühler shows us its application by including case studies in sectors like healthcare and fintech, drawing out continuous improvement, stakeholder engagement, and the balance between technological progress and ethical standards.
""Ethical sensitivity means recognizing the broader implications of our actions and striving to do what is right, even when it's not the easiest path."" Annette Bühler has done an excellent job of writing clear and well-structured arguments logically in Navigating Ethical Leadership in the Age of AI, breaking the work down into organized sections, distinct definitions, and in a style that is both professional and wonderfully accessible. Bühler amplifies this for readers by giving actionable insight that can be applied to businesses in almost any sector. I really appreciate the practical tools she spells out for us, the key piece being the Ethic Pocketknife. It's quite an innovative concept when you think about the handiness of a pocketknife, and I loved that the different tools that flip out of it are symbolic of Bühler's components. I'm partial to the Collaboration Corkscrew; you'll have to find out for yourself what that means. Overall, this is a fantastic, progressive, and forward-thinking guide that should be required reading for leaders, and leaders in the making.""
You can learn more about Annette Bühler and ""Navigating Ethical Leadership in the Age of AI"" at where you can read reviews and the author's biography, as well as connect with the author directly or through their website and social media pages.
MENAFN26082024003238003268ID1108601612
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); BOOK REVIEWS (91%); LITERATURE (90%); WRITERS (90%); TECHNOLOGY (89%); BIOGRAPHICAL LITERATURE (78%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); CASE STUDIES (77%); ACCREDITATION (75%); QUALITY CONTROL (75%); BETTER BUSINESS BUREAUS (73%); PROFILES & BIOGRAPHIES (73%); SOCIAL MEDIA (72%)
Company:  BEST INC (57%);  SIMON & SCHUSTER INC (57%)
Ticker: BEST (NYSE) (57%)
Industry: SIC5999 MISCELLANEOUS RETAIL STORES, NEC (57%); NAICS513130 BOOK PUBLISHERS (57%); SIC2731 BOOKS: PUBLISHING, OR PUBLISHING & PRINTING (57%); BOOK REVIEWS (91%); WRITERS (90%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); PUBLISHING (78%); INTERNET & WWW (77%); WEBSITES (77%); SOCIAL MEDIA (72%); INFORMATION SECURITY & PRIVACY (67%)
Load-Date: January 28, 2025","Link to Story
Readers' Favorite announces the review of the Non-Fiction - Business/Finance book ""Navigating Ethical Leadership in the Age of AI"" by Annette Bühler, currently available at .
Readers' Favorite is one of the largest book review and award contest sites on the Internet. They have earned the respect of renowned publishers like Random House, Simon & Schuster, and Harper Collins, and have received the ""Best Websites for Authors"" and ""Honoring Excellence"" awards from the Association of Independent Authors. They are also fully accredited by the BBB (A+ rating), which is a rarity among Book Review and Book Award Contest companies.
""Reviewed By Asher Syed for Readers' Favorite
Annette Bühler's Navigating Ethical Leadership in the Age of AI: The Ethic Pocketknife covers the roles of ethical leadership as AI technologies take off. Bühler emphasizes how important it is to incorporate ethical frameworks-deontological, teleological, and virtue ethics-into leadership work to avoid any ethical hitches with AI, like data privacy, bias, and transparency. Bühler gives us the ""Ethic Pocketknife,"" a toolkit to help leaders add ethical considerations to their decision-making. Her toolkit includes sections like the Integrity Blade and Fairness File, which help make sure decisions are in line with human values and society. Bühler shows us its application by including case studies in sectors like healthcare and fintech, drawing out continuous improvement, stakeholder engagement, and the balance between technological progress and ethical standards.
""Ethical sensitivity means recognizing the broader implications of our actions and striving to do what is right, even when it's not the easiest path."" Annette Bühler has done an excellent job of writing clear and well-structured arguments logically in Navigating Ethical Leadership in the Age of AI, breaking the work down into organized sections, distinct definitions, and in a style that is both professional and wonderfully accessible. Bühler amplifies this for readers by giving actionable insight that can be applied to businesses in almost any sector. I really appreciate the practical tools she spells out for us, the key piece being the Ethic Pocketknife. It's quite an innovative concept when you think about the handiness of a pocketknife, and I loved that the different tools that flip out of it are symbolic of Bühler's components. I'm partial to the Collaboration Corkscrew; you'll have to find out for yourself what that means. Overall, this is a fantastic, progressive, and forward-thinking guide that should be required reading for leaders, and leaders in the making.""
You can learn more about Annette Bühler and ""Navigating Ethical Leadership in the Age of AI"" at where you can read reviews and the author's biography, as well as connect with the author directly or through their website and social media pages.
MENAFN26082024003238003268ID1108601612
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); BOOK REVIEWS (91%); LITERATURE (90%); WRITERS (90%); TECHNOLOGY (89%); BIOGRAPHICAL LITERATURE (78%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); CASE STUDIES (77%); ACCREDITATION (75%); QUALITY CONTROL (75%); BETTER BUSINESS BUREAUS (73%); PROFILES & BIOGRAPHIES (73%); SOCIAL MEDIA (72%)
Company:  BEST INC (57%);  SIMON & SCHUSTER INC (57%)
Ticker: BEST (NYSE) (57%)
Industry: SIC5999 MISCELLANEOUS RETAIL STORES, NEC (57%); NAICS513130 BOOK PUBLISHERS (57%); SIC2731 BOOKS: PUBLISHING, OR PUBLISHING & PRINTING (57%); BOOK REVIEWS (91%); WRITERS (90%); ENTERTAINMENT & ARTS AWARDS (78%); FINANCIAL TECHNOLOGY (78%); PUBLISHING (78%); INTERNET & WWW (77%); WEBSITES (77%); SOCIAL MEDIA (72%); INFORMATION SECURITY & PRIVACY (67%)
Load-Date: January 28, 2025",positive,0.5249064564704895,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'security']","['deontological', 'virtue ethics', 'fairness']","['standards', 'should']",[],5,3,2,0
2024,Unknown Title,"Dateline: India 
Body
India, Sept. 20 -- As technology rapidly evolves, computer scientists and engineers face a growing number of ethical dilemmas. From safeguarding privacy and data security to mitigating social bias in AI and ensuring the responsible development of autonomous systems, the need for ethical decision-making is more urgent than ever. What are the key ethical challenges today, and what skills are essential to navigate them? How crucial is collaboration between academia, industry, and policymakers in balancing innovation with responsibility? Prof. Vijaysekhar Chellaboina, Dean of the School of Computer Science at UPES, shares his insights on these pressing issues in an email interview with Hindustan Times Digital.
The key ethical issues for computer scientists include privacy and data security, social bias in AI and machine learning, and safety concerns in AI-driven autonomous systems like self-driving cars. Privacy and data security are significant challenges, requiring a balance between the benefits of data collection and the protection of individual privacy. AI and machine learning also pose critical issues, as algorithms can unintentionally perpetuate societal biases. The development of autonomous systems raises important safety and ethical questions. Moreover, managing misinformation and content moderation on digital platforms, along with addressing environmental impact, energy consumption, e-waste, and the digital divide, are also crucial concerns.
To become ethical engineers, students need a strong ethical foundation, including knowledge of ethical theories and professional codes of conduct. Critical thinking and problem-solving skills are essential for analysing and resolving ethical dilemmas. Cultural and social awareness helps engineers consider the broader impacts of their work, while legal and regulatory knowledge ensures compliance with laws and standards. Effective communication and transparency are crucial for engaging stakeholders. Additionally, a commitment to sustainability, interdisciplinary collaboration, and continual learning enables engineers to address complex challenges responsibly and adapt to evolving ethical considerations in their field.
Computer scientists can balance innovation with responsibility by integrating ethical considerations into every stage of development. This involves critically assessing the potential social impacts of new technologies, such as privacy concerns, bias in algorithms, and environmental effects. Engaging with diverse stakeholders, including ethicists, policymakers, and affected communities, helps ensure that innovations align with societal values. Adhering to professional codes of conduct, staying informed about legal regulations, and fostering a culture of transparency and accountability within teams are also crucial. By prioritising ethical principles alongside technical advancement, computer scientists can drive innovation that benefits society responsibly.
AI and machine learning play a crucial role in ethical engineering by enabling the development of technologies that can address complex societal challenges. However, their application also raises significant ethical concerns, such as bias, privacy, and accountability. Ethical engineering in AI involves designing algorithms that are fair, transparent, and explainable, ensuring that they do not reinforce existing inequalities. Engineers must rigorously test AI systems for unintended consequences, adhere to ethical guidelines, and engage with diverse perspectives to avoid harmful impacts. By embedding ethical considerations into AI and machine learning, engineers can create responsible technologies that serve the broader good.
Industry encounters numerous challenges and opportunities to address ethical considerations through real-world experiences. Meanwhile, academia, through research and education, can create technological solutions to identify and prevent unethical behaviour. By analysing these instances, academia can provide students with valuable training in ethical practices, ensuring they are well-prepared to address ethical issues in emerging technologies. Each real-world case serves as a learning opportunity, helping students understand and navigate ethical dilemmas while developing new technologies. This collaboration between industry and academia is crucial for fostering responsible innovation and ethical behaviour in future engineers and technologists.
Policy and regulation play a vital role in guiding ethical engineering practices in computer science by setting clear standards and accountability mechanisms. They ensure that technologies are developed and deployed in ways that protect public interests, such as privacy, safety, and fairness. Regulations can mandate transparency, data protection, and bias mitigation, while policies can promote responsible innovation through incentives and guidelines. By providing a legal and ethical framework, policymakers help prevent the misuse of technology and encourage engineers to prioritise societal well-being. Collaboration between lawmakers, technologists, and ethicists is crucial to crafting effective, forward-thinking policies that adapt to rapid technological advances.
Published by HT Digital Content Services with permission from HT Education. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (94%); COMPUTER SCIENCE (93%); TECHNICIANS & TECHNOLOGICAL WORKERS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); PRIVACY RIGHTS (90%); TECHNOLOGY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); PROFESSIONAL WORKERS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CORPORATE SUSTAINABILITY (78%); DIGITAL DIVIDE (78%); EMERGING TECHNOLOGY (78%); ENVIRONMENTAL RESEARCH (78%); NEGATIVE SOCIETAL NEWS (78%); REGULATORY COMPLIANCE (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); DISINFORMATION & MISINFORMATION (72%); ENERGY & ENVIRONMENT (71%); INTERVIEWS (70%); ENVIRONMENT & NATURAL RESOURCES (66%); POLLUTION & ENVIRONMENTAL IMPACTS (66%)
Company:  AI SYSTEMS (50%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); COMPUTER SCIENCE (93%); INFORMATION SECURITY & PRIVACY (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); DATA SECURITY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); AUTONOMOUS MOTOR VEHICLES (72%); ENERGY & UTILITIES (72%); ENERGY & ENVIRONMENT (71%); ENERGY CONSUMPTION (51%)
Geographic: INDIA (90%)
Load-Date: October 3, 2024","India, Sept. 20 -- As technology rapidly evolves, computer scientists and engineers face a growing number of ethical dilemmas. From safeguarding privacy and data security to mitigating social bias in AI and ensuring the responsible development of autonomous systems, the need for ethical decision-making is more urgent than ever. What are the key ethical challenges today, and what skills are essential to navigate them? How crucial is collaboration between academia, industry, and policymakers in balancing innovation with responsibility? Prof. Vijaysekhar Chellaboina, Dean of the School of Computer Science at UPES, shares his insights on these pressing issues in an email interview with Hindustan Times Digital.
The key ethical issues for computer scientists include privacy and data security, social bias in AI and machine learning, and safety concerns in AI-driven autonomous systems like self-driving cars. Privacy and data security are significant challenges, requiring a balance between the benefits of data collection and the protection of individual privacy. AI and machine learning also pose critical issues, as algorithms can unintentionally perpetuate societal biases. The development of autonomous systems raises important safety and ethical questions. Moreover, managing misinformation and content moderation on digital platforms, along with addressing environmental impact, energy consumption, e-waste, and the digital divide, are also crucial concerns.
To become ethical engineers, students need a strong ethical foundation, including knowledge of ethical theories and professional codes of conduct. Critical thinking and problem-solving skills are essential for analysing and resolving ethical dilemmas. Cultural and social awareness helps engineers consider the broader impacts of their work, while legal and regulatory knowledge ensures compliance with laws and standards. Effective communication and transparency are crucial for engaging stakeholders. Additionally, a commitment to sustainability, interdisciplinary collaboration, and continual learning enables engineers to address complex challenges responsibly and adapt to evolving ethical considerations in their field.
Computer scientists can balance innovation with responsibility by integrating ethical considerations into every stage of development. This involves critically assessing the potential social impacts of new technologies, such as privacy concerns, bias in algorithms, and environmental effects. Engaging with diverse stakeholders, including ethicists, policymakers, and affected communities, helps ensure that innovations align with societal values. Adhering to professional codes of conduct, staying informed about legal regulations, and fostering a culture of transparency and accountability within teams are also crucial. By prioritising ethical principles alongside technical advancement, computer scientists can drive innovation that benefits society responsibly.
AI and machine learning play a crucial role in ethical engineering by enabling the development of technologies that can address complex societal challenges. However, their application also raises significant ethical concerns, such as bias, privacy, and accountability. Ethical engineering in AI involves designing algorithms that are fair, transparent, and explainable, ensuring that they do not reinforce existing inequalities. Engineers must rigorously test AI systems for unintended consequences, adhere to ethical guidelines, and engage with diverse perspectives to avoid harmful impacts. By embedding ethical considerations into AI and machine learning, engineers can create responsible technologies that serve the broader good.
Industry encounters numerous challenges and opportunities to address ethical considerations through real-world experiences. Meanwhile, academia, through research and education, can create technological solutions to identify and prevent unethical behaviour. By analysing these instances, academia can provide students with valuable training in ethical practices, ensuring they are well-prepared to address ethical issues in emerging technologies. Each real-world case serves as a learning opportunity, helping students understand and navigate ethical dilemmas while developing new technologies. This collaboration between industry and academia is crucial for fostering responsible innovation and ethical behaviour in future engineers and technologists.
Policy and regulation play a vital role in guiding ethical engineering practices in computer science by setting clear standards and accountability mechanisms. They ensure that technologies are developed and deployed in ways that protect public interests, such as privacy, safety, and fairness. Regulations can mandate transparency, data protection, and bias mitigation, while policies can promote responsible innovation through incentives and guidelines. By providing a legal and ethical framework, policymakers help prevent the misuse of technology and encourage engineers to prioritise societal well-being. Collaboration between lawmakers, technologists, and ethicists is crucial to crafting effective, forward-thinking policies that adapt to rapid technological advances.
Published by HT Digital Content Services with permission from HT Education. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (94%); COMPUTER SCIENCE (93%); TECHNICIANS & TECHNOLOGICAL WORKERS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); PRIVACY RIGHTS (90%); TECHNOLOGY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); PROFESSIONAL WORKERS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CORPORATE SUSTAINABILITY (78%); DIGITAL DIVIDE (78%); EMERGING TECHNOLOGY (78%); ENVIRONMENTAL RESEARCH (78%); NEGATIVE SOCIETAL NEWS (78%); REGULATORY COMPLIANCE (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); DISINFORMATION & MISINFORMATION (72%); ENERGY & ENVIRONMENT (71%); INTERVIEWS (70%); ENVIRONMENT & NATURAL RESOURCES (66%); POLLUTION & ENVIRONMENTAL IMPACTS (66%)
Company:  AI SYSTEMS (50%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); COMPUTER SCIENCE (93%); INFORMATION SECURITY & PRIVACY (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); DATA SECURITY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); AUTONOMOUS MOTOR VEHICLES (72%); ENERGY & UTILITIES (72%); ENERGY & ENVIRONMENT (71%); ENERGY CONSUMPTION (51%)
Geographic: INDIA (90%)
Load-Date: October 3, 2024",neutral,0.7734254002571106,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'safety', 'security', 'misinformation', 'disinformation', 'digital divide', 'environmental impact']",['fairness'],"['regulation', 'policy', 'standards', 'guidelines', 'framework', 'compliance', 'must']",['machine learning'],11,1,7,1
2024,Unknown Title,"Body
2024 NOV 29 (NewsRx) -- By a News Reporter-Staff News Editor at Information Technology Daily -- Current study results on Information Technology - Information and Data Privacy have been published. According to news reporting originating from Vellore, India, by NewsRx editors, the research stated, ""This study presents a comprehensive bibliometric analysis of ChatGPT's impact on three critical sectors: healthcare, financial services, and education, covering the period from 2022 to 2024. The research aimed to explore the evolving trends, limitations, and ethical considerations associated with the deployment of ChatGPT and similar AI-driven conversational interfaces."" 
 Our news editors obtained a quote from the research from the Vellore Institute of Technology, ""The findings reveal that while ChatGPT offers significant potential in enhancing efficiency and decision-making processes, it also faces substantial challenges in data privacy, integration with existing systems, and the need for improved emotional intelligence. The study highlights the inherent biases in AI models, raising concerns about the accuracy and fairness of AI-driven outputs. Ethical considerations, including data privacy, transparency, accountability, and equity in AI applications, are identified as crucial areas requiring urgent attention and development. Additionally, the research underscores the importance of developing robust regulatory frameworks and ethical guidelines to govern AI deployment in these sectors. Successful integration of ChatGPT and similar technologies depends on addressing these challenges and ethical considerations through collaborative efforts among AI developers, industry professionals, policymakers, and ethicists."" 
 According to the news editors, the research concluded: ""Future research should focus on improving AI's data security, emotional intelligence, bias reduction, human-AI collaboration, and assessing long-term impacts across diverse settings."" 
 This research has been peer-reviewed. 
 For more information on this research see: Evolving Trends, Limitations, and Ethical Considerations In Ai-driven Conversational Interfaces: Assessing Chatgpt's Impact On Healthcare, Financial Services, and Educational Sectors. Technology Analysis and Strategic Management, 2024. Technology Analysis and Strategic Management can be contacted at: Routledge Journals, Taylor & Francis Ltd, 2-4 Park Square, Milton Park, Abingdon OX14 4RN, Oxon, England. 
 The news editors report that additional information may be obtained by contacting Mohd Afjal, Vellore Institute of Technology, Vit Business Sch, Vellore, India. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1080/09537325.2024.2420617. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Vellore, India, Asia, Finance and Investment, Information Technology, Information and Data Privacy, Investment and Finance, Vellore Institute of Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHATBOTS (90%); CONVERSATIONAL AI (90%); GENERATIVE AI (90%); RESEARCH REPORTS (90%); JOURNALISM (78%); NEWS REPORTING (78%); HUMAN IN THE LOOP (76%); PUBLIC POLICY (76%); INFORMATION SCIENCE (74%); EXPERIMENTATION & RESEARCH (73%); INTELLIGENCE & COGNITION (73%); EMOTIONAL INTELLIGENCE (68%); EMOTIONS (68%); COMPANY STRATEGY (66%); Vellore;India;Asia;Finance and Investment;Information Technology;Information and Data Privacy;Investment and Finance (%)
Company:  TAYLOR & FRANCIS LTD (63%)
Industry: INFORMATION SECURITY & PRIVACY (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHATBOTS (90%); CONVERSATIONAL AI (90%); DATA PRIVACY (90%); GENERATIVE AI (90%); BANKING & FINANCE (78%); NEWS REPORTING (78%); DATA SECURITY (74%)
Geographic: INDIA (90%); ASIA (88%)
Load-Date: November 29, 2024","2024 NOV 29 (NewsRx) -- By a News Reporter-Staff News Editor at Information Technology Daily -- Current study results on Information Technology - Information and Data Privacy have been published. According to news reporting originating from Vellore, India, by NewsRx editors, the research stated, ""This study presents a comprehensive bibliometric analysis of ChatGPT's impact on three critical sectors: healthcare, financial services, and education, covering the period from 2022 to 2024. The research aimed to explore the evolving trends, limitations, and ethical considerations associated with the deployment of ChatGPT and similar AI-driven conversational interfaces."" 
 Our news editors obtained a quote from the research from the Vellore Institute of Technology, ""The findings reveal that while ChatGPT offers significant potential in enhancing efficiency and decision-making processes, it also faces substantial challenges in data privacy, integration with existing systems, and the need for improved emotional intelligence. The study highlights the inherent biases in AI models, raising concerns about the accuracy and fairness of AI-driven outputs. Ethical considerations, including data privacy, transparency, accountability, and equity in AI applications, are identified as crucial areas requiring urgent attention and development. Additionally, the research underscores the importance of developing robust regulatory frameworks and ethical guidelines to govern AI deployment in these sectors. Successful integration of ChatGPT and similar technologies depends on addressing these challenges and ethical considerations through collaborative efforts among AI developers, industry professionals, policymakers, and ethicists."" 
 According to the news editors, the research concluded: ""Future research should focus on improving AI's data security, emotional intelligence, bias reduction, human-AI collaboration, and assessing long-term impacts across diverse settings."" 
 This research has been peer-reviewed. 
 For more information on this research see: Evolving Trends, Limitations, and Ethical Considerations In Ai-driven Conversational Interfaces: Assessing Chatgpt's Impact On Healthcare, Financial Services, and Educational Sectors. Technology Analysis and Strategic Management, 2024. Technology Analysis and Strategic Management can be contacted at: Routledge Journals, Taylor & Francis Ltd, 2-4 Park Square, Milton Park, Abingdon OX14 4RN, Oxon, England. 
 The news editors report that additional information may be obtained by contacting Mohd Afjal, Vellore Institute of Technology, Vit Business Sch, Vellore, India. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1080/09537325.2024.2420617. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Vellore, India, Asia, Finance and Investment, Information Technology, Information and Data Privacy, Investment and Finance, Vellore Institute of Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHATBOTS (90%); CONVERSATIONAL AI (90%); GENERATIVE AI (90%); RESEARCH REPORTS (90%); JOURNALISM (78%); NEWS REPORTING (78%); HUMAN IN THE LOOP (76%); PUBLIC POLICY (76%); INFORMATION SCIENCE (74%); EXPERIMENTATION & RESEARCH (73%); INTELLIGENCE & COGNITION (73%); EMOTIONAL INTELLIGENCE (68%); EMOTIONS (68%); COMPANY STRATEGY (66%); Vellore;India;Asia;Finance and Investment;Information Technology;Information and Data Privacy;Investment and Finance (%)
Company:  TAYLOR & FRANCIS LTD (63%)
Industry: INFORMATION SECURITY & PRIVACY (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHATBOTS (90%); CONVERSATIONAL AI (90%); DATA PRIVACY (90%); GENERATIVE AI (90%); BANKING & FINANCE (78%); NEWS REPORTING (78%); DATA SECURITY (74%)
Geographic: INDIA (90%); ASIA (88%)
Load-Date: November 29, 2024",neutral,0.9019321799278259,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'security']","['fairness', 'equity']","['policy', 'guidelines', 'should']","['generative ai', 'chatgpt']",6,2,3,2
2024,Unknown Title,"Body
2024 OCT 28 (NewsRx) -- By a News Reporter-Staff News Editor at Transportation Daily News -- New research on Transportation - Self-Driving Cars is the subject of a report. According to news reporting out of Munich, Germany, by NewsRx editors, research stated, ""Self-driving vehicles (SDVs) will need to make decisions that carry ethical dimensions and are of normative significance. For example, by choosing a specific trajectory, they determine how risks are distributed among traffic participants."" 
 Financial support for this research came from Institute for Ethics in Artificial Intelligence (IEAI); Technical University Munich. 
 Our news journalists obtained a quote from the research from Technical University Munich (TUM), ""Accordingly, policymakers, standardization organizations and scholars have conceptualized what (shall) constitute(s) ethical decision-making for SDVs. Eventually, these conceptualizations must be converted into specific system requirements to ensure proper technical implementation. Therefore, this article aims to translate critical requirements recently formulated in scholarly work, existing standards, regulatory drafts and guidelines into an explicit five-step ethical decision model for SDVs during hazardous situations. This model states a precise sequence of steps, indicates the guiding ethical principles that inform each step and points out a list of terms that demand further investigation and technical specification. By integrating ethical, legal and engineering considerations, we aim to contribute to the scholarly debate on computational ethics (particularly in autonomous driving) while offering practitioners in the automotive sector a decision-making process for SDVs that is technically viable, legally permissible, ethically grounded and adaptable to societal values."" 
 According to the news editors, the research concluded: ""In the future, assessing the actual impact, effectiveness and admissibility of implementing the here sketched theories, terms and the overall decision process requires an empirical evaluation and testing of the overall decision-making model."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethical Decision-Making for Self-Driving Vehicles: A Proposed Model & List of Value-Laden Terms that Warrant (Technical) Specification. Science and Engineering Ethics, 2024;30(5):47. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 Our news journalists report that additional information may be obtained by contacting Franziska Poszler, Peter Loscher Chair of Business Ethics, Institute for Ethics in Artificial Intelligence, Technical University Munich (TUM), Arcisstraße 21, 80333, Munich, Germany. Additional authors for this research include Maximilian Geisslinger and Christoph Lutge. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-024-00513-0. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Publisher contact information for the journal Science and Engineering Ethics is: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Munich, Germany, Europe, Emerging Technologies, Self-Driving Cars, Transportation. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (96%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); ENGINEERING (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (76%); PUBLIC POLICY (74%); NEWS REPORTING (73%); BUSINESS ETHICS (71%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (71%); COLLEGES & UNIVERSITIES (71%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (71%); ARTIFICIAL INTELLIGENCE (70%); ASSOCIATIONS & ORGANIZATIONS (69%); Munich;Germany;Europe;Emerging Technologies;Self-Driving Cars;Transportation (%)
Industry: AUTONOMOUS MOTOR VEHICLES (90%); AUTONOMOUS VEHICLES (90%); SOFTWARE DEFINED VEHICLES (90%); ENGINEERING (89%); WRITERS (89%); AUTOMOTIVE (78%); ARTIFICIAL INTELLIGENCE ETHICS (76%); NEWS REPORTING (73%); COLLEGES & UNIVERSITIES (71%); ARTIFICIAL INTELLIGENCE (70%)
Person: PETER LOESCHER (50%)
Geographic: GERMANY (89%); NETHERLANDS (79%); EUROPE (73%)
Load-Date: October 28, 2024","2024 OCT 28 (NewsRx) -- By a News Reporter-Staff News Editor at Transportation Daily News -- New research on Transportation - Self-Driving Cars is the subject of a report. According to news reporting out of Munich, Germany, by NewsRx editors, research stated, ""Self-driving vehicles (SDVs) will need to make decisions that carry ethical dimensions and are of normative significance. For example, by choosing a specific trajectory, they determine how risks are distributed among traffic participants."" 
 Financial support for this research came from Institute for Ethics in Artificial Intelligence (IEAI); Technical University Munich. 
 Our news journalists obtained a quote from the research from Technical University Munich (TUM), ""Accordingly, policymakers, standardization organizations and scholars have conceptualized what (shall) constitute(s) ethical decision-making for SDVs. Eventually, these conceptualizations must be converted into specific system requirements to ensure proper technical implementation. Therefore, this article aims to translate critical requirements recently formulated in scholarly work, existing standards, regulatory drafts and guidelines into an explicit five-step ethical decision model for SDVs during hazardous situations. This model states a precise sequence of steps, indicates the guiding ethical principles that inform each step and points out a list of terms that demand further investigation and technical specification. By integrating ethical, legal and engineering considerations, we aim to contribute to the scholarly debate on computational ethics (particularly in autonomous driving) while offering practitioners in the automotive sector a decision-making process for SDVs that is technically viable, legally permissible, ethically grounded and adaptable to societal values."" 
 According to the news editors, the research concluded: ""In the future, assessing the actual impact, effectiveness and admissibility of implementing the here sketched theories, terms and the overall decision process requires an empirical evaluation and testing of the overall decision-making model."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethical Decision-Making for Self-Driving Vehicles: A Proposed Model & List of Value-Laden Terms that Warrant (Technical) Specification. Science and Engineering Ethics, 2024;30(5):47. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 Our news journalists report that additional information may be obtained by contacting Franziska Poszler, Peter Loscher Chair of Business Ethics, Institute for Ethics in Artificial Intelligence, Technical University Munich (TUM), Arcisstraße 21, 80333, Munich, Germany. Additional authors for this research include Maximilian Geisslinger and Christoph Lutge. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-024-00513-0. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Publisher contact information for the journal Science and Engineering Ethics is: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Munich, Germany, Europe, Emerging Technologies, Self-Driving Cars, Transportation. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (96%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); ENGINEERING (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (76%); PUBLIC POLICY (74%); NEWS REPORTING (73%); BUSINESS ETHICS (71%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (71%); COLLEGES & UNIVERSITIES (71%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (71%); ARTIFICIAL INTELLIGENCE (70%); ASSOCIATIONS & ORGANIZATIONS (69%); Munich;Germany;Europe;Emerging Technologies;Self-Driving Cars;Transportation (%)
Industry: AUTONOMOUS MOTOR VEHICLES (90%); AUTONOMOUS VEHICLES (90%); SOFTWARE DEFINED VEHICLES (90%); ENGINEERING (89%); WRITERS (89%); AUTOMOTIVE (78%); ARTIFICIAL INTELLIGENCE ETHICS (76%); NEWS REPORTING (73%); COLLEGES & UNIVERSITIES (71%); ARTIFICIAL INTELLIGENCE (70%)
Person: PETER LOESCHER (50%)
Geographic: GERMANY (89%); NETHERLANDS (79%); EUROPE (73%)
Load-Date: October 28, 2024",neutral,0.8932468295097351,balanced/neutral,[],[],"['policy', 'standards', 'guidelines', 'must', 'need to']",[],0,0,5,0
2024,Unknown Title,"Body
2024 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting out of Burnaby, Canada, by NewsRx editors, research stated, ""Artificial Intelligence (AI) systems encode not just statistical models and complex algorithms designed to process and analyze data, but also significant normative baggage."" 
 The news correspondents obtained a quote from the research from Simon Fraser University: ""This ethical dimension, derived from the underlying code and training data, shapes the recommendations given, behaviors exhibited, and perceptions had by AI. These factors influence how AI is regulated, used, misused, and impacts end-users. The multifaceted nature of AI's influence has sparked extensive discussions across disciplines like Science and Technology Studies (STS), Ethical, Legal and Social Implications (ELSI) studies, public policy analysis, and responsible innovation-underscoring the need to examine AI's ethical ramifications. While the initial wave of AI ethics focused on articulating principles and guidelines, recent scholarship increasingly emphasizes the practical implementation of ethical principles, regulatory oversight, and mitigating unforeseen negative consequences. Drawing from the concept of 'ethics dumping' in research ethics, this paper argues that practices surrounding AI development and deployment can, unduly and in a very concerning way, offload ethical responsibilities from developers and regulators to ill-equipped users and host environments. Four key trends illustrating such ethics dumping are identified: (1) AI developers embedding ethics through coded value assumptions, (2) AI ethics guidelines promoting broad or unactionable principles disconnected from local contexts, (3) institutions implementing AI systems without evaluating ethical implications, and (4) decision-makers enacting ethical governance frameworks disconnected from practice."" 
 According to the news reporters, the research concluded: ""Mitigating AI ethics dumping requires empowering users, fostering stakeholder engagement in norm-setting, harmonizing ethical guidelines while allowing flexibility for local variation, and establishing clear accountability mechanisms across the AI ecosystem."" 
 For more information on this research see: Ethics dumping in artificial intelligence. Frontiers in Artificial Intelligence, 2024,7. The publisher for Frontiers in Artificial Intelligence is Frontiers Media S.A. 
 A free version of this journal article is available at https://doi.org/10.3389/frai.2024.1426761. 
 Our news editors report that more information may be obtained by contacting Jean-Christophe Belisle-Pipon, Philosophy Department, Simon Fraser University, Burnaby, BC, Canada. Additional authors for this research include Gavin Victor. 
 Keywords for this news article include: Simon Fraser University, Burnaby, Canada, North and Central America, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); JOURNALISM (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); EMERGING TECHNOLOGY (79%); TECHNOLOGY (79%); NEWS REPORTING (78%); EXPERIMENTATION & RESEARCH (77%); PHILOSOPHY (77%); REGULATORY ACTIONS (77%); PUBLIC POLICY (73%); SOCIAL SCIENCE EDUCATION (73%); WRITERS (73%); STATISTICAL METHOD (71%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (73%)
Geographic: CANADA (93%); CENTRAL AMERICA (79%)
Load-Date: November 22, 2024","2024 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting out of Burnaby, Canada, by NewsRx editors, research stated, ""Artificial Intelligence (AI) systems encode not just statistical models and complex algorithms designed to process and analyze data, but also significant normative baggage."" 
 The news correspondents obtained a quote from the research from Simon Fraser University: ""This ethical dimension, derived from the underlying code and training data, shapes the recommendations given, behaviors exhibited, and perceptions had by AI. These factors influence how AI is regulated, used, misused, and impacts end-users. The multifaceted nature of AI's influence has sparked extensive discussions across disciplines like Science and Technology Studies (STS), Ethical, Legal and Social Implications (ELSI) studies, public policy analysis, and responsible innovation-underscoring the need to examine AI's ethical ramifications. While the initial wave of AI ethics focused on articulating principles and guidelines, recent scholarship increasingly emphasizes the practical implementation of ethical principles, regulatory oversight, and mitigating unforeseen negative consequences. Drawing from the concept of 'ethics dumping' in research ethics, this paper argues that practices surrounding AI development and deployment can, unduly and in a very concerning way, offload ethical responsibilities from developers and regulators to ill-equipped users and host environments. Four key trends illustrating such ethics dumping are identified: (1) AI developers embedding ethics through coded value assumptions, (2) AI ethics guidelines promoting broad or unactionable principles disconnected from local contexts, (3) institutions implementing AI systems without evaluating ethical implications, and (4) decision-makers enacting ethical governance frameworks disconnected from practice."" 
 According to the news reporters, the research concluded: ""Mitigating AI ethics dumping requires empowering users, fostering stakeholder engagement in norm-setting, harmonizing ethical guidelines while allowing flexibility for local variation, and establishing clear accountability mechanisms across the AI ecosystem."" 
 For more information on this research see: Ethics dumping in artificial intelligence. Frontiers in Artificial Intelligence, 2024,7. The publisher for Frontiers in Artificial Intelligence is Frontiers Media S.A. 
 A free version of this journal article is available at https://doi.org/10.3389/frai.2024.1426761. 
 Our news editors report that more information may be obtained by contacting Jean-Christophe Belisle-Pipon, Philosophy Department, Simon Fraser University, Burnaby, BC, Canada. Additional authors for this research include Gavin Victor. 
 Keywords for this news article include: Simon Fraser University, Burnaby, Canada, North and Central America, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); ROBOTICS (90%); JOURNALISM (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); EMERGING TECHNOLOGY (79%); TECHNOLOGY (79%); NEWS REPORTING (78%); EXPERIMENTATION & RESEARCH (77%); PHILOSOPHY (77%); REGULATORY ACTIONS (77%); PUBLIC POLICY (73%); SOCIAL SCIENCE EDUCATION (73%); WRITERS (73%); STATISTICAL METHOD (71%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (73%)
Geographic: CANADA (93%); CENTRAL AMERICA (79%)
Load-Date: November 22, 2024",neutral,0.9383081197738647,balanced/neutral,['accountability'],[],"['regulation', 'policy', 'governance', 'oversight', 'guidelines', 'need to']","['machine learning', 'robotics']",1,0,6,2
2024,Unknown Title,"Body
Ottawa: Governmehas issued the following news release:
Taki Sarantakis, President of the Canada School of Public Service (CSPS), announced the creation of a new permanent Chair dedicated to values and ethics and the promotion of ethical leadership across federal government departments and agencies.
This new role, to be known as the 'Ian D. Shugart Visiting Scholar', is named for the late Clerk of the Privy Council, whose storied 30-year career in the federal public service culminated in being appointed Clerk in 2019, before being appointed to the Senate in 2022. Senator Shugart passed away on October 25, 2023.
The announcement was made on the final day of the two-day 'What Unites Us, Defines Us: Values and Ethics in Today's Federal Public Service' symposium, hosted by the Privy Council Office and the Canada School of Public Service. The event brought federal public servants together to engage in an interactive discussion on the role of values and ethics in the public service, a conversation that the current Clerk, John Hannaford, launched in September 2023.
The symposium featured more than 20 speakers and panelists with a combined on-site and virtual audience of more than 15,500 federal civil servants from across the country and abroad. Hannaford, who delivered a keynote at the symposium, welcomed the initiative.
The new Chair will focus specifically on helping develop and enrich existing learning and training that encourages decision-making rooted in values and ethics principles—particularly at the leadership levels—and promote the importance of ethical leadership across government.
The role will also establish linkages between the public sector and academia to help infuse the public service with the latest insights and research, explore best practices in ethics and governance, within Canada and internationally, as well as provide guidance on ethical frameworks in response to emerging challenges like digital governance, social media, and artificial intelligence.
Appointees will serve on a rotational basis, starting in 2025. Successful candidates will bring to bear their experience in public sector values and ethics and associated disciplines, such as governance, federalism, technology, and history.
nt of Canada
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (91%); APPOINTMENTS (90%); CONFERENCES & CONVENTIONS (90%); GOVERNMENT ETHICS (90%); LEGISLATIVE BODIES (90%); CIVIL SERVICES (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT ADVISORS & MINISTERS (78%); GOVERNMENT BODIES & OFFICES (78%); TYPES OF GOVERNMENT (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (77%); PRESS RELEASES (73%); BEST PRACTICES (70%); ARTIFICIAL INTELLIGENCE (67%)
Industry: ARTIFICIAL INTELLIGENCE (67%)
Geographic: OTTAWA, ON, CANADA (79%); CANADA (94%)
Load-Date: October 17, 2024","Ottawa: Governmehas issued the following news release:
Taki Sarantakis, President of the Canada School of Public Service (CSPS), announced the creation of a new permanent Chair dedicated to values and ethics and the promotion of ethical leadership across federal government departments and agencies.
This new role, to be known as the 'Ian D. Shugart Visiting Scholar', is named for the late Clerk of the Privy Council, whose storied 30-year career in the federal public service culminated in being appointed Clerk in 2019, before being appointed to the Senate in 2022. Senator Shugart passed away on October 25, 2023.
The announcement was made on the final day of the two-day 'What Unites Us, Defines Us: Values and Ethics in Today's Federal Public Service' symposium, hosted by the Privy Council Office and the Canada School of Public Service. The event brought federal public servants together to engage in an interactive discussion on the role of values and ethics in the public service, a conversation that the current Clerk, John Hannaford, launched in September 2023.
The symposium featured more than 20 speakers and panelists with a combined on-site and virtual audience of more than 15,500 federal civil servants from across the country and abroad. Hannaford, who delivered a keynote at the symposium, welcomed the initiative.
The new Chair will focus specifically on helping develop and enrich existing learning and training that encourages decision-making rooted in values and ethics principles—particularly at the leadership levels—and promote the importance of ethical leadership across government.
The role will also establish linkages between the public sector and academia to help infuse the public service with the latest insights and research, explore best practices in ethics and governance, within Canada and internationally, as well as provide guidance on ethical frameworks in response to emerging challenges like digital governance, social media, and artificial intelligence.
Appointees will serve on a rotational basis, starting in 2025. Successful candidates will bring to bear their experience in public sector values and ethics and associated disciplines, such as governance, federalism, technology, and history.
nt of Canada
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (91%); APPOINTMENTS (90%); CONFERENCES & CONVENTIONS (90%); GOVERNMENT ETHICS (90%); LEGISLATIVE BODIES (90%); CIVIL SERVICES (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT ADVISORS & MINISTERS (78%); GOVERNMENT BODIES & OFFICES (78%); TYPES OF GOVERNMENT (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (77%); PRESS RELEASES (73%); BEST PRACTICES (70%); ARTIFICIAL INTELLIGENCE (67%)
Industry: ARTIFICIAL INTELLIGENCE (67%)
Geographic: OTTAWA, ON, CANADA (79%); CANADA (94%)
Load-Date: October 17, 2024",neutral,0.7852470278739929,balanced/neutral,[],[],['governance'],[],0,0,1,0
2024,Unknown Title,"Byline: Cxotoday News Desk
Body
CXOToday has engaged in an exclusive interview with Prof. Daviender Narang, Director, Jaipuria Institute of Management, Indirapuram, Ghaziabad
1. How are business management students rethinking their career aspirations due to AI automation?
The students have witnessed the journey of transition, the tasks being done manually to complete automation. Ais impact on career aspirations has been profound. Business management students increasingly aspire to attain positions where strategic thinking, creativity, and problem-solving take precedence over repetitive tasks. For instance, roles that emphasize data-driven decision-making, innovation, and ethical considerations in AI use are becoming more appealing. This shift also propels students to consider careers in interdisciplinary fields, such as AI ethics, digital strategy, and innovation management, where they can leverage both management skills and technological insights.
2. To what extent are AI-powered tools replacing traditional business management roles?
The traditional management roles have significantly changed. AI-powered tools are advancing at an impressive rate. Functions such as data analysis, customer service, and even decision-making processes are now partially automated in many businesses. For instance, tools like predictive analytics streamline data-driven insights, while chatbots enhance customer interactions. Consequently, some conventional roles, particularly those focused on repetitive or administrative tasks, are at risk of being phased out. However, AI is not fully replacing human oversight in most cases; rather, it's transforming roles to demand higher-order skills such as strategic planning, leadership, and ethical judgment.
3. How are business schools evolving their curricula to address the AI-driven job market?
To prepare students for an AI-driven market, business schools are adapting their curricula, emphasizing both technical skills and soft skills relevant to the future landscape. Courses on data analytics, AI ethics, and digital transformation are being incorporated into traditional business programs. For example, programs now frequently cover topics such as machine learning applications, AI in marketing, and the ethical implications of AI. This integrated approach aims to equip students with the knowledge to work alongside AI systems, enabling them to leverage AI insights while maintaining human-centered perspectives in decision-making. Ethical decision making skills are also indispensable in the current paradigm and students must be trained on these skills also.
4. What are the benefits and drawbacks of AI augmentation in business management for students?
AI presents notable advantages in business management, such as enhanced productivity, reduced error rates, and valuable predictive insights. Students entering the workforce with AI knowledge can drive more efficient operations, innovate in decision-making processes, and contribute to data-informed strategies. However, the drawbacks of AI augmentation include potential job displacement and the need for continuous upskilling. For students, this means they must commit to lifelong learning to stay competitive, especially as AI technologies evolve rapidly. Additionally, there are ethical considerations; reliance on AI can lead to reduced human agency and possible biases in automated decisions, posing challenges for future managers.
5. What role can educators, policymakers, and industry leaders play in mitigating AI automation's impact on business management students' career prospects?
Educators, policymakers, and industry leaders play a critical role in helping students navigate the AI-transformed landscape. Educators can integrate AI concepts into business management courses, teaching students not only how AI operates but also how it can be ethically applied. Policymakers, on the other hand, have the responsibility to ensure fair labor practices, supporting policies that safeguard jobs while promoting AI integration. Industry leaders can offer practical training, internships, and mentorship opportunities, providing students with hands-on experiences that build AI-related competencies. By fostering collaboration between educational institutions, government bodies, and industry players, a supportive ecosystem for AI adaptation can be created, ensuring students have viable career paths.
6. What skills are most critical for business management students to develop in an AI-driven job market?
In an AI-dominated environment, certain skills become indispensable for business management students. Analytical skills are paramount, as interpreting and acting upon data is central to AI utilization. Technical knowledge of AI and data tools, such as proficiency in data visualization software, machine learning basics, and data ethics, also becomes essential. Soft skills like adaptability, ethical decision-making, and leadership take on new importance, as these are areas where human strengths complement AI's capabilities. Additionally, cross-disciplinary skills, combining business acumen with basic programming or data science knowledge, can give students a significant advantage in the job market.
7. How can students effectively integrate AI tools into their future careers?
For students aiming to integrate AI tools effectively into their careers, a proactive approach is essential. Familiarity with AI-powered software used in their chosen industries can provide an edge. Business students should focus on understanding how AI tools can augment decision-making and optimize processes. Engaging in AI-focused projects, internships, and case studies during their academic careers also offers valuable insights into real-world applications. Staying informed about AI trends and continuous upskilling through online courses or certifications can ensure students remain relevant in a rapidly changing environment. By building expertise in both AI tools and their application within business contexts, students can maximize the value they bring to future employers.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS EDUCATION (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); COMPANY STRATEGY (90%); DATA ANALYTICS (90%); ETHICS (90%); MANAGERS & SUPERVISORS (90%); STUDENTS & STUDENT LIFE (90%); BUSINESS ANALYTICS (89%); CURRICULA (89%); DATA SCIENCE (89%); STRATEGIC PLANNING (89%); TECHNOLOGY (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); HUMAN IN THE LOOP (78%); INTERVIEWS (78%); LABOR FORCE (78%); RESKILLING & UPSKILLING (78%); SOFT SKILLS (78%); DISPLACED WORKERS (77%); GENERATIVE AI (77%); LABOR MARKET (77%); LABOR SECTOR PERFORMANCE (77%); PREDICTIVE ANALYTICS (77%); REPETITIVE MOTION DISORDERS (76%); CHATBOTS (73%); CONTINUING EDUCATION (73%); EMPLOYEE TRAINING (72%); MACHINE LEARNING (72%); CUSTOMER SERVICE (67%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (90%); BUSINESS ANALYTICS (89%); DATA SCIENCE (89%); EDUCATIONAL SERVICES (89%); INFORMATION MANAGEMENT & TECHNOLOGY (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GENERATIVE AI (77%); PREDICTIVE ANALYTICS (77%); CHATBOTS (73%); POWER TOOLS (73%); MACHINE LEARNING (72%)
Load-Date: November 6, 2024","CXOToday has engaged in an exclusive interview with Prof. Daviender Narang, Director, Jaipuria Institute of Management, Indirapuram, Ghaziabad
1. How are business management students rethinking their career aspirations due to AI automation?
The students have witnessed the journey of transition, the tasks being done manually to complete automation. Ais impact on career aspirations has been profound. Business management students increasingly aspire to attain positions where strategic thinking, creativity, and problem-solving take precedence over repetitive tasks. For instance, roles that emphasize data-driven decision-making, innovation, and ethical considerations in AI use are becoming more appealing. This shift also propels students to consider careers in interdisciplinary fields, such as AI ethics, digital strategy, and innovation management, where they can leverage both management skills and technological insights.
2. To what extent are AI-powered tools replacing traditional business management roles?
The traditional management roles have significantly changed. AI-powered tools are advancing at an impressive rate. Functions such as data analysis, customer service, and even decision-making processes are now partially automated in many businesses. For instance, tools like predictive analytics streamline data-driven insights, while chatbots enhance customer interactions. Consequently, some conventional roles, particularly those focused on repetitive or administrative tasks, are at risk of being phased out. However, AI is not fully replacing human oversight in most cases; rather, it's transforming roles to demand higher-order skills such as strategic planning, leadership, and ethical judgment.
3. How are business schools evolving their curricula to address the AI-driven job market?
To prepare students for an AI-driven market, business schools are adapting their curricula, emphasizing both technical skills and soft skills relevant to the future landscape. Courses on data analytics, AI ethics, and digital transformation are being incorporated into traditional business programs. For example, programs now frequently cover topics such as machine learning applications, AI in marketing, and the ethical implications of AI. This integrated approach aims to equip students with the knowledge to work alongside AI systems, enabling them to leverage AI insights while maintaining human-centered perspectives in decision-making. Ethical decision making skills are also indispensable in the current paradigm and students must be trained on these skills also.
4. What are the benefits and drawbacks of AI augmentation in business management for students?
AI presents notable advantages in business management, such as enhanced productivity, reduced error rates, and valuable predictive insights. Students entering the workforce with AI knowledge can drive more efficient operations, innovate in decision-making processes, and contribute to data-informed strategies. However, the drawbacks of AI augmentation include potential job displacement and the need for continuous upskilling. For students, this means they must commit to lifelong learning to stay competitive, especially as AI technologies evolve rapidly. Additionally, there are ethical considerations; reliance on AI can lead to reduced human agency and possible biases in automated decisions, posing challenges for future managers.
5. What role can educators, policymakers, and industry leaders play in mitigating AI automation's impact on business management students' career prospects?
Educators, policymakers, and industry leaders play a critical role in helping students navigate the AI-transformed landscape. Educators can integrate AI concepts into business management courses, teaching students not only how AI operates but also how it can be ethically applied. Policymakers, on the other hand, have the responsibility to ensure fair labor practices, supporting policies that safeguard jobs while promoting AI integration. Industry leaders can offer practical training, internships, and mentorship opportunities, providing students with hands-on experiences that build AI-related competencies. By fostering collaboration between educational institutions, government bodies, and industry players, a supportive ecosystem for AI adaptation can be created, ensuring students have viable career paths.
6. What skills are most critical for business management students to develop in an AI-driven job market?
In an AI-dominated environment, certain skills become indispensable for business management students. Analytical skills are paramount, as interpreting and acting upon data is central to AI utilization. Technical knowledge of AI and data tools, such as proficiency in data visualization software, machine learning basics, and data ethics, also becomes essential. Soft skills like adaptability, ethical decision-making, and leadership take on new importance, as these are areas where human strengths complement AI's capabilities. Additionally, cross-disciplinary skills, combining business acumen with basic programming or data science knowledge, can give students a significant advantage in the job market.
7. How can students effectively integrate AI tools into their future careers?
For students aiming to integrate AI tools effectively into their careers, a proactive approach is essential. Familiarity with AI-powered software used in their chosen industries can provide an edge. Business students should focus on understanding how AI tools can augment decision-making and optimize processes. Engaging in AI-focused projects, internships, and case studies during their academic careers also offers valuable insights into real-world applications. Staying informed about AI trends and continuous upskilling through online courses or certifications can ensure students remain relevant in a rapidly changing environment. By building expertise in both AI tools and their application within business contexts, students can maximize the value they bring to future employers.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS EDUCATION (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); COMPANY STRATEGY (90%); DATA ANALYTICS (90%); ETHICS (90%); MANAGERS & SUPERVISORS (90%); STUDENTS & STUDENT LIFE (90%); BUSINESS ANALYTICS (89%); CURRICULA (89%); DATA SCIENCE (89%); STRATEGIC PLANNING (89%); TECHNOLOGY (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); HUMAN IN THE LOOP (78%); INTERVIEWS (78%); LABOR FORCE (78%); RESKILLING & UPSKILLING (78%); SOFT SKILLS (78%); DISPLACED WORKERS (77%); GENERATIVE AI (77%); LABOR MARKET (77%); LABOR SECTOR PERFORMANCE (77%); PREDICTIVE ANALYTICS (77%); REPETITIVE MOTION DISORDERS (76%); CHATBOTS (73%); CONTINUING EDUCATION (73%); EMPLOYEE TRAINING (72%); MACHINE LEARNING (72%); CUSTOMER SERVICE (67%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (90%); BUSINESS ANALYTICS (89%); DATA SCIENCE (89%); EDUCATIONAL SERVICES (89%); INFORMATION MANAGEMENT & TECHNOLOGY (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GENERATIVE AI (77%); PREDICTIVE ANALYTICS (77%); CHATBOTS (73%); POWER TOOLS (73%); MACHINE LEARNING (72%)
Load-Date: November 6, 2024",neutral,0.7729045748710632,balanced/neutral,['agency'],[],"['oversight', 'should', 'must']","['machine learning', 'generative ai', 'predictive analytics']",1,0,3,3
2024,Unknown Title,"Body
Generative artificial intelligence (AI) is hot property when it comes to investment, but there's a pronounced hesitancy around adoption. AI faces a fundamental trust challenge due to uncertainty over safety, reliability, transparency, bias, and ethics. In a recent global survey, 86% of participants said their organizations had dedicated budget to generative AI, but three-quarters admitted to significant concerns about data privacy and security.
What makes AI responsible and trustworthy?
At the top of the list of trust requirements is that AI must do no harm. Compliance is necessary but not sufficient. Rather, the guiding principle for making AI trustworthy is to align it with societal values. Yet determining what AI should do is challenging. What's considered right, accurate, and ethical can vary depending on context, use case, industry, country, and culture. AI teams have to figure out what values their organizations want to reflect and what ""fair"" and ""accurate"" mean in that context.
Governance implications for key gen AI use cases
Some key use cases for generative AI include increasing productivity, improving business functions, reducing risk, and boosting customer engagement. A good governance framework makes generative AI not only more responsible but also more effective.
""Aligning AI with organizational goals and deploying it responsibly and efficiently ensure long-term productivity benefits,"" noted Bruno Domingues, CTO for Intel's financial services industry practice. ""Establishing guardrails based on organizational principles ensures efficient resource allocation, fosters accountability and transparency, and builds trust among stakeholders.""
A solid governance structure addresses ethical issues related to AI across the organization. As part of its model, SAS has an AI Oversight committee that might reject a generative AI marketing message as inappropriate, for example. ""The committee essentially acts as an additional audit layer, ensuring that AI applications and decisions align with SAS's ethical standards,"" said Josefin Rosén, Trustworthy AI specialist at SAS' Data Ethics Practice.
Structure, policies, and oversight
A solid AI governance framework bridges the divide between generative AI's promise and realization of its benefits, including:
Increased productivity due to more distributed decision-making
Competitive advantage and market agility resulting from being forward-compliant
Improved trust thanks to better accountability in data use
Heightened brand value in response to addressing AI's impact on society and the environment
Ability to win and keep top talent who value responsible innovation
Partnering for a sustainable future
A strong AI governance framework also supports sustainability goals, which require intelligent data management, model development and deployment, and decision monitoring and management.
SAS and Intel have forged a partnership that integrates high-performance computing hardware with advanced analytics software to drive sustainability, energy efficiency, and cost-effectiveness. ""SAS's tools enable organizations to analyze and optimize energy consumption, carbon footprints, and operational efficiencies, while Intel's processors and accelerators deliver the performance needed for these analytics with reduced power consumption,"" noted Domingues.
The great promise of generative AI to deliver transformative business benefits rests on the willingness of organizations to commit to good governance and ethical AI practices. Those who make that connection will be well positioned as the AI revolution gains steam.
Check out this webinar to learn how to unlock the benefits of generative AI - ethically and responsibly.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: GENERATIVE AI (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SAFETY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ASSOCIATIONS & ORGANIZATIONS (89%); SUSTAINABLE DEVELOPMENT (89%); SUSTAINABILITY (86%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CORPORATE SUSTAINABILITY (78%); DATA ANALYTICS (78%); ENERGY EFFICIENCY & CONSERVATION (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HIGH PERFORMANCE COMPUTING (74%); PRODUCTIVITY (72%); CONSUMPTION (71%); CUSTOMER ENGAGEMENT (71%); PARALLEL COMPUTING (65%); BRANDING (63%); ENVIRONMENTAL FOOTPRINT (63%); BRAND EQUITY (60%)
Company:  INTEL CORP (83%)
Ticker: INTC (NASDAQ) (83%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (83%); GENERATIVE AI (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); SUSTAINABLE DEVELOPMENT (89%); ENERGY & UTILITIES (79%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); BANKING & FINANCE SECTOR PERFORMANCE (78%); DATA ANALYTICS (78%); ENERGY EFFICIENCY & CONSERVATION (78%); INFORMATION SECURITY & PRIVACY (77%); BUDGETS (76%); DATA PRIVACY (76%); HIGH PERFORMANCE COMPUTING (74%); BANKING & FINANCE (73%); CUSTOMER ENGAGEMENT (71%); DATA SECURITY (71%); COMPUTER SOFTWARE (67%); PARALLEL COMPUTING (65%); BRANDING (63%); BRAND EQUITY (60%); COMPUTER EQUIPMENT (60%); ENERGY CONSUMPTION (60%)
Load-Date: December 5, 2024","Generative artificial intelligence (AI) is hot property when it comes to investment, but there's a pronounced hesitancy around adoption. AI faces a fundamental trust challenge due to uncertainty over safety, reliability, transparency, bias, and ethics. In a recent global survey, 86% of participants said their organizations had dedicated budget to generative AI, but three-quarters admitted to significant concerns about data privacy and security.
What makes AI responsible and trustworthy?
At the top of the list of trust requirements is that AI must do no harm. Compliance is necessary but not sufficient. Rather, the guiding principle for making AI trustworthy is to align it with societal values. Yet determining what AI should do is challenging. What's considered right, accurate, and ethical can vary depending on context, use case, industry, country, and culture. AI teams have to figure out what values their organizations want to reflect and what ""fair"" and ""accurate"" mean in that context.
Governance implications for key gen AI use cases
Some key use cases for generative AI include increasing productivity, improving business functions, reducing risk, and boosting customer engagement. A good governance framework makes generative AI not only more responsible but also more effective.
""Aligning AI with organizational goals and deploying it responsibly and efficiently ensure long-term productivity benefits,"" noted Bruno Domingues, CTO for Intel's financial services industry practice. ""Establishing guardrails based on organizational principles ensures efficient resource allocation, fosters accountability and transparency, and builds trust among stakeholders.""
A solid governance structure addresses ethical issues related to AI across the organization. As part of its model, SAS has an AI Oversight committee that might reject a generative AI marketing message as inappropriate, for example. ""The committee essentially acts as an additional audit layer, ensuring that AI applications and decisions align with SAS's ethical standards,"" said Josefin Rosén, Trustworthy AI specialist at SAS' Data Ethics Practice.
Structure, policies, and oversight
A solid AI governance framework bridges the divide between generative AI's promise and realization of its benefits, including:
Increased productivity due to more distributed decision-making
Competitive advantage and market agility resulting from being forward-compliant
Improved trust thanks to better accountability in data use
Heightened brand value in response to addressing AI's impact on society and the environment
Ability to win and keep top talent who value responsible innovation
Partnering for a sustainable future
A strong AI governance framework also supports sustainability goals, which require intelligent data management, model development and deployment, and decision monitoring and management.
SAS and Intel have forged a partnership that integrates high-performance computing hardware with advanced analytics software to drive sustainability, energy efficiency, and cost-effectiveness. ""SAS's tools enable organizations to analyze and optimize energy consumption, carbon footprints, and operational efficiencies, while Intel's processors and accelerators deliver the performance needed for these analytics with reduced power consumption,"" noted Domingues.
The great promise of generative AI to deliver transformative business benefits rests on the willingness of organizations to commit to good governance and ethical AI practices. Those who make that connection will be well positioned as the AI revolution gains steam.
Check out this webinar to learn how to unlock the benefits of generative AI - ethically and responsibly.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: GENERATIVE AI (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SAFETY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ASSOCIATIONS & ORGANIZATIONS (89%); SUSTAINABLE DEVELOPMENT (89%); SUSTAINABILITY (86%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CORPORATE SUSTAINABILITY (78%); DATA ANALYTICS (78%); ENERGY EFFICIENCY & CONSERVATION (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HIGH PERFORMANCE COMPUTING (74%); PRODUCTIVITY (72%); CONSUMPTION (71%); CUSTOMER ENGAGEMENT (71%); PARALLEL COMPUTING (65%); BRANDING (63%); ENVIRONMENTAL FOOTPRINT (63%); BRAND EQUITY (60%)
Company:  INTEL CORP (83%)
Ticker: INTC (NASDAQ) (83%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (83%); GENERATIVE AI (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); SUSTAINABLE DEVELOPMENT (89%); ENERGY & UTILITIES (79%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); BANKING & FINANCE SECTOR PERFORMANCE (78%); DATA ANALYTICS (78%); ENERGY EFFICIENCY & CONSERVATION (78%); INFORMATION SECURITY & PRIVACY (77%); BUDGETS (76%); DATA PRIVACY (76%); HIGH PERFORMANCE COMPUTING (74%); BANKING & FINANCE (73%); CUSTOMER ENGAGEMENT (71%); DATA SECURITY (71%); COMPUTER SOFTWARE (67%); PARALLEL COMPUTING (65%); BRANDING (63%); BRAND EQUITY (60%); COMPUTER EQUIPMENT (60%); ENERGY CONSUMPTION (60%)
Load-Date: December 5, 2024",neutral,0.6588237285614014,balanced/neutral,"['privacy', 'bias', 'transparency', 'accountability', 'safety', 'security']",['equity'],"['governance', 'oversight', 'standards', 'framework', 'compliance', 'audit', 'should', 'must']",['generative ai'],6,1,8,1
2024,Unknown Title,"Dateline: New Delhi 
Body
Irrigation, Food, and Civil Supplies Minister N. Uttam Kumar Reddy reaffirmed Telangana government’s vision to position Hyderabad as a global hub for Artificial Intelligence (AI). Speaking at the curtain-raiser for the 1st ISF Global AI Summit and International Junicorns Startup Festival, at the International Institute of Information Technology Hyderabad (IIIT-H) on Monday, he underscored the State’s efforts to harness AI for inclusive growth and innovation.
Highlighting both opportunities and challenges presented by AI, Mr. Reddy highlighted its potential to transform industries and drive growth while addressing concerns such as job disruption and ethical dilemmas. He detailed the Telangana government’s initiatives, including the ambitious AI City project and the establishment of a Skills University, aimed at developing a skilled workforce and fostering collaboration with industry and academia to navigate the ethical complexities of AI.
Describing AI as a transformative force across sectors like healthcare, education, smart mobility and manufacturing, Mr. Reddy called for collective effort to address future challenges, particularly the demands for computational power and the importance of AI ethics. He urged governments, industries, and academic institutions to work together to create ethical frameworks and develop AI systems that serve humanity.
The International Startup Foundation formally announced the 1st Global AI Summit and International Junicorns Startup Festival, scheduled to take place in Dallas, USA, from May 28 to 30, 2025.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EDUCATION SYSTEMS & INSTITUTIONS (78%); GOVERNMENT ETHICS (78%); SMART TECHNOLOGY (78%); TECHNOLOGY (78%); LABOR FORCE (69%)
Company:  AI SYSTEMS (51%)
Industry: SIC7372 PREPACKAGED SOFTWARE (51%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EDUCATION SYSTEMS & INSTITUTIONS (78%); EDUCATIONAL SERVICES (78%); MANUFACTURING (78%); SMART TECHNOLOGY (78%)
Geographic: HYDERABAD, ANDHRA PRADESH, INDIA (88%); NEW DELHI, INDIA (79%); TELANGANA, INDIA (88%); INDIA (79%)
Load-Date: December 16, 2024","Irrigation, Food, and Civil Supplies Minister N. Uttam Kumar Reddy reaffirmed Telangana government’s vision to position Hyderabad as a global hub for Artificial Intelligence (AI). Speaking at the curtain-raiser for the 1st ISF Global AI Summit and International Junicorns Startup Festival, at the International Institute of Information Technology Hyderabad (IIIT-H) on Monday, he underscored the State’s efforts to harness AI for inclusive growth and innovation.
Highlighting both opportunities and challenges presented by AI, Mr. Reddy highlighted its potential to transform industries and drive growth while addressing concerns such as job disruption and ethical dilemmas. He detailed the Telangana government’s initiatives, including the ambitious AI City project and the establishment of a Skills University, aimed at developing a skilled workforce and fostering collaboration with industry and academia to navigate the ethical complexities of AI.
Describing AI as a transformative force across sectors like healthcare, education, smart mobility and manufacturing, Mr. Reddy called for collective effort to address future challenges, particularly the demands for computational power and the importance of AI ethics. He urged governments, industries, and academic institutions to work together to create ethical frameworks and develop AI systems that serve humanity.
The International Startup Foundation formally announced the 1st Global AI Summit and International Junicorns Startup Festival, scheduled to take place in Dallas, USA, from May 28 to 30, 2025.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EDUCATION SYSTEMS & INSTITUTIONS (78%); GOVERNMENT ETHICS (78%); SMART TECHNOLOGY (78%); TECHNOLOGY (78%); LABOR FORCE (69%)
Company:  AI SYSTEMS (51%)
Industry: SIC7372 PREPACKAGED SOFTWARE (51%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EDUCATION SYSTEMS & INSTITUTIONS (78%); EDUCATIONAL SERVICES (78%); MANUFACTURING (78%); SMART TECHNOLOGY (78%)
Geographic: HYDERABAD, ANDHRA PRADESH, INDIA (88%); NEW DELHI, INDIA (79%); TELANGANA, INDIA (88%); INDIA (79%)
Load-Date: December 16, 2024",positive,0.5033998489379883,balanced/neutral,[],[],[],[],0,0,0,0
2024,Unknown Title,"Byline: David
Body
From Aidoghie Paulinus, Abuja
The Saudi Data and AI Authority (SDAIA) has launched a pioneering initiative to advance ethical artificial intelligence research and applications aimed at setting a new standard in the global AI landscape, emphasising the Kingdom's commitment to responsible innovation.
The development was announced on the sidelines of the third edition of the Global AI Summit in Riyadh, Saudi Arabia.
In a statement made available to the Daily Sun, the Royal Embassy of Saudi Arabia in Abuja said that the initiative, which was created in collaboration with the United Nations Educational, Scientific, and Cultural Organisation (UNESCO), was aimed at a wide range of stakeholders, including decision-makers, government officials, researchers, academics, corporate leaders, business managers, and AI developers and engineers.
""It aims to create a platform for discussing the future of AI and exploring how modern applications can empower policy development, enhance research environments, foster business growth, and influence various aspects of life.
""The programme promotes the sharing of knowledge and best practices for integrating ethical standards into the development of artificial intelligence. It also aims to provide a comprehensive framework for assessing the ethical maturity of AI systems, facilitate collaboration to advance research and ethical applications and promote responsible AI on a global scale through impactful deliberations and harmonisation of strategies.
""The newly launched programme is part of a collaborative effort to advance AI systems, develop ethical standards that guide the use of AI applications, and ensure these technologies align with religious, human, and moral values while safeguarding family and societal well-being. It also reflects SDAIA's commitment to working with international institutions to promote the ethical use of AI and achieve shared goals in developing data and AI strategies that support societal growth and sustainability,"" the Saudi Arabian Government said.
The Saudi Government further said that as the responsible body for the development of data and artificial intelligence technologies in the Kingdom, SDAIA encouraged relevant authorities to implement ethical best practices in alignment with Saudi societal values and ethics.
""It also supports the promotion of research and policymaking that foster investment in the field, while advancing data-driven economies and artificial intelligence on a global scale,"" the Saudi authorities also said.
In like manner, the SDAIA has collaborated with NVIDIA Corporation to propel Saudi Arabia to the forefront of AI innovation and integration of the latest NVIDIA technological advancements to enable developers to more easily build and deploy AI applications with the ALLaM Arabic LLM model, ensuring an unparalleled performance and scalability for region-specific workloads.
""Leveraging NVIDIA NeMo, part of the NVIDIA AI Enterprise software platform for large-scale language model training and NeMo Guardrails for AI safety, this strategic move will provide developers with a faster, more accessible path to building generative AI applications with ALLaM's capabilities and set a new standard for AI-driven language models in the region, making it a pivotal element in Arabic language AI.
""In addition to these advancements in AI applications, SDAIA is working closely with NVIDIA to significantly scale its supercomputing infrastructure. Plans are in place to establish one of the largest high-performance computing data centres in the MENA region by expanding SDAIA's existing NVIDIA DGX SuperPOD infrastructure. This expansion is planned to integrate NVIDIA's most advanced technologies, including the upcoming NVIDIA Blackwell architecture, and is expected to eventually grow to over 5,000 GPUs, setting a new benchmark for digital innovation and infrastructure in Saudi Arabia,"" the Saudi Arabian Government further said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1228
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); PUBLIC POLICY (88%); GENERATIVE AI (78%); INTERNATIONAL RELATIONS (77%); SUSTAINABLE DEVELOPMENT (77%); GOVERNMENT BODIES & OFFICES (76%); NATIONAL SECURITY & FOREIGN RELATIONS (76%); UNITED NATIONS INSTITUTIONS (75%); GOVERNMENT & PUBLIC ADMINISTRATION (74%); BUSINESS SOFTWARE (73%); INTELLIGENCE SERVICES (73%); MANAGERS & SUPERVISORS (70%); UNITED NATIONS (70%); FORTUNE 500 COMPANIES (69%); PUBLIC OFFICIALS (69%); ASSOCIATIONS & ORGANIZATIONS (55%); RELIGION (50%)
Company:  NVIDIA CORP (81%)
Ticker: NVDA (NASDAQ) (81%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (81%); NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (81%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (81%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (81%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (78%); SOFTWARE SERVICES & APPLICATIONS (78%); SUSTAINABLE DEVELOPMENT (77%); BUSINESS SOFTWARE (73%); COMPUTER SOFTWARE (73%)
Geographic: ABUJA, NIGERIA (92%); RIYADH, SAUDI ARABIA (78%); SAUDI ARABIA (97%); NIGERIA (94%)
Load-Date: September 13, 2024","From Aidoghie Paulinus, Abuja
The Saudi Data and AI Authority (SDAIA) has launched a pioneering initiative to advance ethical artificial intelligence research and applications aimed at setting a new standard in the global AI landscape, emphasising the Kingdom's commitment to responsible innovation.
The development was announced on the sidelines of the third edition of the Global AI Summit in Riyadh, Saudi Arabia.
In a statement made available to the Daily Sun, the Royal Embassy of Saudi Arabia in Abuja said that the initiative, which was created in collaboration with the United Nations Educational, Scientific, and Cultural Organisation (UNESCO), was aimed at a wide range of stakeholders, including decision-makers, government officials, researchers, academics, corporate leaders, business managers, and AI developers and engineers.
""It aims to create a platform for discussing the future of AI and exploring how modern applications can empower policy development, enhance research environments, foster business growth, and influence various aspects of life.
""The programme promotes the sharing of knowledge and best practices for integrating ethical standards into the development of artificial intelligence. It also aims to provide a comprehensive framework for assessing the ethical maturity of AI systems, facilitate collaboration to advance research and ethical applications and promote responsible AI on a global scale through impactful deliberations and harmonisation of strategies.
""The newly launched programme is part of a collaborative effort to advance AI systems, develop ethical standards that guide the use of AI applications, and ensure these technologies align with religious, human, and moral values while safeguarding family and societal well-being. It also reflects SDAIA's commitment to working with international institutions to promote the ethical use of AI and achieve shared goals in developing data and AI strategies that support societal growth and sustainability,"" the Saudi Arabian Government said.
The Saudi Government further said that as the responsible body for the development of data and artificial intelligence technologies in the Kingdom, SDAIA encouraged relevant authorities to implement ethical best practices in alignment with Saudi societal values and ethics.
""It also supports the promotion of research and policymaking that foster investment in the field, while advancing data-driven economies and artificial intelligence on a global scale,"" the Saudi authorities also said.
In like manner, the SDAIA has collaborated with NVIDIA Corporation to propel Saudi Arabia to the forefront of AI innovation and integration of the latest NVIDIA technological advancements to enable developers to more easily build and deploy AI applications with the ALLaM Arabic LLM model, ensuring an unparalleled performance and scalability for region-specific workloads.
""Leveraging NVIDIA NeMo, part of the NVIDIA AI Enterprise software platform for large-scale language model training and NeMo Guardrails for AI safety, this strategic move will provide developers with a faster, more accessible path to building generative AI applications with ALLaM's capabilities and set a new standard for AI-driven language models in the region, making it a pivotal element in Arabic language AI.
""In addition to these advancements in AI applications, SDAIA is working closely with NVIDIA to significantly scale its supercomputing infrastructure. Plans are in place to establish one of the largest high-performance computing data centres in the MENA region by expanding SDAIA's existing NVIDIA DGX SuperPOD infrastructure. This expansion is planned to integrate NVIDIA's most advanced technologies, including the upcoming NVIDIA Blackwell architecture, and is expected to eventually grow to over 5,000 GPUs, setting a new benchmark for digital innovation and infrastructure in Saudi Arabia,"" the Saudi Arabian Government further said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1228
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); PUBLIC POLICY (88%); GENERATIVE AI (78%); INTERNATIONAL RELATIONS (77%); SUSTAINABLE DEVELOPMENT (77%); GOVERNMENT BODIES & OFFICES (76%); NATIONAL SECURITY & FOREIGN RELATIONS (76%); UNITED NATIONS INSTITUTIONS (75%); GOVERNMENT & PUBLIC ADMINISTRATION (74%); BUSINESS SOFTWARE (73%); INTELLIGENCE SERVICES (73%); MANAGERS & SUPERVISORS (70%); UNITED NATIONS (70%); FORTUNE 500 COMPANIES (69%); PUBLIC OFFICIALS (69%); ASSOCIATIONS & ORGANIZATIONS (55%); RELIGION (50%)
Company:  NVIDIA CORP (81%)
Ticker: NVDA (NASDAQ) (81%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (81%); NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (81%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (81%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (81%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (78%); SOFTWARE SERVICES & APPLICATIONS (78%); SUSTAINABLE DEVELOPMENT (77%); BUSINESS SOFTWARE (73%); COMPUTER SOFTWARE (73%)
Geographic: ABUJA, NIGERIA (92%); RIYADH, SAUDI ARABIA (78%); SAUDI ARABIA (97%); NIGERIA (94%)
Load-Date: September 13, 2024",positive,0.5442955493927002,balanced/neutral,"['safety', 'security']",[],"['policy', 'standards', 'framework']","['generative ai', 'llm']",2,0,3,2
2024,Unknown Title,"Body
Riyadh, December 17, 2024, SPA -- With the launch of its cutting-edge self-assessment tool to evaluate ethical compliance in AI development, the Saudi Data & AI Authority (SDAIA) is demonstrating the Kingdom's commitment to leading the development of safe and ethical AI technologies. Available through the National Data Governance Platform, this comprehensive solution helps organizations measure their adherence to established ethical AI principles. Aligned with Saudi Vision 2030's goals, global human rights standards, and UNESCO's recommendations on AI ethics, the tool helps organizations raise AI maturity and enhance ethical AI compliance. 
It will also encourage investment and drive economic growth. The tool serves as a crucial resource for government agencies, private companies, and independent developers. It offers a systematic framework for assessing and analyzing how well their AI products align with ethical guidelines. Organizations can now effectively measure their commitment to responsible AI development, implementation, and adoption through detailed evaluation metrics. Comprising 81 key questions that are aligned with global standards, the assessment framework evaluates AI ethics compliance through seven fundamental principles: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits. As a result of responses to the questions, which use a simple 1-to-5 rating scale, detailed reports are generated that highlight strengths and identify areas for improvement. These seven principles aim to advance ethical AI development while maintaining a balance between innovation and responsibility. The framework emphasizes fairness in AI applications to prevent bias and discrimination while ensuring human-centric development that protects rights and promotes well-being. Key aspects of the assessment include evaluating data privacy and protection while maintaining system reliability and safety. The framework also emphasizes transparency in AI operations, making complex algorithms and decision-making processes more understandable and accountable. A key component of the framework focuses on accountability, ensuring transparent mechanisms for AI implementation and decision-making. Together, these principles foster responsible innovation that aligns with human values and societal needs. Organizations can use the tool multiple times to raise their maturity in AI ethics compliance and monitor their ethical development journey. This iterative approach provides flexibility to strengthen ethical commitments continuously and align practices with emerging technological trends. -- SPA 10:45 Local Time 07:45 GMT 0011
Link to Image
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INTERNET PRIVACY (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SAFETY (77%); TECHNOLOGY TRENDS (77%); STANDARDS & MEASUREMENTS (76%); DISCRIMINATION (75%); HUMAN RIGHTS (75%); NEGATIVE SOCIETAL NEWS (75%); GOVERNMENT BODIES & OFFICES (73%); SAFETY, ACCIDENTS & DISASTERS (72%); PRIVACY RIGHTS (71%); ENVIRONMENT & NATURAL RESOURCES (51%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (77%); DATA SECURITY (77%)
Geographic: RIYADH, SAUDI ARABIA (59%); SAUDI ARABIA (94%)
Load-Date: December 17, 2024","Riyadh, December 17, 2024, SPA -- With the launch of its cutting-edge self-assessment tool to evaluate ethical compliance in AI development, the Saudi Data & AI Authority (SDAIA) is demonstrating the Kingdom's commitment to leading the development of safe and ethical AI technologies. Available through the National Data Governance Platform, this comprehensive solution helps organizations measure their adherence to established ethical AI principles. Aligned with Saudi Vision 2030's goals, global human rights standards, and UNESCO's recommendations on AI ethics, the tool helps organizations raise AI maturity and enhance ethical AI compliance. 
It will also encourage investment and drive economic growth. The tool serves as a crucial resource for government agencies, private companies, and independent developers. It offers a systematic framework for assessing and analyzing how well their AI products align with ethical guidelines. Organizations can now effectively measure their commitment to responsible AI development, implementation, and adoption through detailed evaluation metrics. Comprising 81 key questions that are aligned with global standards, the assessment framework evaluates AI ethics compliance through seven fundamental principles: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits. As a result of responses to the questions, which use a simple 1-to-5 rating scale, detailed reports are generated that highlight strengths and identify areas for improvement. These seven principles aim to advance ethical AI development while maintaining a balance between innovation and responsibility. The framework emphasizes fairness in AI applications to prevent bias and discrimination while ensuring human-centric development that protects rights and promotes well-being. Key aspects of the assessment include evaluating data privacy and protection while maintaining system reliability and safety. The framework also emphasizes transparency in AI operations, making complex algorithms and decision-making processes more understandable and accountable. A key component of the framework focuses on accountability, ensuring transparent mechanisms for AI implementation and decision-making. Together, these principles foster responsible innovation that aligns with human values and societal needs. Organizations can use the tool multiple times to raise their maturity in AI ethics compliance and monitor their ethical development journey. This iterative approach provides flexibility to strengthen ethical commitments continuously and align practices with emerging technological trends. -- SPA 10:45 Local Time 07:45 GMT 0011
Link to Image
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INTERNET PRIVACY (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SAFETY (77%); TECHNOLOGY TRENDS (77%); STANDARDS & MEASUREMENTS (76%); DISCRIMINATION (75%); HUMAN RIGHTS (75%); NEGATIVE SOCIETAL NEWS (75%); GOVERNMENT BODIES & OFFICES (73%); SAFETY, ACCIDENTS & DISASTERS (72%); PRIVACY RIGHTS (71%); ENVIRONMENT & NATURAL RESOURCES (51%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (77%); DATA SECURITY (77%)
Geographic: RIYADH, SAUDI ARABIA (59%); SAUDI ARABIA (94%)
Load-Date: December 17, 2024",positive,0.673020601272583,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'human rights', 'agency']",['fairness'],"['governance', 'standards', 'guidelines', 'framework', 'compliance']",[],11,1,5,0
2024,Unknown Title,"Byline: Mr Gerald Jaideep
Body
In the hushed corridors of leading hospitals, a doctor glances at her smartwatch as an AI-powered alert signals an impending cardiac event for a patient who moments before appeared stable. Across town, in a cutting-edge research lab, scientists are astounded as AI predicts the onset of Alzheimer's years before conventional diagnostics could-a breakthrough poised to redefine neurological care. Meanwhile, in a boardroom, healthcare executives grapple with a pressing question: how to harness the power of AI-driven personalised medicine while upholding patient privacy and ensuring equitable care?
As AI seamlessly integrates into healthcare, it's not just enhancing treatment but redefining our understanding of health itself. From predictive analytics to personalised medicine and operational efficiency, AI is dismantling barriers once deemed insurmountable. Yet, its vast potential requires that technology enhances rather than compromises patient care.
AI is unlocking hidden insights from extensive health datasets. Cedars-Sinai's AI predicts heart attacks with precision, Idoven's platform refines ECG analysis, and Anumana's early detection capabilities have earned FDA recognition. Innovations such as Lupin Digital Health's 'Lyfe Digital Heart Failure Clinic' and SS Innovations' surgical robot are advancing care. Beyond improving outcomes, AI streamlines hospital operations and automates tasks, enhancing efficiency. However, addressing ethical considerations-such as accountability, transparency, and data privacy-is crucial for responsible AI use and maintaining patient trust.
These advancements enhance patient outcomes and streamline hospital operations by reducing unnecessary tests, optimising resource allocation, and automating administrative tasks. AI-driven systems predict patient admissions with remarkable accuracy, enabling real-time adjustments in staffing and resources. In operating rooms, AI optimises procedures, ensuring specialised equipment availability. While AI boosts efficiency, addressing ethical challenges such as accountability, transparency, and bias is essential.
Accountability in AI systems is a primary concern: when an error occurs, responsibility must be clearly defined, whether it falls on the healthcare provider, the AI developer, or the technology itself. Transparency in decision-making processes is essential for informed clinical decisions. Emerging regulatory frameworks, like the EU AI Act, aim to address these challenges by ensuring proper system usage, incorporating human oversight, and maintaining comprehensive logs.
Bias in AI systems, dependent on the diversity of data, can exacerbate existing healthcare disparities. Ensuring inclusivity and representativeness in AI models is a moral imperative. Data privacy is paramount, and techniques like federated learning offer promising solutions, though scaling remains a challenge. Collaborations between healthcare organisations and AI developers are crucial for building secure, privacy-preserving systems.
The integration of AI-powered robotic surgeries and quantum computing is set to revolutionise drug discovery, potentially reducing development times significantly. The fusion of AI with IoT devices promises continuous, real-time health monitoring, shifting the focus from treatment to prevention globally. AI's potential extends to addressing healthcare challenges in developing countries, with diagnostic tools operating in remote areas to bring expert-level insights to underserved populations.
As AI continues to reshape healthcare, leaders must confront ethical and security challenges to fully realise its potential. By ensuring transparency, inclusivity, and data security, we can build a future where AI enhances rather than detracts from the human experience of healthcare. The future will be shaped not just by AI's sophistication but by how we implement and govern this technology, ensuring it drives progress in an equitable, ethical, and human-centered manner.
In this evolving landscape, we envision a future where AI not only predicts but prevents cardiac events, early Alzheimer's detection leads to effective interventions, and personalised medicine becomes the norm. This is the promise of AI in healthcare-a future where technology and humanity work in concert to achieve a healthier, more equitable world. As regulatory frameworks evolve, they will play a crucial role in integrating AI into clinical settings, ensuring it enhances patient care while addressing ethical considerations.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); HEART DISEASE (90%); PRECISION MEDICINE (90%); SMART TECHNOLOGY (90%); ETHICS (89%); INTERNET PRIVACY (89%); PRIVACY RIGHTS (89%); TECHNOLOGY (89%); BUSINESS ANALYTICS (79%); ALZHEIMER'S DISEASE (78%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CLINICAL DECISION SUPPORT (78%); DATA SCIENCE (78%); HEALTH CARE PROFESSIONALS (78%); HEALTH EQUITY (78%); HUMAN IN THE LOOP (78%); MEDICAL ROBOTICS (78%); NEUROSCIENCE (78%); PATIENT PRIVACY (78%); PREDICTIVE ANALYTICS (78%); ROBOTICS (78%); DATA ANALYTICS (77%); HEALTH CARE REGULATION & POLICY (77%); SCIENCE & TECHNOLOGY (77%); VULNERABLE HEALTH POPULATIONS (72%); EXECUTIVES (71%); DEVELOPING COUNTRIES (60%); DRUG DESIGN & DISCOVERY (60%); QUANTUM COMPUTING (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); HEALTH CARE (90%); HOSPITALS (90%); SMART TECHNOLOGY (90%); DATA PRIVACY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); BUSINESS ANALYTICS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CLINICAL DECISION SUPPORT (78%); DATA SCIENCE (78%); HEALTH CARE PROFESSIONALS (78%); HEALTH EQUITY (78%); INTERNET OF THINGS (78%); MEDICAL ROBOTICS (78%); PATIENT PRIVACY (78%); PREDICTIVE ANALYTICS (78%); ROBOTICS (78%); DATA ANALYTICS (77%); HEALTH CARE REGULATION & POLICY (77%); PHARMACEUTICALS INDUSTRY (77%); PHARMACEUTICALS PRODUCT DEVELOPMENT (72%); DRUG DESIGN & DISCOVERY (60%); QUANTUM COMPUTING (50%)
Load-Date: December 6, 2024","In the hushed corridors of leading hospitals, a doctor glances at her smartwatch as an AI-powered alert signals an impending cardiac event for a patient who moments before appeared stable. Across town, in a cutting-edge research lab, scientists are astounded as AI predicts the onset of Alzheimer's years before conventional diagnostics could-a breakthrough poised to redefine neurological care. Meanwhile, in a boardroom, healthcare executives grapple with a pressing question: how to harness the power of AI-driven personalised medicine while upholding patient privacy and ensuring equitable care?
As AI seamlessly integrates into healthcare, it's not just enhancing treatment but redefining our understanding of health itself. From predictive analytics to personalised medicine and operational efficiency, AI is dismantling barriers once deemed insurmountable. Yet, its vast potential requires that technology enhances rather than compromises patient care.
AI is unlocking hidden insights from extensive health datasets. Cedars-Sinai's AI predicts heart attacks with precision, Idoven's platform refines ECG analysis, and Anumana's early detection capabilities have earned FDA recognition. Innovations such as Lupin Digital Health's 'Lyfe Digital Heart Failure Clinic' and SS Innovations' surgical robot are advancing care. Beyond improving outcomes, AI streamlines hospital operations and automates tasks, enhancing efficiency. However, addressing ethical considerations-such as accountability, transparency, and data privacy-is crucial for responsible AI use and maintaining patient trust.
These advancements enhance patient outcomes and streamline hospital operations by reducing unnecessary tests, optimising resource allocation, and automating administrative tasks. AI-driven systems predict patient admissions with remarkable accuracy, enabling real-time adjustments in staffing and resources. In operating rooms, AI optimises procedures, ensuring specialised equipment availability. While AI boosts efficiency, addressing ethical challenges such as accountability, transparency, and bias is essential.
Accountability in AI systems is a primary concern: when an error occurs, responsibility must be clearly defined, whether it falls on the healthcare provider, the AI developer, or the technology itself. Transparency in decision-making processes is essential for informed clinical decisions. Emerging regulatory frameworks, like the EU AI Act, aim to address these challenges by ensuring proper system usage, incorporating human oversight, and maintaining comprehensive logs.
Bias in AI systems, dependent on the diversity of data, can exacerbate existing healthcare disparities. Ensuring inclusivity and representativeness in AI models is a moral imperative. Data privacy is paramount, and techniques like federated learning offer promising solutions, though scaling remains a challenge. Collaborations between healthcare organisations and AI developers are crucial for building secure, privacy-preserving systems.
The integration of AI-powered robotic surgeries and quantum computing is set to revolutionise drug discovery, potentially reducing development times significantly. The fusion of AI with IoT devices promises continuous, real-time health monitoring, shifting the focus from treatment to prevention globally. AI's potential extends to addressing healthcare challenges in developing countries, with diagnostic tools operating in remote areas to bring expert-level insights to underserved populations.
As AI continues to reshape healthcare, leaders must confront ethical and security challenges to fully realise its potential. By ensuring transparency, inclusivity, and data security, we can build a future where AI enhances rather than detracts from the human experience of healthcare. The future will be shaped not just by AI's sophistication but by how we implement and govern this technology, ensuring it drives progress in an equitable, ethical, and human-centered manner.
In this evolving landscape, we envision a future where AI not only predicts but prevents cardiac events, early Alzheimer's detection leads to effective interventions, and personalised medicine becomes the norm. This is the promise of AI in healthcare-a future where technology and humanity work in concert to achieve a healthier, more equitable world. As regulatory frameworks evolve, they will play a crucial role in integrating AI into clinical settings, ensuring it enhances patient care while addressing ethical considerations.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); HEART DISEASE (90%); PRECISION MEDICINE (90%); SMART TECHNOLOGY (90%); ETHICS (89%); INTERNET PRIVACY (89%); PRIVACY RIGHTS (89%); TECHNOLOGY (89%); BUSINESS ANALYTICS (79%); ALZHEIMER'S DISEASE (78%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CLINICAL DECISION SUPPORT (78%); DATA SCIENCE (78%); HEALTH CARE PROFESSIONALS (78%); HEALTH EQUITY (78%); HUMAN IN THE LOOP (78%); MEDICAL ROBOTICS (78%); NEUROSCIENCE (78%); PATIENT PRIVACY (78%); PREDICTIVE ANALYTICS (78%); ROBOTICS (78%); DATA ANALYTICS (77%); HEALTH CARE REGULATION & POLICY (77%); SCIENCE & TECHNOLOGY (77%); VULNERABLE HEALTH POPULATIONS (72%); EXECUTIVES (71%); DEVELOPING COUNTRIES (60%); DRUG DESIGN & DISCOVERY (60%); QUANTUM COMPUTING (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); HEALTH CARE (90%); HOSPITALS (90%); SMART TECHNOLOGY (90%); DATA PRIVACY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); BUSINESS ANALYTICS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CLINICAL DECISION SUPPORT (78%); DATA SCIENCE (78%); HEALTH CARE PROFESSIONALS (78%); HEALTH EQUITY (78%); INTERNET OF THINGS (78%); MEDICAL ROBOTICS (78%); PATIENT PRIVACY (78%); PREDICTIVE ANALYTICS (78%); ROBOTICS (78%); DATA ANALYTICS (77%); HEALTH CARE REGULATION & POLICY (77%); PHARMACEUTICALS INDUSTRY (77%); PHARMACEUTICALS PRODUCT DEVELOPMENT (72%); DRUG DESIGN & DISCOVERY (60%); QUANTUM COMPUTING (50%)
Load-Date: December 6, 2024",neutral,0.74005126953125,balanced/neutral,"['privacy', 'bias', 'transparency', 'accountability', 'security', 'inclusivity']",['equity'],"['regulation', 'policy', 'oversight', 'must']","['robot', 'robotics', 'predictive analytics']",6,1,4,3
2024,Unknown Title,"Body
Ethical use of AI dominates at Rectron Summit
By Christopher Tredger, Portals editorJohannesburg, 13 Sep 2024Futurist Dr Craig Wing delivered the keynote address at Rectron Summit '24. 
AI has the potential to address inequality in South Africa and ensure the country remains connected to the global digital economy. But, this will depend on access to and the ethical use of this emerging technology.
This was the consensus among technology professionals who participated in a panel discussion at the Rectron Summit 2024, the tech distributor's flagship channel event held in Johannesburg on 12 September
Panelists acknowledged the role AI can play in driving efficiency, improving productivity, and generating new revenue streams, especially in use cases across agriculture, manufacturing, education, healthcare and mining. However, this cannot happen independently of ethical practice.
""There are definitely new opportunities with AI, but it has to be treated with respect,"" said Deveshane Naicker, channel lead for Africa at Zebra Technologies.
Model collapse
In his keynote, futurist Dr Craig Wing discussed the impact of model collapse, an emerging trend where machine learning models weaken over time because they are fuelled with erroneous data from other models, including prior versions of themselves.
See also All things being equal: AI ethics in networking
Forbes online defines model collapse as ""what happens when AI models are trained on data that includes content generated by earlier versions of themselves.
""Over time, this recursive process causes the models to drift further away from the original data distribution, losing the ability to accurately represent the world as it really is. Instead of improving, the AI starts to make mistakes that compound over generations, leading to outputs that are increasingly distorted and unreliable,"" Forbes states.
According to Dr Wing this trend is fuelling bias and hallucinations within the application of AI.
Rectron's message to channel
Rectron's core message to the channel is that AI is not there to replace humans, it's there to enhance and speed up work, said Jaco Oosthuizen, category head for AI, mobility, and trends at Rectron.
""It is easier to complete a project that is 80% done than it is to start the project from scratch. I think sometimes in the environments in which we are working, it is hard for people to always be innovative… I think AI really helps with that. It will free up time for individuals and give them the opportunity to become more innovative.""
Oosthuizen advised business leaders against making iron-clad AI management decisions before fully testing the technology.
""I think AI is going to go through a journey where guys are going to test it in the ChatGPT format, in the co-pilot format, they are going to test it at executive level, maybe one or two layers down and get an idea of what the risks are, and define the business process that comes with that – and then I think the next step will be the fast-paced adoption.""
Spencer Chen, Rectron's chief executive, said, ""Artificial intelligence has been a part of humanity for decades already, gradually progressing from experimental settings in the 1950s to the emergence of machine learning in the 1990s, to now becoming a mainstream reality across people's personal and professional lives. Today, we are seeing a rapid acceleration and proliferation of AI applications, from virtual assistants, image (and speech) recognition, natural language processing, predictive analytics, autonomous vehicles, health and biotech, and countless sectors embracing the efficiencies and innovative solutions AI can unlock.""
While promising, the use of AI raises both ethical and technical questions that need to be addressed, Chen added. These range from the impact on public opinion and jobs to concerns about AI autonomy and the security of AI systems against cyber threats or unintended system activity.
Monetising AI
During a second panel discussion on the ethics of AI in business, AI expert Johan Steyn noted that businesses, under pressure to meet margins and targets, might be tempted to use AI without sufficient regard for ethics or without adequate safeguards in place.
He posed a question to the panel: ""Is it possible to use AI ethically and still make money?""
Callan Abrahams, principal AI consultant, iOCO, said the issue speaks to the culture of a business. ""Leadership does not trump AI … you cannot fix business management with AI.""
Oosthuizen said ethics is being built into AI and it is important to 'go deeper' with the technology, collaborate as much as possible to align ethical considerations with the objectives for use of AI.
Wing agreed, adding that it's essential for companies to explain to board members that using AI without ethical considerations could lead to real, devastating consequences.
Balancing ethics with profitability requires a shift in mindset, Wing continued. Decision-makers must view the ethical use of AI not as a 'grudge purchase,' but as a business imperative.
The panelists agreed that as South Africa moves towards a data- and digital-centric fifth industrial revolution, AI will play a significant role. However, this progress cannot come at the expense of ethics and humanity.
Share
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); FUTURES RESEARCH (90%); TECHNOLOGY (90%); TRENDS (89%); CHATBOTS (78%); EMERGING TECHNOLOGY (78%); GENERATIVE AI (78%); MACHINE LEARNING (73%); DIGITAL ECONOMY (72%); TECHNICIANS & TECHNOLOGICAL WORKERS (71%)
Company:  ZEBRA TECHNOLOGIES CORP (56%);  FORBES INC (55%)
Ticker: ZBRA (NASDAQ) (56%)
Industry: NAICS561499 ALL OTHER BUSINESS SUPPORT SERVICES (56%); NAICS541512 COMPUTER SYSTEMS DESIGN SERVICES (56%); SIC7389 BUSINESS SERVICES (56%); SIC7373 COMPUTER INTEGRATED SYSTEMS DESIGN (56%); SIC2721 PERIODICALS: PUBLISHING, OR PUBLISHING & PRINTING (55%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (78%); GENERATIVE AI (78%); MANUFACTURING (78%); MACHINE LEARNING (73%); DIGITAL ECONOMY (72%)
Geographic: JOHANNESBURG, SOUTH AFRICA (73%); AFRICA (90%); SOUTH AFRICA (90%)
Load-Date: September 13, 2024","Ethical use of AI dominates at Rectron Summit
By Christopher Tredger, Portals editorJohannesburg, 13 Sep 2024Futurist Dr Craig Wing delivered the keynote address at Rectron Summit '24. 
AI has the potential to address inequality in South Africa and ensure the country remains connected to the global digital economy. But, this will depend on access to and the ethical use of this emerging technology.
This was the consensus among technology professionals who participated in a panel discussion at the Rectron Summit 2024, the tech distributor's flagship channel event held in Johannesburg on 12 September
Panelists acknowledged the role AI can play in driving efficiency, improving productivity, and generating new revenue streams, especially in use cases across agriculture, manufacturing, education, healthcare and mining. However, this cannot happen independently of ethical practice.
""There are definitely new opportunities with AI, but it has to be treated with respect,"" said Deveshane Naicker, channel lead for Africa at Zebra Technologies.
Model collapse
In his keynote, futurist Dr Craig Wing discussed the impact of model collapse, an emerging trend where machine learning models weaken over time because they are fuelled with erroneous data from other models, including prior versions of themselves.
See also All things being equal: AI ethics in networking
Forbes online defines model collapse as ""what happens when AI models are trained on data that includes content generated by earlier versions of themselves.
""Over time, this recursive process causes the models to drift further away from the original data distribution, losing the ability to accurately represent the world as it really is. Instead of improving, the AI starts to make mistakes that compound over generations, leading to outputs that are increasingly distorted and unreliable,"" Forbes states.
According to Dr Wing this trend is fuelling bias and hallucinations within the application of AI.
Rectron's message to channel
Rectron's core message to the channel is that AI is not there to replace humans, it's there to enhance and speed up work, said Jaco Oosthuizen, category head for AI, mobility, and trends at Rectron.
""It is easier to complete a project that is 80% done than it is to start the project from scratch. I think sometimes in the environments in which we are working, it is hard for people to always be innovative… I think AI really helps with that. It will free up time for individuals and give them the opportunity to become more innovative.""
Oosthuizen advised business leaders against making iron-clad AI management decisions before fully testing the technology.
""I think AI is going to go through a journey where guys are going to test it in the ChatGPT format, in the co-pilot format, they are going to test it at executive level, maybe one or two layers down and get an idea of what the risks are, and define the business process that comes with that – and then I think the next step will be the fast-paced adoption.""
Spencer Chen, Rectron's chief executive, said, ""Artificial intelligence has been a part of humanity for decades already, gradually progressing from experimental settings in the 1950s to the emergence of machine learning in the 1990s, to now becoming a mainstream reality across people's personal and professional lives. Today, we are seeing a rapid acceleration and proliferation of AI applications, from virtual assistants, image (and speech) recognition, natural language processing, predictive analytics, autonomous vehicles, health and biotech, and countless sectors embracing the efficiencies and innovative solutions AI can unlock.""
While promising, the use of AI raises both ethical and technical questions that need to be addressed, Chen added. These range from the impact on public opinion and jobs to concerns about AI autonomy and the security of AI systems against cyber threats or unintended system activity.
Monetising AI
During a second panel discussion on the ethics of AI in business, AI expert Johan Steyn noted that businesses, under pressure to meet margins and targets, might be tempted to use AI without sufficient regard for ethics or without adequate safeguards in place.
He posed a question to the panel: ""Is it possible to use AI ethically and still make money?""
Callan Abrahams, principal AI consultant, iOCO, said the issue speaks to the culture of a business. ""Leadership does not trump AI … you cannot fix business management with AI.""
Oosthuizen said ethics is being built into AI and it is important to 'go deeper' with the technology, collaborate as much as possible to align ethical considerations with the objectives for use of AI.
Wing agreed, adding that it's essential for companies to explain to board members that using AI without ethical considerations could lead to real, devastating consequences.
Balancing ethics with profitability requires a shift in mindset, Wing continued. Decision-makers must view the ethical use of AI not as a 'grudge purchase,' but as a business imperative.
The panelists agreed that as South Africa moves towards a data- and digital-centric fifth industrial revolution, AI will play a significant role. However, this progress cannot come at the expense of ethics and humanity.
Share
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); FUTURES RESEARCH (90%); TECHNOLOGY (90%); TRENDS (89%); CHATBOTS (78%); EMERGING TECHNOLOGY (78%); GENERATIVE AI (78%); MACHINE LEARNING (73%); DIGITAL ECONOMY (72%); TECHNICIANS & TECHNOLOGICAL WORKERS (71%)
Company:  ZEBRA TECHNOLOGIES CORP (56%);  FORBES INC (55%)
Ticker: ZBRA (NASDAQ) (56%)
Industry: NAICS561499 ALL OTHER BUSINESS SUPPORT SERVICES (56%); NAICS541512 COMPUTER SYSTEMS DESIGN SERVICES (56%); SIC7389 BUSINESS SERVICES (56%); SIC7373 COMPUTER INTEGRATED SYSTEMS DESIGN (56%); SIC2721 PERIODICALS: PUBLISHING, OR PUBLISHING & PRINTING (55%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (78%); GENERATIVE AI (78%); MANUFACTURING (78%); MACHINE LEARNING (73%); DIGITAL ECONOMY (72%)
Geographic: JOHANNESBURG, SOUTH AFRICA (73%); AFRICA (90%); SOUTH AFRICA (90%)
Load-Date: September 13, 2024",neutral,0.595535933971405,balanced/neutral,"['bias', 'security', 'autonomy', 'access', 'inequality']",['autonomy'],"['must', 'need to']","['machine learning', 'generative ai', 'chatgpt', 'natural language processing', 'predictive analytics']",5,1,2,5
2024,Unknown Title,"Byline: Jack O'Neill
Body
Artificial Intelligence, especially generative AI, is no longer the stuff of science fiction - it's here, it's powerful, and it's transforming every facet of our lives. From healthcare and finance to environmental management and entertainment, its influence is per-vasive. But here's the catch: while AI holds immense promise, it also poses significant risks if not guided by strong ethical principles.
Australian business stands at a crossroads. Will we harness AI responsibly to benefit all, or will we let it run mostly unchecked, risking societal harm and eroding public trust?
The high stakes of ignoring AI ethics Imagine a future where AI systems make decisions that unfairly discriminate, invade privacy, or operate without accountability. Without ethical oversight, this isn't a dystopian fantasy - but a looming reality. Missteps in AI can lead to public backlash, legal troubles, and long-term damage to brand reputations. Some 58 per cent of Australians are concerned about privacy and security issues with AI accessing their personal data; they need transparency, according to Dentsu's Data Consciousness Project. Companies that ignore these demands risk losing customer loyalty and market share.
Experts, including two of the three ""godfathers"" of modern AI, Geoffrey Hinton and Yoshua Bengio, believe society isn't putting enough of a priority on the risks of AI misuse, focusing instead on pushing the boundaries of innovation whatever the cost to society.
But we can't ignore the risk to society. We need to be able to understand and address how AI can falter, in three pivotal ways.
First, it's only as good as the data we feed it. If that data is biased, unrepresentative, or flawed, the AI's decisions will mirror those imperfections - sometimes with serious repercussions. This year New York City council's new AI chatbot designed to help businesses navigate regulations went awry due to flawed training data. Instead of promoting compliance, it advised companies to ignore legal requirements, essentially telling them to break the law. This was due to incomplete data that failed to cover the complex legal landscape.
Second, AI ""hallucinations"" occur when systems generate outputs that are false, misleading, or downright nonsensical, yet present them as accurate, leading to misinformation and eroding trust. In April, Elon Musk's AI chatbot Grok hallucinated publicly and accused NBA start Klay Thompson of going on a vandalism spree in California. To be clear, he did no such thing. It was pointed out that Grok likely confused a common basketball term in which players are said to be throwing ""bricks"" - when they take an air ball shot that doesn't hit the rim - with vandalism.
Third, as AI becomes more sophisticated, there's a danger that humans might over-rely on it, removing responsibility to think critically and make informed judgments. This complacency can allow errors to go unchecked and ethical oversights to multiply, undermining the very benefits AI seeks to provide. Famously in 2023, a lawyer at Levidow, Levidow & Oberman relied on ChatGPT to research precedents for a case. But at least six of the cases submitted in the brief didn't exist. The result was a fine for the business and the case being thrown out, leading to significant brand damage to the firm.
The importance of having human oversight To prevent AI systems from making flawed decisions that could lead to financial troubles or damage reputations, businesses must implement rigorous data management and ethical practices. This means ensuring all training data is accurate and truly representative of Australia's diverse population - regularly auditing datasets for -biases and inaccuracies.
Ethical data sourcing is just as crucial: collect data responsibly, respect privacy laws, obtain necessary consent, and avoid perpetuating stereotypes or discrimination. Moreover, involving diverse teams in AI development brings varied perspectives, helping to spot biases that homogeneous groups might overlook. By prioritising data integrity and ethics, companies can safeguard against the pitfalls of flawed or biased training data.
We need to maintain a level of human oversight and human verification mechanisms, aligning with best practice policies laid out by the federal government to -ensure we're not missing critical decision-making processes.
Continuous staff training about AI limitations and the importance of critical thinking is essential, emphasising that AI is a tool to aid, not replace, human judgment. By fostering a culture of scepticism and verification, Australian businesses can avoid AI errors and maintain trust with their stakeholders.
Call to action: Embrace ethical AI or risk being left behind The race for AI advancement is on, but without ethics or guardrails, it's a race to the bottom. Companies that ignore ethical principles may gain short-term advantages but will ultimately face backlash - from consumers, regulators, and society at large.
AI systems must operate in alignment with human values. Brands must put people and community above the short-term advantages and focus on driving AI innovation within an ethical framework. This is the only way AI can drive positive results for people, society and business. Jack O'Neill is client partner at Merkle, a Dentsu company.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: The Australian
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); DISCRIMINATION (77%); PRIVACY RIGHTS (74%); VANDALISM (74%); BRANDING (73%); INVASION OF PRIVACY (69%); BASKETBALL (63%); DISINFORMATION & MISINFORMATION (63%); CITY GOVERNMENT (62%); ENVIRONMENT & NATURAL RESOURCES (57%); CITIES (50%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); INFORMATION SECURITY & PRIVACY (74%); BRANDING (73%); MARKET SHARE (70%)
Person: KLAY THOMPSON (66%); ELON MUSK (51%)
Geographic: NEW YORK, NY, USA (68%); CALIFORNIA, USA (73%); NEW YORK, USA (53%)
Load-Date: November 27, 2024","Artificial Intelligence, especially generative AI, is no longer the stuff of science fiction - it's here, it's powerful, and it's transforming every facet of our lives. From healthcare and finance to environmental management and entertainment, its influence is per-vasive. But here's the catch: while AI holds immense promise, it also poses significant risks if not guided by strong ethical principles.
Australian business stands at a crossroads. Will we harness AI responsibly to benefit all, or will we let it run mostly unchecked, risking societal harm and eroding public trust?
The high stakes of ignoring AI ethics Imagine a future where AI systems make decisions that unfairly discriminate, invade privacy, or operate without accountability. Without ethical oversight, this isn't a dystopian fantasy - but a looming reality. Missteps in AI can lead to public backlash, legal troubles, and long-term damage to brand reputations. Some 58 per cent of Australians are concerned about privacy and security issues with AI accessing their personal data; they need transparency, according to Dentsu's Data Consciousness Project. Companies that ignore these demands risk losing customer loyalty and market share.
Experts, including two of the three ""godfathers"" of modern AI, Geoffrey Hinton and Yoshua Bengio, believe society isn't putting enough of a priority on the risks of AI misuse, focusing instead on pushing the boundaries of innovation whatever the cost to society.
But we can't ignore the risk to society. We need to be able to understand and address how AI can falter, in three pivotal ways.
First, it's only as good as the data we feed it. If that data is biased, unrepresentative, or flawed, the AI's decisions will mirror those imperfections - sometimes with serious repercussions. This year New York City council's new AI chatbot designed to help businesses navigate regulations went awry due to flawed training data. Instead of promoting compliance, it advised companies to ignore legal requirements, essentially telling them to break the law. This was due to incomplete data that failed to cover the complex legal landscape.
Second, AI ""hallucinations"" occur when systems generate outputs that are false, misleading, or downright nonsensical, yet present them as accurate, leading to misinformation and eroding trust. In April, Elon Musk's AI chatbot Grok hallucinated publicly and accused NBA start Klay Thompson of going on a vandalism spree in California. To be clear, he did no such thing. It was pointed out that Grok likely confused a common basketball term in which players are said to be throwing ""bricks"" - when they take an air ball shot that doesn't hit the rim - with vandalism.
Third, as AI becomes more sophisticated, there's a danger that humans might over-rely on it, removing responsibility to think critically and make informed judgments. This complacency can allow errors to go unchecked and ethical oversights to multiply, undermining the very benefits AI seeks to provide. Famously in 2023, a lawyer at Levidow, Levidow & Oberman relied on ChatGPT to research precedents for a case. But at least six of the cases submitted in the brief didn't exist. The result was a fine for the business and the case being thrown out, leading to significant brand damage to the firm.
The importance of having human oversight To prevent AI systems from making flawed decisions that could lead to financial troubles or damage reputations, businesses must implement rigorous data management and ethical practices. This means ensuring all training data is accurate and truly representative of Australia's diverse population - regularly auditing datasets for -biases and inaccuracies.
Ethical data sourcing is just as crucial: collect data responsibly, respect privacy laws, obtain necessary consent, and avoid perpetuating stereotypes or discrimination. Moreover, involving diverse teams in AI development brings varied perspectives, helping to spot biases that homogeneous groups might overlook. By prioritising data integrity and ethics, companies can safeguard against the pitfalls of flawed or biased training data.
We need to maintain a level of human oversight and human verification mechanisms, aligning with best practice policies laid out by the federal government to -ensure we're not missing critical decision-making processes.
Continuous staff training about AI limitations and the importance of critical thinking is essential, emphasising that AI is a tool to aid, not replace, human judgment. By fostering a culture of scepticism and verification, Australian businesses can avoid AI errors and maintain trust with their stakeholders.
Call to action: Embrace ethical AI or risk being left behind The race for AI advancement is on, but without ethics or guardrails, it's a race to the bottom. Companies that ignore ethical principles may gain short-term advantages but will ultimately face backlash - from consumers, regulators, and society at large.
AI systems must operate in alignment with human values. Brands must put people and community above the short-term advantages and focus on driving AI innovation within an ethical framework. This is the only way AI can drive positive results for people, society and business. Jack O'Neill is client partner at Merkle, a Dentsu company.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: The Australian
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); DISCRIMINATION (77%); PRIVACY RIGHTS (74%); VANDALISM (74%); BRANDING (73%); INVASION OF PRIVACY (69%); BASKETBALL (63%); DISINFORMATION & MISINFORMATION (63%); CITY GOVERNMENT (62%); ENVIRONMENT & NATURAL RESOURCES (57%); CITIES (50%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); AI HALLUCINATIONS (89%); CHATBOTS (89%); GENERATIVE AI (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); CONVERSATIONAL AI (79%); INFORMATION SECURITY & PRIVACY (74%); BRANDING (73%); MARKET SHARE (70%)
Person: KLAY THOMPSON (66%); ELON MUSK (51%)
Geographic: NEW YORK, NY, USA (68%); CALIFORNIA, USA (73%); NEW YORK, USA (53%)
Load-Date: November 27, 2024",neutral,0.5517666339874268,balanced/neutral,"['privacy', 'discrimination', 'transparency', 'accountability', 'security', 'consent', 'misinformation', 'disinformation']",[],"['oversight', 'framework', 'law', 'compliance', 'must', 'need to']","['generative ai', 'chatgpt']",8,0,6,2
2024,Unknown Title,"Byline: Punam Singh
Body
Ethical AI in the digital age ensures trust, privacy, and fairness. Organizations must balance innovation with responsibility for a sustainable, credible future.
In the digital age, ethical considerations in AI and data analytics go beyond regulatory compliance. They guide tech innovation, balancing short-term gains with long-term societal value.
With the growing adoption of AI, organizations are increasingly focused on maintaining clean data to ensure ethics, fairness, and safety, as customers now make purchasing decisions based on a company's data practices.
Enthusiasm for AI's potential is tempered by fears of data misuse, privacy breaches, and false information, particularly with Deep Fake technologies threatening privacy and information integrity. A 2024 survey highlighted that 27% of respondents in Asia listed maintaining ethics as the second most challenging issue. Ethical guardrails for AI have evolved from a moral imperative to a smart business decision.
The EU has fined companies nearly Euro 3 billion for GDPR violations in recent years. With nations cautious about AI laws, the responsibility falls on organizations and leaders to adopt a clean data approach and set ethical boundaries to maintain user trust. Ethical AI is a win-win, safeguarding consumers and enabling businesses to thrive responsibly.
Enabling a safe AI environment
A safe AI environment relies on traceability and reliability, with transparency in data practices and usage forming the foundation of consumer trust. Organizations enhancing security and privacy controls improve credibility and customer trust and reduce compliance risks and legal problems. Prioritizing data quality, reducing bias in AI models, and upholding ethical AI standards without sacrificing AI effectiveness bolsters organizational resilience.
Striking the balance between ethics and effectiveness
One of the paramount challenges in implementing ethical guardrails is preserving the efficacy of AI models. It is a delicate balance, one that requires a nuanced understanding of AI's potential without sidelining the ethical imperatives. A comprehensive approach towards ethical AI emphasizes bias detection, fairness, and explainability, alongside ensuring privacy and security. This multidimensional strategy lays the groundwork for deploying AI technologies that are not only technically superior but also ethically sound.
An effective framework should involve five key elements of Trust, Ethics, Privacy, Compliance, and Security. Trust demands transparency and accountability, while ethics promote fairness and humanity. Privacy safeguards users' rights, and compliance respects legal mandates. Security protects against harmful activities. To implement these guidelines, we need processes, policies, tools, technologies, people, and skills. Finally, leadership's alignment with these principles solidifies this ethical foundation, promoting a responsible AI future.
Operationalizing ethical guardrails
To convert ethical principles into a practical roadmap, businesses need a clear framework aligned with industry standards and company values. Also, beyond integrity and fairness, businesses must demonstrate tangible ROI by focusing on metrics like customer acquisition cost, lifetime value, and employee engagement.
Operationalizing ethical guardrails involves creating a structured approach to ensure AI deployment aligns with ethical standards. Companies can start by fostering a culture of ethics through comprehensive employee education programs that emphasize the importance of fairness, transparency, and accountability. Establishing clear policies and guidelines is crucial, alongside implementing robust risk assessment frameworks to identify and mitigate potential ethical issues. Regular audits and continuous monitoring should be part of the process to ensure adherence to these standards. Additionally, maintaining transparency for end-users by openly sharing how AI systems make decisions, and providing mechanisms for feedback, further strengthens trust and accountability. A well-defined roadmap, from internal training to external communication, ensures that ethical considerations are seamlessly integrated into every stage of AI development and deployment.
Keys to unlocking ethical AI without compromising effectiveness include governing AI data, models, and usage in the following ways:
* Incorporating human-centric AI to support agency and decisions.
* Refining training data for fair and unbiased outputs.
* Assigning accountability for AI development, deployment, and use.
* Regularly assessing AI systems.
* Enhancing transparency for end-users.
* Protecting fundamental rights, including data privacy and human dignity.
* Communicating AI system capabilities and limitations with appropriate user training.
The Path Forward
Ethical AI governance is more than technical-it is a moral promise to lead AI innovation with principles honoring data integrity, privacy, and collective welfare. This commitment is crucial for brand credibility and ensures AI benefits humanity respectfully and safely. It marks the first step towards an AI future that is ethically bound, enhancing society.
Our commitment to ethical guardrails in this new data era shows our dedication to responsible innovation. Our actions now shape tomorrow's ethical AI landscape, guaranteeing that technology serves the greater good, guided by integrity, fairness, and respect.
Authored by Gaurav Bhandari, Associate Vice President & Head, Data and Analytics, Infosys
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); DATA SCIENCE (90%); TECHNOLOGY (90%); BUSINESS ETHICS (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEPFAKE TECHNOLOGY (78%); EU DATA PROTECTION REGULATION (78%); GENERATIVE AI (78%); REGULATORY COMPLIANCE (78%); NEGATIVE TECHNOLOGY NEWS (77%); CONSUMERS (76%); CUSTOMER RELATIONS (76%); NEGATIVE BUSINESS NEWS (76%); SAFETY (76%); DISINFORMATION & MISINFORMATION (75%); EMPLOYEE ENGAGEMENT (75%); CUSTOMER ACQUISITION STRATEGY (71%); EDUCATION & TRAINING (70%); RISK MANAGEMENT (69%); STANDARDS & MEASUREMENTS (69%); EUROPEAN UNION (68%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); DATA SCIENCE (90%); INFORMATION MANAGEMENT & TECHNOLOGY (90%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEPFAKE TECHNOLOGY (78%); EU DATA PROTECTION REGULATION (78%); GENERATIVE AI (78%); CUSTOMER ACQUISITION STRATEGY (71%); RISK MANAGEMENT (69%)
Geographic: ASIA (79%); EUROPEAN UNION MEMBER STATES (56%)
Load-Date: July 12, 2024","Ethical AI in the digital age ensures trust, privacy, and fairness. Organizations must balance innovation with responsibility for a sustainable, credible future.
In the digital age, ethical considerations in AI and data analytics go beyond regulatory compliance. They guide tech innovation, balancing short-term gains with long-term societal value.
With the growing adoption of AI, organizations are increasingly focused on maintaining clean data to ensure ethics, fairness, and safety, as customers now make purchasing decisions based on a company's data practices.
Enthusiasm for AI's potential is tempered by fears of data misuse, privacy breaches, and false information, particularly with Deep Fake technologies threatening privacy and information integrity. A 2024 survey highlighted that 27% of respondents in Asia listed maintaining ethics as the second most challenging issue. Ethical guardrails for AI have evolved from a moral imperative to a smart business decision.
The EU has fined companies nearly Euro 3 billion for GDPR violations in recent years. With nations cautious about AI laws, the responsibility falls on organizations and leaders to adopt a clean data approach and set ethical boundaries to maintain user trust. Ethical AI is a win-win, safeguarding consumers and enabling businesses to thrive responsibly.
Enabling a safe AI environment
A safe AI environment relies on traceability and reliability, with transparency in data practices and usage forming the foundation of consumer trust. Organizations enhancing security and privacy controls improve credibility and customer trust and reduce compliance risks and legal problems. Prioritizing data quality, reducing bias in AI models, and upholding ethical AI standards without sacrificing AI effectiveness bolsters organizational resilience.
Striking the balance between ethics and effectiveness
One of the paramount challenges in implementing ethical guardrails is preserving the efficacy of AI models. It is a delicate balance, one that requires a nuanced understanding of AI's potential without sidelining the ethical imperatives. A comprehensive approach towards ethical AI emphasizes bias detection, fairness, and explainability, alongside ensuring privacy and security. This multidimensional strategy lays the groundwork for deploying AI technologies that are not only technically superior but also ethically sound.
An effective framework should involve five key elements of Trust, Ethics, Privacy, Compliance, and Security. Trust demands transparency and accountability, while ethics promote fairness and humanity. Privacy safeguards users' rights, and compliance respects legal mandates. Security protects against harmful activities. To implement these guidelines, we need processes, policies, tools, technologies, people, and skills. Finally, leadership's alignment with these principles solidifies this ethical foundation, promoting a responsible AI future.
Operationalizing ethical guardrails
To convert ethical principles into a practical roadmap, businesses need a clear framework aligned with industry standards and company values. Also, beyond integrity and fairness, businesses must demonstrate tangible ROI by focusing on metrics like customer acquisition cost, lifetime value, and employee engagement.
Operationalizing ethical guardrails involves creating a structured approach to ensure AI deployment aligns with ethical standards. Companies can start by fostering a culture of ethics through comprehensive employee education programs that emphasize the importance of fairness, transparency, and accountability. Establishing clear policies and guidelines is crucial, alongside implementing robust risk assessment frameworks to identify and mitigate potential ethical issues. Regular audits and continuous monitoring should be part of the process to ensure adherence to these standards. Additionally, maintaining transparency for end-users by openly sharing how AI systems make decisions, and providing mechanisms for feedback, further strengthens trust and accountability. A well-defined roadmap, from internal training to external communication, ensures that ethical considerations are seamlessly integrated into every stage of AI development and deployment.
Keys to unlocking ethical AI without compromising effectiveness include governing AI data, models, and usage in the following ways:
* Incorporating human-centric AI to support agency and decisions.
* Refining training data for fair and unbiased outputs.
* Assigning accountability for AI development, deployment, and use.
* Regularly assessing AI systems.
* Enhancing transparency for end-users.
* Protecting fundamental rights, including data privacy and human dignity.
* Communicating AI system capabilities and limitations with appropriate user training.
The Path Forward
Ethical AI governance is more than technical-it is a moral promise to lead AI innovation with principles honoring data integrity, privacy, and collective welfare. This commitment is crucial for brand credibility and ensures AI benefits humanity respectfully and safely. It marks the first step towards an AI future that is ethically bound, enhancing society.
Our commitment to ethical guardrails in this new data era shows our dedication to responsible innovation. Our actions now shape tomorrow's ethical AI landscape, guaranteeing that technology serves the greater good, guided by integrity, fairness, and respect.
Authored by Gaurav Bhandari, Associate Vice President & Head, Data and Analytics, Infosys
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); DATA SCIENCE (90%); TECHNOLOGY (90%); BUSINESS ETHICS (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEPFAKE TECHNOLOGY (78%); EU DATA PROTECTION REGULATION (78%); GENERATIVE AI (78%); REGULATORY COMPLIANCE (78%); NEGATIVE TECHNOLOGY NEWS (77%); CONSUMERS (76%); CUSTOMER RELATIONS (76%); NEGATIVE BUSINESS NEWS (76%); SAFETY (76%); DISINFORMATION & MISINFORMATION (75%); EMPLOYEE ENGAGEMENT (75%); CUSTOMER ACQUISITION STRATEGY (71%); EDUCATION & TRAINING (70%); RISK MANAGEMENT (69%); STANDARDS & MEASUREMENTS (69%); EUROPEAN UNION (68%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); DATA SCIENCE (90%); INFORMATION MANAGEMENT & TECHNOLOGY (90%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEPFAKE TECHNOLOGY (78%); EU DATA PROTECTION REGULATION (78%); GENERATIVE AI (78%); CUSTOMER ACQUISITION STRATEGY (71%); RISK MANAGEMENT (69%)
Geographic: ASIA (79%); EUROPEAN UNION MEMBER STATES (56%)
Load-Date: July 12, 2024",neutral,0.6951218247413635,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'agency', 'misinformation', 'disinformation']","['fairness', 'dignity']","['regulation', 'policy', 'governance', 'standards', 'guidelines', 'framework', 'compliance', 'should', 'must']",['generative ai'],11,2,9,1
2024,Unknown Title,"Body
Researchers from the University of Oxford, University of Cambridge, University of Copenhagen, National University of Singapore, and other leading institutions have devised philosophically-grounded ethical guidelines for using Large Language Models in academic writing.
As Large Language Models (LLMs) become more prevalent and easy to access, academics across the globe are using their assistance for academic manuscript writing, in particular developing ideas and content. However, several concerns arise from their probabilistic nature relating to plagiarism, authorship attribution, and the integrity of academia as a whole. As AI tools become increasingly sophisticated, clear ethical guidelines are therefore crucial to maintaining the quality and credibility of scholarly work.
The new research, published in Nature Machine Intelligence, outlines three essential criteria that maximise the beneficial impacts of LLMs on scientific advancement and academic equity:
Human vetting and guaranteeing of accuracy and integrity Ensuring substantial human contribution to the work Appropriate acknowledgment and transparency of LLM use. The authors define a template LLM Use Acknowledgement, which researchers can utilise when submitting manuscripts. This practical tool will streamline adherence to ethical standards in AI-assisted academic writing, and provide greater transparency about LLM use.
Speaking of the guidelines, co-author, Professor Julian Savulescu, of The Uehiro Oxford Institute, said: 'Large Language Models are the Pandora's Box for academic research. They could eliminate academic independence, creativity, originality and thought itself. But they could also facilitate unimaginable co-creation and productivity. These guidelines are the first steps to using LLMs responsibly and ethically in academic writing and research.'
This publication marks a crucial step in managing the relationship between human academic work and machine intelligence. By empowering researchers to leverage AI technology ethically, they aim to boost productivity and innovation while preserving academic integrity.
Co-author, Dr Brian Earp, of The Uehiro Oxford Institute, said: 'It's appropriate and necessary to be extremely cautious when faced with new technological possibilities, including the ability for human writers to co-create academic material using generative AI. This is especially true when things are scaling up and moving quickly. But ethical guidelines are not only about reducing risk; they are also about maximizing potential benefits.'
Professor Timo Minssen from the University of Copenhagen said: 'Guidance is essential in shaping the ethical use of AI in academic research, and in particular concerning the co-creation of academic articles with LLMs. Appropriate acknowledgment based on the principles of research ethics should ensure transparency, ethical integrity, and proper attribution. Ideally, this will promote a collaborative and more inclusive environment where human ingenuity and machine intelligence can enhance scholarly discourse.'
This new research presents opportunities for academic communities worldwide, and can be used across all academic disciplines.
The paper 'Guidelines for ethical use and acknowledgement of large language models in academic writing' has been published in Nature Machine Intelligence.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (93%); LARGE LANGUAGE MODELS (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); PRESS RELEASES (90%); WRITERS (90%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); SCHOOL CHEATING (78%); GENERATIVE AI (77%); RESEARCH REPORTS (74%); PLAGIARISM (71%)
Industry: LARGE LANGUAGE MODELS (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); WRITERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); GENERATIVE AI (77%)
Geographic: OXFORD, ENGLAND (73%)
Load-Date: November 14, 2024","Researchers from the University of Oxford, University of Cambridge, University of Copenhagen, National University of Singapore, and other leading institutions have devised philosophically-grounded ethical guidelines for using Large Language Models in academic writing.
As Large Language Models (LLMs) become more prevalent and easy to access, academics across the globe are using their assistance for academic manuscript writing, in particular developing ideas and content. However, several concerns arise from their probabilistic nature relating to plagiarism, authorship attribution, and the integrity of academia as a whole. As AI tools become increasingly sophisticated, clear ethical guidelines are therefore crucial to maintaining the quality and credibility of scholarly work.
The new research, published in Nature Machine Intelligence, outlines three essential criteria that maximise the beneficial impacts of LLMs on scientific advancement and academic equity:
Human vetting and guaranteeing of accuracy and integrity Ensuring substantial human contribution to the work Appropriate acknowledgment and transparency of LLM use. The authors define a template LLM Use Acknowledgement, which researchers can utilise when submitting manuscripts. This practical tool will streamline adherence to ethical standards in AI-assisted academic writing, and provide greater transparency about LLM use.
Speaking of the guidelines, co-author, Professor Julian Savulescu, of The Uehiro Oxford Institute, said: 'Large Language Models are the Pandora's Box for academic research. They could eliminate academic independence, creativity, originality and thought itself. But they could also facilitate unimaginable co-creation and productivity. These guidelines are the first steps to using LLMs responsibly and ethically in academic writing and research.'
This publication marks a crucial step in managing the relationship between human academic work and machine intelligence. By empowering researchers to leverage AI technology ethically, they aim to boost productivity and innovation while preserving academic integrity.
Co-author, Dr Brian Earp, of The Uehiro Oxford Institute, said: 'It's appropriate and necessary to be extremely cautious when faced with new technological possibilities, including the ability for human writers to co-create academic material using generative AI. This is especially true when things are scaling up and moving quickly. But ethical guidelines are not only about reducing risk; they are also about maximizing potential benefits.'
Professor Timo Minssen from the University of Copenhagen said: 'Guidance is essential in shaping the ethical use of AI in academic research, and in particular concerning the co-creation of academic articles with LLMs. Appropriate acknowledgment based on the principles of research ethics should ensure transparency, ethical integrity, and proper attribution. Ideally, this will promote a collaborative and more inclusive environment where human ingenuity and machine intelligence can enhance scholarly discourse.'
This new research presents opportunities for academic communities worldwide, and can be used across all academic disciplines.
The paper 'Guidelines for ethical use and acknowledgement of large language models in academic writing' has been published in Nature Machine Intelligence.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (93%); LARGE LANGUAGE MODELS (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); PRESS RELEASES (90%); WRITERS (90%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); SCHOOL CHEATING (78%); GENERATIVE AI (77%); RESEARCH REPORTS (74%); PLAGIARISM (71%)
Industry: LARGE LANGUAGE MODELS (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); WRITERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); GENERATIVE AI (77%)
Geographic: OXFORD, ENGLAND (73%)
Load-Date: November 14, 2024",neutral,0.766386866569519,balanced/neutral,"['transparency', 'access']",['equity'],"['standards', 'guidelines', 'should']","['generative ai', 'llm']",2,1,3,2
2024,Unknown Title,"Dateline: New Delhi 
Body
New Delhi, June 10 -- To now say that artificial intelligence (AI) has had a profound societal impact is a bit of an understatement. AI continues to transform the world. It has been shaping recent & future socio-economic landscapes and is bringing unprecedented opportunities for communities & businesses.
The role of AI in corporate decision-making has expanded significantly, with algorithms influencing tactical planning, resource allocation, risk management, and customer engagement. At its core, AI is empowering boards of directors with data-driven insights and predictive analytics, enabling more informed and strategic decision-making. By leveraging AI algorithms and machine learning techniques, boards are able to analyse vast amounts of data and derive actionable insights that may not be apparent through traditional means.
These benefits are leading to every sector in India rapidly embracing AI. As per the recent IBM Global AI Adoption Index 2023 study, 59% of enterprise-scale organizations surveyed in India have AI actively in use in their businesses.
This phenomenon of AI becoming pervasive across the core sectors of the Indian economy is also leading to enhanced perceived risks. The ethical implications of AI implementation are no longer peripheral concerns but central considerations for corporate governance. Concerns such as regulations, ethics, data governance, trust, and legality are gaining rapid significance - warranting the board of directors to add it to their agenda.
Responsible AI in the Boardroom
Incorporating responsible AI into corporate boardrooms requires a multifaceted approach that encompasses governance, culture, and technology. Boards must proactively establish clear guidelines and standards, and integrate ethical considerations into strategic decision-making processes. Moreover, fostering a culture of ethical awareness and accountability throughout the organization is essential for ensuring that responsible AI principles are upheld at every level.
Responsible AI practices in boardrooms can inculcate principles of transparency, accountability, fairness, and privacy throughout the organization. Implementing robust governance structures that delineate roles, responsibilities, and oversight mechanisms is crucial for fostering accountability in AI initiatives.
In addition to obvious benefits such as ethical decision-making and enhanced governance, responsible AI in boardrooms also leads to risk mitigation, and stakeholder trust. By embracing responsible AI practices, company's boards can harness AI to drive sustainable growth, foster innovation, and build a more ethical and resilient organization for the future.
Need for an AI Ethics Board
An AI Ethics Board, working in tandem with the Board of Directors, jointly become the strongest and most effective foundation for instilling responsible AI within organizations. It serves as a critical mechanism to hold individuals and algorithms accountable and ensure that AI technologies are developed, deployed, and utilized in a manner that aligns with the company's ethical principles and the nation's guidelines, if any. An AI Ethics Board can guide navigating complex ethical dilemmas, promoting transparency and accountability in AI decision-making, and mitigating potential risks associated with AI bias, privacy infringement, and unintended consequences.
Organizations need to introduce an AI Ethics Board that provides centralized governance, review, and decision-making for all AI ethics policies and practices. The AI Ethics Board should also provide thought leadership and guidance on how the organization researches and exploits AI technology and associated data. The board can have a Chief AI Ethics Officer who leads a team with other board members and helps monitor and safeguard ethical values incorporated into AI systems, similar to the role of a data protection officer. Thus, by fostering a culture of ethical AI development and usage, organizations can not only safeguard against reputational damage and legal liabilities but also build trust with stakeholders and contribute to the responsible advancement of AI.
In conclusion, the role of responsible AI in corporate boardrooms is becoming indispensable in navigating the ethical complexities of the modern world's AI-driven decision-making. Corporate boards must take a proactive stance in championing responsible AI practices, recognizing that ethical considerations are not just a moral imperative but also a strategic necessity in the digital age.
Companies beyond those in the technology & IT industry are prioritizing responsible AI implementation to stay ahead of the AI curve. Through steps like establishment of AI Ethics Boards, they are increasingly asserting the importance of implementing responsible AI practices to address ethical concerns, mitigate risks, and build trust with users and stakeholders. Responsible AI is all set to occupy a key seat in Indian corporate boardrooms.
Published by HT Digital Content Services with permission from TechCircle. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: BOARDS OF DIRECTORS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ASSOCIATIONS & ORGANIZATIONS (89%); CORPORATE GOVERNANCE (89%); RISK MANAGEMENT (89%); TECHNOLOGY (89%); BUSINESS ETHICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PREDICTIVE ANALYTICS (78%); BUSINESS ANALYTICS (77%); MACHINE LEARNING (73%); ECONOMY & ECONOMIC INDICATORS (72%); SHAREHOLDERS & GOVERNANCE (71%); INVASION OF PRIVACY (62%); CUSTOMER ENGAGEMENT (56%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); RISK MANAGEMENT (89%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PREDICTIVE ANALYTICS (78%); BUSINESS ANALYTICS (77%); DATA GOVERNANCE & STEWARDSHIP (76%); MACHINE LEARNING (73%); CUSTOMER ENGAGEMENT (56%)
Geographic: NEW DELHI, INDIA (74%); INDIA (91%)
Load-Date: June 10, 2024","New Delhi, June 10 -- To now say that artificial intelligence (AI) has had a profound societal impact is a bit of an understatement. AI continues to transform the world. It has been shaping recent & future socio-economic landscapes and is bringing unprecedented opportunities for communities & businesses.
The role of AI in corporate decision-making has expanded significantly, with algorithms influencing tactical planning, resource allocation, risk management, and customer engagement. At its core, AI is empowering boards of directors with data-driven insights and predictive analytics, enabling more informed and strategic decision-making. By leveraging AI algorithms and machine learning techniques, boards are able to analyse vast amounts of data and derive actionable insights that may not be apparent through traditional means.
These benefits are leading to every sector in India rapidly embracing AI. As per the recent IBM Global AI Adoption Index 2023 study, 59% of enterprise-scale organizations surveyed in India have AI actively in use in their businesses.
This phenomenon of AI becoming pervasive across the core sectors of the Indian economy is also leading to enhanced perceived risks. The ethical implications of AI implementation are no longer peripheral concerns but central considerations for corporate governance. Concerns such as regulations, ethics, data governance, trust, and legality are gaining rapid significance - warranting the board of directors to add it to their agenda.
Responsible AI in the Boardroom
Incorporating responsible AI into corporate boardrooms requires a multifaceted approach that encompasses governance, culture, and technology. Boards must proactively establish clear guidelines and standards, and integrate ethical considerations into strategic decision-making processes. Moreover, fostering a culture of ethical awareness and accountability throughout the organization is essential for ensuring that responsible AI principles are upheld at every level.
Responsible AI practices in boardrooms can inculcate principles of transparency, accountability, fairness, and privacy throughout the organization. Implementing robust governance structures that delineate roles, responsibilities, and oversight mechanisms is crucial for fostering accountability in AI initiatives.
In addition to obvious benefits such as ethical decision-making and enhanced governance, responsible AI in boardrooms also leads to risk mitigation, and stakeholder trust. By embracing responsible AI practices, company's boards can harness AI to drive sustainable growth, foster innovation, and build a more ethical and resilient organization for the future.
Need for an AI Ethics Board
An AI Ethics Board, working in tandem with the Board of Directors, jointly become the strongest and most effective foundation for instilling responsible AI within organizations. It serves as a critical mechanism to hold individuals and algorithms accountable and ensure that AI technologies are developed, deployed, and utilized in a manner that aligns with the company's ethical principles and the nation's guidelines, if any. An AI Ethics Board can guide navigating complex ethical dilemmas, promoting transparency and accountability in AI decision-making, and mitigating potential risks associated with AI bias, privacy infringement, and unintended consequences.
Organizations need to introduce an AI Ethics Board that provides centralized governance, review, and decision-making for all AI ethics policies and practices. The AI Ethics Board should also provide thought leadership and guidance on how the organization researches and exploits AI technology and associated data. The board can have a Chief AI Ethics Officer who leads a team with other board members and helps monitor and safeguard ethical values incorporated into AI systems, similar to the role of a data protection officer. Thus, by fostering a culture of ethical AI development and usage, organizations can not only safeguard against reputational damage and legal liabilities but also build trust with stakeholders and contribute to the responsible advancement of AI.
In conclusion, the role of responsible AI in corporate boardrooms is becoming indispensable in navigating the ethical complexities of the modern world's AI-driven decision-making. Corporate boards must take a proactive stance in championing responsible AI practices, recognizing that ethical considerations are not just a moral imperative but also a strategic necessity in the digital age.
Companies beyond those in the technology & IT industry are prioritizing responsible AI implementation to stay ahead of the AI curve. Through steps like establishment of AI Ethics Boards, they are increasingly asserting the importance of implementing responsible AI practices to address ethical concerns, mitigate risks, and build trust with users and stakeholders. Responsible AI is all set to occupy a key seat in Indian corporate boardrooms.
Published by HT Digital Content Services with permission from TechCircle. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: BOARDS OF DIRECTORS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ASSOCIATIONS & ORGANIZATIONS (89%); CORPORATE GOVERNANCE (89%); RISK MANAGEMENT (89%); TECHNOLOGY (89%); BUSINESS ETHICS (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PREDICTIVE ANALYTICS (78%); BUSINESS ANALYTICS (77%); MACHINE LEARNING (73%); ECONOMY & ECONOMIC INDICATORS (72%); SHAREHOLDERS & GOVERNANCE (71%); INVASION OF PRIVACY (62%); CUSTOMER ENGAGEMENT (56%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); RISK MANAGEMENT (89%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PREDICTIVE ANALYTICS (78%); BUSINESS ANALYTICS (77%); DATA GOVERNANCE & STEWARDSHIP (76%); MACHINE LEARNING (73%); CUSTOMER ENGAGEMENT (56%)
Geographic: NEW DELHI, INDIA (74%); INDIA (91%)
Load-Date: June 10, 2024",positive,0.8787550330162048,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability']",['fairness'],"['governance', 'oversight', 'standards', 'guidelines', 'should', 'must', 'need to']","['machine learning', 'predictive analytics']",5,1,7,2
2024,Unknown Title,"Byline: Hillary
Body
March 5th, 2024 ( TechBullion  — Delivered by  Newstex )
In the ever-evolving landscape of education, the integration of Artificial Intelligence (AI) presents tremendous  opportunities for innovation and improvement. However, as we embrace the potential benefits of AI in education, it is crucial to navigate the ethical considerations that come with this technological advancement. Striking the right balance between harnessing the power of AI and ensuring ethical practices is imperative for creating a responsible and equitable educational environment. This article delves into the ethical considerations in AI education, exploring the challenges, potential biases, and the need for transparency in order to strike the right balance.
The Promise of AI in Education:
Unlocking Personalized Learning:
AI in education promises to revolutionize traditional teaching methods by unlocking personalized learning experiences. Through sophisticated algorithms, AI can analyze vast amounts of data to understand individual student needs, preferences, and learning styles. This information is then used to tailor educational content, providing a more customized and effective learning path for each student.
Efficiency and Automation:
AI also offers the potential to streamline administrative tasks, allowing educators to focus more on teaching and less on paperwork. Tasks like grading, attendance tracking, and lesson planning can be automated, saving valuable time and resources. This efficiency can contribute to a more productive and engaging learning environment.
The Ethical Challenges of AI in Education:
Guarding Against Bias:
One of the primary ethical challenges in AI education is the potential for bias in algorithms. If not carefully designed, AI systems can inadvertently perpetuate and reinforce existing biases present in the data used to train them. This bias could manifest in unequal opportunities for students, disadvantaging certain groups based on socio-economic status, race, or gender.
Data Privacy Concerns:
As educational institutions increasingly digitize their processes, concerns about data privacy become paramount. The vast amount of personal data collected by AI systems, including student performance, learning preferences, and behavioral patterns, raises questions about how this information is handled, stored, and protected. Ensuring robust data protection measures is essential to maintaining trust in AI-driven education.
Striking the Right Balance: Ensuring Ethical AI Practices:
Transparency in Algorithms:
To address ethical concerns, transparency in AI algorithms is key. Educational institutions and technology  developers must prioritize transparency, providing insights into how algorithms make decisions. This transparency not only builds trust but also allows educators and stakeholders to understand and address potential biases within the system.
Guardrails for Ethical AI Use:
Establishing clear guidelines and guardrails for the ethical use of AI in education is crucial. This includes defining what data can be collected, how it can be used, and who has access to it. By creating a framework that prioritizes ethical considerations, educational institutions can ensure responsible AI integration that aligns with their values and goals.
Addressing Bias in AI Education:
Diverse and Representative Data:
To mitigate bias in AI algorithms, it is essential to use diverse and representative datasets during the training process. Ensuring that the data used encompasses a broad range of demographics, backgrounds, and experiences helps minimize the risk of perpetuating existing biases present in society.
Continuous Monitoring and Evaluation:
Even with the best intentions, biases can emerge over time as AI systems interact with real-world data. Therefore, continuous monitoring and evaluation of AI systems are essential. Regular audits and assessments can identify and rectify any unintended biases, ensuring that the system remains fair and equitable.
AI Education and Student Privacy:
Strategies for Robust Data Protection:
Protecting student privacy is a cornerstone of ethical AI education. Educational institutions should implement robust strategies for data protection, including encryption, secure storage practices, and restricted access to sensitive information. This commitment to privacy builds trust among students, parents, and educators.
Informed Consent and Transparency:
Obtaining informed consent from students and their parents regarding the collection and use of their data is crucial. Transparency about how AI systems operate, what data is being collected, and how it will be utilized empowers stakeholders to make informed decisions and fosters a sense of control over their personal information.
AI Ethics Education: Empowering Stakeholders:
Training Educators and Administrators:
To navigate the ethical challenges of AI in education, it is essential to provide comprehensive training for educators and administrators. This training should cover not only the technical aspects of AI but also the ethical implications, ensuring that those responsible for implementing AI systems are well-equipped to make ethical decisions.
Raising Awareness Among Students:
Empowering students with an understanding of AI ethics is equally crucial. Educators should incorporate discussions about the ethical use of technology into the curriculum, fostering a sense of digital citizenship. This awareness enables students to critically evaluate the use of AI and advocate for ethical practices.
The Social and Cultural Impact of AI Education:
Addressing Socio-economic Disparities:
AI has the potential to either exacerbate or alleviate existing socio-economic disparities in education. If not carefully implemented, AI systems may unintentionally disadvantage students who lack access to technology or come from underprivileged backgrounds. Ethical considerations must prioritize equity, ensuring that AI benefits all students, regardless of their socio-economic status.
Cultural Sensitivity in AI Systems:
Cultural diversity should be a central consideration in the development of AI systems for education . AI platforms should be sensitive to cultural nuances, avoiding the reinforcement of stereotypes or the imposition of a singular cultural perspective. This inclusivity ensures that AI-driven education respects and celebrates diverse backgrounds.
Conclusion:
The integration of AI in education holds immense promise, but it also brings forth ethical considerations that demand careful attention. Striking the right balance between leveraging the power of AI and ensuring ethical practices is essential for creating a responsible and equitable educational environment. Transparency in algorithms, addressing bias, safeguarding student privacy, and empowering stakeholders through education are key components of ethical AI integration in education. As we navigate the future of education, it is imperative to prioritize ethical considerations, fostering a learning environment that is not only technologically advanced but also ethically sound, empowering, and inclusive. Ethical AI has the potential to revolutionize education positively, and by staying vigilant and proactive, we can ensure that it becomes a force for empowerment and enlightenment in the classrooms of the future.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); LEARNING THEORIES (89%); TEACHING & TEACHERS (89%); TECHNOLOGY (89%); ACCESS TO EDUCATION (78%); SCHOOL PERFORMANCE (78%); STUDENTS & STUDENT LIFE (78%); PRIVACY RIGHTS (67%); Artificial intelligence (%); 2024 Technology (%); A.I. Software (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); EDUCATIONAL SERVICES (89%); INFORMATION SECURITY & PRIVACY (89%); DATA SECURITY (73%)
Load-Date: March 5, 2024","March 5th, 2024 ( TechBullion  — Delivered by  Newstex )
In the ever-evolving landscape of education, the integration of Artificial Intelligence (AI) presents tremendous  opportunities for innovation and improvement. However, as we embrace the potential benefits of AI in education, it is crucial to navigate the ethical considerations that come with this technological advancement. Striking the right balance between harnessing the power of AI and ensuring ethical practices is imperative for creating a responsible and equitable educational environment. This article delves into the ethical considerations in AI education, exploring the challenges, potential biases, and the need for transparency in order to strike the right balance.
The Promise of AI in Education:
Unlocking Personalized Learning:
AI in education promises to revolutionize traditional teaching methods by unlocking personalized learning experiences. Through sophisticated algorithms, AI can analyze vast amounts of data to understand individual student needs, preferences, and learning styles. This information is then used to tailor educational content, providing a more customized and effective learning path for each student.
Efficiency and Automation:
AI also offers the potential to streamline administrative tasks, allowing educators to focus more on teaching and less on paperwork. Tasks like grading, attendance tracking, and lesson planning can be automated, saving valuable time and resources. This efficiency can contribute to a more productive and engaging learning environment.
The Ethical Challenges of AI in Education:
Guarding Against Bias:
One of the primary ethical challenges in AI education is the potential for bias in algorithms. If not carefully designed, AI systems can inadvertently perpetuate and reinforce existing biases present in the data used to train them. This bias could manifest in unequal opportunities for students, disadvantaging certain groups based on socio-economic status, race, or gender.
Data Privacy Concerns:
As educational institutions increasingly digitize their processes, concerns about data privacy become paramount. The vast amount of personal data collected by AI systems, including student performance, learning preferences, and behavioral patterns, raises questions about how this information is handled, stored, and protected. Ensuring robust data protection measures is essential to maintaining trust in AI-driven education.
Striking the Right Balance: Ensuring Ethical AI Practices:
Transparency in Algorithms:
To address ethical concerns, transparency in AI algorithms is key. Educational institutions and technology  developers must prioritize transparency, providing insights into how algorithms make decisions. This transparency not only builds trust but also allows educators and stakeholders to understand and address potential biases within the system.
Guardrails for Ethical AI Use:
Establishing clear guidelines and guardrails for the ethical use of AI in education is crucial. This includes defining what data can be collected, how it can be used, and who has access to it. By creating a framework that prioritizes ethical considerations, educational institutions can ensure responsible AI integration that aligns with their values and goals.
Addressing Bias in AI Education:
Diverse and Representative Data:
To mitigate bias in AI algorithms, it is essential to use diverse and representative datasets during the training process. Ensuring that the data used encompasses a broad range of demographics, backgrounds, and experiences helps minimize the risk of perpetuating existing biases present in society.
Continuous Monitoring and Evaluation:
Even with the best intentions, biases can emerge over time as AI systems interact with real-world data. Therefore, continuous monitoring and evaluation of AI systems are essential. Regular audits and assessments can identify and rectify any unintended biases, ensuring that the system remains fair and equitable.
AI Education and Student Privacy:
Strategies for Robust Data Protection:
Protecting student privacy is a cornerstone of ethical AI education. Educational institutions should implement robust strategies for data protection, including encryption, secure storage practices, and restricted access to sensitive information. This commitment to privacy builds trust among students, parents, and educators.
Informed Consent and Transparency:
Obtaining informed consent from students and their parents regarding the collection and use of their data is crucial. Transparency about how AI systems operate, what data is being collected, and how it will be utilized empowers stakeholders to make informed decisions and fosters a sense of control over their personal information.
AI Ethics Education: Empowering Stakeholders:
Training Educators and Administrators:
To navigate the ethical challenges of AI in education, it is essential to provide comprehensive training for educators and administrators. This training should cover not only the technical aspects of AI but also the ethical implications, ensuring that those responsible for implementing AI systems are well-equipped to make ethical decisions.
Raising Awareness Among Students:
Empowering students with an understanding of AI ethics is equally crucial. Educators should incorporate discussions about the ethical use of technology into the curriculum, fostering a sense of digital citizenship. This awareness enables students to critically evaluate the use of AI and advocate for ethical practices.
The Social and Cultural Impact of AI Education:
Addressing Socio-economic Disparities:
AI has the potential to either exacerbate or alleviate existing socio-economic disparities in education. If not carefully implemented, AI systems may unintentionally disadvantage students who lack access to technology or come from underprivileged backgrounds. Ethical considerations must prioritize equity, ensuring that AI benefits all students, regardless of their socio-economic status.
Cultural Sensitivity in AI Systems:
Cultural diversity should be a central consideration in the development of AI systems for education . AI platforms should be sensitive to cultural nuances, avoiding the reinforcement of stereotypes or the imposition of a singular cultural perspective. This inclusivity ensures that AI-driven education respects and celebrates diverse backgrounds.
Conclusion:
The integration of AI in education holds immense promise, but it also brings forth ethical considerations that demand careful attention. Striking the right balance between leveraging the power of AI and ensuring ethical practices is essential for creating a responsible and equitable educational environment. Transparency in algorithms, addressing bias, safeguarding student privacy, and empowering stakeholders through education are key components of ethical AI integration in education. As we navigate the future of education, it is imperative to prioritize ethical considerations, fostering a learning environment that is not only technologically advanced but also ethically sound, empowering, and inclusive. Ethical AI has the potential to revolutionize education positively, and by staying vigilant and proactive, we can ensure that it becomes a force for empowerment and enlightenment in the classrooms of the future.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); LEARNING THEORIES (89%); TEACHING & TEACHERS (89%); TECHNOLOGY (89%); ACCESS TO EDUCATION (78%); SCHOOL PERFORMANCE (78%); STUDENTS & STUDENT LIFE (78%); PRIVACY RIGHTS (67%); Artificial intelligence (%); 2024 Technology (%); A.I. Software (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); EDUCATIONAL SERVICES (89%); INFORMATION SECURITY & PRIVACY (89%); DATA SECURITY (73%)
Load-Date: March 5, 2024",positive,0.6640112400054932,balanced/neutral,"['privacy', 'bias', 'transparency', 'security', 'consent', 'inclusivity', 'access']",['equity'],"['guidelines', 'framework', 'should', 'must', 'advocate']",[],7,1,5,0
2024,Unknown Title,"Byline: IT VAR News
Body
As AI reshapes the business landscape, the role of channel partners in ensuring responsible AI governance has become more critical than ever. Channel partners are no longer just distributors of technology; they are vital stakeholders who drive ethical AI practices, safeguard data, and align with corporate values. This story explores how channel partners are leading the charge in ethical AI governance, helping businesses adopt AI responsibly and sustainably.
1. Channel Partners as Ethical AI Advocates
Channel partners are uniquely positioned to influence how AI technologies are adopted across industries. Their in-depth knowledge of both the technology and customer needs enables them to champion ethical AI practices. Channel partners work closely with vendors to prioritize transparency, fairness, and security in AI solutions. By ensuring these values are upheld, they not only enhance trust with customers but also contribute to a more responsible AI ecosystem.
2. Establishing Trust through Transparent Practices
Transparency is a cornerstone of ethical AI governance, and channel partners play a pivotal role in ensuring that AI solutions remain transparent and explainable. By advocating for AI solutions that allow customers to understand how decisions are made, partners build trust with end-users. For example, partners may require vendors to provide clear documentation, model explanations, and data protection guidelines, ensuring customers feel confident in AI's decision-making processes.
3. Reducing Bias: Partners as Guardians of Fairness
AI bias is a growing concern, and channel partners are stepping in as guardians of fairness. They work closely with AI vendors to identify potential biases within algorithms, particularly those that may lead to discrimination. Partners are demanding that AI products undergo rigorous testing for bias reduction, ensuring that the technology serves all users equitably. This commitment to fairness positions channel partners as trusted advisors to customers who value ethical practices.
4. Data Security and Privacy: A Top Priority
In a world of constant data breaches and privacy concerns, channel partners recognize that responsible AI governance includes stringent data security. They play a crucial role in helping businesses choose AI solutions that adhere to top privacy standards and regulations, such as GDPR. Channel partners not only provide AI tools but also guide businesses on implementing these solutions in ways that prioritize user privacy and data integrity.
5. Supporting Compliance with Evolving Regulations
AI regulations are evolving worldwide, and channel partners help businesses stay compliant with these changes. By staying informed about new laws and standards, partners can advise customers on AI solutions that meet regulatory requirements. This guidance is invaluable for businesses navigating the complex landscape of AI compliance, from the European Union's AI Act to sector-specific regulations.
6. Educating Customers on Responsible AI Use
One of the most impactful ways channel partners contribute to responsible AI governance is by educating customers. They provide training, resources, and best practices on the ethical implications of AI. By empowering customers to understand both the benefits and risks of AI, partners ensure that businesses use AI responsibly. This educational role positions channel partners as thought leaders and trusted advisors in the AI space.
7. The Business Benefits of Ethical AI Practices
Channel partners understand that ethical AI practices are not just a moral responsibility but also a business advantage. Responsible AI governance enhances a company's reputation, attracts top clients, and reduces risk. By promoting responsible AI, channel partners help their clients build lasting, trust-based relationships with customers, ultimately benefiting the entire partner ecosystem.
The Future of Responsible AI Governance with Channel Partners
Channel partners are at the forefront of driving ethical AI governance, supporting vendors and customers alike in adopting AI responsibly. Their unique position as intermediaries enables them to bridge the gap between technology providers and end-users, ensuring that AI solutions align with both ethical principles and business goals. As the need for responsible AI governance grows itVARnews will continue to spotlight the vital role that channel partners play in shaping an AI-driven future that prioritizes trust, fairness, and accountability.
This story celebrates the critical role of channel partners in the AI ecosystem, highlighting how their commitment to ethical practices is transforming the business landscape.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ALLIANCES & PARTNERSHIPS (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); TECHNOLOGY (89%); BEST PRACTICES (78%); CORPORATE CULTURE (78%); EU DATA PROTECTION REGULATION (77%); SUSTAINABLE DEVELOPMENT (76%); DATA BREACHES (72%); NEGATIVE TECHNOLOGY NEWS (72%); DISCRIMINATION (71%); REGULATORY ACTIONS (65%); INVASION OF PRIVACY (62%); LEGISLATION (60%); EUROPEAN UNION (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); DATA SECURITY (89%); INFORMATION SECURITY & PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); EU DATA PROTECTION REGULATION (77%); SUSTAINABLE DEVELOPMENT (76%); DATA BREACHES (72%)
Geographic: EUROPEAN UNION MEMBER STATES (51%)
Load-Date: November 12, 2024","As AI reshapes the business landscape, the role of channel partners in ensuring responsible AI governance has become more critical than ever. Channel partners are no longer just distributors of technology; they are vital stakeholders who drive ethical AI practices, safeguard data, and align with corporate values. This story explores how channel partners are leading the charge in ethical AI governance, helping businesses adopt AI responsibly and sustainably.
1. Channel Partners as Ethical AI Advocates
Channel partners are uniquely positioned to influence how AI technologies are adopted across industries. Their in-depth knowledge of both the technology and customer needs enables them to champion ethical AI practices. Channel partners work closely with vendors to prioritize transparency, fairness, and security in AI solutions. By ensuring these values are upheld, they not only enhance trust with customers but also contribute to a more responsible AI ecosystem.
2. Establishing Trust through Transparent Practices
Transparency is a cornerstone of ethical AI governance, and channel partners play a pivotal role in ensuring that AI solutions remain transparent and explainable. By advocating for AI solutions that allow customers to understand how decisions are made, partners build trust with end-users. For example, partners may require vendors to provide clear documentation, model explanations, and data protection guidelines, ensuring customers feel confident in AI's decision-making processes.
3. Reducing Bias: Partners as Guardians of Fairness
AI bias is a growing concern, and channel partners are stepping in as guardians of fairness. They work closely with AI vendors to identify potential biases within algorithms, particularly those that may lead to discrimination. Partners are demanding that AI products undergo rigorous testing for bias reduction, ensuring that the technology serves all users equitably. This commitment to fairness positions channel partners as trusted advisors to customers who value ethical practices.
4. Data Security and Privacy: A Top Priority
In a world of constant data breaches and privacy concerns, channel partners recognize that responsible AI governance includes stringent data security. They play a crucial role in helping businesses choose AI solutions that adhere to top privacy standards and regulations, such as GDPR. Channel partners not only provide AI tools but also guide businesses on implementing these solutions in ways that prioritize user privacy and data integrity.
5. Supporting Compliance with Evolving Regulations
AI regulations are evolving worldwide, and channel partners help businesses stay compliant with these changes. By staying informed about new laws and standards, partners can advise customers on AI solutions that meet regulatory requirements. This guidance is invaluable for businesses navigating the complex landscape of AI compliance, from the European Union's AI Act to sector-specific regulations.
6. Educating Customers on Responsible AI Use
One of the most impactful ways channel partners contribute to responsible AI governance is by educating customers. They provide training, resources, and best practices on the ethical implications of AI. By empowering customers to understand both the benefits and risks of AI, partners ensure that businesses use AI responsibly. This educational role positions channel partners as thought leaders and trusted advisors in the AI space.
7. The Business Benefits of Ethical AI Practices
Channel partners understand that ethical AI practices are not just a moral responsibility but also a business advantage. Responsible AI governance enhances a company's reputation, attracts top clients, and reduces risk. By promoting responsible AI, channel partners help their clients build lasting, trust-based relationships with customers, ultimately benefiting the entire partner ecosystem.
The Future of Responsible AI Governance with Channel Partners
Channel partners are at the forefront of driving ethical AI governance, supporting vendors and customers alike in adopting AI responsibly. Their unique position as intermediaries enables them to bridge the gap between technology providers and end-users, ensuring that AI solutions align with both ethical principles and business goals. As the need for responsible AI governance grows itVARnews will continue to spotlight the vital role that channel partners play in shaping an AI-driven future that prioritizes trust, fairness, and accountability.
This story celebrates the critical role of channel partners in the AI ecosystem, highlighting how their commitment to ethical practices is transforming the business landscape.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ALLIANCES & PARTNERSHIPS (92%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); TECHNOLOGY (89%); BEST PRACTICES (78%); CORPORATE CULTURE (78%); EU DATA PROTECTION REGULATION (77%); SUSTAINABLE DEVELOPMENT (76%); DATA BREACHES (72%); NEGATIVE TECHNOLOGY NEWS (72%); DISCRIMINATION (71%); REGULATORY ACTIONS (65%); INVASION OF PRIVACY (62%); LEGISLATION (60%); EUROPEAN UNION (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); DATA SECURITY (89%); INFORMATION SECURITY & PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); EU DATA PROTECTION REGULATION (77%); SUSTAINABLE DEVELOPMENT (76%); DATA BREACHES (72%)
Geographic: EUROPEAN UNION MEMBER STATES (51%)
Load-Date: November 12, 2024",neutral,0.49558547139167786,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'security']",['fairness'],"['regulation', 'policy', 'governance', 'standards', 'guidelines', 'legislation', 'compliance']",[],7,1,7,0
2024,Unknown Title,"Byline: Adriaan Brits
Body
December 27th, 2024 ( TechBullion  - Delivered by  Newstex )
Artificial intelligence, the once-futuristic concept, has now become an integral part of our reality. Its tendrils reach far and wide, including into the critical realm of criminal justice. As AI's influence grows, so does the need for a guiding light to ensure its ethical application. Pramod Kunju, a luminary in the field, has taken up this mantle, becoming the moral compass that directs the course of AI within the legal system.
The Ethical Foundation
Kunju's approach to AI in criminal justice is built upon a bedrock of ethical principles. He firmly believes that the integration of AI must be grounded in a framework that prioritizes fairness, transparency, and accountability. In a system where lives hang in the balance, there is no room for bias or opacity.
Kunju's stance is unwavering. 'We are at a crucial juncture,' he asserts. 'The decisions we make now about how AI is deployed in criminal justice will have far-reaching consequences. It is our duty to ensure that these systems operate in a manner that upholds, rather than undermines, the principles of justice.'
Transparency: The Key to Trust
One of the central pillars of Kunju's ethical framework is transparency. He argues that AI systems used in  criminal justice must be open to examination and questioning. Algorithms that operate in the shadows, making decisions without explanation, are incompatible with the ideals of due process.
Kunju emphasizes the importance of trust in the justice system. 'For the public to have faith in the use of AI, there must be a commitment to transparency,' he explains. 'The inner workings of these systems must be accessible and understandable. Opacity breeds mistrust.'
This dedication to transparency is evident in Kunju's work, where he focuses on developing AI tools that prioritize interpretability and clear communication of decision-making processes.
Accountability and Oversight
Alongside transparency, Kunju advocates for robust accountability measures. He believes that AI systems must be subject to stringent oversight to ensure they are being used responsibly and ethically.
'Accountability is essential,' Kunju stresses. 'There must be mechanisms in place to audit and challenge the decisions made by AI systems. The ultimate responsibility for fair justice must lie with human decision-makers.'
Kunju has been a strong proponent of independent oversight bodies and clear regulatory frameworks to govern the use of AI in criminal justice. He believes that these measures are crucial to maintaining public trust and ensuring that AI remains a tool for good.
Human Judgment at the Helm
At the core of Kunju's vision is the belief that AI should augment, not replace, human judgment. He sees AI as a tool to support and enhance decision-making, rather than a substitute for human wisdom.
'AI has immense potential in the realm of criminal justice,' Kunju acknowledges. 'But it must always remain in service to human judgment. The goal should be a partnership, where AI's capabilities are leveraged to inform and assist, but never to override human discretion.'
This ethos is reflected in the AI tools Kunju develops, which are designed to provide insights and recommendations while always deferring final decisions to human experts.
A Guiding Light
In the rapidly evolving landscape of AI in criminal justice, Pramod Kunju stands as a guiding light. His unwavering commitment to ethics, his thought leadership, and his practical innovations are shaping the path forward.
Kunju's book, 'AI in Criminal Justice: A Primer on Implications, Ethics, Policy,' serves as a lodestar for navigating the complexities of this brave new world. It provides a clear-eyed analysis of the challenges and a roadmap for ethical implementation.
As we navigate the uncharted waters of AI in criminal justice, Pramod Kunju's vision is a compass that points true north. It is a vision of a future where the power of technology is harnessed in service of the highest ideals of justice, integrity, and the unwavering protection of human rights.
To explore Pramod Kunju's groundbreaking work at the intersection of AI and criminal justice further, visit www.pramodkunju.com.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: CRIME, LAW ENFORCEMENT & CORRECTIONS (92%); ARTIFICIAL INTELLIGENCE (90%); CRIMINAL JUSTICE (90%); ETHICS (90%); DUE PROCESS (78%); LAW & LEGAL SYSTEM (78%); Artificial intelligence (%); AI Ethics (%); criminal justice (%); Ethical Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%)
Load-Date: December 27, 2024","December 27th, 2024 ( TechBullion  - Delivered by  Newstex )
Artificial intelligence, the once-futuristic concept, has now become an integral part of our reality. Its tendrils reach far and wide, including into the critical realm of criminal justice. As AI's influence grows, so does the need for a guiding light to ensure its ethical application. Pramod Kunju, a luminary in the field, has taken up this mantle, becoming the moral compass that directs the course of AI within the legal system.
The Ethical Foundation
Kunju's approach to AI in criminal justice is built upon a bedrock of ethical principles. He firmly believes that the integration of AI must be grounded in a framework that prioritizes fairness, transparency, and accountability. In a system where lives hang in the balance, there is no room for bias or opacity.
Kunju's stance is unwavering. 'We are at a crucial juncture,' he asserts. 'The decisions we make now about how AI is deployed in criminal justice will have far-reaching consequences. It is our duty to ensure that these systems operate in a manner that upholds, rather than undermines, the principles of justice.'
Transparency: The Key to Trust
One of the central pillars of Kunju's ethical framework is transparency. He argues that AI systems used in  criminal justice must be open to examination and questioning. Algorithms that operate in the shadows, making decisions without explanation, are incompatible with the ideals of due process.
Kunju emphasizes the importance of trust in the justice system. 'For the public to have faith in the use of AI, there must be a commitment to transparency,' he explains. 'The inner workings of these systems must be accessible and understandable. Opacity breeds mistrust.'
This dedication to transparency is evident in Kunju's work, where he focuses on developing AI tools that prioritize interpretability and clear communication of decision-making processes.
Accountability and Oversight
Alongside transparency, Kunju advocates for robust accountability measures. He believes that AI systems must be subject to stringent oversight to ensure they are being used responsibly and ethically.
'Accountability is essential,' Kunju stresses. 'There must be mechanisms in place to audit and challenge the decisions made by AI systems. The ultimate responsibility for fair justice must lie with human decision-makers.'
Kunju has been a strong proponent of independent oversight bodies and clear regulatory frameworks to govern the use of AI in criminal justice. He believes that these measures are crucial to maintaining public trust and ensuring that AI remains a tool for good.
Human Judgment at the Helm
At the core of Kunju's vision is the belief that AI should augment, not replace, human judgment. He sees AI as a tool to support and enhance decision-making, rather than a substitute for human wisdom.
'AI has immense potential in the realm of criminal justice,' Kunju acknowledges. 'But it must always remain in service to human judgment. The goal should be a partnership, where AI's capabilities are leveraged to inform and assist, but never to override human discretion.'
This ethos is reflected in the AI tools Kunju develops, which are designed to provide insights and recommendations while always deferring final decisions to human experts.
A Guiding Light
In the rapidly evolving landscape of AI in criminal justice, Pramod Kunju stands as a guiding light. His unwavering commitment to ethics, his thought leadership, and his practical innovations are shaping the path forward.
Kunju's book, 'AI in Criminal Justice: A Primer on Implications, Ethics, Policy,' serves as a lodestar for navigating the complexities of this brave new world. It provides a clear-eyed analysis of the challenges and a roadmap for ethical implementation.
As we navigate the uncharted waters of AI in criminal justice, Pramod Kunju's vision is a compass that points true north. It is a vision of a future where the power of technology is harnessed in service of the highest ideals of justice, integrity, and the unwavering protection of human rights.
To explore Pramod Kunju's groundbreaking work at the intersection of AI and criminal justice further, visit www.pramodkunju.com.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: CRIME, LAW ENFORCEMENT & CORRECTIONS (92%); ARTIFICIAL INTELLIGENCE (90%); CRIMINAL JUSTICE (90%); ETHICS (90%); DUE PROCESS (78%); LAW & LEGAL SYSTEM (78%); Artificial intelligence (%); AI Ethics (%); criminal justice (%); Ethical Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%)
Load-Date: December 27, 2024",neutral,0.6211299896240234,balanced/neutral,"['bias', 'fairness', 'transparency', 'accountability', 'human rights']","['justice', 'fairness', 'justice']","['policy', 'oversight', 'framework', 'law', 'audit', 'should', 'must', 'emphasizes the importance']",[],5,3,8,0
2024,Unknown Title,"Body
2024 DEC 20 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New study results on artificial intelligence have been published. According to news reporting from Suleyman Demirel University by NewsRx journalists, research stated, ""The rapid proliferation of artificial intelligence (AI) in healthcare services has underscored the importance of ethical considerations. This development highlights the need to examine ethical implications, debates, concerns, and thoughts from diverse and broad perspectives."" 
 Our news reporters obtained a quote from the research from Suleyman Demirel University: ""In this context, the study focuses on the ethical dimensions of AI in the healthcare domain. AI is increasingly being used in various healthcare applications, but this usage brings along ethical challenges. The aim of the research is to identify themes, trends, and critical points related to AI ethics in healthcare. Through literature review and bibliometric analyses, it is observed that AI ethics research in healthcare revolves around fundamental concepts such as ethics, AI, machine learning, healthcare services, and privacy. Additionally, the leading countries, authors, and institutions in the field are examined. The intensity of collaboration and knowledge sharing in the literature is steadily increasing."" 
 According to the news editors, the research concluded: ""In conclusion, considering the potential benefits and challenges of AI use in healthcare, addressing ethical issues, ensuring data security, and enhancing transparency in AI decision processes are crucial. The study aims to provide a deeper understanding of AI ethics topics in the existing literature and guide future research."" 
 For more information on this research see: Artificial Intelligence and Ethics in Healthcare: A Bibliometric Analysis. Sdu Vizyoner Dergisi, 2024,15(43):1046-1062. (Sdu Vizyoner Dergisi - https://dergipark.org.tr/vizyoner). The publisher for Sdu Vizyoner Dergisi is Suleyman Demirel Universitesi. 
 A free version of this journal article is available at https://doi.org/10.21076/vizyoner.1455659. 
 Our news journalists report that more information may be obtained by contacting Omer Celik, SULEYMAN DEMIREL UNIVERSITY. 
 Keywords for this news article include: Suleyman Demirel University, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); HEALTH CARE POLICY (90%); JOURNALISM (90%); ROBOTICS (90%); RESEARCH REPORTS (89%); WRITERS (89%); NEWS REPORTING (78%); TRENDS (77%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (74%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); HEALTH CARE (90%); HEALTH CARE POLICY (90%); ROBOTICS (90%); WRITERS (89%); NEWS REPORTING (78%); PUBLISHING (78%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (74%); INFORMATION SECURITY & PRIVACY (72%); DATA SECURITY (65%)
Load-Date: December 20, 2024","2024 DEC 20 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New study results on artificial intelligence have been published. According to news reporting from Suleyman Demirel University by NewsRx journalists, research stated, ""The rapid proliferation of artificial intelligence (AI) in healthcare services has underscored the importance of ethical considerations. This development highlights the need to examine ethical implications, debates, concerns, and thoughts from diverse and broad perspectives."" 
 Our news reporters obtained a quote from the research from Suleyman Demirel University: ""In this context, the study focuses on the ethical dimensions of AI in the healthcare domain. AI is increasingly being used in various healthcare applications, but this usage brings along ethical challenges. The aim of the research is to identify themes, trends, and critical points related to AI ethics in healthcare. Through literature review and bibliometric analyses, it is observed that AI ethics research in healthcare revolves around fundamental concepts such as ethics, AI, machine learning, healthcare services, and privacy. Additionally, the leading countries, authors, and institutions in the field are examined. The intensity of collaboration and knowledge sharing in the literature is steadily increasing."" 
 According to the news editors, the research concluded: ""In conclusion, considering the potential benefits and challenges of AI use in healthcare, addressing ethical issues, ensuring data security, and enhancing transparency in AI decision processes are crucial. The study aims to provide a deeper understanding of AI ethics topics in the existing literature and guide future research."" 
 For more information on this research see: Artificial Intelligence and Ethics in Healthcare: A Bibliometric Analysis. Sdu Vizyoner Dergisi, 2024,15(43):1046-1062. (Sdu Vizyoner Dergisi - https://dergipark.org.tr/vizyoner). The publisher for Sdu Vizyoner Dergisi is Suleyman Demirel Universitesi. 
 A free version of this journal article is available at https://doi.org/10.21076/vizyoner.1455659. 
 Our news journalists report that more information may be obtained by contacting Omer Celik, SULEYMAN DEMIREL UNIVERSITY. 
 Keywords for this news article include: Suleyman Demirel University, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); HEALTH CARE POLICY (90%); JOURNALISM (90%); ROBOTICS (90%); RESEARCH REPORTS (89%); WRITERS (89%); NEWS REPORTING (78%); TRENDS (77%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (74%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); HEALTH CARE (90%); HEALTH CARE POLICY (90%); ROBOTICS (90%); WRITERS (89%); NEWS REPORTING (78%); PUBLISHING (78%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (74%); INFORMATION SECURITY & PRIVACY (72%); DATA SECURITY (65%)
Load-Date: December 20, 2024",neutral,0.8358816504478455,balanced/neutral,"['privacy', 'transparency', 'security']",[],"['policy', 'need to']","['machine learning', 'robotics']",3,0,2,2
2024,Unknown Title,"Byline: States News Service
Dateline: WASHINGTON, DC 
Body
The following information was released by U.S. Department of Commerce National Telecommunications and Information Administration (NTIA):
Researchers around the world regularly use online data about people (or ""pervasive data""), which can come from web-based monitoring tools, education technology, Internet of Things devices, wearables, connected cars, AI systems, and more. This research is important for understanding topics such as social media habits, mental health, and human migration. However, it also poses new ethical challenges, since the research often includes data from many individuals, may not involve traditional notions of consent, and can have large-scale impacts on society. Much of this research is outside current U.S. governmental ethics guidelines. NTIA, in conjunction with other government agencies, is considering the development of non-binding ethical guidelines for researchers working with pervasive data. These guidelines would not supersede any existing laws or regulations.
This listening session aims to gather feedback from the public, researchers, civil society, and industry about this important topic. Each participant will have up to three minutes to share their comments with government representatives. The session will be recorded and posted publicly online. The results of the listening session, along with NTIA's Request for Comments [link] on the same topic, will help NTIA make decisions related to drafting non-binding ethical guidelines for researchers. Listening session participants and other interested parties are also encouraged to consider submitting a comment through the Request for Comments which will close on [Date].
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); TELECOMMUNICATIONS DEPARTMENTS (90%); US FEDERAL GOVERNMENT (90%); COMMERCE DEPARTMENTS (78%); GOVERNMENT ETHICS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SOCIAL MEDIA (73%); ARTIFICIAL INTELLIGENCE (72%)
Company:  AI SYSTEMS (57%)
Organization: NATIONAL TELECOMMUNICATIONS & INFORMATION ADMINISTRATION (84%); US DEPARTMENT OF COMMERCE (84%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); COMMUNICATIONS REGULATION & POLICY (90%); TELECOMMUNICATIONS (90%); TELECOMMUNICATIONS DEPARTMENTS (90%); COMPUTER NETWORKS (78%); INTERNET & WWW (78%); INTERNET OF THINGS (77%); SOCIAL MEDIA (73%); ARTIFICIAL INTELLIGENCE (72%)
Geographic: WASHINGTON DC, USA (79%); UNITED STATES (92%)
Load-Date: November 18, 2024","The following information was released by U.S. Department of Commerce National Telecommunications and Information Administration (NTIA):
Researchers around the world regularly use online data about people (or ""pervasive data""), which can come from web-based monitoring tools, education technology, Internet of Things devices, wearables, connected cars, AI systems, and more. This research is important for understanding topics such as social media habits, mental health, and human migration. However, it also poses new ethical challenges, since the research often includes data from many individuals, may not involve traditional notions of consent, and can have large-scale impacts on society. Much of this research is outside current U.S. governmental ethics guidelines. NTIA, in conjunction with other government agencies, is considering the development of non-binding ethical guidelines for researchers working with pervasive data. These guidelines would not supersede any existing laws or regulations.
This listening session aims to gather feedback from the public, researchers, civil society, and industry about this important topic. Each participant will have up to three minutes to share their comments with government representatives. The session will be recorded and posted publicly online. The results of the listening session, along with NTIA's Request for Comments [link] on the same topic, will help NTIA make decisions related to drafting non-binding ethical guidelines for researchers. Listening session participants and other interested parties are also encouraged to consider submitting a comment through the Request for Comments which will close on [Date].
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); TELECOMMUNICATIONS DEPARTMENTS (90%); US FEDERAL GOVERNMENT (90%); COMMERCE DEPARTMENTS (78%); GOVERNMENT ETHICS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SOCIAL MEDIA (73%); ARTIFICIAL INTELLIGENCE (72%)
Company:  AI SYSTEMS (57%)
Organization: NATIONAL TELECOMMUNICATIONS & INFORMATION ADMINISTRATION (84%); US DEPARTMENT OF COMMERCE (84%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); COMMUNICATIONS REGULATION & POLICY (90%); TELECOMMUNICATIONS (90%); TELECOMMUNICATIONS DEPARTMENTS (90%); COMPUTER NETWORKS (78%); INTERNET & WWW (78%); INTERNET OF THINGS (77%); SOCIAL MEDIA (73%); ARTIFICIAL INTELLIGENCE (72%)
Geographic: WASHINGTON DC, USA (79%); UNITED STATES (92%)
Load-Date: November 18, 2024",neutral,0.9031702280044556,balanced/neutral,['consent'],[],"['regulation', 'policy', 'guidelines']",[],1,0,3,0
2024,Unknown Title,"Body
Artificial intelligence (AI) is transforming education at an unprecedented pace, bringing both opportunities and challenges. From primary schools to universities, students and educators are grappling with its rapid rise. While AI opens doors to innovative teaching and learning methods, it also raises serious ethical concerns.
As we accelerate further into this AI-augmented era, educators have a critical role to play beyond teaching the mechanics of AI. We must equip students to engage with AI thoughtfully, question its impact, and navigate its ethical implications. As AI continues to reshape education, preparing students to use these tools responsibly is more urgent than ever.
I recently organised the Lovelace-Hodgkin Symposium on AI Ethics, in collaboration with Dr Lydia Bach (Equality, Diversity, Inclusion Officer, University of Glasgow) and Professor Ana Basiri (Director, Centre for Data Science and AI, University of Glasgow).
The event was inspired by my experience in higher education, listening to students and colleagues and their concerns around AI and questions of ethics. The symposium covered wide-ranging topics from feminism in AI, race, disability, and environmental considerations. The symposium cast new light on AI ethics in education and has helped shape my thinking about a call to action for educators and decisionmakers across Scotland.
Public debate around AI is often deeply divided. On one side, there-s admiration, hailing AI as a transformative force for good. On the other, there's criticism, warning of its potential dangers. Too often, these discussions consider AI technologies as if they are sentient beings, either -good- or -bad-. They are neither.
They are tools, which mirror the biases, inequalities, and accepted norms of the societies that build them. The way we talk about AI matters. When we give it human qualities, we risk masking the real issue: the ethical challenges we face - like bias and discrimination - are not caused by the technology itself but by the human systems and societies behind it.
Educators will have to grapple with and AI future (Image: PA) A recent report published by the Learned Societies- Group, Royal Society of Edinburgh, led by Professor Martin Hendry (Vice-Principal Academic Services, University of Glasgow) highlights the importance of teaching ethical literacies from a young age.
By introducing these ideas in schools, we can demystify AI and help students understand that these technologies are human-made tools, capable of perpetuating or reinforcing social inequalities. Ethical discussions in education must go beyond superficial concerns like cheating and focus on deeper, more critical questions.
Key to ethical considerations around AI is asking not just whether we can develop a certain technology, but whether we should. This distinction is crucial, yet often overlooked in the race to innovate.
As Professor Ana Basiri proposed at the symposium, -We can go fast in technology development, but we also need to go deep-. This sentiment underscores the importance of pausing to ask meaningful questions about the kind of AI we want. What does AI mean for marginalised communities? Will it challenge or entrench existing power structures?
Ethics in AI education isn-t just an academic concern - it-s a societal one. Dr Mhairi Aitken from The Alan Turing Institute stresses the importance of putting children's ideas,rights and safety at the centre of AI development.
READ MORE:
SNP MSP Emma Roddick in calls for urgent AI regulation Scots Uni finds AI's ability to change who we find attractive Our cartoonist Steven Camley-s take on AI in classrooms
Today-s children are growing up in a world shaped by AI, and they deserve a voice in how these technologies evolve. Grassroots initiatives, like those led by the Children-s Parliament and the Scottish AI Alliance, offer a promising model of how to engage young people in these vital conversations.
MSP Clare Adamson, Chair of the Scottish Parliament-s Cross-Party Committee on STEM and Technology, echoes the need for further collaboration between policy makers, educators and community groups on key questions around digital rights and ethics. Sustained political support could ensure that ethical AI education becomes a national priority, laying the foundation for a society in which AI is built and used responsibly.
The responsibility doesn-t end with schools. Scottish universities, too, have a role to play as AI reshapes higher education. Anxiety is growing, with concerns that AI could replace traditional learning methods or encourage academic misconduct.
AI will change the way we learn (Image: PA) But as Professor Hendry suggests, universities must move beyond simply policing AI use. Instead, we should foster spaces where students can critically engage with these technologies. Rather than seeing AI as something to fear, students should be encouraged to question its role in society.
Universities should create spaces for collaborative learning, where students are encouraged to critique AI technologies. Professor Chris Pearce (Vice-Principal Research, University of Glasgow) has noted that no one institution leads in the AI ethics space, it is complex and rapidly changing, but the more we can work together, the more comprehensive and informed our approaches will be. As Dr Lydia Bach puts it, ""The key is to foster a collaborative dialogue among students, staff, and stakeholders to shape the future of AI in higher education together-.
In the long run, AI could drive education toward a more human-centred focus, one that prioritises ethical decision-making and inclusivity. Professor Leanne Williams (University of Warwick and LearnSci) believes AI has the potential to break down barriers for students with disabilities, specific learning difficuties, and neurodiversity.
But to realise this potential, we need policies that reflect individual learning preferences and diverse voices in these conversations. AI is here to stay, and as it evolves, our teaching must evolve too. The responsibility is clear: educators, students, and policymakers must work together to ensure AI serves society ethically, equitably, and responsibly.
Dr Ciorsdaidh Watts is a Senior Lecturer in Chemistry, University of Glasgow, co-creator of the Lovelace-Hodgkin Symposium on AI Ethics, advocate for ethics in scientific discourse, and mum of two. Follow me on X/Twitter using @Ciorsdaidh and @LHSymposiumAI
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CONFERENCES & CONVENTIONS (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); PRIMARY & SECONDARY EDUCATION (90%); PRIMARY & SECONDARY SCHOOL TEACHERS (90%); PRIMARY SCHOOLS (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); NEGATIVE SOCIETAL NEWS (85%); COLLEGES & UNIVERSITIES (78%); SOCIAL JUSTICE (78%); DATA SCIENCE (74%); DISCRIMINATION (74%); DIVERSITY & INCLUSION (74%); FEMINISM & WOMEN'S RIGHTS (73%); LEARNING THEORIES (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); EDUCATIONAL SERVICES (90%); PRIMARY & SECONDARY EDUCATION (90%); PRIMARY SCHOOLS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGES & UNIVERSITIES (78%); DATA SCIENCE (74%); MEDIA & TELECOMMUNICATIONS (73%)
Geographic: EDINBURGH, SCOTLAND (58%); SCOTLAND (93%)
Load-Date: November 5, 2024","Artificial intelligence (AI) is transforming education at an unprecedented pace, bringing both opportunities and challenges. From primary schools to universities, students and educators are grappling with its rapid rise. While AI opens doors to innovative teaching and learning methods, it also raises serious ethical concerns.
As we accelerate further into this AI-augmented era, educators have a critical role to play beyond teaching the mechanics of AI. We must equip students to engage with AI thoughtfully, question its impact, and navigate its ethical implications. As AI continues to reshape education, preparing students to use these tools responsibly is more urgent than ever.
I recently organised the Lovelace-Hodgkin Symposium on AI Ethics, in collaboration with Dr Lydia Bach (Equality, Diversity, Inclusion Officer, University of Glasgow) and Professor Ana Basiri (Director, Centre for Data Science and AI, University of Glasgow).
The event was inspired by my experience in higher education, listening to students and colleagues and their concerns around AI and questions of ethics. The symposium covered wide-ranging topics from feminism in AI, race, disability, and environmental considerations. The symposium cast new light on AI ethics in education and has helped shape my thinking about a call to action for educators and decisionmakers across Scotland.
Public debate around AI is often deeply divided. On one side, there-s admiration, hailing AI as a transformative force for good. On the other, there's criticism, warning of its potential dangers. Too often, these discussions consider AI technologies as if they are sentient beings, either -good- or -bad-. They are neither.
They are tools, which mirror the biases, inequalities, and accepted norms of the societies that build them. The way we talk about AI matters. When we give it human qualities, we risk masking the real issue: the ethical challenges we face - like bias and discrimination - are not caused by the technology itself but by the human systems and societies behind it.
Educators will have to grapple with and AI future (Image: PA) A recent report published by the Learned Societies- Group, Royal Society of Edinburgh, led by Professor Martin Hendry (Vice-Principal Academic Services, University of Glasgow) highlights the importance of teaching ethical literacies from a young age.
By introducing these ideas in schools, we can demystify AI and help students understand that these technologies are human-made tools, capable of perpetuating or reinforcing social inequalities. Ethical discussions in education must go beyond superficial concerns like cheating and focus on deeper, more critical questions.
Key to ethical considerations around AI is asking not just whether we can develop a certain technology, but whether we should. This distinction is crucial, yet often overlooked in the race to innovate.
As Professor Ana Basiri proposed at the symposium, -We can go fast in technology development, but we also need to go deep-. This sentiment underscores the importance of pausing to ask meaningful questions about the kind of AI we want. What does AI mean for marginalised communities? Will it challenge or entrench existing power structures?
Ethics in AI education isn-t just an academic concern - it-s a societal one. Dr Mhairi Aitken from The Alan Turing Institute stresses the importance of putting children's ideas,rights and safety at the centre of AI development.
READ MORE:
SNP MSP Emma Roddick in calls for urgent AI regulation Scots Uni finds AI's ability to change who we find attractive Our cartoonist Steven Camley-s take on AI in classrooms
Today-s children are growing up in a world shaped by AI, and they deserve a voice in how these technologies evolve. Grassroots initiatives, like those led by the Children-s Parliament and the Scottish AI Alliance, offer a promising model of how to engage young people in these vital conversations.
MSP Clare Adamson, Chair of the Scottish Parliament-s Cross-Party Committee on STEM and Technology, echoes the need for further collaboration between policy makers, educators and community groups on key questions around digital rights and ethics. Sustained political support could ensure that ethical AI education becomes a national priority, laying the foundation for a society in which AI is built and used responsibly.
The responsibility doesn-t end with schools. Scottish universities, too, have a role to play as AI reshapes higher education. Anxiety is growing, with concerns that AI could replace traditional learning methods or encourage academic misconduct.
AI will change the way we learn (Image: PA) But as Professor Hendry suggests, universities must move beyond simply policing AI use. Instead, we should foster spaces where students can critically engage with these technologies. Rather than seeing AI as something to fear, students should be encouraged to question its role in society.
Universities should create spaces for collaborative learning, where students are encouraged to critique AI technologies. Professor Chris Pearce (Vice-Principal Research, University of Glasgow) has noted that no one institution leads in the AI ethics space, it is complex and rapidly changing, but the more we can work together, the more comprehensive and informed our approaches will be. As Dr Lydia Bach puts it, ""The key is to foster a collaborative dialogue among students, staff, and stakeholders to shape the future of AI in higher education together-.
In the long run, AI could drive education toward a more human-centred focus, one that prioritises ethical decision-making and inclusivity. Professor Leanne Williams (University of Warwick and LearnSci) believes AI has the potential to break down barriers for students with disabilities, specific learning difficuties, and neurodiversity.
But to realise this potential, we need policies that reflect individual learning preferences and diverse voices in these conversations. AI is here to stay, and as it evolves, our teaching must evolve too. The responsibility is clear: educators, students, and policymakers must work together to ensure AI serves society ethically, equitably, and responsibly.
Dr Ciorsdaidh Watts is a Senior Lecturer in Chemistry, University of Glasgow, co-creator of the Lovelace-Hodgkin Symposium on AI Ethics, advocate for ethics in scientific discourse, and mum of two. Follow me on X/Twitter using @Ciorsdaidh and @LHSymposiumAI
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CONFERENCES & CONVENTIONS (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); PRIMARY & SECONDARY EDUCATION (90%); PRIMARY & SECONDARY SCHOOL TEACHERS (90%); PRIMARY SCHOOLS (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TECHNOLOGY (89%); NEGATIVE SOCIETAL NEWS (85%); COLLEGES & UNIVERSITIES (78%); SOCIAL JUSTICE (78%); DATA SCIENCE (74%); DISCRIMINATION (74%); DIVERSITY & INCLUSION (74%); FEMINISM & WOMEN'S RIGHTS (73%); LEARNING THEORIES (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); EDUCATIONAL SERVICES (90%); PRIMARY & SECONDARY EDUCATION (90%); PRIMARY SCHOOLS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); COLLEGES & UNIVERSITIES (78%); DATA SCIENCE (74%); MEDIA & TELECOMMUNICATIONS (73%)
Geographic: EDINBURGH, SCOTLAND (58%); SCOTLAND (93%)
Load-Date: November 5, 2024",neutral,0.5479039549827576,balanced/neutral,"['bias', 'discrimination', 'safety', 'inclusivity']","['justice', 'equality', 'justice']","['regulation', 'policy', 'should', 'must', 'need to', 'advocate', 'calls for']",[],4,3,7,0
2024,Unknown Title,"Body
By Stacey Kusterbeck
It is not uncommon for hospitals to share patient data with technology companies, either to spur research and product development or to train artificial intelligence (AI) models designed to improve clinical decision making.1,2Brian Jackson, MD, MS, began to wonder how often hospitals shared patient data with third parties. ""While most of the terms of the agreements seem pretty ethical, the secrecy of it bothered me,"" says Jackson, adjunct professor of pathology and adjunct associate professor of biomedical informatics at the University of Utah. 
Jackson and colleagues interviewed and surveyed 24 informatics leaders about current data sharing practices at their institutions.3 There was considerable heterogeneity across organizations, with data sharing policies and practices varying widely. ""The people we interviewed were responsible for data sharing arrangements. Surprisingly, a number of them didn't know if their organizations had data sharing policies or what they were,"" says Bonnie Kaplan, PhD, FACMI, co-first author of the study. Kaplan is faculty in the Yale Department of Biostatistics (Health Informatics) in the Yale School of Public Health, a Yale Bioethics Center Scholar, and an affiliated fellow at the Yale Information Society Project and at Yale Solomon Center for Health Law & Policy at the Yale Law School.
Surprisingly, most organizations had not developed specific policies for external clinical data sharing - even in the case of sharing with commercial entities. Most organizations relied on Health Insurance Portability and Accountability Act (HIPAA) de-identification standards to preserve patient privacy. The ethical concern with that practice is that data could be re-identified. ""Data from multiple sources gets combined. Some of it may be identified, some may be de-identified. This mix of data makes it easier to re-identify the de-identified data,"" says Kaplan. 
When data are de-identified to HIPAA standards, it is no longer subject to HIPAA at all. That means patients do not have to be notified, and no consent is legally required. ""Even for identifiable data, though, hospitals can use business associate agreements to go around many of HIPAA's requirements. This is how Ascension was able to share hundreds of millions of patient records with Google a few years ago without any public disclosure, and certainly no informed consent,"" notes Jackson.4
Re-identification of de-identified data has become much easier over the years. In part, this is the result of the availability of huge datasets of personal data that companies can use to cross-reference against. Therefore, de-identification by itself does not fully preserve privacy. ""Organizations also need to ensure, through contracts and other means, that re-identification will not be attempted. And they should be highly selective about the kinds of de-identified data that are shared, and with whom,"" says Jackson. 
The study findings suggested that patients mostly are not told that data were being shared or sold, and they do not have much control over what happens with data about them. Consent forms are unclear about how data will be used. ""It's especially problematic if treatment is contingent on a patient's consent,"" says Kaplan. One interviewee stated, ""These forms may appeal to the institution's attorney, but they don't do much to inform patients.""
Healthcare providers can tell patients what the institution's policies and practices are. ""But it would be difficult, if not impossible, to inform patients of what happens to data about them once it's shared and re-packaged and re-shared and shared yet again. Getting consent at each step would be unwieldy, even if it could be done. Exactly what happens to data down the sharing pipeline is unpredictable, especially over time,"" explains Kaplan. 
The reality is that there are very few ways for patients to control what happens to data about them. It is difficult or impossible to opt out from the process altogether. ""Many of the people we spoke with indicated that their hospitals did not have well-developed technical mechanisms to allow patients to opt out of third-party data sharing,"" reports Jackson. From an ethical standpoint, says Kaplan, ""There are gaps between data sharing practices and the Belmont principles of beneficence/non-maleficence, respect for persons/autonomy, and social justice, and also the data sharing principles of transparency and accountability."" 
The people interviewed understood the term ""data sharing"" in different ways. Some interpreted the term as making data available for public health or academic use. Others interpreted it as selling data for corporate research and commercial purposes or contracting with electronic health record (EHR) and device vendors, or selling the data to aggregators who would re-sell the data for future use. ""Different kinds of data sharing have different privacy and ethical risks. Those risks should be handled differently,"" says Kaplan.5
The term ""data sharing"" is used to refer to different categories of activities that have different ethical implications. A hospital can share records with a competing hospital when a patient seeks care there. A hospital also can share records for purposes of academic research or sell records to a pharmaceutical company. ""Because the ethical issues are so different across these use cases, it's problematic to lump them all under the same term,"" says Jackson. 
The authors suggest some ways healthcare institutions can align data sharing practices with ethical principles. ""Ethicists can help others, including their IRBs [Institutional Review Boards], to pay attention to ethics. They can help their institutions' decision-makers be aware of these issues,"" says Kaplan. Ethicists can suggest how the data sharing can be addressed from an ethical standpoint and can help to draft policies and procedures on data sharing. ""Ethicists can bring up these issues when serving as consultants or advisors, in informal conversations with colleagues, and in talks, presentations, and publications,"" recommends Kaplan.
There appear to be a lot of data sharing activities in healthcare settings that are not currently receiving formal ethics review. ""It's ironic that data sharing is much more tightly scrutinized in academic research, specifically by IRBs, than non-research activities,"" observes Jackson. For instance, there is no formal ethics review if organizations sell de-identified data to pharmaceutical companies, or sign contracts with EHR vendors that allow extensive access to local data. ""I hope that, in at least some cases, ethicists might have the ear of senior administrators and be able to insert formal ethics review into these kinds of activities,"" says Jackson. 
One interviewee stated that their IRB routinely reviewed all external data sharing requests. This was the case regardless of whether the requests were tied to formal research protocols. However, as a general rule, IRBs are unlikely to review data requests that do not involve an IRB submission. ""I'd like to see ethicists inserted into the loop for these other cases, to do some sort of IRB-style review and assess whether patients' interests are being adequately protected,"" says Jackson.
Exploitation is a pressing ethical concern. Patients bear the risks of data sharing, while companies and health systems reap the benefits. ""To avoid exploitation, it's essential to ensure that the patient communities whose data are being used share in the benefits of these arrangements,"" says Matthew McCoy, PhD, assistant professor in the Department of Medical Ethics and Health Policy at University of Pennsylvania's Perelman School of Medicine.6
Risks to patient privacy is another central ethical concern. ""It's virtually impossible for patients to give informed consent for these sorts of secondary uses of their data,"" says McCoy. Patients may be unaware that the data sharing is occurring or cannot fully understand all the ways in which their data might be used. Without transparency, patients cannot give informed consent to the sharing of their data. Even with transparency, many patients would not be able to give voluntary consent to data sharing since they do not have options for where they seek their care. ""Thus, in addition to being informed about any plans to share their data, patients should be given the right to opt out of data sharing,"" concludes McCoy.
References
McGraw D, Petersen C. From commercialization to accountability: Responsible health data collection, use, and disclosure for the 21st century. Appl Clin Inform. 2020;11(2):366-373.
Wakabayashi D. Google and the University of Chicago are sued over data sharing. The New York Times. Published June 26, 2019. https://www.nytimes.com/2019/06/26/technology/google-university-chicago-data-sharing-lawsuit.html
Jackson BR, Kaplan B, Schreiber R, et al. Ethical dimensions of clinical data sharing by US healthcare organizations for purposes beyond direct patient care: Interviews with healthcare leaders. Appl Clin Inform. 2024; Oct 3. doi: 10.1055/a-2432-0329. [Online ahead of print]. 
Schneble CO, Elger BS, Shaw DM. Google's Project Nightingale highlights the necessity of data science ethics review. EMBO Mol Med. 2020;12(3):e12053.
Schreiber R, Koppel R, Kaplan B. What do we mean by sharing of patient data? DaSH: A data sharing hierarchy of privacy and ethical challenges. Appl Clin Inform. 2024;15(5):833-841. 
McCoy MS, Joffe S, Emanuel EJ. Sharing patient data without exploiting patients. JAMA. 2020;323(6):505-506. 
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (93%); COLLEGE & UNIVERSITY PROFESSORS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); CLINICAL DECISION SUPPORT (90%); HEALTH CARE INFORMATION (90%); HEALTH CARE INFORMATION TECHNOLOGY (90%); HEALTH CARE LAW (90%); HUMAN SUBJECTS (90%); INFORMATION SCIENCE (90%); MEDICAL ETHICS (90%); AGREEMENTS (89%); HEALTH CARE REGULATION & POLICY (89%); US HEALTH INSURANCE PORTABILITY & ACCOUNTABILITY ACT (89%); BIOETHICS (79%); BIOMEDICINE (79%); COMPUTATIONAL BIOLOGY (79%); MEDICAL RECORDS (79%); PATIENT CONSENT (79%); PATIENT PRIVACY (79%); HEALTH CARE POLICY (78%); PRODUCT DEVELOPMENT (78%); RESEARCH REPORTS (78%); TECHNOLOGY (78%); LAW SCHOOLS (76%); PRIVACY RIGHTS (76%); GRADUATE & PROFESSIONAL SCHOOLS (75%); PUBLIC HEALTH (74%); LAWYERS (72%)
Company:  GOOGLE LLC (58%)
Organization: UNIVERSITY OF UTAH (57%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); COLLEGE & UNIVERSITY PROFESSORS (91%); ARTIFICIAL INTELLIGENCE (90%); CLINICAL DECISION SUPPORT (90%); HEALTH CARE INFORMATION (90%); HEALTH CARE INFORMATION TECHNOLOGY (90%); HEALTH CARE LAW (90%); HOSPITALS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); HEALTH CARE REGULATION & POLICY (89%); US HEALTH INSURANCE PORTABILITY & ACCOUNTABILITY ACT (89%); BIOMEDICINE (79%); COMPUTATIONAL BIOLOGY (79%); HEALTH CARE (79%); MEDICAL RECORDS (79%); PATIENT CONSENT (79%); PATIENT PRIVACY (79%); DATA PRIVACY (78%); HEALTH CARE POLICY (78%); MEDIA & TELECOMMUNICATIONS (78%); LAW SCHOOLS (76%); GRADUATE & PROFESSIONAL SCHOOLS (75%); HEALTH INSURANCE (74%); BIG DATA (73%); LAWYERS (72%); INSURANCE REGULATION & POLICY (64%)
Load-Date: November 22, 2024","By Stacey Kusterbeck
It is not uncommon for hospitals to share patient data with technology companies, either to spur research and product development or to train artificial intelligence (AI) models designed to improve clinical decision making.1,2Brian Jackson, MD, MS, began to wonder how often hospitals shared patient data with third parties. ""While most of the terms of the agreements seem pretty ethical, the secrecy of it bothered me,"" says Jackson, adjunct professor of pathology and adjunct associate professor of biomedical informatics at the University of Utah. 
Jackson and colleagues interviewed and surveyed 24 informatics leaders about current data sharing practices at their institutions.3 There was considerable heterogeneity across organizations, with data sharing policies and practices varying widely. ""The people we interviewed were responsible for data sharing arrangements. Surprisingly, a number of them didn't know if their organizations had data sharing policies or what they were,"" says Bonnie Kaplan, PhD, FACMI, co-first author of the study. Kaplan is faculty in the Yale Department of Biostatistics (Health Informatics) in the Yale School of Public Health, a Yale Bioethics Center Scholar, and an affiliated fellow at the Yale Information Society Project and at Yale Solomon Center for Health Law & Policy at the Yale Law School.
Surprisingly, most organizations had not developed specific policies for external clinical data sharing - even in the case of sharing with commercial entities. Most organizations relied on Health Insurance Portability and Accountability Act (HIPAA) de-identification standards to preserve patient privacy. The ethical concern with that practice is that data could be re-identified. ""Data from multiple sources gets combined. Some of it may be identified, some may be de-identified. This mix of data makes it easier to re-identify the de-identified data,"" says Kaplan. 
When data are de-identified to HIPAA standards, it is no longer subject to HIPAA at all. That means patients do not have to be notified, and no consent is legally required. ""Even for identifiable data, though, hospitals can use business associate agreements to go around many of HIPAA's requirements. This is how Ascension was able to share hundreds of millions of patient records with Google a few years ago without any public disclosure, and certainly no informed consent,"" notes Jackson.4
Re-identification of de-identified data has become much easier over the years. In part, this is the result of the availability of huge datasets of personal data that companies can use to cross-reference against. Therefore, de-identification by itself does not fully preserve privacy. ""Organizations also need to ensure, through contracts and other means, that re-identification will not be attempted. And they should be highly selective about the kinds of de-identified data that are shared, and with whom,"" says Jackson. 
The study findings suggested that patients mostly are not told that data were being shared or sold, and they do not have much control over what happens with data about them. Consent forms are unclear about how data will be used. ""It's especially problematic if treatment is contingent on a patient's consent,"" says Kaplan. One interviewee stated, ""These forms may appeal to the institution's attorney, but they don't do much to inform patients.""
Healthcare providers can tell patients what the institution's policies and practices are. ""But it would be difficult, if not impossible, to inform patients of what happens to data about them once it's shared and re-packaged and re-shared and shared yet again. Getting consent at each step would be unwieldy, even if it could be done. Exactly what happens to data down the sharing pipeline is unpredictable, especially over time,"" explains Kaplan. 
The reality is that there are very few ways for patients to control what happens to data about them. It is difficult or impossible to opt out from the process altogether. ""Many of the people we spoke with indicated that their hospitals did not have well-developed technical mechanisms to allow patients to opt out of third-party data sharing,"" reports Jackson. From an ethical standpoint, says Kaplan, ""There are gaps between data sharing practices and the Belmont principles of beneficence/non-maleficence, respect for persons/autonomy, and social justice, and also the data sharing principles of transparency and accountability."" 
The people interviewed understood the term ""data sharing"" in different ways. Some interpreted the term as making data available for public health or academic use. Others interpreted it as selling data for corporate research and commercial purposes or contracting with electronic health record (EHR) and device vendors, or selling the data to aggregators who would re-sell the data for future use. ""Different kinds of data sharing have different privacy and ethical risks. Those risks should be handled differently,"" says Kaplan.5
The term ""data sharing"" is used to refer to different categories of activities that have different ethical implications. A hospital can share records with a competing hospital when a patient seeks care there. A hospital also can share records for purposes of academic research or sell records to a pharmaceutical company. ""Because the ethical issues are so different across these use cases, it's problematic to lump them all under the same term,"" says Jackson. 
The authors suggest some ways healthcare institutions can align data sharing practices with ethical principles. ""Ethicists can help others, including their IRBs [Institutional Review Boards], to pay attention to ethics. They can help their institutions' decision-makers be aware of these issues,"" says Kaplan. Ethicists can suggest how the data sharing can be addressed from an ethical standpoint and can help to draft policies and procedures on data sharing. ""Ethicists can bring up these issues when serving as consultants or advisors, in informal conversations with colleagues, and in talks, presentations, and publications,"" recommends Kaplan.
There appear to be a lot of data sharing activities in healthcare settings that are not currently receiving formal ethics review. ""It's ironic that data sharing is much more tightly scrutinized in academic research, specifically by IRBs, than non-research activities,"" observes Jackson. For instance, there is no formal ethics review if organizations sell de-identified data to pharmaceutical companies, or sign contracts with EHR vendors that allow extensive access to local data. ""I hope that, in at least some cases, ethicists might have the ear of senior administrators and be able to insert formal ethics review into these kinds of activities,"" says Jackson. 
One interviewee stated that their IRB routinely reviewed all external data sharing requests. This was the case regardless of whether the requests were tied to formal research protocols. However, as a general rule, IRBs are unlikely to review data requests that do not involve an IRB submission. ""I'd like to see ethicists inserted into the loop for these other cases, to do some sort of IRB-style review and assess whether patients' interests are being adequately protected,"" says Jackson.
Exploitation is a pressing ethical concern. Patients bear the risks of data sharing, while companies and health systems reap the benefits. ""To avoid exploitation, it's essential to ensure that the patient communities whose data are being used share in the benefits of these arrangements,"" says Matthew McCoy, PhD, assistant professor in the Department of Medical Ethics and Health Policy at University of Pennsylvania's Perelman School of Medicine.6
Risks to patient privacy is another central ethical concern. ""It's virtually impossible for patients to give informed consent for these sorts of secondary uses of their data,"" says McCoy. Patients may be unaware that the data sharing is occurring or cannot fully understand all the ways in which their data might be used. Without transparency, patients cannot give informed consent to the sharing of their data. Even with transparency, many patients would not be able to give voluntary consent to data sharing since they do not have options for where they seek their care. ""Thus, in addition to being informed about any plans to share their data, patients should be given the right to opt out of data sharing,"" concludes McCoy.
References
McGraw D, Petersen C. From commercialization to accountability: Responsible health data collection, use, and disclosure for the 21st century. Appl Clin Inform. 2020;11(2):366-373.
Wakabayashi D. Google and the University of Chicago are sued over data sharing. The New York Times. Published June 26, 2019. https://www.nytimes.com/2019/06/26/technology/google-university-chicago-data-sharing-lawsuit.html
Jackson BR, Kaplan B, Schreiber R, et al. Ethical dimensions of clinical data sharing by US healthcare organizations for purposes beyond direct patient care: Interviews with healthcare leaders. Appl Clin Inform. 2024; Oct 3. doi: 10.1055/a-2432-0329. [Online ahead of print]. 
Schneble CO, Elger BS, Shaw DM. Google's Project Nightingale highlights the necessity of data science ethics review. EMBO Mol Med. 2020;12(3):e12053.
Schreiber R, Koppel R, Kaplan B. What do we mean by sharing of patient data? DaSH: A data sharing hierarchy of privacy and ethical challenges. Appl Clin Inform. 2024;15(5):833-841. 
McCoy MS, Joffe S, Emanuel EJ. Sharing patient data without exploiting patients. JAMA. 2020;323(6):505-506. 
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (93%); COLLEGE & UNIVERSITY PROFESSORS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); CLINICAL DECISION SUPPORT (90%); HEALTH CARE INFORMATION (90%); HEALTH CARE INFORMATION TECHNOLOGY (90%); HEALTH CARE LAW (90%); HUMAN SUBJECTS (90%); INFORMATION SCIENCE (90%); MEDICAL ETHICS (90%); AGREEMENTS (89%); HEALTH CARE REGULATION & POLICY (89%); US HEALTH INSURANCE PORTABILITY & ACCOUNTABILITY ACT (89%); BIOETHICS (79%); BIOMEDICINE (79%); COMPUTATIONAL BIOLOGY (79%); MEDICAL RECORDS (79%); PATIENT CONSENT (79%); PATIENT PRIVACY (79%); HEALTH CARE POLICY (78%); PRODUCT DEVELOPMENT (78%); RESEARCH REPORTS (78%); TECHNOLOGY (78%); LAW SCHOOLS (76%); PRIVACY RIGHTS (76%); GRADUATE & PROFESSIONAL SCHOOLS (75%); PUBLIC HEALTH (74%); LAWYERS (72%)
Company:  GOOGLE LLC (58%)
Organization: UNIVERSITY OF UTAH (57%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); COLLEGE & UNIVERSITY PROFESSORS (91%); ARTIFICIAL INTELLIGENCE (90%); CLINICAL DECISION SUPPORT (90%); HEALTH CARE INFORMATION (90%); HEALTH CARE INFORMATION TECHNOLOGY (90%); HEALTH CARE LAW (90%); HOSPITALS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); HEALTH CARE REGULATION & POLICY (89%); US HEALTH INSURANCE PORTABILITY & ACCOUNTABILITY ACT (89%); BIOMEDICINE (79%); COMPUTATIONAL BIOLOGY (79%); HEALTH CARE (79%); MEDICAL RECORDS (79%); PATIENT CONSENT (79%); PATIENT PRIVACY (79%); DATA PRIVACY (78%); HEALTH CARE POLICY (78%); MEDIA & TELECOMMUNICATIONS (78%); LAW SCHOOLS (76%); GRADUATE & PROFESSIONAL SCHOOLS (75%); HEALTH INSURANCE (74%); BIG DATA (73%); LAWYERS (72%); INSURANCE REGULATION & POLICY (64%)
Load-Date: November 22, 2024",neutral,0.8953644633293152,balanced/neutral,"['privacy', 'transparency', 'accountability', 'autonomy', 'consent', 'access']","['justice', 'autonomy', 'beneficence', 'non-maleficence', 'justice']","['regulation', 'policy', 'standards', 'law', 'should', 'need to', 'suggest']",[],6,5,7,0
2024,Unknown Title,"Byline: Targeted News Service
Dateline: BAYREUTH, Germany 
Body
The University of Bayreuth issued the following news release:
The Federal Government has appointed Prof. Dr. Aldo Faisal from the University of Bayreuth to the German Ethics Council. The Professor of Digital Health, specializing in data science in the life sciences, teaches and conducts research at the Faculty of Life Sciences: Food, Nutrition, and Health at the University of Bayreuth in Kulmbach.
Prof. Faisal joined the young faculty in 2022 as Professor of Digital Health & Data Science in the Life Sciences at Kulmbach, having previously been with the Faculty of Engineering at Imperial College London. He is also head of research at the Brain and Behavior Lab, which operates in both London and Bayreuth, working at the intersection of machine learning, neuroscience, and biomedical engineering. Additionally, he holds a professorship in AI and Neuroscience at Imperial College London and serves as Director of the Behaviour Analytics Lab at the Data Science Institute in London. There, he is also Professor of AI & Neuroscience and Director of the Centre for AI in Healthcare. In Kulmbach, he founded the Live-in Lab, Europe's leading laboratory for digital, AI-supported research on human behaviour in everyday life.
Prof. Faisal's work integrates cross-disciplinary computational and scientific approaches to explore how humans and machines can learn and control complex, goal-oriented behaviours. He is particularly interested in how human abilities can be enhanced through technologies such as AI. His experiments with pianists learning to play with an AI-controlled third robotic thumb, thus using eleven fingers, have garnered significant attention.
The German Ethics Council
Founded in 2008, the German Ethics Council is an independent body of experts advising the German Bundestag and the Federal Government. It serves as a national forum for dialogue on ethical issues in the life sciences. The Council consists of 26 members representing a broad range of fields, including science, medicine, theology, philosophy, ethics, social sciences, economics, and law. Its members include academics and distinguished individuals with significant expertise in ethical matters concerning the life sciences. Half of the members are appointed by the President of the German Bundestag upon recommendation from the Bundestag, while the other half are appointed by the Federal Government. Members serve a term of four years, with the possibility of one reappointment. (Source: https://www.ethikrat.org/ueber-uns/der-ethikrat/)
* * *
Original text here: https://www.uni-bayreuth.de/en/press-release/faisal-ethics-council
MSTRUCK-8884738 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: COLLEGE & UNIVERSITY PROFESSORS (92%); PRESS RELEASES (92%); ETHICS (91%); APPOINTMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (90%); NEUROSCIENCE (90%); GERMAN PARLIAMENT (89%); GOVERNMENT & PUBLIC ADMINISTRATION (89%); GOVERNMENT BODIES & OFFICES (89%); HUMANITIES & SOCIAL SCIENCE (78%); BEHAVIOR & COGNITION (77%); BIOENGINEERING (77%); BIOMEDICAL ENGINEERING (77%); BIOMEDICINE (77%); DATA ANALYTICS (77%); ENGINEERING (77%); SOCIAL SCIENCES (77%); TECHNOLOGY (77%); ROBOTICS (73%); MACHINE LEARNING (72%); HUMAN SUBJECTS (68%); THEOLOGY (61%); NUTRITION (57%); RELIGION (50%); SINGERS & MUSICIANS (50%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (92%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (90%); BIOMEDICINE (77%); DATA ANALYTICS (77%); ENGINEERING (77%); ROBOTICS (73%); MACHINE LEARNING (72%); SINGERS & MUSICIANS (50%)
Geographic: LONDON, ENGLAND (92%); GERMANY (95%); EUROPE (79%)
Load-Date: October 19, 2024","The University of Bayreuth issued the following news release:
The Federal Government has appointed Prof. Dr. Aldo Faisal from the University of Bayreuth to the German Ethics Council. The Professor of Digital Health, specializing in data science in the life sciences, teaches and conducts research at the Faculty of Life Sciences: Food, Nutrition, and Health at the University of Bayreuth in Kulmbach.
Prof. Faisal joined the young faculty in 2022 as Professor of Digital Health & Data Science in the Life Sciences at Kulmbach, having previously been with the Faculty of Engineering at Imperial College London. He is also head of research at the Brain and Behavior Lab, which operates in both London and Bayreuth, working at the intersection of machine learning, neuroscience, and biomedical engineering. Additionally, he holds a professorship in AI and Neuroscience at Imperial College London and serves as Director of the Behaviour Analytics Lab at the Data Science Institute in London. There, he is also Professor of AI & Neuroscience and Director of the Centre for AI in Healthcare. In Kulmbach, he founded the Live-in Lab, Europe's leading laboratory for digital, AI-supported research on human behaviour in everyday life.
Prof. Faisal's work integrates cross-disciplinary computational and scientific approaches to explore how humans and machines can learn and control complex, goal-oriented behaviours. He is particularly interested in how human abilities can be enhanced through technologies such as AI. His experiments with pianists learning to play with an AI-controlled third robotic thumb, thus using eleven fingers, have garnered significant attention.
The German Ethics Council
Founded in 2008, the German Ethics Council is an independent body of experts advising the German Bundestag and the Federal Government. It serves as a national forum for dialogue on ethical issues in the life sciences. The Council consists of 26 members representing a broad range of fields, including science, medicine, theology, philosophy, ethics, social sciences, economics, and law. Its members include academics and distinguished individuals with significant expertise in ethical matters concerning the life sciences. Half of the members are appointed by the President of the German Bundestag upon recommendation from the Bundestag, while the other half are appointed by the Federal Government. Members serve a term of four years, with the possibility of one reappointment. (Source: https://www.ethikrat.org/ueber-uns/der-ethikrat/)
* * *
Original text here: https://www.uni-bayreuth.de/en/press-release/faisal-ethics-council
MSTRUCK-8884738 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: COLLEGE & UNIVERSITY PROFESSORS (92%); PRESS RELEASES (92%); ETHICS (91%); APPOINTMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (90%); NEUROSCIENCE (90%); GERMAN PARLIAMENT (89%); GOVERNMENT & PUBLIC ADMINISTRATION (89%); GOVERNMENT BODIES & OFFICES (89%); HUMANITIES & SOCIAL SCIENCE (78%); BEHAVIOR & COGNITION (77%); BIOENGINEERING (77%); BIOMEDICAL ENGINEERING (77%); BIOMEDICINE (77%); DATA ANALYTICS (77%); ENGINEERING (77%); SOCIAL SCIENCES (77%); TECHNOLOGY (77%); ROBOTICS (73%); MACHINE LEARNING (72%); HUMAN SUBJECTS (68%); THEOLOGY (61%); NUTRITION (57%); RELIGION (50%); SINGERS & MUSICIANS (50%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (92%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (90%); BIOMEDICINE (77%); DATA ANALYTICS (77%); ENGINEERING (77%); ROBOTICS (73%); MACHINE LEARNING (72%); SINGERS & MUSICIANS (50%)
Geographic: LONDON, ENGLAND (92%); GERMANY (95%); EUROPE (79%)
Load-Date: October 19, 2024",neutral,0.8552911281585693,balanced/neutral,[],[],['law'],"['machine learning', 'robotics']",0,0,1,2
2024,Unknown Title,"Body
The financial space has witnessed a seismic shift with the advent of financial technology (FinTech). This revolutionary field has transformed the way people interact with money, offering innovative solutions to age-old problems. However, for the Islamic world, which adheres to Sharia principles, FinTech must align with the ethical and legal frameworks outlined by Islamic law. This intersection of technology, finance, and religion has given rise to Islamic FinTech, a burgeoning sector that not only adheres to Sharia compliance but also holds the potential to serve a global audience.
Understanding Islamic Finance and Sharia Compliance
Islamic finance operates on principles derived from the Quran and Sunnah. At its core, it emphasizes fairness, transparency, and ethical dealings. Key principles include:
Prohibition of Riba (Interest):
Earning interest is strictly forbidden as it is considered exploitative.
Risk Sharing:
Financial transactions must involve shared risk and reward, ensuring equity among parties.
Prohibition of Haram Activities:
Investments must not support activities forbidden in Islam, such as gambling, alcohol production, or unethical industries.
Asset-Backed Financing:
Transactions must involve tangible assets to prevent speculative behavior.
FinTech solutions aiming to cater to Muslim consumers must embed these principles within their operations, ensuring Sharia compliance while leveraging technological advancement
The Rise of Islamic FinTech
The global Islamic finance industry is valued at over $2 trillion and is projected to grow significantly. With a youthful and tech-savvy Muslim population, the demand for digital financial solutions tailored to Islamic principles is on the rise. Islamic FinTech serves this demand by integrating technology with Sharia-compliant financial practices, providing solutions that are ethical, accessible, and inclusive.
Key Areas of Islamic FinTech
Digital Banking: Islamic digital banks are emerging to offer services like savings, loans, and investments, all structured to comply with Sharia principles. These banks often operate without charging interest, instead using profit-and-loss sharing models.
Crowdfunding Platforms:
Platforms like Ethis and Blossom Finance enable individuals to invest in projects through Sharia-compliant crowdfunding. These platforms facilitate ethical investments in sectors like real estate, education, and healthcare.
Blockchain and Smart Contracts:
Blockchain technology ensures transparency and traceability, aligning with the Islamic finance principle of fairness. Smart contracts eliminate ambiguity in transactions, enhancing trust and compliance.
Halal Investment Apps:
Apps like Wahed Invest and Zoya allow users to invest in Sharia-compliant portfolios. These platforms provide tools to screen stocks and funds for compliance, making ethical investing more accessible.
Insurance (Takaful):
Islamic insurance operates on a cooperative model where participants contribute to a shared pool to cover risks. Digital Takaful platforms streamline this process, making it more efficient and user-friendly.
Challenges in Islamic FinTech
Despite its potential, Islamic FinTech faces several challenges that must be addressed for sustainable growth:
Standardization of Sharia Compliance:
Islamic jurisprudence varies across regions, leading to differing interpretations of what constitutes Sharia compliance. This lack of standardization poses challenges for FinTech companies aiming to scale globally.
Limited Awareness:
Many potential users are unaware of Islamic FinTech solutions or their benefits. Educating consumers about these offerings is crucial to driving adoption.
Regulatory Hurdles:
FinTech operates in a heavily regulated space, and integrating Sharia compliance adds another layer of complexity. Governments and regulatory bodies must create frameworks that support Islamic FinTech.
Integration with Legacy Systems:
Traditional financial institutions may resist integrating with Islamic FinTech solutions, viewing them as competition rather than complementary offerings.
Innovations Driving Growth
The Islamic FinTech sector is not merely adapting existing technologies; it is also pioneering innovations to address unique challenges:
AI and Machine Learning:
These technologies are used to analyze financial data and ensure compliance with Sharia principles. For instance, AI-powered tools can screen investments for compliance more efficiently than manual processes.
Decentralized Finance (DeFi):
DeFi platforms are being adapted to Sharia principles, enabling decentralized and transparent financial services without the need for intermediaries.
Gamification:
To engage younger users, Islamic FinTech platforms are incorporating gamification elements, making financial education and management more interactive and appealing.
The Role of Governments and Regulators
For Islamic FinTech to thrive, governments and regulators must play a proactive role. This includes:
Developing Clear Guidelines:
Creating standardized frameworks for Sharia compliance in FinTech.
Encouraging Collaboration:
Facilitating partnerships between traditional financial institutions and FinTech startups.
Promoting Financial Inclusion:
Supporting initiatives that make Islamic financial services accessible to underserved populations.
The Global Appeal of Islamic FinTech
While Islamic FinTech primarily targets Muslim consumers, its ethical foundation has universal appeal. Islamic FinTechs focus on fairness, transparency, and ethical investing resonates with a broader audience. Non-Muslim consumers seeking ethical financial solutions are also drawn to these offerings, expanding the market potential.
Case Studies
Wahed Invest:
A New York-based Halal investment platform, Wahed Invest offers automated investment services in Sharia-compliant portfolios. The platform has gained global recognition for its user-friendly approach and commitment to ethical investing.
Ethis:
This crowdfunding platform connects investors with ethical projects, particularly in real estate and community development. By focusing on transparency and impact, Ethis has attracted both Muslim and non-Muslim investors.
Al Baraka Banking Group:
A pioneer in Islamic digital banking, Al Baraka has launched various initiatives to integrate FinTech solutions with traditional banking, offering seamless and compliant services to its customers.
The Future of Islamic FinTech
The Islamic FinTech sector is poised for exponential growth. Key trends shaping its future include:
Increased Collaboration:
Partnerships between Islamic financial institutions and tech companies will drive innovation and scalability.
Global Expansion:
With increasing awareness, Islamic FinTech platforms are expanding beyond Muslim-majority countries, targeting regions with significant Muslim populations like Europe, North America, and Africa.
Focus on Sustainability:
Aligning with global sustainability goals, Islamic FinTech solutions are likely to emphasize green investments and ethical practices.
Integration with Emerging Technologies:
Continued adoption of blockchain, AI, and IoT will enhance transparency, efficiency, and compliance in Islamic FinTech.
Conclusion
Islamic FinTech represents a harmonious blend of tradition and modernity, leveraging cutting-edge technology to uphold centuries-old ethical principles. By addressing the unique financial needs of Muslims while appealing to a global audience, it stands as a testament to the versatility and inclusivity of FinTech. As the sector matures, it has the potential to redefine not just Islamic finance but the broader financial ecosystem, paving the way for a more ethical and inclusive global economy.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1663
Subject: RELIGION (97%); FINANCIAL TECHNOLOGY (94%); MUSLIMS & ISLAM (94%); ISLAMIC LAW (91%); ETHICS (90%); TECHNOLOGY (90%); BLOCKCHAIN (89%); ELECTRONIC BANKING (89%); ETHICAL INVESTING (89%); HALAL PRODUCTS & SERVICES (89%); ISLAMIC BANKING (89%); SMART CONTRACTS (89%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CROWDFUNDING (78%); SMART TECHNOLOGY (78%); CORPORATE SUSTAINABILITY (77%); QURAN & ISLAMIC TEXTS (74%); CONSUMERS (71%); CROWDSOURCING (61%)
Industry: FINANCIAL TECHNOLOGY (94%); ALTERNATIVE LENDING (89%); BANKING & FINANCE (89%); BLOCKCHAIN (89%); ELECTRONIC BANKING (89%); ETHICAL INVESTING (89%); HALAL PRODUCTS & SERVICES (89%); ISLAMIC BANKING (89%); SMART CONTRACTS (89%); BANKING & FINANCE REGULATION & POLICY (78%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CROWDFUNDING (78%); SMART TECHNOLOGY (78%); ALCOHOLS (67%); REAL ESTATE INVESTING (67%)
Load-Date: December 23, 2024","The financial space has witnessed a seismic shift with the advent of financial technology (FinTech). This revolutionary field has transformed the way people interact with money, offering innovative solutions to age-old problems. However, for the Islamic world, which adheres to Sharia principles, FinTech must align with the ethical and legal frameworks outlined by Islamic law. This intersection of technology, finance, and religion has given rise to Islamic FinTech, a burgeoning sector that not only adheres to Sharia compliance but also holds the potential to serve a global audience.
Understanding Islamic Finance and Sharia Compliance
Islamic finance operates on principles derived from the Quran and Sunnah. At its core, it emphasizes fairness, transparency, and ethical dealings. Key principles include:
Prohibition of Riba (Interest):
Earning interest is strictly forbidden as it is considered exploitative.
Risk Sharing:
Financial transactions must involve shared risk and reward, ensuring equity among parties.
Prohibition of Haram Activities:
Investments must not support activities forbidden in Islam, such as gambling, alcohol production, or unethical industries.
Asset-Backed Financing:
Transactions must involve tangible assets to prevent speculative behavior.
FinTech solutions aiming to cater to Muslim consumers must embed these principles within their operations, ensuring Sharia compliance while leveraging technological advancement
The Rise of Islamic FinTech
The global Islamic finance industry is valued at over $2 trillion and is projected to grow significantly. With a youthful and tech-savvy Muslim population, the demand for digital financial solutions tailored to Islamic principles is on the rise. Islamic FinTech serves this demand by integrating technology with Sharia-compliant financial practices, providing solutions that are ethical, accessible, and inclusive.
Key Areas of Islamic FinTech
Digital Banking: Islamic digital banks are emerging to offer services like savings, loans, and investments, all structured to comply with Sharia principles. These banks often operate without charging interest, instead using profit-and-loss sharing models.
Crowdfunding Platforms:
Platforms like Ethis and Blossom Finance enable individuals to invest in projects through Sharia-compliant crowdfunding. These platforms facilitate ethical investments in sectors like real estate, education, and healthcare.
Blockchain and Smart Contracts:
Blockchain technology ensures transparency and traceability, aligning with the Islamic finance principle of fairness. Smart contracts eliminate ambiguity in transactions, enhancing trust and compliance.
Halal Investment Apps:
Apps like Wahed Invest and Zoya allow users to invest in Sharia-compliant portfolios. These platforms provide tools to screen stocks and funds for compliance, making ethical investing more accessible.
Insurance (Takaful):
Islamic insurance operates on a cooperative model where participants contribute to a shared pool to cover risks. Digital Takaful platforms streamline this process, making it more efficient and user-friendly.
Challenges in Islamic FinTech
Despite its potential, Islamic FinTech faces several challenges that must be addressed for sustainable growth:
Standardization of Sharia Compliance:
Islamic jurisprudence varies across regions, leading to differing interpretations of what constitutes Sharia compliance. This lack of standardization poses challenges for FinTech companies aiming to scale globally.
Limited Awareness:
Many potential users are unaware of Islamic FinTech solutions or their benefits. Educating consumers about these offerings is crucial to driving adoption.
Regulatory Hurdles:
FinTech operates in a heavily regulated space, and integrating Sharia compliance adds another layer of complexity. Governments and regulatory bodies must create frameworks that support Islamic FinTech.
Integration with Legacy Systems:
Traditional financial institutions may resist integrating with Islamic FinTech solutions, viewing them as competition rather than complementary offerings.
Innovations Driving Growth
The Islamic FinTech sector is not merely adapting existing technologies; it is also pioneering innovations to address unique challenges:
AI and Machine Learning:
These technologies are used to analyze financial data and ensure compliance with Sharia principles. For instance, AI-powered tools can screen investments for compliance more efficiently than manual processes.
Decentralized Finance (DeFi):
DeFi platforms are being adapted to Sharia principles, enabling decentralized and transparent financial services without the need for intermediaries.
Gamification:
To engage younger users, Islamic FinTech platforms are incorporating gamification elements, making financial education and management more interactive and appealing.
The Role of Governments and Regulators
For Islamic FinTech to thrive, governments and regulators must play a proactive role. This includes:
Developing Clear Guidelines:
Creating standardized frameworks for Sharia compliance in FinTech.
Encouraging Collaboration:
Facilitating partnerships between traditional financial institutions and FinTech startups.
Promoting Financial Inclusion:
Supporting initiatives that make Islamic financial services accessible to underserved populations.
The Global Appeal of Islamic FinTech
While Islamic FinTech primarily targets Muslim consumers, its ethical foundation has universal appeal. Islamic FinTechs focus on fairness, transparency, and ethical investing resonates with a broader audience. Non-Muslim consumers seeking ethical financial solutions are also drawn to these offerings, expanding the market potential.
Case Studies
Wahed Invest:
A New York-based Halal investment platform, Wahed Invest offers automated investment services in Sharia-compliant portfolios. The platform has gained global recognition for its user-friendly approach and commitment to ethical investing.
Ethis:
This crowdfunding platform connects investors with ethical projects, particularly in real estate and community development. By focusing on transparency and impact, Ethis has attracted both Muslim and non-Muslim investors.
Al Baraka Banking Group:
A pioneer in Islamic digital banking, Al Baraka has launched various initiatives to integrate FinTech solutions with traditional banking, offering seamless and compliant services to its customers.
The Future of Islamic FinTech
The Islamic FinTech sector is poised for exponential growth. Key trends shaping its future include:
Increased Collaboration:
Partnerships between Islamic financial institutions and tech companies will drive innovation and scalability.
Global Expansion:
With increasing awareness, Islamic FinTech platforms are expanding beyond Muslim-majority countries, targeting regions with significant Muslim populations like Europe, North America, and Africa.
Focus on Sustainability:
Aligning with global sustainability goals, Islamic FinTech solutions are likely to emphasize green investments and ethical practices.
Integration with Emerging Technologies:
Continued adoption of blockchain, AI, and IoT will enhance transparency, efficiency, and compliance in Islamic FinTech.
Conclusion
Islamic FinTech represents a harmonious blend of tradition and modernity, leveraging cutting-edge technology to uphold centuries-old ethical principles. By addressing the unique financial needs of Muslims while appealing to a global audience, it stands as a testament to the versatility and inclusivity of FinTech. As the sector matures, it has the potential to redefine not just Islamic finance but the broader financial ecosystem, paving the way for a more ethical and inclusive global economy.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1663
Subject: RELIGION (97%); FINANCIAL TECHNOLOGY (94%); MUSLIMS & ISLAM (94%); ISLAMIC LAW (91%); ETHICS (90%); TECHNOLOGY (90%); BLOCKCHAIN (89%); ELECTRONIC BANKING (89%); ETHICAL INVESTING (89%); HALAL PRODUCTS & SERVICES (89%); ISLAMIC BANKING (89%); SMART CONTRACTS (89%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CROWDFUNDING (78%); SMART TECHNOLOGY (78%); CORPORATE SUSTAINABILITY (77%); QURAN & ISLAMIC TEXTS (74%); CONSUMERS (71%); CROWDSOURCING (61%)
Industry: FINANCIAL TECHNOLOGY (94%); ALTERNATIVE LENDING (89%); BANKING & FINANCE (89%); BLOCKCHAIN (89%); ELECTRONIC BANKING (89%); ETHICAL INVESTING (89%); HALAL PRODUCTS & SERVICES (89%); ISLAMIC BANKING (89%); SMART CONTRACTS (89%); BANKING & FINANCE REGULATION & POLICY (78%); BANKING & FINANCE SECTOR PERFORMANCE (78%); CROWDFUNDING (78%); SMART TECHNOLOGY (78%); ALCOHOLS (67%); REAL ESTATE INVESTING (67%)
Load-Date: December 23, 2024",positive,0.6614726185798645,balanced/neutral,"['fairness', 'transparency', 'inclusivity']","['fairness', 'equity']","['regulation', 'policy', 'guidelines', 'law', 'compliance', 'must']",['machine learning'],3,2,6,1
2024,Unknown Title,"Body
The Saudi Data and AI Authority (SDAIA) has demonstrated Saudi Arabia' s commitment and leadership in the development of ethical and safe AI technologies with the launch of a cutting-edge self-assessment tool that assesses ethical compliance in AI development. This solution, available through the National Data Governance Platform, helps organizations measure their adherence to established ethical principles regarding AI.
Thus, in line with Saudi Vision 2030 goals, global human rights standards and UNESCO recommendations regarding AI ethics, this tool assists companies with increased improvement of ethical compliance and AI maturity, encouraging investment and driving economic growth.
How does the tool measure organizational engagement?
The tool serves as a crucial resource for government agencies, private companies and independent developers, providing a systematic framework with which to assess and analyze how well their AI products align with ethical guidelines. In this way, organizations will be able to measure their commitment to responsible AI development, adoption and deployment through detailed evaluation metrics.
Based on 81 key questions aligned to global standards, the assessment framework determines AI ethical compliance through seven fundamental principles, which aim to promote its ethical development while maintaining a balance between innovation and responsibility. These principles are: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits.
As a result, the answers to the questions, which use a simple rating scale from 1 to 5, generate detailed reports to highlight the strengths of each organization and identify areas for improvement.
Equity and well-being
The framework emphasizes equity in AI applications to avoid bias and discrimination, while ensuring human-centered development and the protection of human rights while promoting human well-being.
Key aspects of the evaluation include the assessment of privacy and data protection while maintaining the reliability and security of the system. The tool also focuses on the transparency of AI operations, making complex algorithms and decision-making processes more understandable and accountable. Thus, a key component of the tool focuses on accountability, ensuring transparent mechanisms in AI application and decision making. Taken together, all these principles foster responsible innovation that is aligned with human values and societal needs.
For all these reasons, organizations can use the tool multiple times to increase their maturity in AI ethics compliance and monitor their ethical development. This interactive approach provides flexibility with which to continually strengthen ethical commitments and align practices with emerging technology trends.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE ETHICS (92%); BUSINESS ETHICS (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); ASSOCIATIONS & ORGANIZATIONS (89%); HUMAN RIGHTS (89%); INTERNET PRIVACY (89%); ARTIFICIAL INTELLIGENCE GOVERNANCE (78%); DATA PROTECTION LAWS (78%); EMERGING TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY TRENDS (78%); DISCRIMINATION (76%); NEGATIVE SOCIETAL NEWS (76%); STANDARDS & MEASUREMENTS (76%); SAFETY (73%); PRIVACY RIGHTS (71%); ECONOMIC GROWTH (70%); GOVERNMENT BODIES & OFFICES (54%); ENVIRONMENT & NATURAL RESOURCES (51%); Ciencia y Tecnología (%);  Inteligencia Artificial (%);  Arabia Saudita (%);  Tecnología (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); ARTIFICIAL INTELLIGENCE GOVERNANCE (78%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (78%); DATA PROTECTION LAWS (78%); DATA SECURITY (78%)
Geographic: SAUDI ARABIA (92%)
Load-Date: January 27, 2025","The Saudi Data and AI Authority (SDAIA) has demonstrated Saudi Arabia' s commitment and leadership in the development of ethical and safe AI technologies with the launch of a cutting-edge self-assessment tool that assesses ethical compliance in AI development. This solution, available through the National Data Governance Platform, helps organizations measure their adherence to established ethical principles regarding AI.
Thus, in line with Saudi Vision 2030 goals, global human rights standards and UNESCO recommendations regarding AI ethics, this tool assists companies with increased improvement of ethical compliance and AI maturity, encouraging investment and driving economic growth.
How does the tool measure organizational engagement?
The tool serves as a crucial resource for government agencies, private companies and independent developers, providing a systematic framework with which to assess and analyze how well their AI products align with ethical guidelines. In this way, organizations will be able to measure their commitment to responsible AI development, adoption and deployment through detailed evaluation metrics.
Based on 81 key questions aligned to global standards, the assessment framework determines AI ethical compliance through seven fundamental principles, which aim to promote its ethical development while maintaining a balance between innovation and responsibility. These principles are: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits.
As a result, the answers to the questions, which use a simple rating scale from 1 to 5, generate detailed reports to highlight the strengths of each organization and identify areas for improvement.
Equity and well-being
The framework emphasizes equity in AI applications to avoid bias and discrimination, while ensuring human-centered development and the protection of human rights while promoting human well-being.
Key aspects of the evaluation include the assessment of privacy and data protection while maintaining the reliability and security of the system. The tool also focuses on the transparency of AI operations, making complex algorithms and decision-making processes more understandable and accountable. Thus, a key component of the tool focuses on accountability, ensuring transparent mechanisms in AI application and decision making. Taken together, all these principles foster responsible innovation that is aligned with human values and societal needs.
For all these reasons, organizations can use the tool multiple times to increase their maturity in AI ethics compliance and monitor their ethical development. This interactive approach provides flexibility with which to continually strengthen ethical commitments and align practices with emerging technology trends.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE ETHICS (92%); BUSINESS ETHICS (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); ASSOCIATIONS & ORGANIZATIONS (89%); HUMAN RIGHTS (89%); INTERNET PRIVACY (89%); ARTIFICIAL INTELLIGENCE GOVERNANCE (78%); DATA PROTECTION LAWS (78%); EMERGING TECHNOLOGY (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNOLOGY TRENDS (78%); DISCRIMINATION (76%); NEGATIVE SOCIETAL NEWS (76%); STANDARDS & MEASUREMENTS (76%); SAFETY (73%); PRIVACY RIGHTS (71%); ECONOMIC GROWTH (70%); GOVERNMENT BODIES & OFFICES (54%); ENVIRONMENT & NATURAL RESOURCES (51%); Ciencia y Tecnología (%);  Inteligencia Artificial (%);  Arabia Saudita (%);  Tecnología (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); ARTIFICIAL INTELLIGENCE GOVERNANCE (78%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (78%); DATA PROTECTION LAWS (78%); DATA SECURITY (78%)
Geographic: SAUDI ARABIA (92%)
Load-Date: January 27, 2025",positive,0.685903012752533,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'human rights']","['fairness', 'equity']","['governance', 'standards', 'guidelines', 'framework', 'compliance']",[],10,2,5,0
2024,Unknown Title,"Body
FAIRFAX, Va., Dec. 10 -- George Mason University issued the following news release:
While the debates continue over artificial intelligence's possible impacts on privacy, economics, education, and job displacement, perhaps the largest question regards the ethics of AI. Bias, accountability, transparency, and governance of the powerful technology are aspects that have yet to be fully answered.
A new cross-disciplinary course at George Mason University is designed to prepare students to tackle the ethical, societal, and governance challenges presented by AI. The course, AI: Ethics, Policy, and Society, will draw expertise from the Schar School of Policy and Government, the College of Engineering and Computing (CEC), and the College of Humanities and Social Sciences (CHSS).
The master's degree-level course begins in spring 2025 and will be taught by Jesse Kirkpatrick, a research associate professor in the CEC, the Department of Philosophy, and codirector of the Mason Autonomy and Robotics Center.
The course is important now, said Kirkpatrick, because ""artificial intelligence is transforming industries, reshaping societal norms, and challenging long-standing ethical frameworks. This course provides critical insights into the ethical, societal, and policy implications of AI at a time when these technologies are increasingly deployed in areas like healthcare, criminal justice, and national defense.""
Debates about bias in AI systems, the governance of autonomous decision-making, and the risks of misinformation ""underscore the urgency of equipping students and professionals with the tools to address the opportunities and challenges responsibly,"" he added.
This course is designed for students and professionals from diverse fields, including policy, computer science, engineering, law, philosophy, and business.
The course is open to George Mason students and is a core component of the university's new graduate certificate in Responsible AI, making it an essential step for those pursuing advanced study or leadership roles in ethical AI design and governance.
In addition to critical readings and written assignments, the course incorporates hands-on components such as workshops, interactive discussions, and practical tools includes algorithmic audits, ethical toolkits, and risk management frameworks.
""Students will also engage in scenario-building exercises and present collaborative projects that apply ethical AI principles to real-world challenges,"" Kirkpatrick said. ""The course also features distinguished guest speakers from academia, industry, and government, providing students with diverse perspectives on AI.""
As the codirector of the Mason Autonomy and Robotics Center, Kirkpatrick is engaged in ""Responsible AI"" initiatives.
""I bring a unique blend of academic expertise and practical experience,"" he said. ""My work spans creating ethical AI frameworks, consulting on AI policy, and teaching at the intersection of ethics, technology, and public policy.
""This course reflects my commitment to equipping students with the knowledge and tools to address the profound ethical challenges and opportunities posed by AI technologies in society."" For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); HUMANITIES & SOCIAL SCIENCE (90%); SOCIAL SCIENCE EDUCATION (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTS & HUMANITIES EDUCATION (89%); ENGINEERING (89%); INDUSTRIAL AUTOMATION (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); CERTIFICATES, DEGREES & DIPLOMAS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); PHILOSOPHY (78%); PRESS RELEASES (78%); ROBOTICS (78%); HUMANITIES (77%); NEGATIVE NEWS (77%); PUBLIC POLICY (77%); SOCIAL SCIENCES (77%); TEACHING & TEACHERS (76%); COMPUTER ENGINEERING (74%); DISINFORMATION & MISINFORMATION (72%); DISPLACED WORKERS (72%); CRIMINAL JUSTICE (70%); CRIMINAL LAW (70%); NATIONAL SECURITY & FOREIGN RELATIONS (70%); RISK MANAGEMENT (70%); CRIME, LAW ENFORCEMENT & CORRECTIONS (51%)
Company:  AI SYSTEMS (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ENGINEERING (89%); INDUSTRIAL AUTOMATION (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); ROBOTICS (78%); COMPUTER ENGINEERING (74%); RISK MANAGEMENT (70%)
Geographic: VIRGINIA, USA (79%)
Load-Date: December 11, 2024","FAIRFAX, Va., Dec. 10 -- George Mason University issued the following news release:
While the debates continue over artificial intelligence's possible impacts on privacy, economics, education, and job displacement, perhaps the largest question regards the ethics of AI. Bias, accountability, transparency, and governance of the powerful technology are aspects that have yet to be fully answered.
A new cross-disciplinary course at George Mason University is designed to prepare students to tackle the ethical, societal, and governance challenges presented by AI. The course, AI: Ethics, Policy, and Society, will draw expertise from the Schar School of Policy and Government, the College of Engineering and Computing (CEC), and the College of Humanities and Social Sciences (CHSS).
The master's degree-level course begins in spring 2025 and will be taught by Jesse Kirkpatrick, a research associate professor in the CEC, the Department of Philosophy, and codirector of the Mason Autonomy and Robotics Center.
The course is important now, said Kirkpatrick, because ""artificial intelligence is transforming industries, reshaping societal norms, and challenging long-standing ethical frameworks. This course provides critical insights into the ethical, societal, and policy implications of AI at a time when these technologies are increasingly deployed in areas like healthcare, criminal justice, and national defense.""
Debates about bias in AI systems, the governance of autonomous decision-making, and the risks of misinformation ""underscore the urgency of equipping students and professionals with the tools to address the opportunities and challenges responsibly,"" he added.
This course is designed for students and professionals from diverse fields, including policy, computer science, engineering, law, philosophy, and business.
The course is open to George Mason students and is a core component of the university's new graduate certificate in Responsible AI, making it an essential step for those pursuing advanced study or leadership roles in ethical AI design and governance.
In addition to critical readings and written assignments, the course incorporates hands-on components such as workshops, interactive discussions, and practical tools includes algorithmic audits, ethical toolkits, and risk management frameworks.
""Students will also engage in scenario-building exercises and present collaborative projects that apply ethical AI principles to real-world challenges,"" Kirkpatrick said. ""The course also features distinguished guest speakers from academia, industry, and government, providing students with diverse perspectives on AI.""
As the codirector of the Mason Autonomy and Robotics Center, Kirkpatrick is engaged in ""Responsible AI"" initiatives.
""I bring a unique blend of academic expertise and practical experience,"" he said. ""My work spans creating ethical AI frameworks, consulting on AI policy, and teaching at the intersection of ethics, technology, and public policy.
""This course reflects my commitment to equipping students with the knowledge and tools to address the profound ethical challenges and opportunities posed by AI technologies in society."" For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); HUMANITIES & SOCIAL SCIENCE (90%); SOCIAL SCIENCE EDUCATION (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTS & HUMANITIES EDUCATION (89%); ENGINEERING (89%); INDUSTRIAL AUTOMATION (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); CERTIFICATES, DEGREES & DIPLOMAS (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); PHILOSOPHY (78%); PRESS RELEASES (78%); ROBOTICS (78%); HUMANITIES (77%); NEGATIVE NEWS (77%); PUBLIC POLICY (77%); SOCIAL SCIENCES (77%); TEACHING & TEACHERS (76%); COMPUTER ENGINEERING (74%); DISINFORMATION & MISINFORMATION (72%); DISPLACED WORKERS (72%); CRIMINAL JUSTICE (70%); CRIMINAL LAW (70%); NATIONAL SECURITY & FOREIGN RELATIONS (70%); RISK MANAGEMENT (70%); CRIME, LAW ENFORCEMENT & CORRECTIONS (51%)
Company:  AI SYSTEMS (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ENGINEERING (89%); INDUSTRIAL AUTOMATION (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); COMPUTER SCIENCE (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); ROBOTICS (78%); COMPUTER ENGINEERING (74%); RISK MANAGEMENT (70%)
Geographic: VIRGINIA, USA (79%)
Load-Date: December 11, 2024",neutral,0.924837589263916,balanced/neutral,"['privacy', 'bias', 'transparency', 'accountability', 'security', 'autonomy', 'misinformation', 'disinformation']","['justice', 'autonomy', 'justice']","['regulation', 'policy', 'governance', 'law']",['robotics'],8,3,4,1
2024,Unknown Title,"Body
 Introduction
The quickest way to know a company with haphazard financial operations is through the ethical practices of its financial practitioners. The absence of a credible ethical framework guiding the practitioners of any career is a gateway to professional disrespect and mistrust. The world is currently fast-paced; modern businesses are expanding and gaining standard formal outlook; this summons the need to conceive a credible accounting team, ensuring the reflection of values such as integrity and trust. However, this would only be realised when vehement accounting ethics are considered.
Ethics is not entirely a body of laws and rules governing a given practice; in accounting, it's a habitual cycle that must be imbibed to birth legitimate and responsible business practice leading to financial security, accurate reports, and reasonable assurance that enhance confidence to the users of the financial statements, devoid of manipulation and personal interests. The advent of emerging technologies used to ease complex financial problems has grown to threaten the ethical adherence of accountants, reducing their integrity in businesses. This article explores accounting ethics and how they can be carefully adhered to in modern business practices.
Historically, accounting operations were conducted informally, with ethical practices lacking due to the focus on earning salaries. However, with evolution, accounting has developed robust structures to guide businesses and ensure accountants' professional dispositions align with accepted standards, reshaping the profession and guiding accountants' practices.
The accounting profession has evolved through regulatory bodies like GAAP and IFRS, which set ethical standards for transparency, accuracy, consistency, and comprehensiveness in reports. The Sarbanes-Oxley Act of 2002 introduced professional accountability, particularly in the Enron and Worldcom scandals. In Nigeria, organisations like ICAN and ANAN have contributed to ethical frameworks for accounting experts, highlighting the distinction between ethics and law. These frameworks aim to ensure professional accountability and transparency in the accounting profession.
Ethics in accounting has grown to dimensions of complexity; accountants now go about their day using modern technologies and abandoning salient ethical codes. Contributing factors to this rising challenge include the emergence of advanced financial tools and technologies and the unwillingness of large corporations to embark on thorough checks. These concerns demand the need for exploring ethical codes, broadening the awareness of professional responsibility in accounting.
Globalisation has led to a shift in modern businesses, presenting new ethical challenges for accountants. Companies must align operations with local regulations and socio-cultural norms, requiring them to produce accurate financial reports. This can lead to ethical dilemmas, such as accepting gifts from external individuals to influence figures in Nigeria or balancing the need to meet cultural standards with the need to avoid violating professional ethics in multinational companies with branches in different countries.
Globalisation has led to advancements in accounting technologies, such as artificial intelligence (AI) and automated software. These tools have improved efficiency and accuracy but raise ethical concerns. Automated technologies reduce the intellectual potency of accountants, as their intelligence is traded with machine intelligence. This raises questions about responsibility in cases of AI predictions or fault detection, highlighting the need for ethical arrangements with technology.
Financial instruments and off-balance-sheet activities can compromise trust and make it difficult for companies to make informed decisions. Accountants must use creative accounting to manage financial inflow and outflow, improving financial ratios. The Enron financial scandal illustrates how complex financial instruments can be used to conceal true figures, leading to misguided financial reports. However, critical analysis revealed the financial team's conniving offence, causing heavy bankruptcy and job loss for workers. This failed ethical duty resulted in the annihilation of the accounting firm and the loss of jobs.
The case study brings to light why ethical considerations in accounting are important and the dangers that lurk around when they're not upheld. It's therefore a necessity that amidst the technological rave and advancements, accountants must remain upright and devoted to their jobs, maintaining integrity and the profession's standards even when faced with compromising situations.
Accountants are responsible for maintaining a company's finances and upholding strong integrity. They should stay updated on new accounting practices, learn from professional dilemmas, and advocate for ethical conduct within their companies. They should also issue consequences for erring workers to cultivate integrity values, leading to long-term success.
Strategies to promote ethical considerations
Ethics can be initiated in diverse ways, especially as it actively involves an organisation and its workers:
Training programmes:
Accountants should engage themselves in training programs to be trained and exposed on ethical issues. When they get more exposed and in-depth in ethics, they integrate it into their daily practice, enabling them to accomplish complementary services such as conflict resolution, ethical decisiveness, and core values on transparency, responsibility, and accountability.
Corporate governance:
Companies should adopt strong and strict governmental structures, as this ensures that ethical standards are consistently applied. These structures are in the form of external virtual auditors, an independent board of directors, coherent internal managers, and human resource personnel to facilitate ethical behaviours in compliance with the company's guiding policies.
Ethical culture:
To foster a culture of commitment and integrity, companies should highlight ethical behaviours in all aspects of their operations. This can be achieved by rewarding diligent employees, punishing those who violate ethical standards, and ensuring leaders reflect credible ethical practices. This approach creates a high awareness of the dangers of unethical practices.
In the future, ethical challenges will continue to grow as long as businesses are on the rise and technologies are also in rapid growth. It's therefore pertinent that accountants stay informed and abreast of ethical values, developing strong integrity values, fairness, ethical judgement, and continually promoting ethical culture in their individual companies.
Conclusion
Professional ethics are beneficial, fulfilling, and prestigious, but challenges arise due to modern business approaches and excessive use of advanced technologies. While technology ensures reliability and transparency, ethical use requires a balance. Integrating integrity, objectivity, professional competence, confidentiality, accountability, independence, and fairness into accounting practice is crucial to navigating strong ethics in modern businesses.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (98%); BUSINESS ETHICS (90%); BUSINESS OPERATIONS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); PROFESSIONAL WORKERS (90%); GLOBALIZATION (89%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE (82%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (79%); CORPORATE WRONGDOING (79%); ACCOUNTING STANDARDS (78%); BANKING & FINANCE REGULATION (78%); SCANDALS (78%); US SARBANES OXLEY ACT (78%); FINANCIAL PERFORMANCE & REPORTS (74%); FINANCIAL RESULTS (74%); NEGATIVE NEWS (74%); EMERGING TECHNOLOGY (73%); MULTINATIONAL CORPORATIONS (60%)
Company:  VERIZON COMMUNICATIONS INC (58%);  ENRON CREDITORS RECOVERY CORP (54%)
Ticker: VZC (LSE) (58%); VZ (NYSE) (58%)
Industry: NAICS517112 WIRELESS TELECOMMUNICATIONS CARRIERS (EXCEPT SATELLITE) (58%); SIC4911 ELECTRIC SERVICES (54%); ACCOUNTING (90%); ARTIFICIAL INTELLIGENCE (82%); ACCOUNTING STANDARDS (78%); BANKING & FINANCE REGULATION (78%)
Geographic: NIGERIA (90%)
Load-Date: September 21, 2024","Introduction
The quickest way to know a company with haphazard financial operations is through the ethical practices of its financial practitioners. The absence of a credible ethical framework guiding the practitioners of any career is a gateway to professional disrespect and mistrust. The world is currently fast-paced; modern businesses are expanding and gaining standard formal outlook; this summons the need to conceive a credible accounting team, ensuring the reflection of values such as integrity and trust. However, this would only be realised when vehement accounting ethics are considered.
Ethics is not entirely a body of laws and rules governing a given practice; in accounting, it's a habitual cycle that must be imbibed to birth legitimate and responsible business practice leading to financial security, accurate reports, and reasonable assurance that enhance confidence to the users of the financial statements, devoid of manipulation and personal interests. The advent of emerging technologies used to ease complex financial problems has grown to threaten the ethical adherence of accountants, reducing their integrity in businesses. This article explores accounting ethics and how they can be carefully adhered to in modern business practices.
Historically, accounting operations were conducted informally, with ethical practices lacking due to the focus on earning salaries. However, with evolution, accounting has developed robust structures to guide businesses and ensure accountants' professional dispositions align with accepted standards, reshaping the profession and guiding accountants' practices.
The accounting profession has evolved through regulatory bodies like GAAP and IFRS, which set ethical standards for transparency, accuracy, consistency, and comprehensiveness in reports. The Sarbanes-Oxley Act of 2002 introduced professional accountability, particularly in the Enron and Worldcom scandals. In Nigeria, organisations like ICAN and ANAN have contributed to ethical frameworks for accounting experts, highlighting the distinction between ethics and law. These frameworks aim to ensure professional accountability and transparency in the accounting profession.
Ethics in accounting has grown to dimensions of complexity; accountants now go about their day using modern technologies and abandoning salient ethical codes. Contributing factors to this rising challenge include the emergence of advanced financial tools and technologies and the unwillingness of large corporations to embark on thorough checks. These concerns demand the need for exploring ethical codes, broadening the awareness of professional responsibility in accounting.
Globalisation has led to a shift in modern businesses, presenting new ethical challenges for accountants. Companies must align operations with local regulations and socio-cultural norms, requiring them to produce accurate financial reports. This can lead to ethical dilemmas, such as accepting gifts from external individuals to influence figures in Nigeria or balancing the need to meet cultural standards with the need to avoid violating professional ethics in multinational companies with branches in different countries.
Globalisation has led to advancements in accounting technologies, such as artificial intelligence (AI) and automated software. These tools have improved efficiency and accuracy but raise ethical concerns. Automated technologies reduce the intellectual potency of accountants, as their intelligence is traded with machine intelligence. This raises questions about responsibility in cases of AI predictions or fault detection, highlighting the need for ethical arrangements with technology.
Financial instruments and off-balance-sheet activities can compromise trust and make it difficult for companies to make informed decisions. Accountants must use creative accounting to manage financial inflow and outflow, improving financial ratios. The Enron financial scandal illustrates how complex financial instruments can be used to conceal true figures, leading to misguided financial reports. However, critical analysis revealed the financial team's conniving offence, causing heavy bankruptcy and job loss for workers. This failed ethical duty resulted in the annihilation of the accounting firm and the loss of jobs.
The case study brings to light why ethical considerations in accounting are important and the dangers that lurk around when they're not upheld. It's therefore a necessity that amidst the technological rave and advancements, accountants must remain upright and devoted to their jobs, maintaining integrity and the profession's standards even when faced with compromising situations.
Accountants are responsible for maintaining a company's finances and upholding strong integrity. They should stay updated on new accounting practices, learn from professional dilemmas, and advocate for ethical conduct within their companies. They should also issue consequences for erring workers to cultivate integrity values, leading to long-term success.
Strategies to promote ethical considerations
Ethics can be initiated in diverse ways, especially as it actively involves an organisation and its workers:
Training programmes:
Accountants should engage themselves in training programs to be trained and exposed on ethical issues. When they get more exposed and in-depth in ethics, they integrate it into their daily practice, enabling them to accomplish complementary services such as conflict resolution, ethical decisiveness, and core values on transparency, responsibility, and accountability.
Corporate governance:
Companies should adopt strong and strict governmental structures, as this ensures that ethical standards are consistently applied. These structures are in the form of external virtual auditors, an independent board of directors, coherent internal managers, and human resource personnel to facilitate ethical behaviours in compliance with the company's guiding policies.
Ethical culture:
To foster a culture of commitment and integrity, companies should highlight ethical behaviours in all aspects of their operations. This can be achieved by rewarding diligent employees, punishing those who violate ethical standards, and ensuring leaders reflect credible ethical practices. This approach creates a high awareness of the dangers of unethical practices.
In the future, ethical challenges will continue to grow as long as businesses are on the rise and technologies are also in rapid growth. It's therefore pertinent that accountants stay informed and abreast of ethical values, developing strong integrity values, fairness, ethical judgement, and continually promoting ethical culture in their individual companies.
Conclusion
Professional ethics are beneficial, fulfilling, and prestigious, but challenges arise due to modern business approaches and excessive use of advanced technologies. While technology ensures reliability and transparency, ethical use requires a balance. Integrating integrity, objectivity, professional competence, confidentiality, accountability, independence, and fairness into accounting practice is crucial to navigating strong ethics in modern businesses.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (98%); BUSINESS ETHICS (90%); BUSINESS OPERATIONS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); PROFESSIONAL WORKERS (90%); GLOBALIZATION (89%); TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE (82%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (79%); CORPORATE WRONGDOING (79%); ACCOUNTING STANDARDS (78%); BANKING & FINANCE REGULATION (78%); SCANDALS (78%); US SARBANES OXLEY ACT (78%); FINANCIAL PERFORMANCE & REPORTS (74%); FINANCIAL RESULTS (74%); NEGATIVE NEWS (74%); EMERGING TECHNOLOGY (73%); MULTINATIONAL CORPORATIONS (60%)
Company:  VERIZON COMMUNICATIONS INC (58%);  ENRON CREDITORS RECOVERY CORP (54%)
Ticker: VZC (LSE) (58%); VZ (NYSE) (58%)
Industry: NAICS517112 WIRELESS TELECOMMUNICATIONS CARRIERS (EXCEPT SATELLITE) (58%); SIC4911 ELECTRIC SERVICES (54%); ACCOUNTING (90%); ARTIFICIAL INTELLIGENCE (82%); ACCOUNTING STANDARDS (78%); BANKING & FINANCE REGULATION (78%)
Geographic: NIGERIA (90%)
Load-Date: September 21, 2024",neutral,0.5737953186035156,balanced/neutral,"['fairness', 'transparency', 'accountability', 'job loss', 'security', 'manipulation']",['fairness'],"['regulation', 'governance', 'standards', 'framework', 'law', 'compliance', 'should', 'must', 'need to', 'advocate']",[],6,1,10,0
2024,Unknown Title,"Byline: James Andrew
Body
November 4th, 2024 ( TechBullion  - Delivered by  Newstex )
In today's era, ITIL 4 through integration with generative AI can bring new opportunities and capabilities for the improvement of IT service management. With new opportunities, it brings an ethical challenge and compliance by compelling organizations to walk with a responsible usage of AI at one end while staying authentic with the standards of ITIL at the other.
Let's have a closer look at how ethics, compliance, and ITIL 4 are converging and give a basic understanding of proper and ethical integration of generative AI:
Understanding Generative AI and its Relevance to ITIL 4
ITIL 4 is an Information Technology Infrastructure Library that follows a service-based approach towards IT management and focuses on efficiency, reliability, and customer satisfaction.
Generative AI works with ITIL 4 as it automates and streamlines tasks from requests for service to incident management. However, the generative AI power needs to be managed with care since it can change the very nature of decision-making and can introduce biases that may bring unforeseen results when applied loosely.
Ethical Considerations for Integrating Generative AI
When implementing  generative AI in an ITIL framework, ethical concerns must be addressed based on fairness, transparency, and accountability.
Bias Mitigation: Generative AI could unintentionally reproduce biases contained in the training data. In customer service applications, biased responses may lead to unfair treatment or miscommunication with different users. Organizations must work with unbiased data and check AI outputs for alignment with fair treatment standards.
Transparency and Explainability: The users as well as the stakeholders need to understand how AI-based decisions are being made, especially if they are customer-facing. This will help users make sense of the logic behind AI outputs. With the infusion of transparency in AI systems, organizations can assure their users that their AI-based decisions are being used ethically.
Data Privacy: Data-intensive generative AI operations can reveal sensitive information regarding its customers. In order to prevent unwanted legal and ethical implications, keeping compliance with the data protection regulations such as GDPR is needed. The basic steps of achieving data privacy are proper anonymization of the data and restricted access.
Compliance Considerations for Integration of ITIL 4 and AI
Global Regulation As the worldwide regulation for AI technologies advances, ITIL 4 and the regulatory standards, thus, become important to be compliant. Important areas of Compliance are as follows:
Data Security and Privacy: AI Models need to be installed securely by keeping sensitive information away from breaching. Role-based access and encryption might be necessary for data, both at rest and traveling, thereby ensuring that its security would match all the needs of ITIL 4.
Accountability and oversight ITIL 4, accountability is fostered, but this is also extended to the implementation of AI. For example, the defined roles and responsibilities will call for monitoring and managing outcomes from generative AI with correction when deemed inappropriate. This way, misuse would be prevented and the systems integrity built.
Compliance with Regulatory Norms: Responsible AI practice follows regulations, such as the EU's AI Act and international standards. Thus, adherence to these standards reduces the risk associated with ethics breaches and stays compliant in an AI-based operation.
ITIL 4 Governance Models of Ethical AI
A good governance model can enable the integration of AI in a responsible manner with ITIL 4 processes. A few of the main strategies involved are:
Ethical AI Committees: Committees or task forces responsible for the ethical use of AI maintain integrity by forming committees. Such committees can develop acceptable AI usage guidelines, oversee the accuracy of models, and ensure the alignment of AI systems with organizational values.
Regular Audits and Compliance Check: Regular audits ensure that AI models work as expected and are in compliance with regulatory and ethical standards. Audits must assess the model's factors, such as bias, transparency, and data security protocols, in order to maintain an ethical foundation.
AI Risk Management: An AI risk framework recognizes and mitigates the risk of AI-enabled processes. This could encompass a series of activities like the quantification of impact of the risks, monitoring decisions from AI-powered tools, and inclusion of fail-safes so that any undesired impact due to AI-powered applications is prevented or managed well within its capability, thereby completing all objectives of ITIL relating to reliability and control.
Ethics and Compliance of Future AI-enabled ITIL
The future of AI in ITIL 4 would, no doubt, require better ethical standards and updates to regulations to fit the advanced capabilities of AI. Organizations adopting generative AI need to continually revisit their ethical concerns, reassess measures of compliance, and refine governance frameworks in maintaining that balance between innovation and responsible application of AI. Therefore, by ensuring active governance and responsible use of AI, organizations can capitalize on generative AI and yet conform to the ITIL 4 principles.
Moving Forward To
The inculcation of generative AI in ITIL 4 should be approached with proper ethics and compliance. Although the ability to harness AI power in the management of IT services does not undermine ethical standards, it only does so with the application of governance structures and compliance standards while having ethics guidelines. Technology and ethical integrity balance is crucial for sustainable success and innovation in the fast-paced digital world today.
These guidelines for organizations committed to both the ethical usage of AI and the norms set by  ITIL 4 provide an underpinning for ethical, compliant use of AI in IT management .
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (94%); GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (89%); CUSTOMER SERVICE (88%); INTERNET PRIVACY (85%); PRIVACY RIGHTS (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DATA PROTECTION LAWS (78%); BUSINESS ETHICS (77%); CUSTOMER RELATIONS (68%); CUSTOMER SATISFACTION (68%); EU DATA PROTECTION REGULATION (65%); Tech News (%); Compliance in ITIL 4 (%); Generative AI Integration (%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); GENERATIVE AI (93%); INFORMATION TECHNOLOGY INFRASTRUCTURE LIBRARY (91%); COMPUTING & INFORMATION TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); DATA SECURITY (88%); INTERNET PRIVACY (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DATA PROTECTION LAWS (78%); INFORMATION MANAGEMENT (77%); CUSTOMER SATISFACTION (68%); EU DATA PROTECTION REGULATION (65%)
Load-Date: November 4, 2024","November 4th, 2024 ( TechBullion  - Delivered by  Newstex )
In today's era, ITIL 4 through integration with generative AI can bring new opportunities and capabilities for the improvement of IT service management. With new opportunities, it brings an ethical challenge and compliance by compelling organizations to walk with a responsible usage of AI at one end while staying authentic with the standards of ITIL at the other.
Let's have a closer look at how ethics, compliance, and ITIL 4 are converging and give a basic understanding of proper and ethical integration of generative AI:
Understanding Generative AI and its Relevance to ITIL 4
ITIL 4 is an Information Technology Infrastructure Library that follows a service-based approach towards IT management and focuses on efficiency, reliability, and customer satisfaction.
Generative AI works with ITIL 4 as it automates and streamlines tasks from requests for service to incident management. However, the generative AI power needs to be managed with care since it can change the very nature of decision-making and can introduce biases that may bring unforeseen results when applied loosely.
Ethical Considerations for Integrating Generative AI
When implementing  generative AI in an ITIL framework, ethical concerns must be addressed based on fairness, transparency, and accountability.
Bias Mitigation: Generative AI could unintentionally reproduce biases contained in the training data. In customer service applications, biased responses may lead to unfair treatment or miscommunication with different users. Organizations must work with unbiased data and check AI outputs for alignment with fair treatment standards.
Transparency and Explainability: The users as well as the stakeholders need to understand how AI-based decisions are being made, especially if they are customer-facing. This will help users make sense of the logic behind AI outputs. With the infusion of transparency in AI systems, organizations can assure their users that their AI-based decisions are being used ethically.
Data Privacy: Data-intensive generative AI operations can reveal sensitive information regarding its customers. In order to prevent unwanted legal and ethical implications, keeping compliance with the data protection regulations such as GDPR is needed. The basic steps of achieving data privacy are proper anonymization of the data and restricted access.
Compliance Considerations for Integration of ITIL 4 and AI
Global Regulation As the worldwide regulation for AI technologies advances, ITIL 4 and the regulatory standards, thus, become important to be compliant. Important areas of Compliance are as follows:
Data Security and Privacy: AI Models need to be installed securely by keeping sensitive information away from breaching. Role-based access and encryption might be necessary for data, both at rest and traveling, thereby ensuring that its security would match all the needs of ITIL 4.
Accountability and oversight ITIL 4, accountability is fostered, but this is also extended to the implementation of AI. For example, the defined roles and responsibilities will call for monitoring and managing outcomes from generative AI with correction when deemed inappropriate. This way, misuse would be prevented and the systems integrity built.
Compliance with Regulatory Norms: Responsible AI practice follows regulations, such as the EU's AI Act and international standards. Thus, adherence to these standards reduces the risk associated with ethics breaches and stays compliant in an AI-based operation.
ITIL 4 Governance Models of Ethical AI
A good governance model can enable the integration of AI in a responsible manner with ITIL 4 processes. A few of the main strategies involved are:
Ethical AI Committees: Committees or task forces responsible for the ethical use of AI maintain integrity by forming committees. Such committees can develop acceptable AI usage guidelines, oversee the accuracy of models, and ensure the alignment of AI systems with organizational values.
Regular Audits and Compliance Check: Regular audits ensure that AI models work as expected and are in compliance with regulatory and ethical standards. Audits must assess the model's factors, such as bias, transparency, and data security protocols, in order to maintain an ethical foundation.
AI Risk Management: An AI risk framework recognizes and mitigates the risk of AI-enabled processes. This could encompass a series of activities like the quantification of impact of the risks, monitoring decisions from AI-powered tools, and inclusion of fail-safes so that any undesired impact due to AI-powered applications is prevented or managed well within its capability, thereby completing all objectives of ITIL relating to reliability and control.
Ethics and Compliance of Future AI-enabled ITIL
The future of AI in ITIL 4 would, no doubt, require better ethical standards and updates to regulations to fit the advanced capabilities of AI. Organizations adopting generative AI need to continually revisit their ethical concerns, reassess measures of compliance, and refine governance frameworks in maintaining that balance between innovation and responsible application of AI. Therefore, by ensuring active governance and responsible use of AI, organizations can capitalize on generative AI and yet conform to the ITIL 4 principles.
Moving Forward To
The inculcation of generative AI in ITIL 4 should be approached with proper ethics and compliance. Although the ability to harness AI power in the management of IT services does not undermine ethical standards, it only does so with the application of governance structures and compliance standards while having ethics guidelines. Technology and ethical integrity balance is crucial for sustainable success and innovation in the fast-paced digital world today.
These guidelines for organizations committed to both the ethical usage of AI and the norms set by  ITIL 4 provide an underpinning for ethical, compliant use of AI in IT management .
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (94%); GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (89%); CUSTOMER SERVICE (88%); INTERNET PRIVACY (85%); PRIVACY RIGHTS (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DATA PROTECTION LAWS (78%); BUSINESS ETHICS (77%); CUSTOMER RELATIONS (68%); CUSTOMER SATISFACTION (68%); EU DATA PROTECTION REGULATION (65%); Tech News (%); Compliance in ITIL 4 (%); Generative AI Integration (%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); GENERATIVE AI (93%); INFORMATION TECHNOLOGY INFRASTRUCTURE LIBRARY (91%); COMPUTING & INFORMATION TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); DATA SECURITY (88%); INTERNET PRIVACY (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DATA PROTECTION LAWS (78%); INFORMATION MANAGEMENT (77%); CUSTOMER SATISFACTION (68%); EU DATA PROTECTION REGULATION (65%)
Load-Date: November 4, 2024",positive,0.5269933938980103,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'access']",['fairness'],"['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'framework', 'compliance', 'should', 'must', 'need to']",['generative ai'],8,1,11,1
2024,Unknown Title,"Body
2024 OCT 28 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting from Chongqing, People's Republic of China, by NewsRx journalists, research stated, ""This study constructs a moderating mediation model to link public sector employees' Artificial Intelligence (AI) usage with employees' moral norms and ethical decision-making behaviors."" 
 Our news journalists obtained a quote from the research from Southwest University: ""Based on the theory of public service motivation, this study hypothesizes that the impact of AI usage on employees' ethical decision-making behaviors acts through the mediating effects of employees' service motivation, employees' moral norms, and employees' ethical perceptions and that the relationship between AI usage and employees' service motivation, employees' ethical norms, and employees' ethical perceptions is moderated by the culture of the public organization. The selected data from 417 public sector employees in China supported most of the research hypotheses. The findings show that employee service motivation, employee moral norms, and employee moral cognition mediate the relationship between AI usage and employee ethical decision-making behavior. Public organization culture moderated the relationship between AI usage and employee service motivation, as well as AI usage and employee ethics. This study reveals the complex mediating and moderating relationships between AI usage and employees' ethical decision-making behaviors in the public sector."" 
 According to the news reporters, the research concluded: ""It provides important theoretical and practical insights for further understanding and promoting public sector employees' ethical behaviors in the era of AI."" 
 For more information on this research see: Exploring the Influence of Artificial Intelligence Usage on Ethical Decision Making Among Public Sector Employees: Insights into Moral Identity and Service Motivation. Business Ethics and Leadership, 2024,8(3):133-150. The publisher for Business Ethics and Leadership is Academic Research and Publishing UG (AR&P). 
 A free version of this journal article is available at https://doi.org/10.61093/bel.8(3).133-150.2024. 
 Our news editors report that additional information may be obtained by contacting Xiangyu Bian, Ph.D., College of State Governance, Southwest University, Chongqing, People's Republic of China. Additional authors for this research include Bin Wang. 
 Keywords for this news article include: Southwest University, Chongqing, People's Republic of China, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); WORKER CATEGORIES (90%); COLLEGES & UNIVERSITIES (89%); PERSONNEL CHANGES (89%); RESEARCH REPORTS (89%); WRITERS (89%); BUSINESS ETHICS (76%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (76%); CORPORATE CULTURE (75%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); EMPLOYEE PROMOTIONS (73%); NEWS REPORTING (73%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); PUBLISHING (78%); NEWS REPORTING (73%)
Geographic: CHONGQING, CHINA (90%); SOUTHWEST CHINA (90%); CHINA (94%); TAIWAN (93%); ASIA (79%)
Load-Date: October 28, 2024","2024 OCT 28 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting from Chongqing, People's Republic of China, by NewsRx journalists, research stated, ""This study constructs a moderating mediation model to link public sector employees' Artificial Intelligence (AI) usage with employees' moral norms and ethical decision-making behaviors."" 
 Our news journalists obtained a quote from the research from Southwest University: ""Based on the theory of public service motivation, this study hypothesizes that the impact of AI usage on employees' ethical decision-making behaviors acts through the mediating effects of employees' service motivation, employees' moral norms, and employees' ethical perceptions and that the relationship between AI usage and employees' service motivation, employees' ethical norms, and employees' ethical perceptions is moderated by the culture of the public organization. The selected data from 417 public sector employees in China supported most of the research hypotheses. The findings show that employee service motivation, employee moral norms, and employee moral cognition mediate the relationship between AI usage and employee ethical decision-making behavior. Public organization culture moderated the relationship between AI usage and employee service motivation, as well as AI usage and employee ethics. This study reveals the complex mediating and moderating relationships between AI usage and employees' ethical decision-making behaviors in the public sector."" 
 According to the news reporters, the research concluded: ""It provides important theoretical and practical insights for further understanding and promoting public sector employees' ethical behaviors in the era of AI."" 
 For more information on this research see: Exploring the Influence of Artificial Intelligence Usage on Ethical Decision Making Among Public Sector Employees: Insights into Moral Identity and Service Motivation. Business Ethics and Leadership, 2024,8(3):133-150. The publisher for Business Ethics and Leadership is Academic Research and Publishing UG (AR&P). 
 A free version of this journal article is available at https://doi.org/10.61093/bel.8(3).133-150.2024. 
 Our news editors report that additional information may be obtained by contacting Xiangyu Bian, Ph.D., College of State Governance, Southwest University, Chongqing, People's Republic of China. Additional authors for this research include Bin Wang. 
 Keywords for this news article include: Southwest University, Chongqing, People's Republic of China, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); WORKER CATEGORIES (90%); COLLEGES & UNIVERSITIES (89%); PERSONNEL CHANGES (89%); RESEARCH REPORTS (89%); WRITERS (89%); BUSINESS ETHICS (76%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (76%); CORPORATE CULTURE (75%); EMERGING TECHNOLOGY (74%); TECHNOLOGY (74%); EMPLOYEE PROMOTIONS (73%); NEWS REPORTING (73%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); PUBLISHING (78%); NEWS REPORTING (73%)
Geographic: CHONGQING, CHINA (90%); SOUTHWEST CHINA (90%); CHINA (94%); TAIWAN (93%); ASIA (79%)
Load-Date: October 28, 2024",neutral,0.935523271560669,balanced/neutral,[],[],['governance'],"['machine learning', 'robotics']",0,0,1,2
2024,Unknown Title,"Body
 ARTIFICIAL INTELLIGENCE (AI) is rapidly permeating various aspects of our lives.
Defined as the simulation of human intelligence processes by machines, especially computer systems, AI has found applications in numerous areas, including healthcare, the academic field, manufacturing and transportation.
AI systems, while powerful, are tools programmed by humans.
They lack consciousness and the ability to make independent decisions. However, they can learn from data and adapt their responses, leading to significant advancements.
One of the most prominent applications of AI is in the healthcare industry. AI-powered systems are being used to improve medical diagnoses, drug discovery and personalised treatment plans.
In transportation, self-driving cars powered by AI promise to revolutionise the way we commute, reducing accidents and traffic congestion.
We also encounter AI in our daily lives, often without realising it. From the auto-correct feature on our smartphones to personalised recommendations on streaming platforms, AI is constantly working behind the scenes.
While AI holds immense potential for positive impact, it also raises significant ethical and societal concerns.
As AI systems become increasingly sophisticated, there are fears about job displacement, infringement of data privacy and the potential for misuse.
At the same time, as AI continues to evolve, it is crucial to strike a balance between innovation and responsibility.
It is imperative to address ethical concerns and ensure transparent development so that we can harness the power of AI for the betterment of humanity.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SMART TECHNOLOGY (79%); SOCIETAL ISSUES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); COMMUTING (77%); PRECISION MEDICINE (77%); DRUG DESIGN & DISCOVERY (70%); DISPLACED WORKERS (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HEALTH CARE (90%); SMART TECHNOLOGY (79%); MANUFACTURING (78%); VEHICLE TRAFFIC (77%); PHARMACEUTICALS PRODUCT DEVELOPMENT (73%); PHARMACEUTICALS INDUSTRY (72%); INFORMATION SECURITY & PRIVACY (71%); DRUG DESIGN & DISCOVERY (70%); AUTONOMOUS MOTOR VEHICLES (69%); MOBILE & CELLULAR TELEPHONES (53%)
Load-Date: November 18, 2024","ARTIFICIAL INTELLIGENCE (AI) is rapidly permeating various aspects of our lives.
Defined as the simulation of human intelligence processes by machines, especially computer systems, AI has found applications in numerous areas, including healthcare, the academic field, manufacturing and transportation.
AI systems, while powerful, are tools programmed by humans.
They lack consciousness and the ability to make independent decisions. However, they can learn from data and adapt their responses, leading to significant advancements.
One of the most prominent applications of AI is in the healthcare industry. AI-powered systems are being used to improve medical diagnoses, drug discovery and personalised treatment plans.
In transportation, self-driving cars powered by AI promise to revolutionise the way we commute, reducing accidents and traffic congestion.
We also encounter AI in our daily lives, often without realising it. From the auto-correct feature on our smartphones to personalised recommendations on streaming platforms, AI is constantly working behind the scenes.
While AI holds immense potential for positive impact, it also raises significant ethical and societal concerns.
As AI systems become increasingly sophisticated, there are fears about job displacement, infringement of data privacy and the potential for misuse.
At the same time, as AI continues to evolve, it is crucial to strike a balance between innovation and responsibility.
It is imperative to address ethical concerns and ensure transparent development so that we can harness the power of AI for the betterment of humanity.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SMART TECHNOLOGY (79%); SOCIETAL ISSUES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); COMMUTING (77%); PRECISION MEDICINE (77%); DRUG DESIGN & DISCOVERY (70%); DISPLACED WORKERS (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HEALTH CARE (90%); SMART TECHNOLOGY (79%); MANUFACTURING (78%); VEHICLE TRAFFIC (77%); PHARMACEUTICALS PRODUCT DEVELOPMENT (73%); PHARMACEUTICALS INDUSTRY (72%); INFORMATION SECURITY & PRIVACY (71%); DRUG DESIGN & DISCOVERY (70%); AUTONOMOUS MOTOR VEHICLES (69%); MOBILE & CELLULAR TELEPHONES (53%)
Load-Date: November 18, 2024",positive,0.5010049939155579,balanced/neutral,"['privacy', 'security']",[],[],[],2,0,0,0
2024,Unknown Title,"Byline: Usman Ghani
Body
December 2nd, 2024 ( TechBullion  - Delivered by  Newstex )
When the term 'hacking' is mentioned, many people assume it means something illegal. However, that's not entirely true. Ethical hacking, also referred to as penetration testing or white hat hacking, is a legitimate and authorized practice that aims to strengthen computer security by identifying vulnerabilities in systems. Ethical hacking is the backbone of CyberSecurity. The main objective of ethical hacking is to proactively detect and fix security flaws before malicious hackers can exploit them, thereby protecting an organization's defenses. Below, we've compiled a list of the top 10 Indian ethical hackers.
Sunny Nehra
Vivek Ramachandran
Sai Satish
Rahul Tyagi
Saket Modi
Anand Prakash
Trishneet Arora
Ankit Fadia
Sangeet Chopra
Benild Joseph
Let's know about them in detail:
Sunny Nehra
Sunny Nehra, the visionary founder of  Secure Your Hacks, stands unparalleled as India's top ethical hacker. His exceptional skills and expertise have cemented his position as a leading figure in the cybersecurity community. Nehra's impressive track record includes identifying critical vulnerabilities in top tech companies and collaborating with prominent organizations to secure their systems. What sets Nehra apart is his remarkable ability to detect flaws in highly complex digital infrastructures. Nehra's recognition extends beyond India's borders, earning him accolades from global tech giants and foreign governments. Beyond detecting critical vulnerabilities in web applications, networks, operating systems, and IoT devices, Nehra possesses a unique talent for finding weaknesses in the core functionality of AI and machine learning models. Nehra's unique combination of strong mathematical skills, passion for research, and ability to create sophisticated exploits by merging complex mathematics with coding makes him a standout in the field. This is why Nehra is considered a next-generation hacker and is regarded as the number 1 hacker in India.
As a next-generation hacker, Nehra's multi-domain expertise, top-level certifications, and ability to test a wide range of digital infrastructures make him incomparable to others. He is unanimously regarded as  India's top hacker, and his unparalleled expertise has earned him a reputation as a trailblazer in the CyberSecurity community. That's why he holds the top spot on this list.
Vivek Ramachandran
Vivek Ramachandran is one of the top Indian hackers and is the founder and CEO of SecurityTube and Pentester Academy. He is a renowned author, speaker, and security researcher.
Sai Satish
Sai Satish is a young entrepreneur and Indian hacker, founder, and CEO of Indian Servers. He teaches about cyber security to thousands of college students and professionals all over the nation and has assisted the government in securing official websites.
Rahul Tyagi
Rahul Tyagi is the co-founder of Safe Security, providing cybersecurity awareness and protection services. He is a prominent hacker in India, conducting seminars and training programs on cyber threats.
Saket Modi
Saket Modi is a distinguished Indian cybersecurity expert and entrepreneur, recognized for his innovative approaches to digital security. As the co-founder and CEO of Safe Security, he spearheads the development of cutting-edge cybersecurity solutions for organizations worldwide.
Anand Prakash
Anand Prakash is a famous bug hunter. gained popularity when he found flaws in Facebook, and Uber and got a good amount as bug bounty rewards. He predominantly works on identifying bugs in popular software or websites to help in securing them.
Trishneet Arora
Trishneet Arora is the founder and CEO of Tac Security, an IT security company. Being one of the most famous hackers in India, he has been listed in the 50 Most Influential Young Indians by GQ Magazine.
Ankit Fadia
Ankit Fadia is a very famous self-proclaimed ethical hacker, though his credentials and abilities have been met with skepticism and controversy within the cybersecurity community, raising concerns about his legitimacy and expertise. He is well known for his first book which he wrote at the age of 14. He is also a television host and speaker who inspires people to develop an interest and take up a career in ethical hacking.
Sangeet Chopra
Sangeet Chopra is an IT security specialist and public speaker, excelling in ethical hacking. As CEO of IT Risk Consulting at CyberCure Technologies Pvt. Ltd, he has conducted workshops across top universities, including IITs and NITs, esteemed ethical hacking institutes in India.
Benild Joseph
Benild Joseph is a recognized cybersecurity expert, author, TEDx speaker, and a well-known white-hat hacker.
Conclusion:
So, this was the list of the top 10 ethical hackers in India. If your question is about who the best or top hacker in India is, the answer would undoubtedly be Sunny Nehra. The article has already explained well why Sunny Nehra is regarded as the best ethical hacker in India.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: HACKING (92%); COMPUTER CRIME (90%); CYBERCRIME (90%); NEGATIVE NEWS (90%); NEGATIVE TECHNOLOGY NEWS (90%); ETHICS (89%); TECHNOLOGY (89%); EXPLOIT ATTACKS (79%); MALICIOUS SOFTWARE (79%); BLOGS & MESSAGE BOARDS (78%); MATH & SCIENCE EDUCATION (77%); ASSOCIATIONS & ORGANIZATIONS (75%); MACHINE LEARNING (71%); ARTIFICIAL INTELLIGENCE (69%); ENTREPRENEURSHIP (66%); EXECUTIVES (60%); STUDENTS & STUDENT LIFE (50%); Cybersecurity (%); @mdextech (%); tech (%)
Company:  SAFE SECURITY (50%)
Industry: NAICS238210 ELECTRICAL CONTRACTORS & OTHER WIRING INSTALLATION CONTRACTORS (50%); SIC1731 ELECTRICAL WORK (50%); HACKING (92%); COMPUTER CRIME (90%); CYBERCRIME (90%); CYBERSECURITY (90%); INFORMATION SECURITY VULNERABILITIES (90%); INFORMATION SECURITY & PRIVACY (89%); COMPUTER NETWORK SECURITY (79%); EXPLOIT ATTACKS (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); MALICIOUS SOFTWARE (79%); BIG TECH (78%); BLOGS & MESSAGE BOARDS (78%); NETWORK SERVERS (76%); COMPUTER OPERATING SYSTEMS (71%); MACHINE LEARNING (71%); INTERNET & WWW (70%); ARTIFICIAL INTELLIGENCE (69%); INTERNET OF THINGS (69%); WEB DEVELOPMENT (69%)
Geographic: INDIA (94%)
Load-Date: December 2, 2024","December 2nd, 2024 ( TechBullion  - Delivered by  Newstex )
When the term 'hacking' is mentioned, many people assume it means something illegal. However, that's not entirely true. Ethical hacking, also referred to as penetration testing or white hat hacking, is a legitimate and authorized practice that aims to strengthen computer security by identifying vulnerabilities in systems. Ethical hacking is the backbone of CyberSecurity. The main objective of ethical hacking is to proactively detect and fix security flaws before malicious hackers can exploit them, thereby protecting an organization's defenses. Below, we've compiled a list of the top 10 Indian ethical hackers.
Sunny Nehra
Vivek Ramachandran
Sai Satish
Rahul Tyagi
Saket Modi
Anand Prakash
Trishneet Arora
Ankit Fadia
Sangeet Chopra
Benild Joseph
Let's know about them in detail:
Sunny Nehra
Sunny Nehra, the visionary founder of  Secure Your Hacks, stands unparalleled as India's top ethical hacker. His exceptional skills and expertise have cemented his position as a leading figure in the cybersecurity community. Nehra's impressive track record includes identifying critical vulnerabilities in top tech companies and collaborating with prominent organizations to secure their systems. What sets Nehra apart is his remarkable ability to detect flaws in highly complex digital infrastructures. Nehra's recognition extends beyond India's borders, earning him accolades from global tech giants and foreign governments. Beyond detecting critical vulnerabilities in web applications, networks, operating systems, and IoT devices, Nehra possesses a unique talent for finding weaknesses in the core functionality of AI and machine learning models. Nehra's unique combination of strong mathematical skills, passion for research, and ability to create sophisticated exploits by merging complex mathematics with coding makes him a standout in the field. This is why Nehra is considered a next-generation hacker and is regarded as the number 1 hacker in India.
As a next-generation hacker, Nehra's multi-domain expertise, top-level certifications, and ability to test a wide range of digital infrastructures make him incomparable to others. He is unanimously regarded as  India's top hacker, and his unparalleled expertise has earned him a reputation as a trailblazer in the CyberSecurity community. That's why he holds the top spot on this list.
Vivek Ramachandran
Vivek Ramachandran is one of the top Indian hackers and is the founder and CEO of SecurityTube and Pentester Academy. He is a renowned author, speaker, and security researcher.
Sai Satish
Sai Satish is a young entrepreneur and Indian hacker, founder, and CEO of Indian Servers. He teaches about cyber security to thousands of college students and professionals all over the nation and has assisted the government in securing official websites.
Rahul Tyagi
Rahul Tyagi is the co-founder of Safe Security, providing cybersecurity awareness and protection services. He is a prominent hacker in India, conducting seminars and training programs on cyber threats.
Saket Modi
Saket Modi is a distinguished Indian cybersecurity expert and entrepreneur, recognized for his innovative approaches to digital security. As the co-founder and CEO of Safe Security, he spearheads the development of cutting-edge cybersecurity solutions for organizations worldwide.
Anand Prakash
Anand Prakash is a famous bug hunter. gained popularity when he found flaws in Facebook, and Uber and got a good amount as bug bounty rewards. He predominantly works on identifying bugs in popular software or websites to help in securing them.
Trishneet Arora
Trishneet Arora is the founder and CEO of Tac Security, an IT security company. Being one of the most famous hackers in India, he has been listed in the 50 Most Influential Young Indians by GQ Magazine.
Ankit Fadia
Ankit Fadia is a very famous self-proclaimed ethical hacker, though his credentials and abilities have been met with skepticism and controversy within the cybersecurity community, raising concerns about his legitimacy and expertise. He is well known for his first book which he wrote at the age of 14. He is also a television host and speaker who inspires people to develop an interest and take up a career in ethical hacking.
Sangeet Chopra
Sangeet Chopra is an IT security specialist and public speaker, excelling in ethical hacking. As CEO of IT Risk Consulting at CyberCure Technologies Pvt. Ltd, he has conducted workshops across top universities, including IITs and NITs, esteemed ethical hacking institutes in India.
Benild Joseph
Benild Joseph is a recognized cybersecurity expert, author, TEDx speaker, and a well-known white-hat hacker.
Conclusion:
So, this was the list of the top 10 ethical hackers in India. If your question is about who the best or top hacker in India is, the answer would undoubtedly be Sunny Nehra. The article has already explained well why Sunny Nehra is regarded as the best ethical hacker in India.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: HACKING (92%); COMPUTER CRIME (90%); CYBERCRIME (90%); NEGATIVE NEWS (90%); NEGATIVE TECHNOLOGY NEWS (90%); ETHICS (89%); TECHNOLOGY (89%); EXPLOIT ATTACKS (79%); MALICIOUS SOFTWARE (79%); BLOGS & MESSAGE BOARDS (78%); MATH & SCIENCE EDUCATION (77%); ASSOCIATIONS & ORGANIZATIONS (75%); MACHINE LEARNING (71%); ARTIFICIAL INTELLIGENCE (69%); ENTREPRENEURSHIP (66%); EXECUTIVES (60%); STUDENTS & STUDENT LIFE (50%); Cybersecurity (%); @mdextech (%); tech (%)
Company:  SAFE SECURITY (50%)
Industry: NAICS238210 ELECTRICAL CONTRACTORS & OTHER WIRING INSTALLATION CONTRACTORS (50%); SIC1731 ELECTRICAL WORK (50%); HACKING (92%); COMPUTER CRIME (90%); CYBERCRIME (90%); CYBERSECURITY (90%); INFORMATION SECURITY VULNERABILITIES (90%); INFORMATION SECURITY & PRIVACY (89%); COMPUTER NETWORK SECURITY (79%); EXPLOIT ATTACKS (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); MALICIOUS SOFTWARE (79%); BIG TECH (78%); BLOGS & MESSAGE BOARDS (78%); NETWORK SERVERS (76%); COMPUTER OPERATING SYSTEMS (71%); MACHINE LEARNING (71%); INTERNET & WWW (70%); ARTIFICIAL INTELLIGENCE (69%); INTERNET OF THINGS (69%); WEB DEVELOPMENT (69%)
Geographic: INDIA (94%)
Load-Date: December 2, 2024",neutral,0.8558493852615356,balanced/neutral,"['privacy', 'security']",[],['should'],['machine learning'],2,0,1,1
2024,Unknown Title,"Dateline: NEW YORK, March 5, 2024 
Body
PR NewswireImportance of ethical AI guidelines and policies corresponds with revenue growth, responses indicateNEW YORK, March 5, 2024 /PRNewswire/ -- Today, Deloitte released a new study,""Preparing the workforce for ethical, responsible, and trustworthy AI: C-suite perspectives,""that outlines corporate priorities and actions to harness AI's benefits while maintaining trust and equitable outcomes. 
 The study from Deloitte'sTechnology Trust Ethics practice surveyed 100 C-level executives to understand how their organizations develop ethical AI principles, and how they inform and educate their workforces about AI ethics.Among executives surveyed, publishing clear policies and guidelines was ranked the most effective method of communicating AI ethics to the workforce, followed by workshops and trainings. The survey also shows that C-level executives associate the highest importance of ethical guidelines for emerging tech with revenue growth (55%), followed by brand reputation and marketplace trust (47%).Additional key findings include:Among C-level executives surveyed, 86% say their organizations have either implemented ethics policies and guidelines or are about to do so. Almost half of respondents (49%) report their organizations currently have guidelines or policies in place regarding the ethical use of AI, and another 37% said they are nearly ready to roll policies out.Boards of directors are involved in creating AI ethics policies as often as ethics officers. Respondents indicated that boards of directors (52%) and chief ethics officers (52%) are always involved in creating policies and guidelines for the ethical use of AI.  Organizations are reskilling and making corporate acquisitions to prepare their labor force for AI. Enterprises are actively training and upskilling their workforces (45%), acquiring organizations with AI capabilities and skills (45%) and hiring for AI (44%) to prepare their employees for the integration of AI — and roughly an additional 40% say they are close to ready to do the same.Ethics researchers and specialists are sought out more than ethics officers. More executives surveyed said their organizations are currently hiring or planning to hire for positions including AI ethics researchers (53%), compliance specialists (53%), and technology policy analysts (51%) than C-suite roles such as a chief ethics officer (38%) or chief trust officer (36%).Key quotes""At every step, the creation or use of emerging technologies like AI present an opportunity to ensure we're positively advancing a more equitable and prosperous world,"" saidKwasi Mitchell, chief purpose and DEI officer at Deloitte US. ""Organizations certainly play a critical role in the responsible adoption and implementation of AI, and I'm encouraged by the inputs we're seeing from C-level leaders to prioritize ethical awareness, training and use so we can collectively produce better outcome for our businesses and people as a result.""""As organizations increase their use of AI, the survey indicates that the C-suite is highly aware of the need to provide comprehensive ethics trainings in tandem to prepare their labor force,"" saidBeena Ammanath, US Technology Trust Ethics leader, Deloitte LLP. ""Companies' concurrent strategies — upskilling their own employees, hiring for new roles and even acquiring companies that have existing AI capabilities — demonstrate they recognize the immense possibility that only the human element can generate from AI.""About the surveyDeloitte's study, ""Preparing the workforce for ethical, responsible and trustworthy AI: C-suite perspectives,"" surveyed 100 executives and was conducted online by an independent research company between Jan. 17 and 22, 2024. Respondents represented C-level, president, board member and partner/owner roles at companies in the U.S.The survey is a follow-up to Deloitte's ""State of Ethics and Trust in Technology"" annual report that assessed if and how ethical standards are being applied to emerging technology. To learn more about Deloitte'sUS Purpose & DEI Office orTechnology Trust Ethics practice, including itsframework to guide responsible decision-making in the design, operation and governance of technologies, visitwww.deloitte.com.About Deloitte
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world's most admired brands, including nearly 90% of the Fortune 500® and more than 8,500 U.S.-based private companies. At Deloitte, we strive to live our purpose of making animpact that mattersby creating trust and confidence in a more equitable society. We leverage our unique blend of business acumen, command of technology, and strategic technology alliances to advise our clients across industries as theybuild their future. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Bringing more than 175 years of service, our network of member firms spans more than 150 countries and territories. Learn how Deloitte's approximately 457,000 people worldwide connect for impact atwww.deloitte.com.Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee (""DTTL""), its network of member firms, and their related entities. DTTL and each of its member firms are legally separate and independent entities. DTTL (also referred to as ""Deloitte Global"") does not provide services to clients. In the United States, Deloitte refers to one or more of the US member firms of DTTL, their related entities that operate using the ""Deloitte"" name in the United States and their respective affiliates. Certain services may not be available to attest clients under the rules and regulations of public accounting. Please seewww.deloitte.com/about to learn more about our global network of member firms.   View original content to download multimedia:https://www.prnewswire.com/news-releases/deloitte-study-ethical-use-guides-c-level-decisions-about-workforce-preparation-for-ai-302079036.htmlSOURCE Deloitte 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ASSOCIATIONS & ORGANIZATIONS (90%); POLLS & SURVEYS (90%); PRESS RELEASES (90%); BUSINESS ETHICS (89%); EXECUTIVES (89%); LABOR FORCE (89%); RESKILLING & UPSKILLING (89%); EMERGING TECHNOLOGY (78%); RESEARCH REPORTS (78%); TECHNOLOGY (78%); BOARDS OF DIRECTORS (77%); EMPLOYEE RETRAINING (77%); EMPLOYEE TRAINING (77%); ACQUISITIONS (63%); BRANDING (53%); DELOITTE-EthicalAISvy (%); SVY Surveys, polls & research studies (%)
Company:  DELOITTE LLP (92%); Deloitte
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (92%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (92%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); BRANDING (53%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: March 5, 2024","PR NewswireImportance of ethical AI guidelines and policies corresponds with revenue growth, responses indicateNEW YORK, March 5, 2024 /PRNewswire/ -- Today, Deloitte released a new study,""Preparing the workforce for ethical, responsible, and trustworthy AI: C-suite perspectives,""that outlines corporate priorities and actions to harness AI's benefits while maintaining trust and equitable outcomes. 
 The study from Deloitte'sTechnology Trust Ethics practice surveyed 100 C-level executives to understand how their organizations develop ethical AI principles, and how they inform and educate their workforces about AI ethics.Among executives surveyed, publishing clear policies and guidelines was ranked the most effective method of communicating AI ethics to the workforce, followed by workshops and trainings. The survey also shows that C-level executives associate the highest importance of ethical guidelines for emerging tech with revenue growth (55%), followed by brand reputation and marketplace trust (47%).Additional key findings include:Among C-level executives surveyed, 86% say their organizations have either implemented ethics policies and guidelines or are about to do so. Almost half of respondents (49%) report their organizations currently have guidelines or policies in place regarding the ethical use of AI, and another 37% said they are nearly ready to roll policies out.Boards of directors are involved in creating AI ethics policies as often as ethics officers. Respondents indicated that boards of directors (52%) and chief ethics officers (52%) are always involved in creating policies and guidelines for the ethical use of AI.  Organizations are reskilling and making corporate acquisitions to prepare their labor force for AI. Enterprises are actively training and upskilling their workforces (45%), acquiring organizations with AI capabilities and skills (45%) and hiring for AI (44%) to prepare their employees for the integration of AI — and roughly an additional 40% say they are close to ready to do the same.Ethics researchers and specialists are sought out more than ethics officers. More executives surveyed said their organizations are currently hiring or planning to hire for positions including AI ethics researchers (53%), compliance specialists (53%), and technology policy analysts (51%) than C-suite roles such as a chief ethics officer (38%) or chief trust officer (36%).Key quotes""At every step, the creation or use of emerging technologies like AI present an opportunity to ensure we're positively advancing a more equitable and prosperous world,"" saidKwasi Mitchell, chief purpose and DEI officer at Deloitte US. ""Organizations certainly play a critical role in the responsible adoption and implementation of AI, and I'm encouraged by the inputs we're seeing from C-level leaders to prioritize ethical awareness, training and use so we can collectively produce better outcome for our businesses and people as a result.""""As organizations increase their use of AI, the survey indicates that the C-suite is highly aware of the need to provide comprehensive ethics trainings in tandem to prepare their labor force,"" saidBeena Ammanath, US Technology Trust Ethics leader, Deloitte LLP. ""Companies' concurrent strategies — upskilling their own employees, hiring for new roles and even acquiring companies that have existing AI capabilities — demonstrate they recognize the immense possibility that only the human element can generate from AI.""About the surveyDeloitte's study, ""Preparing the workforce for ethical, responsible and trustworthy AI: C-suite perspectives,"" surveyed 100 executives and was conducted online by an independent research company between Jan. 17 and 22, 2024. Respondents represented C-level, president, board member and partner/owner roles at companies in the U.S.The survey is a follow-up to Deloitte's ""State of Ethics and Trust in Technology"" annual report that assessed if and how ethical standards are being applied to emerging technology. To learn more about Deloitte'sUS Purpose & DEI Office orTechnology Trust Ethics practice, including itsframework to guide responsible decision-making in the design, operation and governance of technologies, visitwww.deloitte.com.About Deloitte
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world's most admired brands, including nearly 90% of the Fortune 500® and more than 8,500 U.S.-based private companies. At Deloitte, we strive to live our purpose of making animpact that mattersby creating trust and confidence in a more equitable society. We leverage our unique blend of business acumen, command of technology, and strategic technology alliances to advise our clients across industries as theybuild their future. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Bringing more than 175 years of service, our network of member firms spans more than 150 countries and territories. Learn how Deloitte's approximately 457,000 people worldwide connect for impact atwww.deloitte.com.Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee (""DTTL""), its network of member firms, and their related entities. DTTL and each of its member firms are legally separate and independent entities. DTTL (also referred to as ""Deloitte Global"") does not provide services to clients. In the United States, Deloitte refers to one or more of the US member firms of DTTL, their related entities that operate using the ""Deloitte"" name in the United States and their respective affiliates. Certain services may not be available to attest clients under the rules and regulations of public accounting. Please seewww.deloitte.com/about to learn more about our global network of member firms.   View original content to download multimedia:https://www.prnewswire.com/news-releases/deloitte-study-ethical-use-guides-c-level-decisions-about-workforce-preparation-for-ai-302079036.htmlSOURCE Deloitte 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ASSOCIATIONS & ORGANIZATIONS (90%); POLLS & SURVEYS (90%); PRESS RELEASES (90%); BUSINESS ETHICS (89%); EXECUTIVES (89%); LABOR FORCE (89%); RESKILLING & UPSKILLING (89%); EMERGING TECHNOLOGY (78%); RESEARCH REPORTS (78%); TECHNOLOGY (78%); BOARDS OF DIRECTORS (77%); EMPLOYEE RETRAINING (77%); EMPLOYEE TRAINING (77%); ACQUISITIONS (63%); BRANDING (53%); DELOITTE-EthicalAISvy (%); SVY Surveys, polls & research studies (%)
Company:  DELOITTE LLP (92%); Deloitte
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (92%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (92%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); BRANDING (53%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: March 5, 2024",neutral,0.7057539224624634,balanced/neutral,[],[],"['regulation', 'policy', 'governance', 'standards', 'guidelines', 'compliance', 'audit', 'need to']",[],0,0,8,0
2024,Unknown Title,"Body
 31 Jan 2024 (Saudi Press Agency) The Saudi Data and Artificial Intelligence Authority (SDAIA) has recently conducted two high-level workshops in collaboration with the Arab League (AL), Gulf Cooperation Council (GCC), and the International Center for Artificial Intelligence Research and Ethics (ICAIRE). These workshops aimed to enhance the role of ethical practices in artificial intelligence and its tools for regulating technology and achieving sustainable development in the region.The first workshop, titled 'Artificial Intelligence for Sustainability,' held at SDAIA's National Artificial Intelligence Center, emphasized the importance of ethical considerations in regulating technology and promoting sustainable development in Arab countries. It highlighted the ethical aspects of artificial intelligence applications and encouraged collaboration among Arab nations in spreading values and ethical tools related to artificial intelligence. 
The workshop witnessed the participation of 73 experts and 50 Arab organizations from 18 countries.The second workshop, 'Ethical Tools for Artificial Intelligence,' took place at the GCC General Secretariat General. It featured the involvement of GCC countries in sharing their experiences with artificial intelligence and the role of AI ethics. A representative from UNESCO presented an ethical AI tool developed by the organization, expressing a willingness to support interested countries in its implementation. This workshop brought together 31 experts and 12 entities from the GCC countries.These workshops, organized by SDAIA, align with its role in regulating artificial intelligence technologies, fostering data and AI development, and promoting awareness in the Kingdom of Saudi Arabia. SDAIA serves as the national reference for data and artificial intelligence, overseeing their regulation, development, and progress.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); ASSOCIATIONS & ORGANIZATIONS (77%); UNITED NATIONS INSTITUTIONS (77%); SUSTAINABILITY (76%); UNITED NATIONS (76%); INTELLIGENCE SERVICES (73%)
Organization: LEAGUE OF ARAB STATES (84%); COOPERATION COUNCIL FOR THE ARAB STATES OF THE GULF (83%); THE INTERNATIONAL CENTER (57%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%)
Geographic: RIYADH, SAUDI ARABIA (79%); SAUDI ARABIA (94%); GULF STATES (93%); Riyadh
Load-Date: February 1, 2024","31 Jan 2024 (Saudi Press Agency) The Saudi Data and Artificial Intelligence Authority (SDAIA) has recently conducted two high-level workshops in collaboration with the Arab League (AL), Gulf Cooperation Council (GCC), and the International Center for Artificial Intelligence Research and Ethics (ICAIRE). These workshops aimed to enhance the role of ethical practices in artificial intelligence and its tools for regulating technology and achieving sustainable development in the region.The first workshop, titled 'Artificial Intelligence for Sustainability,' held at SDAIA's National Artificial Intelligence Center, emphasized the importance of ethical considerations in regulating technology and promoting sustainable development in Arab countries. It highlighted the ethical aspects of artificial intelligence applications and encouraged collaboration among Arab nations in spreading values and ethical tools related to artificial intelligence. 
The workshop witnessed the participation of 73 experts and 50 Arab organizations from 18 countries.The second workshop, 'Ethical Tools for Artificial Intelligence,' took place at the GCC General Secretariat General. It featured the involvement of GCC countries in sharing their experiences with artificial intelligence and the role of AI ethics. A representative from UNESCO presented an ethical AI tool developed by the organization, expressing a willingness to support interested countries in its implementation. This workshop brought together 31 experts and 12 entities from the GCC countries.These workshops, organized by SDAIA, align with its role in regulating artificial intelligence technologies, fostering data and AI development, and promoting awareness in the Kingdom of Saudi Arabia. SDAIA serves as the national reference for data and artificial intelligence, overseeing their regulation, development, and progress.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); ASSOCIATIONS & ORGANIZATIONS (77%); UNITED NATIONS INSTITUTIONS (77%); SUSTAINABILITY (76%); UNITED NATIONS (76%); INTELLIGENCE SERVICES (73%)
Organization: LEAGUE OF ARAB STATES (84%); COOPERATION COUNCIL FOR THE ARAB STATES OF THE GULF (83%); THE INTERNATIONAL CENTER (57%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%)
Geographic: RIYADH, SAUDI ARABIA (79%); SAUDI ARABIA (94%); GULF STATES (93%); Riyadh
Load-Date: February 1, 2024",neutral,0.6834455728530884,balanced/neutral,['agency'],[],"['regulation', 'policy']",[],1,0,2,0
2024,Unknown Title,"Body
By Stacey Kusterbeck
Large language models (LLMs) in surgery have the potential to enhance decision-making, documentation, and patient engagement. However, the body of literature addressing the ethical concerns of applying LLMs in surgical settings is relatively limited. ""Most existing research tends to focus on the technical performance, integration, and potential benefits of these technologies, rather than the ethical aspects of these tools,"" observes Sahar Borna, MD, a research fellow in the Division of Plastic Surgery at Mayo Clinic in Jacksonville, FL.
Borna and colleagues conducted a review of the surgery literature on ethics of LLMs.1 The researchers analyzed how the ethical principles of autonomy, beneficence, nonmaleficience, and justice were discussed in 53 studies. The aim was to understand, from an ethical perspective, the biggest concerns with LLMs in the surgical field. Some key findings:
Autonomy was the ethical principle explicitly cited most often.
""The complex nature of LLMs may complicate the informed consent process, potentially impacting patients' ability to make well-informed decisions regarding their treatment,"" says Sophia M. Pressman, BS, the study's lead author and a research trainee at the Mayo Clinic in Jacksonville in the Division of Plastic Surgery.
Accuracy was the most frequently discussed ethical concern, cited in about 85% of studies. 
""This underscores a significant apprehension within the surgical community regarding the potential ramifications of errors associated with LLMs,"" says Pressman. Surgeons are concerned that errors in LLM outputs might lead to misdiagnoses or incorrect surgical procedures, for example. ""Although LLMs should not be used to replace a physician's clinical judgment, future applications may see the involvement of LLMs to automate certain processes. But this will depend upon accurate outputs and validated LLMs,"" says Pressman.
Bias was frequently discussed, including the potential for perpetuation of existing healthcare disparities.
Patient confidentiality was cited often, based on the concern that breaches can undermine patient trust and privacy.
Overall, the study findings emphasize the need for robust ethical frameworks for responsible integration of LLMs into clinical practice, according to the authors.
""Surgeons are particularly concerned about the implications of LLMs for clinical decision-making. Inaccurate and biased information is a major concern, as this can greatly undermine the clinical decision-making process,"" according to study author Antonio J. Forte, MD, PhD, director of the Plastic Surgery Outcomes Research Team at Mayo Clinic. To address ethical concerns with LLMs in surgery, Forte says that these steps are essential:
Having continuous ethical dialogue to address evolving challenges. 
LLMs are not yet directly involved in performing surgeries. ""As LLMs become more integrated into surgical settings, it's crucial to address the ethical issues they might raise proactively,"" says Forte. Evolving concerns include ensuring the accuracy of LLMs, managing bias, and maintaining patient confidentiality and autonomy. 
Institutional-level ethical dialogue on LLMs in surgery could include multidisciplinary discussions and integration of ethicists into surgical teams to address ethical issues in real time. ""Ethical guidelines and robust oversight mechanisms will be essential to ensure these technologies benefit patient care while upholding ethical standards,"" adds Forte.
Improving the transparency and validity of LLMs in hospitals.
""Ethicists can guide the ethical integration and monitoring of LLMs, while IT experts can ensure their technical robustness and transparency,"" suggests Forte.
Educating healthcare providers on ethical use of LLMs.
Ethicists can help to develop training modules or can offer workshops on the ethical use of AI in clinical practice. 
Developing hospital-wide policies for the ethical integration of LLMs into healthcare practices. 
""Ethicists can help ensure that these models are being utilized in a way that supports patient rights and improves the quality of healthcare,"" says Forte. 
REFERENCE
Pressman SM, Borna S, Gomez-Cabello CA, et al. AI and ethics: A systematic review of the ethical considerations of large language model use in surgery research. Healthcare (Basel). 2024;12(8):825. 
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (97%); HUMAN SUBJECTS (90%); LARGE LANGUAGE MODELS (90%); MEDICAL ETHICS (90%); SURGERY & TRANSPLANTATION (90%); CLINICAL DECISION SUPPORT (89%); COSMETIC & RECONSTRUCTIVE SURGERY (89%); MEDICAL RECORDS (89%); PATIENT PRIVACY (89%); RESEARCH REPORTS (89%); WRITERS (89%); HEALTH EQUITY (79%); MEDICAL TREATMENTS & PROCEDURES (79%); PATIENT CONSENT (79%); TECHNOLOGY (76%); VULNERABLE HEALTH POPULATIONS (74%)
Organization: MAYO CLINIC (83%)
Industry: ACADEMIC MEDICAL CENTERS (90%); LARGE LANGUAGE MODELS (90%); CLINICAL DECISION SUPPORT (89%); MEDICAL RECORDS (89%); PATIENT PRIVACY (89%); WRITERS (89%); HEALTH EQUITY (79%); PATIENT CONSENT (79%); MEDIA & TELECOMMUNICATIONS (73%)
Geographic: JACKSONVILLE, FL, USA (72%); FLORIDA, USA (57%)
Load-Date: October 23, 2024","By Stacey Kusterbeck
Large language models (LLMs) in surgery have the potential to enhance decision-making, documentation, and patient engagement. However, the body of literature addressing the ethical concerns of applying LLMs in surgical settings is relatively limited. ""Most existing research tends to focus on the technical performance, integration, and potential benefits of these technologies, rather than the ethical aspects of these tools,"" observes Sahar Borna, MD, a research fellow in the Division of Plastic Surgery at Mayo Clinic in Jacksonville, FL.
Borna and colleagues conducted a review of the surgery literature on ethics of LLMs.1 The researchers analyzed how the ethical principles of autonomy, beneficence, nonmaleficience, and justice were discussed in 53 studies. The aim was to understand, from an ethical perspective, the biggest concerns with LLMs in the surgical field. Some key findings:
Autonomy was the ethical principle explicitly cited most often.
""The complex nature of LLMs may complicate the informed consent process, potentially impacting patients' ability to make well-informed decisions regarding their treatment,"" says Sophia M. Pressman, BS, the study's lead author and a research trainee at the Mayo Clinic in Jacksonville in the Division of Plastic Surgery.
Accuracy was the most frequently discussed ethical concern, cited in about 85% of studies. 
""This underscores a significant apprehension within the surgical community regarding the potential ramifications of errors associated with LLMs,"" says Pressman. Surgeons are concerned that errors in LLM outputs might lead to misdiagnoses or incorrect surgical procedures, for example. ""Although LLMs should not be used to replace a physician's clinical judgment, future applications may see the involvement of LLMs to automate certain processes. But this will depend upon accurate outputs and validated LLMs,"" says Pressman.
Bias was frequently discussed, including the potential for perpetuation of existing healthcare disparities.
Patient confidentiality was cited often, based on the concern that breaches can undermine patient trust and privacy.
Overall, the study findings emphasize the need for robust ethical frameworks for responsible integration of LLMs into clinical practice, according to the authors.
""Surgeons are particularly concerned about the implications of LLMs for clinical decision-making. Inaccurate and biased information is a major concern, as this can greatly undermine the clinical decision-making process,"" according to study author Antonio J. Forte, MD, PhD, director of the Plastic Surgery Outcomes Research Team at Mayo Clinic. To address ethical concerns with LLMs in surgery, Forte says that these steps are essential:
Having continuous ethical dialogue to address evolving challenges. 
LLMs are not yet directly involved in performing surgeries. ""As LLMs become more integrated into surgical settings, it's crucial to address the ethical issues they might raise proactively,"" says Forte. Evolving concerns include ensuring the accuracy of LLMs, managing bias, and maintaining patient confidentiality and autonomy. 
Institutional-level ethical dialogue on LLMs in surgery could include multidisciplinary discussions and integration of ethicists into surgical teams to address ethical issues in real time. ""Ethical guidelines and robust oversight mechanisms will be essential to ensure these technologies benefit patient care while upholding ethical standards,"" adds Forte.
Improving the transparency and validity of LLMs in hospitals.
""Ethicists can guide the ethical integration and monitoring of LLMs, while IT experts can ensure their technical robustness and transparency,"" suggests Forte.
Educating healthcare providers on ethical use of LLMs.
Ethicists can help to develop training modules or can offer workshops on the ethical use of AI in clinical practice. 
Developing hospital-wide policies for the ethical integration of LLMs into healthcare practices. 
""Ethicists can help ensure that these models are being utilized in a way that supports patient rights and improves the quality of healthcare,"" says Forte. 
REFERENCE
Pressman SM, Borna S, Gomez-Cabello CA, et al. AI and ethics: A systematic review of the ethical considerations of large language model use in surgery research. Healthcare (Basel). 2024;12(8):825. 
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (97%); HUMAN SUBJECTS (90%); LARGE LANGUAGE MODELS (90%); MEDICAL ETHICS (90%); SURGERY & TRANSPLANTATION (90%); CLINICAL DECISION SUPPORT (89%); COSMETIC & RECONSTRUCTIVE SURGERY (89%); MEDICAL RECORDS (89%); PATIENT PRIVACY (89%); RESEARCH REPORTS (89%); WRITERS (89%); HEALTH EQUITY (79%); MEDICAL TREATMENTS & PROCEDURES (79%); PATIENT CONSENT (79%); TECHNOLOGY (76%); VULNERABLE HEALTH POPULATIONS (74%)
Organization: MAYO CLINIC (83%)
Industry: ACADEMIC MEDICAL CENTERS (90%); LARGE LANGUAGE MODELS (90%); CLINICAL DECISION SUPPORT (89%); MEDICAL RECORDS (89%); PATIENT PRIVACY (89%); WRITERS (89%); HEALTH EQUITY (79%); PATIENT CONSENT (79%); MEDIA & TELECOMMUNICATIONS (73%)
Geographic: JACKSONVILLE, FL, USA (72%); FLORIDA, USA (57%)
Load-Date: October 23, 2024",neutral,0.8180062770843506,balanced/neutral,"['privacy', 'bias', 'transparency', 'autonomy', 'consent']","['justice', 'equity', 'autonomy', 'beneficence', 'justice']","['oversight', 'standards', 'guidelines', 'should']","['large language model', 'llm']",5,5,4,2
2024,Unknown Title,"Byline: Targeted News Service
Dateline: NOTRE DAME, Indiana 
Body
The University of Notre Dame issued the following news:
The University of Notre Dame has been awarded a $539,000 grant from Lilly Endowment Inc. to support Faith-Based Frameworks for AI Ethics, a one-year planning project that will engage and build a network of leaders in higher education, technology and a diverse array of faith-based communities focused on developing faith-based ethical frameworks and applying them to emerging debates around artificial general intelligence (AGI). AGI is a field of research aimed at developing and deploying software with the ability to rival human capacities for self-organized learning, creativity and generalized reasoning. This project will be led by the Notre Dame Institute for Ethics and the Common Good (ECG).
""This is a pivotal moment for technology ethics,"" said Meghan Sullivan, the Wilsey Family College Professor of Philosophy and director of ECG and the Notre Dame Ethics Initiative. ""AGI is developing quickly and has the potential to change our economies, our systems of education and the fabric of our social lives. We believe that the wisdom of faith traditions can make a significant contribution to the development of ethical frameworks for AGI.
""This project will encourage broader dialogue about the role that concepts such as dignity, embodiment, love, transcendence and being created in the image of God should play in how we understand and use this technology. These concepts at the bedrock of many faith-based traditions are vital for how we advance the common good in the era of AGI.""
Notre Dame has the conviction that faith-based ethical frameworks are vital to the ethical development and deployment of these new technologies, Sullivan added. Faith-Based Frameworks for AI Ethics will seek to establish a unique and influential network of scholars, technology industry leaders and faith leaders to create, study and disseminate complementary faith-based ethical frameworks to meet this era of profound disruption.
This project will include asset mapping to identify and recruit key participants across the three sectors, focus groups to determine common faith-based and ethical commitments and priorities, and a landscape analysis to inform subsequent steps for coordinating participants and catalyzing this work. The project will culminate in a major conference in September 2025 that will focus on the most pressing faith-based issues relating to the proliferation of AGI and provide training and networking opportunities for leaders who attend.
""We are grateful to Lilly Endowment for this support, which will enable us to convene a diverse group of technology experts, scholars and religious leaders for important conversations about artificial general intelligence and all the ways it could impact our society,"" said David Go, vice president and associate provost for academic strategy. ""As a leading global Catholic research university, Notre Dame has a special obligation to address the most significant ethical questions of the day through scholarship, education and public engagement, and this conference will enable our University-wide Ethics Initiative to engage others in doing just that.""
The Institute for Ethics and the Common Good facilitates interdisciplinary research in foundational and applied ethics, coordinates projects that cross departments and units and supports ethics-related education and public engagement efforts. ECG is a signature element of the Ethics Initiative, which aims to establish Notre Dame as a premier global destination for the study of ethics, offering superb training for future generations of ethicists and moral leaders, a platform for engaging the Catholic moral tradition with other modes of inquiry and an opportunity to forge insights into some of the most significant ethical issues of our time.
Lilly Endowment Inc. is a private foundation created in 1937 by J.K. Lilly Sr. and his sons Eli and J.K. Jr. through gifts of stock in their pharmaceutical business, Eli Lilly and Company. While those gifts remain the financial bedrock of the Endowment, it is a separate entity from the company, with a distinct governing board, staff and location. In keeping with the founders' wishes, the Endowment supports the causes of community development, education and religion and maintains a special commitment to its hometown, Indianapolis, and home state, Indiana. A principal aim of the Endowment's religion grantmaking is to deepen and enrich the lives of Christians in the United States, primarily by seeking out and supporting efforts that enhance the vitality of congregations and strengthen the pastoral and lay leadership of Christian communities. The Endowment also seeks to improve public understanding of diverse religious traditions by supporting fair and accurate portrayals of the role religion plays in the United States and across the globe.
Contact: Carrie Gates, associate director of media relations, 574-993-9220, c.gates@nd.edu
***
Original text here: https://news.nd.edu/news/notre-dame-receives-lilly-endowment-grant-to-support-development-of-faith-based-frameworks-for-ai-ethics/
MSTRUCK-8869329 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: RELIGION (95%); ETHICS (92%); GRANTS & GIFTS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHRISTIANS & CHRISTIANITY (90%); ENDOWMENTS (90%); FOUNDATIONS (90%); COLLEGES & UNIVERSITIES (89%); INTELLIGENCE & COGNITION (89%); TECHNOLOGY (89%); EDUCATION SYSTEMS & INSTITUTIONS (78%); PHILOSOPHY (78%); SCHOLARSHIPS & GRANTS (78%); STUDENT EXPENSES & FINANCING (78%); UNIVERSITY ADMINISTRATION (78%); EDUCATIONAL TECHNOLOGY (77%); EMERGING TECHNOLOGY (77%); TEACHING MATERIALS & MEDIA (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); SOCIAL NETWORKING (72%); CATHOLICS & CATHOLICISM (60%); CLERGY & RELIGIOUS VOCATIONS (60%)
Organization: UNIVERSITY OF NOTRE DAME (94%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (89%); EDUCATION SYSTEMS & INSTITUTIONS (78%); SOFTWARE SERVICES & APPLICATIONS (78%); INFORMATION TECHNOLOGY INDUSTRY (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); FOCUS GROUPS (70%)
Geographic: INDIANA, USA (79%)
Load-Date: October 10, 2024","The University of Notre Dame issued the following news:
The University of Notre Dame has been awarded a $539,000 grant from Lilly Endowment Inc. to support Faith-Based Frameworks for AI Ethics, a one-year planning project that will engage and build a network of leaders in higher education, technology and a diverse array of faith-based communities focused on developing faith-based ethical frameworks and applying them to emerging debates around artificial general intelligence (AGI). AGI is a field of research aimed at developing and deploying software with the ability to rival human capacities for self-organized learning, creativity and generalized reasoning. This project will be led by the Notre Dame Institute for Ethics and the Common Good (ECG).
""This is a pivotal moment for technology ethics,"" said Meghan Sullivan, the Wilsey Family College Professor of Philosophy and director of ECG and the Notre Dame Ethics Initiative. ""AGI is developing quickly and has the potential to change our economies, our systems of education and the fabric of our social lives. We believe that the wisdom of faith traditions can make a significant contribution to the development of ethical frameworks for AGI.
""This project will encourage broader dialogue about the role that concepts such as dignity, embodiment, love, transcendence and being created in the image of God should play in how we understand and use this technology. These concepts at the bedrock of many faith-based traditions are vital for how we advance the common good in the era of AGI.""
Notre Dame has the conviction that faith-based ethical frameworks are vital to the ethical development and deployment of these new technologies, Sullivan added. Faith-Based Frameworks for AI Ethics will seek to establish a unique and influential network of scholars, technology industry leaders and faith leaders to create, study and disseminate complementary faith-based ethical frameworks to meet this era of profound disruption.
This project will include asset mapping to identify and recruit key participants across the three sectors, focus groups to determine common faith-based and ethical commitments and priorities, and a landscape analysis to inform subsequent steps for coordinating participants and catalyzing this work. The project will culminate in a major conference in September 2025 that will focus on the most pressing faith-based issues relating to the proliferation of AGI and provide training and networking opportunities for leaders who attend.
""We are grateful to Lilly Endowment for this support, which will enable us to convene a diverse group of technology experts, scholars and religious leaders for important conversations about artificial general intelligence and all the ways it could impact our society,"" said David Go, vice president and associate provost for academic strategy. ""As a leading global Catholic research university, Notre Dame has a special obligation to address the most significant ethical questions of the day through scholarship, education and public engagement, and this conference will enable our University-wide Ethics Initiative to engage others in doing just that.""
The Institute for Ethics and the Common Good facilitates interdisciplinary research in foundational and applied ethics, coordinates projects that cross departments and units and supports ethics-related education and public engagement efforts. ECG is a signature element of the Ethics Initiative, which aims to establish Notre Dame as a premier global destination for the study of ethics, offering superb training for future generations of ethicists and moral leaders, a platform for engaging the Catholic moral tradition with other modes of inquiry and an opportunity to forge insights into some of the most significant ethical issues of our time.
Lilly Endowment Inc. is a private foundation created in 1937 by J.K. Lilly Sr. and his sons Eli and J.K. Jr. through gifts of stock in their pharmaceutical business, Eli Lilly and Company. While those gifts remain the financial bedrock of the Endowment, it is a separate entity from the company, with a distinct governing board, staff and location. In keeping with the founders' wishes, the Endowment supports the causes of community development, education and religion and maintains a special commitment to its hometown, Indianapolis, and home state, Indiana. A principal aim of the Endowment's religion grantmaking is to deepen and enrich the lives of Christians in the United States, primarily by seeking out and supporting efforts that enhance the vitality of congregations and strengthen the pastoral and lay leadership of Christian communities. The Endowment also seeks to improve public understanding of diverse religious traditions by supporting fair and accurate portrayals of the role religion plays in the United States and across the globe.
Contact: Carrie Gates, associate director of media relations, 574-993-9220, c.gates@nd.edu
***
Original text here: https://news.nd.edu/news/notre-dame-receives-lilly-endowment-grant-to-support-development-of-faith-based-frameworks-for-ai-ethics/
MSTRUCK-8869329 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: RELIGION (95%); ETHICS (92%); GRANTS & GIFTS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CHRISTIANS & CHRISTIANITY (90%); ENDOWMENTS (90%); FOUNDATIONS (90%); COLLEGES & UNIVERSITIES (89%); INTELLIGENCE & COGNITION (89%); TECHNOLOGY (89%); EDUCATION SYSTEMS & INSTITUTIONS (78%); PHILOSOPHY (78%); SCHOLARSHIPS & GRANTS (78%); STUDENT EXPENSES & FINANCING (78%); UNIVERSITY ADMINISTRATION (78%); EDUCATIONAL TECHNOLOGY (77%); EMERGING TECHNOLOGY (77%); TEACHING MATERIALS & MEDIA (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); SOCIAL NETWORKING (72%); CATHOLICS & CATHOLICISM (60%); CLERGY & RELIGIOUS VOCATIONS (60%)
Organization: UNIVERSITY OF NOTRE DAME (94%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COLLEGES & UNIVERSITIES (89%); EDUCATION SYSTEMS & INSTITUTIONS (78%); SOFTWARE SERVICES & APPLICATIONS (78%); INFORMATION TECHNOLOGY INDUSTRY (77%); COLLEGE & UNIVERSITY PROFESSORS (73%); FOCUS GROUPS (70%)
Geographic: INDIANA, USA (79%)
Load-Date: October 10, 2024",positive,0.5008128881454468,balanced/neutral,[],['dignity'],['should'],[],0,1,1,0
2024,Unknown Title,"Byline: Leo S. Lo, Dean and Professor, College of University Libraries and Learning Sciences, University of New Mexico
Highlight: Where are the limits to using AI honestly and transparently? 3 philosophies can help the debate: deontological ethics, consequentialism and virtue ethics.
Body
Artificial intelligence can be used in countless ways - and the ethical headaches it raises are countless, too.
Consider ""adult content creators"" - not necessarily the first field that comes to mind. In 2024, there was a surge in AI-generated influencers on Instagram: fake models with faces made by AI, attached to stolen photos and videos of real models' bodies. Not only did the original content creators not consent to having their images used, but they were not compensated.
Across industries, workers encounter more immediate ethical questions about whether to use AI every day. In a trial by the U.K.-based law firm Ashurst, three AI systems dramatically sped up document review but missed subtle legal nuances that experienced lawyers would catch. Similarly, journalists must balance AI's efficiency for summarizing background research with the rigor required by fact-checking standards.
These examples highlight the growing tension between innovation and ethics. What do AI users owe the creators whose work forms the backbone of those technologies? How do we navigate a world where AI challenges the meaning of creativity - and humans' role in it?
As a dean overseeing university libraries, academic programs and the university press, I witness daily how students, staff and faculty grapple with generative AI. Looking at three different schools of ethics can help us go beyond gut reactions to address core questions about how to use AI tools with honesty and integrity. 
Rights and duties
At its core, deontological ethics asks what fundamental duties people have toward one another - what's right or wrong, regardless of consequences.
Applied to AI, this approach focuses on basic rights and obligations. Through this lens, we must examine not only what AI enables us to do, but what responsibilities we have toward other people in our professional communities.
For instance, AI systems often learn by analyzing vast collections of human-created work, which challenges traditional notions of creative rights. A photographer whose work was used to train an AI model might question whether their labor has been appropriated without fair compensation - whether their basic ownership of their own work has been violated.
On the other hand, deontological ethics also emphasizes people's positive duties toward others - responsibilities that certain AI programs can assist in fulfilling. The nonprofit Tarjimly aims to use an AI-powered platform to connect refugees with volunteer translators. The organization's AI tool also gives real-time translation, which the human volunteers can revise for accuracy.
This dual focus on respecting creators' rights while fulfilling duties to other people illustrates how deontological ethics can guide ethical AI use.
AI's implications
Another approach comes from consequentialism, a philosophy that evaluates actions by their outcomes. This perspective shifts focus from individuals' rights and responsibilities to AI's broader effects. Do the potential boons of generative AI justify the economic and cultural impact? Is AI advancing innovation at the expense of creative livelihoods?
This ethical tension of weighing benefits and harms drives current debates - and lawsuits. Organizations such as Getty Images have taken legal action to protect human contributors' work from unauthorized AI training. Some platforms that use AI to create images, such as DeviantArt and Shutterstock, are offering artists options to opt out or receive compensation, a shift toward recognizing creative rights in the AI era.
The implications of adopting AI extend far beyond individual creators' rights and could fundamentally reshape creative industries. Publishing, entertainment and design sectors face unprecedented automation, which could affect workers along the entire production pipeline, from conceptualization to distribution. 
These disruptions have sparked significant resistance. In 2023, for example, labor unions for screenwriters and actors initiated strikes that brought Hollywood productions to a halt.
A consequentialist approach, however, compels us to look beyond immediate economic threats, or individuals' rights and responsibilities, to examine AI's broader societal impact. From this wider perspective, consequentialism suggests that concerns about social harms must be balanced with potential societal benefits. 
Sophisticated AI tools are already transforming fields such as scientific research, accelerating drug discovery and climate change solutions. In education, AI supports personalized learning for struggling students. Small businesses and entrepreneurs in developing regions can now compete globally by accessing professional-level capabilities once reserved for larger enterprises. 
Even artists need to weigh the pros and cons of AI's impact: It's not just negative. AI has given rise to new ways to express creativity, such as AI-generated music and visual art. These technologies enable complex compositions and visuals that might be challenging to produce by hand - making it an especially valuable collaborator for artists with disabilities.
Character for the AI era
Virtue ethics, the third approach, asks how using AI shapes who users become as professionals and people. Unlike approaches that focus on rules or consequences, this framework centers on character and judgment.
Recent cases illustrate what's at stake. A lawyer's reliance on AI-generated legal citations led to court sanctions, highlighting how automation can erode professional diligence. In health care, discovering racial bias in medical AI chatbots forced providers to confront how automation might compromise their commitment to equitable care.
These failures reveal a deeper truth: Mastering AI requires cultivating sound judgment. Lawyers' professional integrity demands that they verify AI-generated claims. Doctors' commitment to patient welfare requires questioning AI recommendations that might perpetuate bias. Each decision to use or reject AI tools shapes not just immediate outcomes but professional character.
Individual workers often have limited control over how their workplaces implement AI, so it is all the more important that professional organizations develop clear guidelines. What's more, individuals need space to maintain professional integrity within their employers' rules to exercise their own sound judgment. 
Beyond asking ""Can AI do this task?"" organizations should consider how its implementation could affect workers' professional judgment and practice. Right now, technology is evolving faster than collective wisdom in using it, making deliberate reflection and virtue-driven practice more essential than ever.
Charting a path forward
Each of these three ethical frameworks illuminates different aspects of our society's AI dilemma.
Rights-based thinking highlights our obligations to creators whose work trains AI systems. Consequentialism reveals both the broader benefits of AI democratization and its potential threats, including to creative livelihoods. Virtue ethics shows how individual choices about AI shape not just outcomes but professional character.
Together, these perspectives suggest that ethical AI use requires more than new guidelines. It requires rethinking how creative work is valued.
The debate about AI often feels like a battle between innovation and tradition. But this framing misses the real challenge: developing approaches that honor both human creativity and technological progress and allow them to enhance each other. At its core, that balance depends on values.
Leo S. Lo is affiliated with the Association of College and Research Libraries (ACRL).
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (79%); TECHNOLOGY (79%); APPROPRIATIONS (78%); ASSOCIATIONS & ORGANIZATIONS (78%); FACT CHECKING (78%); SEX WORKERS (78%); SOCIAL MEDIA INFLUENCERS (78%); PHOTOGRAPHY SERVICES (76%); EDUCATION & TRAINING (75%); EDUCATIONAL INSTITUTION EMPLOYEES (75%); LAW & LEGAL SYSTEM (75%); LAWYERS (75%); VOLUNTEERS (75%); WITNESSES (75%); ACADEMIC LIBRARIES (74%); LEGAL SERVICES (74%); PROFESSIONAL WORKERS (74%); LIBRARIES (71%); VISUAL ARTISTS (71%); HUMAN RIGHTS (69%); WRITERS (69%); NONPROFIT ORGANIZATIONS (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (79%); MEDIA & TELECOMMUNICATIONS (78%); SEX WORKERS (78%); SOCIAL MEDIA INFLUENCERS (78%); PHOTOGRAPHY SERVICES (76%); LAWYERS (75%); ACADEMIC LIBRARIES (74%); LEGAL SERVICES (74%); TRANSLATORS & INTERPRETERS (74%); LIBRARIES (71%); VISUAL ARTISTS (71%); WRITERS (69%)
Geographic: UNITED STATES (90%); UNITED KINGDOM (78%)
Load-Date: November 27, 2024","Artificial intelligence can be used in countless ways - and the ethical headaches it raises are countless, too.
Consider ""adult content creators"" - not necessarily the first field that comes to mind. In 2024, there was a surge in AI-generated influencers on Instagram: fake models with faces made by AI, attached to stolen photos and videos of real models' bodies. Not only did the original content creators not consent to having their images used, but they were not compensated.
Across industries, workers encounter more immediate ethical questions about whether to use AI every day. In a trial by the U.K.-based law firm Ashurst, three AI systems dramatically sped up document review but missed subtle legal nuances that experienced lawyers would catch. Similarly, journalists must balance AI's efficiency for summarizing background research with the rigor required by fact-checking standards.
These examples highlight the growing tension between innovation and ethics. What do AI users owe the creators whose work forms the backbone of those technologies? How do we navigate a world where AI challenges the meaning of creativity - and humans' role in it?
As a dean overseeing university libraries, academic programs and the university press, I witness daily how students, staff and faculty grapple with generative AI. Looking at three different schools of ethics can help us go beyond gut reactions to address core questions about how to use AI tools with honesty and integrity. 
Rights and duties
At its core, deontological ethics asks what fundamental duties people have toward one another - what's right or wrong, regardless of consequences.
Applied to AI, this approach focuses on basic rights and obligations. Through this lens, we must examine not only what AI enables us to do, but what responsibilities we have toward other people in our professional communities.
For instance, AI systems often learn by analyzing vast collections of human-created work, which challenges traditional notions of creative rights. A photographer whose work was used to train an AI model might question whether their labor has been appropriated without fair compensation - whether their basic ownership of their own work has been violated.
On the other hand, deontological ethics also emphasizes people's positive duties toward others - responsibilities that certain AI programs can assist in fulfilling. The nonprofit Tarjimly aims to use an AI-powered platform to connect refugees with volunteer translators. The organization's AI tool also gives real-time translation, which the human volunteers can revise for accuracy.
This dual focus on respecting creators' rights while fulfilling duties to other people illustrates how deontological ethics can guide ethical AI use.
AI's implications
Another approach comes from consequentialism, a philosophy that evaluates actions by their outcomes. This perspective shifts focus from individuals' rights and responsibilities to AI's broader effects. Do the potential boons of generative AI justify the economic and cultural impact? Is AI advancing innovation at the expense of creative livelihoods?
This ethical tension of weighing benefits and harms drives current debates - and lawsuits. Organizations such as Getty Images have taken legal action to protect human contributors' work from unauthorized AI training. Some platforms that use AI to create images, such as DeviantArt and Shutterstock, are offering artists options to opt out or receive compensation, a shift toward recognizing creative rights in the AI era.
The implications of adopting AI extend far beyond individual creators' rights and could fundamentally reshape creative industries. Publishing, entertainment and design sectors face unprecedented automation, which could affect workers along the entire production pipeline, from conceptualization to distribution. 
These disruptions have sparked significant resistance. In 2023, for example, labor unions for screenwriters and actors initiated strikes that brought Hollywood productions to a halt.
A consequentialist approach, however, compels us to look beyond immediate economic threats, or individuals' rights and responsibilities, to examine AI's broader societal impact. From this wider perspective, consequentialism suggests that concerns about social harms must be balanced with potential societal benefits. 
Sophisticated AI tools are already transforming fields such as scientific research, accelerating drug discovery and climate change solutions. In education, AI supports personalized learning for struggling students. Small businesses and entrepreneurs in developing regions can now compete globally by accessing professional-level capabilities once reserved for larger enterprises. 
Even artists need to weigh the pros and cons of AI's impact: It's not just negative. AI has given rise to new ways to express creativity, such as AI-generated music and visual art. These technologies enable complex compositions and visuals that might be challenging to produce by hand - making it an especially valuable collaborator for artists with disabilities.
Character for the AI era
Virtue ethics, the third approach, asks how using AI shapes who users become as professionals and people. Unlike approaches that focus on rules or consequences, this framework centers on character and judgment.
Recent cases illustrate what's at stake. A lawyer's reliance on AI-generated legal citations led to court sanctions, highlighting how automation can erode professional diligence. In health care, discovering racial bias in medical AI chatbots forced providers to confront how automation might compromise their commitment to equitable care.
These failures reveal a deeper truth: Mastering AI requires cultivating sound judgment. Lawyers' professional integrity demands that they verify AI-generated claims. Doctors' commitment to patient welfare requires questioning AI recommendations that might perpetuate bias. Each decision to use or reject AI tools shapes not just immediate outcomes but professional character.
Individual workers often have limited control over how their workplaces implement AI, so it is all the more important that professional organizations develop clear guidelines. What's more, individuals need space to maintain professional integrity within their employers' rules to exercise their own sound judgment. 
Beyond asking ""Can AI do this task?"" organizations should consider how its implementation could affect workers' professional judgment and practice. Right now, technology is evolving faster than collective wisdom in using it, making deliberate reflection and virtue-driven practice more essential than ever.
Charting a path forward
Each of these three ethical frameworks illuminates different aspects of our society's AI dilemma.
Rights-based thinking highlights our obligations to creators whose work trains AI systems. Consequentialism reveals both the broader benefits of AI democratization and its potential threats, including to creative livelihoods. Virtue ethics shows how individual choices about AI shape not just outcomes but professional character.
Together, these perspectives suggest that ethical AI use requires more than new guidelines. It requires rethinking how creative work is valued.
The debate about AI often feels like a battle between innovation and tradition. But this framing misses the real challenge: developing approaches that honor both human creativity and technological progress and allow them to enhance each other. At its core, that balance depends on values.
Leo S. Lo is affiliated with the Association of College and Research Libraries (ACRL).
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (79%); TECHNOLOGY (79%); APPROPRIATIONS (78%); ASSOCIATIONS & ORGANIZATIONS (78%); FACT CHECKING (78%); SEX WORKERS (78%); SOCIAL MEDIA INFLUENCERS (78%); PHOTOGRAPHY SERVICES (76%); EDUCATION & TRAINING (75%); EDUCATIONAL INSTITUTION EMPLOYEES (75%); LAW & LEGAL SYSTEM (75%); LAWYERS (75%); VOLUNTEERS (75%); WITNESSES (75%); ACADEMIC LIBRARIES (74%); LEGAL SERVICES (74%); PROFESSIONAL WORKERS (74%); LIBRARIES (71%); VISUAL ARTISTS (71%); HUMAN RIGHTS (69%); WRITERS (69%); NONPROFIT ORGANIZATIONS (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (79%); MEDIA & TELECOMMUNICATIONS (78%); SEX WORKERS (78%); SOCIAL MEDIA INFLUENCERS (78%); PHOTOGRAPHY SERVICES (76%); LAWYERS (75%); ACADEMIC LIBRARIES (74%); LEGAL SERVICES (74%); TRANSLATORS & INTERPRETERS (74%); LIBRARIES (71%); VISUAL ARTISTS (71%); WRITERS (69%)
Geographic: UNITED STATES (90%); UNITED KINGDOM (78%)
Load-Date: November 27, 2024",negative,0.515436053276062,balanced/neutral,"['bias', 'transparency', 'human rights', 'consent']","['deontological', 'virtue ethics', 'character', 'consequentialism', 'consequentialist']","['standards', 'guidelines', 'framework', 'law', 'should', 'must', 'need to', 'suggest']","['generative ai', 'ai model']",4,5,8,2
2024,Unknown Title,"Body
 In an era where Artificial Intelligence (AI) is advancing at a rapid pace, Vietnam is taking steps to ensure that its AI development is ethical and socially responsible, according to an article recently published on Singaporean site opengovasia.com.
The article said the Vietnam Software and IT Services Association (VINASA) has unveiled the formation of the AI Ethics Committee. The move places Vietnam firmly on the map of nations taking proactive measures to ensure that AI responsibly benefits society.
This committee's primary mission is to guide the nation's AI journey, ensuring that it not only adheres to ethical principles but also fosters innovation and aligns with societal values.
The AI Ethics Committee will play a crucial role in shaping Vietnam's AI policies, developing risk assessment standards, and advising the government on AI-related matters.
It will also act as a bridge for international cooperation in AI, ensuring that the country stays aligned with global efforts to create ethical frameworks for the emerging technology.
Professor Yoshua Bengio, who is the founder of the AI research institute Mila in Canada, expressed his support for the initiative, noting that the establishment of the committee was a significant step towards ensuring that Vietnam's AI future adheres to global standards of transparency, accountability, and societal benefit.
He praised the country's effort to take an ethical approach to AI development, which he believes is essential for fostering public trust and confidence in the technology.
With AI increasingly playing a central role in shaping the future, Vietnam's AI Ethics Committee marks a critical step in ensuring that the country's AI development is both innovative and ethically sound. As the global landscape continues to evolve, Vietnam's approach to AI ethics may serve as a model for other nations looking to navigate the complexities of this transformative technology, the Singaporean site said.
Classification
Language: English US
Publication-Type: Web Publication
Subject: ETHICS (92%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); TECHNOLOGY (90%); EMERGING TECHNOLOGY (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); STANDARDS & MEASUREMENTS (76%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); INTERNATIONAL RELATIONS (69%); COLLEGE & UNIVERSITY PROFESSORS (67%); RESEARCH INSTITUTES (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SOFTWARE SERVICES & APPLICATIONS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); COLLEGE & UNIVERSITY PROFESSORS (67%)
Geographic: VIETNAM (94%); CANADA (79%)
Load-Date: December 11, 2024","In an era where Artificial Intelligence (AI) is advancing at a rapid pace, Vietnam is taking steps to ensure that its AI development is ethical and socially responsible, according to an article recently published on Singaporean site opengovasia.com.
The article said the Vietnam Software and IT Services Association (VINASA) has unveiled the formation of the AI Ethics Committee. The move places Vietnam firmly on the map of nations taking proactive measures to ensure that AI responsibly benefits society.
This committee's primary mission is to guide the nation's AI journey, ensuring that it not only adheres to ethical principles but also fosters innovation and aligns with societal values.
The AI Ethics Committee will play a crucial role in shaping Vietnam's AI policies, developing risk assessment standards, and advising the government on AI-related matters.
It will also act as a bridge for international cooperation in AI, ensuring that the country stays aligned with global efforts to create ethical frameworks for the emerging technology.
Professor Yoshua Bengio, who is the founder of the AI research institute Mila in Canada, expressed his support for the initiative, noting that the establishment of the committee was a significant step towards ensuring that Vietnam's AI future adheres to global standards of transparency, accountability, and societal benefit.
He praised the country's effort to take an ethical approach to AI development, which he believes is essential for fostering public trust and confidence in the technology.
With AI increasingly playing a central role in shaping the future, Vietnam's AI Ethics Committee marks a critical step in ensuring that the country's AI development is both innovative and ethically sound. As the global landscape continues to evolve, Vietnam's approach to AI ethics may serve as a model for other nations looking to navigate the complexities of this transformative technology, the Singaporean site said.
Classification
Language: English US
Publication-Type: Web Publication
Subject: ETHICS (92%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); TECHNOLOGY (90%); EMERGING TECHNOLOGY (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); STANDARDS & MEASUREMENTS (76%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); INTERNATIONAL RELATIONS (69%); COLLEGE & UNIVERSITY PROFESSORS (67%); RESEARCH INSTITUTES (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SOFTWARE SERVICES & APPLICATIONS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); COLLEGE & UNIVERSITY PROFESSORS (67%)
Geographic: VIETNAM (94%); CANADA (79%)
Load-Date: December 11, 2024",positive,0.6066220998764038,balanced/neutral,"['transparency', 'accountability', 'security']",[],"['regulation', 'policy', 'standards']",[],3,0,3,0
2024,Unknown Title,"Dateline: India 
Body
India, Sept. 20 -- As technology rapidly evolves, computer scientists and engineers face a growing number of ethical dilemmas. From safeguarding privacy and data security to mitigating social bias in AI and ensuring the responsible development of autonomous systems, the need for ethical decision-making is more urgent than ever. What are the key ethical challenges today, and what skills are essential to navigate them? How crucial is collaboration between academia, industry, and policymakers in balancing innovation with responsibility? Prof. Vijaysekhar Chellaboina, Dean of the School of Computer Science at UPES, shares his insights on these pressing issues in an email interview with Hindustan Times Digital.
The key ethical issues for computer scientists include privacy and data security, social bias in AI and machine learning, and safety concerns in AI-driven autonomous systems like self-driving cars. Privacy and data security are significant challenges, requiring a balance between the benefits of data collection and the protection of individual privacy. AI and machine learning also pose critical issues, as algorithms can unintentionally perpetuate societal biases. The development of autonomous systems raises important safety and ethical questions. Moreover, managing misinformation and content moderation on digital platforms, along with addressing environmental impact, energy consumption, e-waste, and the digital divide, are also crucial concerns.
To become ethical engineers, students need a strong ethical foundation, including knowledge of ethical theories and professional codes of conduct. Critical thinking and problem-solving skills are essential for analysing and resolving ethical dilemmas. Cultural and social awareness helps engineers consider the broader impacts of their work, while legal and regulatory knowledge ensures compliance with laws and standards. Effective communication and transparency are crucial for engaging stakeholders. Additionally, a commitment to sustainability, interdisciplinary collaboration, and continual learning enables engineers to address complex challenges responsibly and adapt to evolving ethical considerations in their field.
Computer scientists can balance innovation with responsibility by integrating ethical considerations into every stage of development. This involves critically assessing the potential social impacts of new technologies, such as privacy concerns, bias in algorithms, and environmental effects. Engaging with diverse stakeholders, including ethicists, policymakers, and affected communities, helps ensure that innovations align with societal values. Adhering to professional codes of conduct, staying informed about legal regulations, and fostering a culture of transparency and accountability within teams are also crucial. By prioritising ethical principles alongside technical advancement, computer scientists can drive innovation that benefits society responsibly.
AI and machine learning play a crucial role in ethical engineering by enabling the development of technologies that can address complex societal challenges. However, their application also raises significant ethical concerns, such as bias, privacy, and accountability. Ethical engineering in AI involves designing algorithms that are fair, transparent, and explainable, ensuring that they do not reinforce existing inequalities. Engineers must rigorously test AI systems for unintended consequences, adhere to ethical guidelines, and engage with diverse perspectives to avoid harmful impacts. By embedding ethical considerations into AI and machine learning, engineers can create responsible technologies that serve the broader good.
Industry encounters numerous challenges and opportunities to address ethical considerations through real-world experiences. Meanwhile, academia, through research and education, can create technological solutions to identify and prevent unethical behaviour. By analysing these instances, academia can provide students with valuable training in ethical practices, ensuring they are well-prepared to address ethical issues in emerging technologies. Each real-world case serves as a learning opportunity, helping students understand and navigate ethical dilemmas while developing new technologies. This collaboration between industry and academia is crucial for fostering responsible innovation and ethical behaviour in future engineers and technologists.
Policy and regulation play a vital role in guiding ethical engineering practices in computer science by setting clear standards and accountability mechanisms. They ensure that technologies are developed and deployed in ways that protect public interests, such as privacy, safety, and fairness. Regulations can mandate transparency, data protection, and bias mitigation, while policies can promote responsible innovation through incentives and guidelines. By providing a legal and ethical framework, policymakers help prevent the misuse of technology and encourage engineers to prioritise societal well-being. Collaboration between lawmakers, technologists, and ethicists is crucial to crafting effective, forward-thinking policies that adapt to rapid technological advances.
Published by HT Digital Content Services with permission from Hindustan Times. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); COMPUTER SCIENCE (93%); TECHNICIANS & TECHNOLOGICAL WORKERS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); PRIVACY RIGHTS (90%); TECHNOLOGY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); PROFESSIONAL WORKERS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CORPORATE SUSTAINABILITY (78%); DIGITAL DIVIDE (78%); EMERGING TECHNOLOGY (78%); ENVIRONMENTAL RESEARCH (78%); NEGATIVE SOCIETAL NEWS (78%); REGULATORY COMPLIANCE (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); INTERVIEWS (73%); DISINFORMATION & MISINFORMATION (72%); ENERGY & ENVIRONMENT (71%); ENVIRONMENT & NATURAL RESOURCES (66%); POLLUTION & ENVIRONMENTAL IMPACTS (66%)
Company:  AI SYSTEMS (50%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); COMPUTER SCIENCE (93%); INFORMATION SECURITY & PRIVACY (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); DATA PRIVACY (90%); DATA SECURITY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); AUTONOMOUS MOTOR VEHICLES (72%); ENERGY & UTILITIES (72%); ENERGY & ENVIRONMENT (71%); ENERGY CONSUMPTION (51%)
Geographic: INDIA (90%)
Load-Date: September 20, 2024","India, Sept. 20 -- As technology rapidly evolves, computer scientists and engineers face a growing number of ethical dilemmas. From safeguarding privacy and data security to mitigating social bias in AI and ensuring the responsible development of autonomous systems, the need for ethical decision-making is more urgent than ever. What are the key ethical challenges today, and what skills are essential to navigate them? How crucial is collaboration between academia, industry, and policymakers in balancing innovation with responsibility? Prof. Vijaysekhar Chellaboina, Dean of the School of Computer Science at UPES, shares his insights on these pressing issues in an email interview with Hindustan Times Digital.
The key ethical issues for computer scientists include privacy and data security, social bias in AI and machine learning, and safety concerns in AI-driven autonomous systems like self-driving cars. Privacy and data security are significant challenges, requiring a balance between the benefits of data collection and the protection of individual privacy. AI and machine learning also pose critical issues, as algorithms can unintentionally perpetuate societal biases. The development of autonomous systems raises important safety and ethical questions. Moreover, managing misinformation and content moderation on digital platforms, along with addressing environmental impact, energy consumption, e-waste, and the digital divide, are also crucial concerns.
To become ethical engineers, students need a strong ethical foundation, including knowledge of ethical theories and professional codes of conduct. Critical thinking and problem-solving skills are essential for analysing and resolving ethical dilemmas. Cultural and social awareness helps engineers consider the broader impacts of their work, while legal and regulatory knowledge ensures compliance with laws and standards. Effective communication and transparency are crucial for engaging stakeholders. Additionally, a commitment to sustainability, interdisciplinary collaboration, and continual learning enables engineers to address complex challenges responsibly and adapt to evolving ethical considerations in their field.
Computer scientists can balance innovation with responsibility by integrating ethical considerations into every stage of development. This involves critically assessing the potential social impacts of new technologies, such as privacy concerns, bias in algorithms, and environmental effects. Engaging with diverse stakeholders, including ethicists, policymakers, and affected communities, helps ensure that innovations align with societal values. Adhering to professional codes of conduct, staying informed about legal regulations, and fostering a culture of transparency and accountability within teams are also crucial. By prioritising ethical principles alongside technical advancement, computer scientists can drive innovation that benefits society responsibly.
AI and machine learning play a crucial role in ethical engineering by enabling the development of technologies that can address complex societal challenges. However, their application also raises significant ethical concerns, such as bias, privacy, and accountability. Ethical engineering in AI involves designing algorithms that are fair, transparent, and explainable, ensuring that they do not reinforce existing inequalities. Engineers must rigorously test AI systems for unintended consequences, adhere to ethical guidelines, and engage with diverse perspectives to avoid harmful impacts. By embedding ethical considerations into AI and machine learning, engineers can create responsible technologies that serve the broader good.
Industry encounters numerous challenges and opportunities to address ethical considerations through real-world experiences. Meanwhile, academia, through research and education, can create technological solutions to identify and prevent unethical behaviour. By analysing these instances, academia can provide students with valuable training in ethical practices, ensuring they are well-prepared to address ethical issues in emerging technologies. Each real-world case serves as a learning opportunity, helping students understand and navigate ethical dilemmas while developing new technologies. This collaboration between industry and academia is crucial for fostering responsible innovation and ethical behaviour in future engineers and technologists.
Policy and regulation play a vital role in guiding ethical engineering practices in computer science by setting clear standards and accountability mechanisms. They ensure that technologies are developed and deployed in ways that protect public interests, such as privacy, safety, and fairness. Regulations can mandate transparency, data protection, and bias mitigation, while policies can promote responsible innovation through incentives and guidelines. By providing a legal and ethical framework, policymakers help prevent the misuse of technology and encourage engineers to prioritise societal well-being. Collaboration between lawmakers, technologists, and ethicists is crucial to crafting effective, forward-thinking policies that adapt to rapid technological advances.
Published by HT Digital Content Services with permission from Hindustan Times. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htdigital.in
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); COMPUTER SCIENCE (93%); TECHNICIANS & TECHNOLOGICAL WORKERS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); PRIVACY RIGHTS (90%); TECHNOLOGY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); PROFESSIONAL WORKERS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CORPORATE SUSTAINABILITY (78%); DIGITAL DIVIDE (78%); EMERGING TECHNOLOGY (78%); ENVIRONMENTAL RESEARCH (78%); NEGATIVE SOCIETAL NEWS (78%); REGULATORY COMPLIANCE (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); INTERVIEWS (73%); DISINFORMATION & MISINFORMATION (72%); ENERGY & ENVIRONMENT (71%); ENVIRONMENT & NATURAL RESOURCES (66%); POLLUTION & ENVIRONMENTAL IMPACTS (66%)
Company:  AI SYSTEMS (50%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); COMPUTER SCIENCE (93%); INFORMATION SECURITY & PRIVACY (91%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER ENGINEERING (90%); DATA PRIVACY (90%); DATA SECURITY (90%); ENGINEERING (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (77%); COLLEGE & UNIVERSITY PROFESSORS (76%); ELECTRONIC WASTE (73%); AUTONOMOUS MOTOR VEHICLES (72%); ENERGY & UTILITIES (72%); ENERGY & ENVIRONMENT (71%); ENERGY CONSUMPTION (51%)
Geographic: INDIA (90%)
Load-Date: September 20, 2024",neutral,0.7734254002571106,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'safety', 'security', 'misinformation', 'disinformation', 'digital divide', 'environmental impact']",['fairness'],"['regulation', 'policy', 'standards', 'guidelines', 'framework', 'compliance', 'must']",['machine learning'],11,1,7,1
2024,Unknown Title,"Dateline: MCLEAN, Va., Dec. 20, 2024 
Body
PR NewswireMCLEAN, Va., Dec. 20, 2024 /PRNewswire/ -- CoVar, a leading developer of AI and machine learning solutions for the Department of Defense, has been awarded a multi-year contract with the Defense Advanced Research Projects Agency (DARPA) to support the Autonomy Standards and Ideals with Military Operational Values (ASIMOV) program. The goal of the program is to establish a framework that quantitatively measures the ethical readiness of autonomous systems, a crucial step as these systems gain widespread adoption across military and civilian sectors. 
 DARPA recognizes that as autonomy and AI become increasingly integrated into complex decision-making roles, it is essential to measure and validate the ethical capabilities of these technologies, not just their technical performance. ASIMOV will address this challenge by establishing a shared language for ethical autonomy, enabling the Developmental Testing/Operational Testing community to meaningfully and quantitatively assess the ethical complexity of specific military scenarios and evaluate the capability of autonomous systems to perform ethically within those scenarios. Additionally, the program will incorporate an Ethical, Legal, and Societal Implications (ELSI) group to advise participants and provide ongoing guidance throughout the project.CoVar will be responsible for developing an ethical testing infrastructure for autonomous systems called GEARS or Gauging Ethical Autonomous Reliable Systems. GEARS will define a newmathematics of ethicsby representing ethical scenarios and commander's intent with knowledge graphs that are suitable for both human and machine understanding and from which quantifiable ethical challenge ratings of specific scenarios can be derived.CoVar has formed a multidisciplinary team to address the challenges posed in the ASIMOV program. The team consists of Professors of Ethics, widely published authors in the fields of ethics and Artificial Intelligence/Machine Learning (AI/ML) trust, engineers and ethicists with combatant command experience, and Duality AI, whose digital twin platform, Falcon, empowers autonomous system simulation and comprehensive observable extraction.""If this work is successful, it will represent the first quantitative ELSI-based evaluation framework suitable for testing ethics of autonomous systems,"" said Dr. Pete Torrione, CTO of CoVar. ""This will empower the US Department of Defense to deploy AI/ML capable autonomous systems with a clear understanding of not only the technical capabilities of the systems, but also the ethics of their behaviors.""By participating in ASIMOV, CoVar will continue to be a leader in developing responsible AI/ML solutions for the Department of Defense and help to shape the future of testing and evaluation for ethical autonomous systems.For more information on CoVar's work, please visitwww.covar.com. For ASIMOV specific inquiries, please contact DARPA Public Affairs, .About CoVarCoVar has over ten years of experience innovating and implementing advanced artificial intelligence and machine learning (AI/ML) solutions for defense, industrial, commercial, and medical sectors. CoVar's research team of principal investigators are recognized subject matter experts in the field and lead teams capable of combining big-company reliability and traceability with small company agility and flexibility. The company has developed and delivered state-of-the-art implementations of advanced algorithms in easy-to-use software packages across multiple platforms and stacks. CoVar has repeatedly demonstrated the ability to provide end-to-end solutions that bring game-changing AI/ML technology to implemented software that reliably and effectively improve customer capability.   View original content to download multimedia:https://www.prnewswire.com/news-releases/covar-awarded-darpa-contract-to-define-ethical-standards-for-future-autonomous-systems-302337393.htmlSOURCE CoVar 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); PRESS RELEASES (91%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (90%); NATIONAL SECURITY & FOREIGN RELATIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEFENSE DEPARTMENTS (89%); INVESTIGATIONS (89%); MACHINE LEARNING (89%); ASSOCIATIONS & ORGANIZATIONS (78%); DEFENSE RESEARCH (78%); DIGITAL TWIN (78%); RESEARCH & DEVELOPMENT (78%); TECHNOLOGY (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (73%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (72%); WRITERS (50%); COVAR-got-contract (%); CON Contracts (%)
Company: CoVar
Organization: DEFENSE ADVANCED RESEARCH PROJECTS AGENCY (94%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEFENSE DEPARTMENTS (89%); MACHINE LEARNING (89%); DEFENSE RESEARCH (78%); DIGITAL TWIN (78%); DEFENSE INDUSTRY (73%); WRITERS (50%); CPR Computer; Electronics Products (%); ARO Aerospace; Defense (%); STW Computer Software (%)
Geographic: VIRGINIA, USA (92%); UNITED STATES (79%); Virginia
Load-Date: December 20, 2024","PR NewswireMCLEAN, Va., Dec. 20, 2024 /PRNewswire/ -- CoVar, a leading developer of AI and machine learning solutions for the Department of Defense, has been awarded a multi-year contract with the Defense Advanced Research Projects Agency (DARPA) to support the Autonomy Standards and Ideals with Military Operational Values (ASIMOV) program. The goal of the program is to establish a framework that quantitatively measures the ethical readiness of autonomous systems, a crucial step as these systems gain widespread adoption across military and civilian sectors. 
 DARPA recognizes that as autonomy and AI become increasingly integrated into complex decision-making roles, it is essential to measure and validate the ethical capabilities of these technologies, not just their technical performance. ASIMOV will address this challenge by establishing a shared language for ethical autonomy, enabling the Developmental Testing/Operational Testing community to meaningfully and quantitatively assess the ethical complexity of specific military scenarios and evaluate the capability of autonomous systems to perform ethically within those scenarios. Additionally, the program will incorporate an Ethical, Legal, and Societal Implications (ELSI) group to advise participants and provide ongoing guidance throughout the project.CoVar will be responsible for developing an ethical testing infrastructure for autonomous systems called GEARS or Gauging Ethical Autonomous Reliable Systems. GEARS will define a newmathematics of ethicsby representing ethical scenarios and commander's intent with knowledge graphs that are suitable for both human and machine understanding and from which quantifiable ethical challenge ratings of specific scenarios can be derived.CoVar has formed a multidisciplinary team to address the challenges posed in the ASIMOV program. The team consists of Professors of Ethics, widely published authors in the fields of ethics and Artificial Intelligence/Machine Learning (AI/ML) trust, engineers and ethicists with combatant command experience, and Duality AI, whose digital twin platform, Falcon, empowers autonomous system simulation and comprehensive observable extraction.""If this work is successful, it will represent the first quantitative ELSI-based evaluation framework suitable for testing ethics of autonomous systems,"" said Dr. Pete Torrione, CTO of CoVar. ""This will empower the US Department of Defense to deploy AI/ML capable autonomous systems with a clear understanding of not only the technical capabilities of the systems, but also the ethics of their behaviors.""By participating in ASIMOV, CoVar will continue to be a leader in developing responsible AI/ML solutions for the Department of Defense and help to shape the future of testing and evaluation for ethical autonomous systems.For more information on CoVar's work, please visitwww.covar.com. For ASIMOV specific inquiries, please contact DARPA Public Affairs, .About CoVarCoVar has over ten years of experience innovating and implementing advanced artificial intelligence and machine learning (AI/ML) solutions for defense, industrial, commercial, and medical sectors. CoVar's research team of principal investigators are recognized subject matter experts in the field and lead teams capable of combining big-company reliability and traceability with small company agility and flexibility. The company has developed and delivered state-of-the-art implementations of advanced algorithms in easy-to-use software packages across multiple platforms and stacks. CoVar has repeatedly demonstrated the ability to provide end-to-end solutions that bring game-changing AI/ML technology to implemented software that reliably and effectively improve customer capability.   View original content to download multimedia:https://www.prnewswire.com/news-releases/covar-awarded-darpa-contract-to-define-ethical-standards-for-future-autonomous-systems-302337393.htmlSOURCE CoVar 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); PRESS RELEASES (91%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (90%); NATIONAL SECURITY & FOREIGN RELATIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEFENSE DEPARTMENTS (89%); INVESTIGATIONS (89%); MACHINE LEARNING (89%); ASSOCIATIONS & ORGANIZATIONS (78%); DEFENSE RESEARCH (78%); DIGITAL TWIN (78%); RESEARCH & DEVELOPMENT (78%); TECHNOLOGY (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (73%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (72%); WRITERS (50%); COVAR-got-contract (%); CON Contracts (%)
Company: CoVar
Organization: DEFENSE ADVANCED RESEARCH PROJECTS AGENCY (94%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEFENSE DEPARTMENTS (89%); MACHINE LEARNING (89%); DEFENSE RESEARCH (78%); DIGITAL TWIN (78%); DEFENSE INDUSTRY (73%); WRITERS (50%); CPR Computer; Electronics Products (%); ARO Aerospace; Defense (%); STW Computer Software (%)
Geographic: VIRGINIA, USA (92%); UNITED STATES (79%); Virginia
Load-Date: December 20, 2024",neutral,0.7422149181365967,balanced/neutral,"['security', 'autonomy', 'agency']",['autonomy'],"['standards', 'framework']",['machine learning'],3,1,2,1
2024,Unknown Title,"Body
Link to Story
LISBON, Portugal, Dec. 3, 2024PRNewswire/ -- Altar, a leading technology consulting firm, proudly announces its partnership with Dr. Rumman Chowdhury, an acclaimed AI ethics expert. This collaboration is a key milestone in promoting responsible AI globally.
About Altar
Altar is a Lisbon-based, award-winning software development company founded by ex-startup founders. Specializing in product development from ideation to market-ready solutions, the firm leverages strategic insight and cutting-edge technology to turn ideas into scalable, impactful digital products. By focusing on startups and innovative companies, Altar empowers businesses to drive industry transformation.
About Dr. Rumman Chowdhury
Dr. Rumman Chowdhury is a leading figure in AI ethics, dedicated to bridging the gap between technology and humanity. She leads Parity Consulting and the Parity Responsible Innovation Fund and serves as a Responsible AI Fellow at Harvard's Berkman Klein Center. Known for her pioneering work on mitigating algorithmic biases, Dr. Chowdhury is driven by a passion for advancing responsible technology.
The Project: AI Model Public Feedback System
Following the major AI regulation meeting last year with tech leaders like Sundar Pichai, Elon Musk, Mark Zuckerberg, and Sam Altman, Dr. Chowdhury reached out to Altar to develop an AI model public feedback system. This innovative project aims to democratize AI evaluation through a community-driven approach, using the ""wisdom of the crowds"" to establish ethical benchmarks for AI models.
Project Highlights
Statements from Leaders
Rui Lourenço, Managing Director of Altar, said: ""Working with Dr. Chowdhury is a privilege that strengthens our commitment to responsible technology. Her expertise and passion for ethical AI perfectly align with our vision to create impactful solutions that serve society with integrity.""
Dr. Chowdhury added: ""Our partnership aims to make AI ethics accessible and actionable. Empowering users to evaluate AI models brings us closer to transparent and equitable tech systems.""
Future Outlook
This project marks the beginning of a broader initiative by Altar and Dr. Chowdhury to embed ethics throughout the AI lifecycle, from development to deployment.
Contact Information:
For more information about this partnership or Altar's services, please contact:
Rui Lourenço(CMO & Partner)
+351 963 630 105
[email protected]
Email: [email protected]
Website:
Follow Us:
LinkedIn
Twitter
Relevant Links:
SOURCE Altar
WANT YOUR COMPANY'S NEWS FEATURED ON PRNEWSWIRE?
440k+
Newsrooms &
Influencers
9k+
Digital Media
Outlets
270k+
Journalists
Opted In
GET STARTEDMENAFN03122024003732001241ID1108951634
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); TECHNOLOGY (90%); INTERNET SOCIAL NETWORKING (87%); EMERGING TECHNOLOGY (78%); ENTREPRENEURSHIP (78%); PRODUCT DEVELOPMENT (77%); SOCIAL MEDIA INFLUENCERS (77%); PRODUCT INNOVATION (76%); PRODUCT MANAGEMENT (76%); WRITERS (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); MANAGERS & SUPERVISORS (68%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); CONSULTING SERVICES (90%); INTERNET SOCIAL NETWORKING (87%); SOFTWARE SERVICES & APPLICATIONS (78%); SOCIAL MEDIA INFLUENCERS (77%); WRITERS (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); COMPUTER SOFTWARE (57%); SOFTWARE DEVELOPMENT & ENGINEERING (57%)
Person: SAM ALTMAN (79%); ELON MUSK (77%); MARK ZUCKERBERG (72%); SUNDAR PICHAI (70%)
Geographic: LISBON, PORTUGAL (73%); PORTUGAL (78%)
Load-Date: March 5, 2025","Link to Story
LISBON, Portugal, Dec. 3, 2024PRNewswire/ -- Altar, a leading technology consulting firm, proudly announces its partnership with Dr. Rumman Chowdhury, an acclaimed AI ethics expert. This collaboration is a key milestone in promoting responsible AI globally.
About Altar
Altar is a Lisbon-based, award-winning software development company founded by ex-startup founders. Specializing in product development from ideation to market-ready solutions, the firm leverages strategic insight and cutting-edge technology to turn ideas into scalable, impactful digital products. By focusing on startups and innovative companies, Altar empowers businesses to drive industry transformation.
About Dr. Rumman Chowdhury
Dr. Rumman Chowdhury is a leading figure in AI ethics, dedicated to bridging the gap between technology and humanity. She leads Parity Consulting and the Parity Responsible Innovation Fund and serves as a Responsible AI Fellow at Harvard's Berkman Klein Center. Known for her pioneering work on mitigating algorithmic biases, Dr. Chowdhury is driven by a passion for advancing responsible technology.
The Project: AI Model Public Feedback System
Following the major AI regulation meeting last year with tech leaders like Sundar Pichai, Elon Musk, Mark Zuckerberg, and Sam Altman, Dr. Chowdhury reached out to Altar to develop an AI model public feedback system. This innovative project aims to democratize AI evaluation through a community-driven approach, using the ""wisdom of the crowds"" to establish ethical benchmarks for AI models.
Project Highlights
Statements from Leaders
Rui Lourenço, Managing Director of Altar, said: ""Working with Dr. Chowdhury is a privilege that strengthens our commitment to responsible technology. Her expertise and passion for ethical AI perfectly align with our vision to create impactful solutions that serve society with integrity.""
Dr. Chowdhury added: ""Our partnership aims to make AI ethics accessible and actionable. Empowering users to evaluate AI models brings us closer to transparent and equitable tech systems.""
Future Outlook
This project marks the beginning of a broader initiative by Altar and Dr. Chowdhury to embed ethics throughout the AI lifecycle, from development to deployment.
Contact Information:
For more information about this partnership or Altar's services, please contact:
Rui Lourenço(CMO & Partner)
+351 963 630 105
[email protected]
Email: [email protected]
Website:
Follow Us:
LinkedIn
Twitter
Relevant Links:
SOURCE Altar
WANT YOUR COMPANY'S NEWS FEATURED ON PRNEWSWIRE?
440k+
Newsrooms &
Influencers
9k+
Digital Media
Outlets
270k+
Journalists
Opted In
GET STARTEDMENAFN03122024003732001241ID1108951634
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); TECHNOLOGY (90%); INTERNET SOCIAL NETWORKING (87%); EMERGING TECHNOLOGY (78%); ENTREPRENEURSHIP (78%); PRODUCT DEVELOPMENT (77%); SOCIAL MEDIA INFLUENCERS (77%); PRODUCT INNOVATION (76%); PRODUCT MANAGEMENT (76%); WRITERS (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); MANAGERS & SUPERVISORS (68%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); CONSULTING SERVICES (90%); INTERNET SOCIAL NETWORKING (87%); SOFTWARE SERVICES & APPLICATIONS (78%); SOCIAL MEDIA INFLUENCERS (77%); WRITERS (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); COMPUTER SOFTWARE (57%); SOFTWARE DEVELOPMENT & ENGINEERING (57%)
Person: SAM ALTMAN (79%); ELON MUSK (77%); MARK ZUCKERBERG (72%); SUNDAR PICHAI (70%)
Geographic: LISBON, PORTUGAL (73%); PORTUGAL (78%)
Load-Date: March 5, 2025",positive,0.8578763008117676,balanced/neutral,[],[],"['regulation', 'policy', 'governance']",['ai model'],0,0,3,1
2024,Unknown Title,"Byline: Targeted News Service
Dateline: MINNEAPOLIS, Minnesota 
Body
Taft, a law firm, issued the following news:
Cari Sheehan, assistant general counsel at Taft, presented in the Rossdale CLE program titled ""Using Artificial Intelligence & ChatGPT Law in 2025"" on Nov. 21. Her presentation covered Implementing Artificial Intelligence (AI), ChatGPT, and AI-Powered Technology in Law Practice, AI Legal Applications, Limits and Weaknesses of AI, and Avoiding Legal Ethical Pitfalls.
With over 15 years of legal experience in civil litigation, conflicts of interest, and professional responsibility, Sheehan serves as the firm's Assistant General Counsel. In this role, she advises firm attorneys with respect to ethics compliance, risk prevention, and conflicts of interest.
In addition, she assists in the review and negotiation of outside counsel guidelines, conflict waivers and engagement letters, and other items with ethical implications.
In addition, she assists in providing ethical training and education within the firm to its attorneys and staff. Sheehan is an Adjunct Professor at the IU Robert H. McKinney School where she teaches Professional Responsibility.
She is also a former Assistant Clinical Professor of Business Law and Ethics at the Kelley School of Business. She is passionate about promoting ethical awareness, integrity, and professionalism in the legal and business fields and contributing to the advancement of knowledge and practice in these domains.
* * *
Original text here: https://www.taftlaw.com/news-events/news/sheehan-to-present-in-rossdale-group-cle-program/
[Category: BizLaw/Legal]
MSTRUCK-8949544 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: LAWYERS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); BUSINESS EDUCATION (90%); CHATBOTS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CONFLICTS OF INTEREST (90%); CORPORATE COUNSEL (90%); GENERATIVE AI (90%); LAW & LEGAL SYSTEM (90%); LEGAL SERVICES (90%); PROFESSIONAL CONTINUING EDUCATION (90%); PROFESSIONAL WORKERS (90%); TEACHING & TEACHERS (90%); EDUCATION & TRAINING (78%); LAW SCHOOLS (78%); LITIGATION (73%)
Industry: LAWYERS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); CHATBOTS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CORPORATE COUNSEL (90%); GENERATIVE AI (90%); LEGAL SERVICES (90%); LAW SCHOOLS (78%)
Geographic: MINNEAPOLIS, MN, USA (59%); MINNESOTA, USA (59%)
Load-Date: December 4, 2024","Taft, a law firm, issued the following news:
Cari Sheehan, assistant general counsel at Taft, presented in the Rossdale CLE program titled ""Using Artificial Intelligence & ChatGPT Law in 2025"" on Nov. 21. Her presentation covered Implementing Artificial Intelligence (AI), ChatGPT, and AI-Powered Technology in Law Practice, AI Legal Applications, Limits and Weaknesses of AI, and Avoiding Legal Ethical Pitfalls.
With over 15 years of legal experience in civil litigation, conflicts of interest, and professional responsibility, Sheehan serves as the firm's Assistant General Counsel. In this role, she advises firm attorneys with respect to ethics compliance, risk prevention, and conflicts of interest.
In addition, she assists in the review and negotiation of outside counsel guidelines, conflict waivers and engagement letters, and other items with ethical implications.
In addition, she assists in providing ethical training and education within the firm to its attorneys and staff. Sheehan is an Adjunct Professor at the IU Robert H. McKinney School where she teaches Professional Responsibility.
She is also a former Assistant Clinical Professor of Business Law and Ethics at the Kelley School of Business. She is passionate about promoting ethical awareness, integrity, and professionalism in the legal and business fields and contributing to the advancement of knowledge and practice in these domains.
* * *
Original text here: https://www.taftlaw.com/news-events/news/sheehan-to-present-in-rossdale-group-cle-program/
[Category: BizLaw/Legal]
MSTRUCK-8949544 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: LAWYERS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); BUSINESS EDUCATION (90%); CHATBOTS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CONFLICTS OF INTEREST (90%); CORPORATE COUNSEL (90%); GENERATIVE AI (90%); LAW & LEGAL SYSTEM (90%); LEGAL SERVICES (90%); PROFESSIONAL CONTINUING EDUCATION (90%); PROFESSIONAL WORKERS (90%); TEACHING & TEACHERS (90%); EDUCATION & TRAINING (78%); LAW SCHOOLS (78%); LITIGATION (73%)
Industry: LAWYERS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); CHATBOTS (90%); COLLEGE & UNIVERSITY PROFESSORS (90%); CORPORATE COUNSEL (90%); GENERATIVE AI (90%); LEGAL SERVICES (90%); LAW SCHOOLS (78%)
Geographic: MINNEAPOLIS, MN, USA (59%); MINNESOTA, USA (59%)
Load-Date: December 4, 2024",neutral,0.8622578978538513,balanced/neutral,[],[],"['regulation', 'policy', 'guidelines', 'law', 'compliance']","['generative ai', 'chatgpt']",0,0,5,2
2024,Unknown Title,"Byline: wguoyu@fudan.edu.cn
Body
Ethics committees in China began in the 1990s in hospital settings, and focused on physician virtues and physician–patient relationships. Since the turn of the century, the Chinese public and academics have also become increasingly concerned about the ethical challenges posed by science and technology.
Guoyu Wang
In response to these concerns, the Ministry of Health issued legislation (《涉及人的生物医学研究伦理审查办法》) in 2007 that required the establishment of three-level ethics committees: the Ministry of Health, provincial and municipal, and institutional ethics committees.
In November 2018, however, the scientist Jiankui He, while on leave from his university position, declared that he had created the world’s first gene-edited babies. His work was not rigorously reviewed by a qualified ethics committee and the ethics documents were forged. This incident shocked the world. It also catalysed the formation of the National Ethics Committee of China, which is now responsible for guiding and coordinating the construction of the national science and technology ethics governance system. Following this, government guidance (《关于加强科技伦理治理的意见》) in March 2022 called for improved governance of science and technology ethics. Subsequently, more than a dozen provinces have established local ethics committees. Institutional ethics committees have also sprung up like mushrooms after a rain.
More recently, further regulation (《科技伦理审查办法（试行）》) in October 2023 specified that seven research activities (including research on the introduction of human stem cells into animal embryos, and clinical research on invasive brain–computer interfaces) need to be reported to or approved by the higher-level ethics committee or even the National Ethics Committee. This is to ensure an ‘ethics first’ approach.
Risk prevention and control, protecting individual rights and social well-being, and promoting responsible innovation are the main aims of the ethical review. I have seen first-hand the value of ethics committees, especially when research involves vulnerable populations such as minors and people with mental illness. With the rapid development of interdisciplinary science and technology, many researchers do not have a medical or life science background themselves and lack basic bioethics education, which makes ethical review increasingly important.
Members of institutional ethics committee generally consist of experts from different disciplines and public representatives. They either possess ‘dispositional knowledge’ (that is, positive knowledge of causes, effects and means) in the natural and technical sciences or have ‘orientational knowledge’ (that is, regulative knowledge of (justified) goals and purposes) in the humanities and social sciences. Different knowledge backgrounds bring various perspectives, positions and ways of observing problems. These advantages cannot be matched by the limited rationality of a single individual. Given that scientific research, especially in areas such as artificial intelligence and synthetic biology, is becoming increasingly complex and uncertain, it is more crucial than ever to have such a committee with diverse perspectives.
In most cases, our ethics committees not only point out the problems but also help the project applicants to modify and improve the research plan so that it complies with national laws and regulations, and internationally recognized ethical norms. According to the requirements set forth by the Natural Science Foundation of China (NSFC), applications for NSFC funding must undergo ethical review. As a result, each year in early March, the ethics committee convenes for several days to scrutinize these projects. Particular attention is paid to aspects such as the drafting of informed consent documents and the recruitment of volunteers. Occasionally, recruitment posters may use inappropriate promises to attract volunteers, which prompts the ethics committees to ask for and assist in their revision. Meanwhile, some scientists obtain research samples from hospitals through personal connection or simple partnerships. They do not realize that such cooperation is neither legal nor ethical, and this is also where ethics committees have a vital role. Furthermore, scientific journals usually mandate that research projects undergo ethics review if they are to be considered for publication. Consequently, researchers may proactively seek guidance and support from ethics committees. In this manner, ethical review serves as a form of assistance in promoting responsible research practices.
The review process also reflects the openness and transparency of science. Although most scientists acknowledge the norms of research ethics, there is a difference between recognizing principles and consciously observing them in practice. In my opinion, the temptation of wealth and the pursuit of fame and fortune sometimes cause people to avoid moral constraints, intentionally or unintentionally. Without the external supervision of an ethics committee and an open and transparent ethical review mechanism, it would be difficult to ensure that incidents similar to that of Jiankui He will never happen again.
Some believe that the review by ethics committees may limit or even hinder scientific research. Indeed, some ethical reviews are formalistic and poorly standardized, and some people think that ethics review is a ‘rubber stamp’ — such as in the case of the Golden Rice controversy (a report on this incident can be found in ref. ). These cases have a negative effect on scientific research and undermine the reputation of ethics committees.
Although the institutionalization of ethics committees is essential, the review capabilities and self-construction of ethics committees are even more important to promote good scientific practice. The scientific and ethical attainment, sincere and responsible attitude, and deliberation capacity of the ethics committee experts are critical for an effective and high-quality ethical review, and also a guarantee for promoting responsible research.
Acknowledgements
This work was supported by the National Natural Science Foundation of China (grant no. L2224015).
Classification
Language: ENGLISH
Publication-Type: Magazine
Journal Code: 41562
Subject: ETHICS (98%); BEHAVIOR & COGNITION (89%); BIOETHICS (89%); EXPERIMENTATION & RESEARCH (89%); HEALTH DEPARTMENTS (89%); NATURAL SCIENCES (89%); SCIENCE & TECHNOLOGY (89%); HUMANITIES & SOCIAL SCIENCE (79%); BIOLOGY (78%); MEDICAL RESEARCH (78%); PUBLIC HEALTH ADMINISTRATION (78%); SOCIAL SCIENCES (78%); GOVERNMENT BODIES & OFFICES (76%); COUNTERFEITING & FORGERY (73%); APPROVALS (71%); GENETIC ENGINEERING (69%); VULNERABLE HEALTH POPULATIONS (67%); GENE EDITING (55%); ARTIFICIAL INTELLIGENCE (50%); MENTAL ILLNESS (50%)
Organization: School of Philosophy, Institute of Technology Ethics for Human Future; Fudan University
Industry: HEALTH DEPARTMENTS (89%); ARTIFICIAL INTELLIGENCE (50%)
Person: Wang Guoyu
Geographic: CHINA (93%)
Load-Date: July 26, 2024","Ethics committees in China began in the 1990s in hospital settings, and focused on physician virtues and physician–patient relationships. Since the turn of the century, the Chinese public and academics have also become increasingly concerned about the ethical challenges posed by science and technology.
Guoyu Wang
In response to these concerns, the Ministry of Health issued legislation (《涉及人的生物医学研究伦理审查办法》) in 2007 that required the establishment of three-level ethics committees: the Ministry of Health, provincial and municipal, and institutional ethics committees.
In November 2018, however, the scientist Jiankui He, while on leave from his university position, declared that he had created the world’s first gene-edited babies. His work was not rigorously reviewed by a qualified ethics committee and the ethics documents were forged. This incident shocked the world. It also catalysed the formation of the National Ethics Committee of China, which is now responsible for guiding and coordinating the construction of the national science and technology ethics governance system. Following this, government guidance (《关于加强科技伦理治理的意见》) in March 2022 called for improved governance of science and technology ethics. Subsequently, more than a dozen provinces have established local ethics committees. Institutional ethics committees have also sprung up like mushrooms after a rain.
More recently, further regulation (《科技伦理审查办法（试行）》) in October 2023 specified that seven research activities (including research on the introduction of human stem cells into animal embryos, and clinical research on invasive brain–computer interfaces) need to be reported to or approved by the higher-level ethics committee or even the National Ethics Committee. This is to ensure an ‘ethics first’ approach.
Risk prevention and control, protecting individual rights and social well-being, and promoting responsible innovation are the main aims of the ethical review. I have seen first-hand the value of ethics committees, especially when research involves vulnerable populations such as minors and people with mental illness. With the rapid development of interdisciplinary science and technology, many researchers do not have a medical or life science background themselves and lack basic bioethics education, which makes ethical review increasingly important.
Members of institutional ethics committee generally consist of experts from different disciplines and public representatives. They either possess ‘dispositional knowledge’ (that is, positive knowledge of causes, effects and means) in the natural and technical sciences or have ‘orientational knowledge’ (that is, regulative knowledge of (justified) goals and purposes) in the humanities and social sciences. Different knowledge backgrounds bring various perspectives, positions and ways of observing problems. These advantages cannot be matched by the limited rationality of a single individual. Given that scientific research, especially in areas such as artificial intelligence and synthetic biology, is becoming increasingly complex and uncertain, it is more crucial than ever to have such a committee with diverse perspectives.
In most cases, our ethics committees not only point out the problems but also help the project applicants to modify and improve the research plan so that it complies with national laws and regulations, and internationally recognized ethical norms. According to the requirements set forth by the Natural Science Foundation of China (NSFC), applications for NSFC funding must undergo ethical review. As a result, each year in early March, the ethics committee convenes for several days to scrutinize these projects. Particular attention is paid to aspects such as the drafting of informed consent documents and the recruitment of volunteers. Occasionally, recruitment posters may use inappropriate promises to attract volunteers, which prompts the ethics committees to ask for and assist in their revision. Meanwhile, some scientists obtain research samples from hospitals through personal connection or simple partnerships. They do not realize that such cooperation is neither legal nor ethical, and this is also where ethics committees have a vital role. Furthermore, scientific journals usually mandate that research projects undergo ethics review if they are to be considered for publication. Consequently, researchers may proactively seek guidance and support from ethics committees. In this manner, ethical review serves as a form of assistance in promoting responsible research practices.
The review process also reflects the openness and transparency of science. Although most scientists acknowledge the norms of research ethics, there is a difference between recognizing principles and consciously observing them in practice. In my opinion, the temptation of wealth and the pursuit of fame and fortune sometimes cause people to avoid moral constraints, intentionally or unintentionally. Without the external supervision of an ethics committee and an open and transparent ethical review mechanism, it would be difficult to ensure that incidents similar to that of Jiankui He will never happen again.
Some believe that the review by ethics committees may limit or even hinder scientific research. Indeed, some ethical reviews are formalistic and poorly standardized, and some people think that ethics review is a ‘rubber stamp’ — such as in the case of the Golden Rice controversy (a report on this incident can be found in ref. ). These cases have a negative effect on scientific research and undermine the reputation of ethics committees.
Although the institutionalization of ethics committees is essential, the review capabilities and self-construction of ethics committees are even more important to promote good scientific practice. The scientific and ethical attainment, sincere and responsible attitude, and deliberation capacity of the ethics committee experts are critical for an effective and high-quality ethical review, and also a guarantee for promoting responsible research.
Acknowledgements
This work was supported by the National Natural Science Foundation of China (grant no. L2224015).
Classification
Language: ENGLISH
Publication-Type: Magazine
Journal Code: 41562
Subject: ETHICS (98%); BEHAVIOR & COGNITION (89%); BIOETHICS (89%); EXPERIMENTATION & RESEARCH (89%); HEALTH DEPARTMENTS (89%); NATURAL SCIENCES (89%); SCIENCE & TECHNOLOGY (89%); HUMANITIES & SOCIAL SCIENCE (79%); BIOLOGY (78%); MEDICAL RESEARCH (78%); PUBLIC HEALTH ADMINISTRATION (78%); SOCIAL SCIENCES (78%); GOVERNMENT BODIES & OFFICES (76%); COUNTERFEITING & FORGERY (73%); APPROVALS (71%); GENETIC ENGINEERING (69%); VULNERABLE HEALTH POPULATIONS (67%); GENE EDITING (55%); ARTIFICIAL INTELLIGENCE (50%); MENTAL ILLNESS (50%)
Organization: School of Philosophy, Institute of Technology Ethics for Human Future; Fudan University
Industry: HEALTH DEPARTMENTS (89%); ARTIFICIAL INTELLIGENCE (50%)
Person: Wang Guoyu
Geographic: CHINA (93%)
Load-Date: July 26, 2024",neutral,0.7569437026977539,balanced/neutral,"['transparency', 'consent']",['virtues'],"['regulation', 'governance', 'legislation', 'must', 'need to']",[],2,1,5,0
2024,Unknown Title,"Dateline: BEIJING, Dec. 29, 2024 
Body
PR NewswireBEIJING, Dec. 29, 2024 /PRNewswire/ -- In 1949, pioneering computer scientist Edmund Callis Berkeley envisioned a future filled with thinking machines in his book Giant Brains, or Machines That Think. Decades later, his vision has become a reality with artificial intelligence (AI) reshaping industries, societies and daily lives.The progress however, is far from straightforward. While AI excites people with its potential, it also raises questions about ethics, safety and its impact on human life.Recently, Science and Technology Daily hosted a panel discussion, ""Tech with Heart, AI for Good"", on how AI empowers life and bridges human limitations but also needs guard rails to ensure it remains under control.Omnipresent AIAI is reshaping the way we live, work and interact with the world. 
For Zeng Yi, a professor at the Institute of Automation, Chinese Academy of Sciences and an expert of the United Nations' high-level advisory body on AI, the motivation to advance AI technology lies in its potential to liberate humans from repetitive and labor-intensive tasks.""Combining AI with robotics allows us to redirect human energy toward more creative and meaningful pursuits,"" Zeng said. He highlighted how AI-powered robots are stepping into hazardous fields such as firefighting, disaster relief and space exploration. Lunar rovers equipped with advanced AI capabilities are conducting complex analyses on the moon's surface — tasks too risky for human scientists.Besides industrial applications, AI is making a significant impact on environmental conservation such as tracking wildlife.AI's potential extends into our everyday lives as well. Gao Shaolin, an expert at Peking University Law and Artificial Intelligence Research Center, mentioned a recent road trip during which he drove 3,000 kilometers on highways without coming across a single traffic accident.""This is extraordinary,"" Gao said, attributing the improvement to advancements in AI-driven safety features in modern vehicles.From fatigue-monitoring systems in trucks to self-driving technologies in electric cars, these innovations are drastically reducing the likelihood of accidents.However, both Zeng and Gao agreed that AI should not aim to replace humans but rather enhance human expertise and efficiency. AI can amplify human capacity, leaving room for creativity and innovation.Responsible AIAs AI continues to evolve, responsibility becomes a critical issue. Zeng quoted Berkeley, who wrote, ""It is often easier for scientists to create a device than to guide it well afterward."" Berkeley urged innovators to think beyond breakthroughs and address potential risks.The question of accountability becomes central. Who will be responsible for any problem caused by AI? ""AI is not an independent legal entity,"" Gao emphasized, pointing out that current AI systems are tools rather than autonomous entities. The responsibility for their actions lies squarely with their developers, service providers and users.""AI should be as intelligent as necessary, but it must remain under human control,"" Gao stressed. As Zeng put it, ""The key is ensuring AI coexists harmoniously with humans, not as a competitor but as a collaborator.""Wu Baojun, executive deputy secretary-general of the Association for Science and Technology of the University of Chinese Academy of Sciences, said the rapid advancement of AI must be accompanied by efforts to ensure its reliability and safety within ethical frameworks.""Our research in AI,"" Wu said, ""aims to explore unknown territories, eliminate human fears and make AI more reliable.""Reliable AIChina has consistently demonstrated a forward-thinking approach to AI development, balancing technological innovation with social and ethical considerations.As Matt Sheehan from the Carnegie Endowment for International Peace wrote in an article, ""China is in the midst of rolling out some of the world's earliest and most detailed regulations governing artificial intelligence.""In 2017, China released the Next Generation Artificial Intelligence Development Plan to encourage diverse AI methodologies, such as deep learning, knowledge-based reasoning and large-scale modeling. The plan also emphasized ethical governance, with over a dozen references to social and legal challenges.In May 2019, it was followed by the Beijing AI Principles, which set out clear guidelines for AI research and development, advocating respect for privacy, human dignity and human rights.These visions were strengthened in July 2024 when the 78th UN General Assembly unanimously adopted a resolution proposed by China and co-sponsored by over 140 countries. The resolution emphasized the human-centered development of AI, international cooperation, and promotion of AI to benefit humanity as a whole.Zeng said China's AI strategy reflects a responsible and inclusive approach: ""China's AI development strategy is not limited to promoting domestic economic growth. They aim to empower humanity and promote sustainable development goals.""Shared AI principlesAI governance has become a global priority with nations striving to ensure that technology develops responsibly and inclusively.""We analyzed global AI ethics guidelines and found that 95 percent of the topics are consistent across countries. Concepts like human-centered development, transparency, fairness, safety and privacy protection are widely endorsed,"" Zeng said, adding that nations worldwide largely agree on the foundational principles for AI ethics and governance.In 2023, the Bletchley Declaration on AI safety was signed by 28 countries and the European Union. This marked the first broad agreement on the importance of AI safety as a global issue. In 2024, the UNESCO Recommendation on the Ethics of Artificial Intelligence was adopted unanimously by all member states, which is another example of the global consensus.China is playing an active role in promoting international cooperation on AI governance. ""AI must empower all nations, not just the technologically advanced ones. We should guide AI for good with collective efforts and shared responsibilities,"" Gao said.Executive Producers:Wang Junming, He YiProducer:Fang LinlinReporters:Long Yun, Zhong Jianli, Gong QianSubtitle Proofreaders:Wang Jing, Cen YingjieVideo Editing Instructor:Wang XiaolongAI Technology Advisor:Liu YangCameramen:Liu Xiao, Li Huitao, Li TianjiVideo Editor:Zhang ShunpingReviewer:Fang Linlin  View original content to download multimedia:https://www.prnewswire.com/news-releases/science-and-technology-daily-tech-with-heart-ai-for-good-ai-with-a-human-touch-302339939.htmlSOURCE Science and Technology Daily 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPUTER SCIENCE (90%); PRESS RELEASES (90%); SAFETY (89%); SAFETY, ACCIDENTS & DISASTERS (89%); TECHNOLOGY (89%); AUTOMOTIVE TECHNOLOGY (78%); CHATBOTS (78%); ETHICS (78%); INDUSTRIAL AUTOMATION (78%); ROBOTICS (78%); SPACE TECHNOLOGY (78%); ELECTRIC VEHICLE INDUSTRY (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); LIFE FORMS (76%); SUSTAINABLE TRANSPORTATION (74%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); ELECTRIC MOBILITY (73%); RESEARCH INSTITUTES (73%); NEGATIVE NEWS (72%); ACCIDENTS & DISASTERS (70%); COLLEGE & UNIVERSITY PROFESSORS (68%); UNITED NATIONS (68%); UNITED NATIONS INSTITUTIONS (68%); TRAFFIC ACCIDENTS (67%); POLLUTION & ENVIRONMENTAL IMPACTS (66%); SPACE EXPLORATION (65%); CONSERVATION (64%); ENVIRONMENT & NATURAL RESOURCES (64%); WILDLIFE (64%); AUTOMOTIVE SAFETY (61%); ELECTRIC VEHICLES (61%); DISASTER RELIEF (51%); Science-Tech-AI (%)
Company:  AI SYSTEMS (50%); Science and Technology Daily
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER SCIENCE (90%); AUTOMOTIVE TECHNOLOGY (78%); CHATBOTS (78%); INDUSTRIAL AUTOMATION (78%); ROBOTICS (78%); SPACE TECHNOLOGY (78%); ELECTRIC VEHICLE INDUSTRY (77%); SUSTAINABLE TRANSPORTATION (74%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); ELECTRIC MOBILITY (73%); COLLEGE & UNIVERSITY PROFESSORS (68%); TRAFFIC ACCIDENTS (67%); VEHICLE TRAFFIC (67%); SPACE EXPLORATION (65%); AUTOMOTIVE SAFETY (61%); ELECTRIC VEHICLES (61%); MOTOR VEHICLES (61%); CPR Computer; Electronics Products (%); ITE Internet Technology (%); PUB Publishing; Information Services (%)
Geographic: BEIJING, CHINA (89%); NORTH CENTRAL CHINA (79%); CHINA (79%); New York; China
Load-Date: December 29, 2024","PR NewswireBEIJING, Dec. 29, 2024 /PRNewswire/ -- In 1949, pioneering computer scientist Edmund Callis Berkeley envisioned a future filled with thinking machines in his book Giant Brains, or Machines That Think. Decades later, his vision has become a reality with artificial intelligence (AI) reshaping industries, societies and daily lives.The progress however, is far from straightforward. While AI excites people with its potential, it also raises questions about ethics, safety and its impact on human life.Recently, Science and Technology Daily hosted a panel discussion, ""Tech with Heart, AI for Good"", on how AI empowers life and bridges human limitations but also needs guard rails to ensure it remains under control.Omnipresent AIAI is reshaping the way we live, work and interact with the world. 
For Zeng Yi, a professor at the Institute of Automation, Chinese Academy of Sciences and an expert of the United Nations' high-level advisory body on AI, the motivation to advance AI technology lies in its potential to liberate humans from repetitive and labor-intensive tasks.""Combining AI with robotics allows us to redirect human energy toward more creative and meaningful pursuits,"" Zeng said. He highlighted how AI-powered robots are stepping into hazardous fields such as firefighting, disaster relief and space exploration. Lunar rovers equipped with advanced AI capabilities are conducting complex analyses on the moon's surface — tasks too risky for human scientists.Besides industrial applications, AI is making a significant impact on environmental conservation such as tracking wildlife.AI's potential extends into our everyday lives as well. Gao Shaolin, an expert at Peking University Law and Artificial Intelligence Research Center, mentioned a recent road trip during which he drove 3,000 kilometers on highways without coming across a single traffic accident.""This is extraordinary,"" Gao said, attributing the improvement to advancements in AI-driven safety features in modern vehicles.From fatigue-monitoring systems in trucks to self-driving technologies in electric cars, these innovations are drastically reducing the likelihood of accidents.However, both Zeng and Gao agreed that AI should not aim to replace humans but rather enhance human expertise and efficiency. AI can amplify human capacity, leaving room for creativity and innovation.Responsible AIAs AI continues to evolve, responsibility becomes a critical issue. Zeng quoted Berkeley, who wrote, ""It is often easier for scientists to create a device than to guide it well afterward."" Berkeley urged innovators to think beyond breakthroughs and address potential risks.The question of accountability becomes central. Who will be responsible for any problem caused by AI? ""AI is not an independent legal entity,"" Gao emphasized, pointing out that current AI systems are tools rather than autonomous entities. The responsibility for their actions lies squarely with their developers, service providers and users.""AI should be as intelligent as necessary, but it must remain under human control,"" Gao stressed. As Zeng put it, ""The key is ensuring AI coexists harmoniously with humans, not as a competitor but as a collaborator.""Wu Baojun, executive deputy secretary-general of the Association for Science and Technology of the University of Chinese Academy of Sciences, said the rapid advancement of AI must be accompanied by efforts to ensure its reliability and safety within ethical frameworks.""Our research in AI,"" Wu said, ""aims to explore unknown territories, eliminate human fears and make AI more reliable.""Reliable AIChina has consistently demonstrated a forward-thinking approach to AI development, balancing technological innovation with social and ethical considerations.As Matt Sheehan from the Carnegie Endowment for International Peace wrote in an article, ""China is in the midst of rolling out some of the world's earliest and most detailed regulations governing artificial intelligence.""In 2017, China released the Next Generation Artificial Intelligence Development Plan to encourage diverse AI methodologies, such as deep learning, knowledge-based reasoning and large-scale modeling. The plan also emphasized ethical governance, with over a dozen references to social and legal challenges.In May 2019, it was followed by the Beijing AI Principles, which set out clear guidelines for AI research and development, advocating respect for privacy, human dignity and human rights.These visions were strengthened in July 2024 when the 78th UN General Assembly unanimously adopted a resolution proposed by China and co-sponsored by over 140 countries. The resolution emphasized the human-centered development of AI, international cooperation, and promotion of AI to benefit humanity as a whole.Zeng said China's AI strategy reflects a responsible and inclusive approach: ""China's AI development strategy is not limited to promoting domestic economic growth. They aim to empower humanity and promote sustainable development goals.""Shared AI principlesAI governance has become a global priority with nations striving to ensure that technology develops responsibly and inclusively.""We analyzed global AI ethics guidelines and found that 95 percent of the topics are consistent across countries. Concepts like human-centered development, transparency, fairness, safety and privacy protection are widely endorsed,"" Zeng said, adding that nations worldwide largely agree on the foundational principles for AI ethics and governance.In 2023, the Bletchley Declaration on AI safety was signed by 28 countries and the European Union. This marked the first broad agreement on the importance of AI safety as a global issue. In 2024, the UNESCO Recommendation on the Ethics of Artificial Intelligence was adopted unanimously by all member states, which is another example of the global consensus.China is playing an active role in promoting international cooperation on AI governance. ""AI must empower all nations, not just the technologically advanced ones. We should guide AI for good with collective efforts and shared responsibilities,"" Gao said.Executive Producers:Wang Junming, He YiProducer:Fang LinlinReporters:Long Yun, Zhong Jianli, Gong QianSubtitle Proofreaders:Wang Jing, Cen YingjieVideo Editing Instructor:Wang XiaolongAI Technology Advisor:Liu YangCameramen:Liu Xiao, Li Huitao, Li TianjiVideo Editor:Zhang ShunpingReviewer:Fang Linlin  View original content to download multimedia:https://www.prnewswire.com/news-releases/science-and-technology-daily-tech-with-heart-ai-for-good-ai-with-a-human-touch-302339939.htmlSOURCE Science and Technology Daily 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPUTER SCIENCE (90%); PRESS RELEASES (90%); SAFETY (89%); SAFETY, ACCIDENTS & DISASTERS (89%); TECHNOLOGY (89%); AUTOMOTIVE TECHNOLOGY (78%); CHATBOTS (78%); ETHICS (78%); INDUSTRIAL AUTOMATION (78%); ROBOTICS (78%); SPACE TECHNOLOGY (78%); ELECTRIC VEHICLE INDUSTRY (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); LIFE FORMS (76%); SUSTAINABLE TRANSPORTATION (74%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); ELECTRIC MOBILITY (73%); RESEARCH INSTITUTES (73%); NEGATIVE NEWS (72%); ACCIDENTS & DISASTERS (70%); COLLEGE & UNIVERSITY PROFESSORS (68%); UNITED NATIONS (68%); UNITED NATIONS INSTITUTIONS (68%); TRAFFIC ACCIDENTS (67%); POLLUTION & ENVIRONMENTAL IMPACTS (66%); SPACE EXPLORATION (65%); CONSERVATION (64%); ENVIRONMENT & NATURAL RESOURCES (64%); WILDLIFE (64%); AUTOMOTIVE SAFETY (61%); ELECTRIC VEHICLES (61%); DISASTER RELIEF (51%); Science-Tech-AI (%)
Company:  AI SYSTEMS (50%); Science and Technology Daily
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE (90%); COMPUTER SCIENCE (90%); AUTOMOTIVE TECHNOLOGY (78%); CHATBOTS (78%); INDUSTRIAL AUTOMATION (78%); ROBOTICS (78%); SPACE TECHNOLOGY (78%); ELECTRIC VEHICLE INDUSTRY (77%); SUSTAINABLE TRANSPORTATION (74%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); ELECTRIC MOBILITY (73%); COLLEGE & UNIVERSITY PROFESSORS (68%); TRAFFIC ACCIDENTS (67%); VEHICLE TRAFFIC (67%); SPACE EXPLORATION (65%); AUTOMOTIVE SAFETY (61%); ELECTRIC VEHICLES (61%); MOTOR VEHICLES (61%); CPR Computer; Electronics Products (%); ITE Internet Technology (%); PUB Publishing; Information Services (%)
Geographic: BEIJING, CHINA (89%); NORTH CENTRAL CHINA (79%); CHINA (79%); New York; China
Load-Date: December 29, 2024",neutral,0.6880591511726379,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'safety', 'human rights']","['fairness', 'dignity']","['regulation', 'policy', 'governance', 'guidelines', 'law', 'should', 'must']","['deep learning', 'robotics']",6,2,7,2
2024,Unknown Title,"Body
Riyadh, September 12, 2024, SPA -- The Saudi Data and Artificial Intelligence Authority (SDAIA) initiated the AI Ethics Early Adopters initiative to encourage both public- and private-sector organizations to prioritize ethical considerations when using artificial intelligence (AI). The launch occurred during the third edition of the Global AI Summit (GAIN Summit) at the King Abdulaziz International Conference Center in Riyadh. The initiative's goal is to promote awareness and responsible use of AI products and guide their use for maximum benefit. 
It includes offering incentives to promote compliance and enhance the trustworthiness of AI products, as well as adopting ethical and advanced practices in the development of AI systems across the products and services provided by these organizations. The program awards incentive badges at the product level based on five risk-based levels -- Aware, Adopting, Compliant, Assured, and Pioneer -- for a specific period, reflecting the maturity of AI risk-management practices associated with product use. SDAIA aims to support Saudi Arabia's progress in AI, bolster its global standing, and attain leadership, especially given the rapid development of these advanced technologies and their overall impact on individuals and entities. This initiative is in line with SDAIA's efforts to regulate AI. During the second edition of the Global AI Summit in 2022, SDAIA introduced the AI Ethics Principles to facilitate practical and responsible application throughout the lifecycle of AI system development. The initiative supports endeavors to advance research, development, and innovation in the Kingdom, contributing positively to the quality of services provided by Saudi Arabia while ensuring the responsible use of AI applications. -- SPA 23:53 Local Time 20:53 GMT 0081
Link to Image
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RESEARCH & DEVELOPMENT (78%); TECHNOLOGY (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); RISK MANAGEMENT (53%)
Company:  PIONEER PE HOLDING LLC (54%)
Industry: NAICS211130 NATURAL GAS EXTRACTION (54%); NAICS211120 CRUDE PETROLEUM EXTRACTION (54%); SIC1311 CRUDE PETROLEUM & NATURAL GAS (54%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); RISK MANAGEMENT (53%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (93%)
Load-Date: September 12, 2024","Riyadh, September 12, 2024, SPA -- The Saudi Data and Artificial Intelligence Authority (SDAIA) initiated the AI Ethics Early Adopters initiative to encourage both public- and private-sector organizations to prioritize ethical considerations when using artificial intelligence (AI). The launch occurred during the third edition of the Global AI Summit (GAIN Summit) at the King Abdulaziz International Conference Center in Riyadh. The initiative's goal is to promote awareness and responsible use of AI products and guide their use for maximum benefit. 
It includes offering incentives to promote compliance and enhance the trustworthiness of AI products, as well as adopting ethical and advanced practices in the development of AI systems across the products and services provided by these organizations. The program awards incentive badges at the product level based on five risk-based levels -- Aware, Adopting, Compliant, Assured, and Pioneer -- for a specific period, reflecting the maturity of AI risk-management practices associated with product use. SDAIA aims to support Saudi Arabia's progress in AI, bolster its global standing, and attain leadership, especially given the rapid development of these advanced technologies and their overall impact on individuals and entities. This initiative is in line with SDAIA's efforts to regulate AI. During the second edition of the Global AI Summit in 2022, SDAIA introduced the AI Ethics Principles to facilitate practical and responsible application throughout the lifecycle of AI system development. The initiative supports endeavors to advance research, development, and innovation in the Kingdom, contributing positively to the quality of services provided by Saudi Arabia while ensuring the responsible use of AI applications. -- SPA 23:53 Local Time 20:53 GMT 0081
Link to Image
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RESEARCH & DEVELOPMENT (78%); TECHNOLOGY (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); RISK MANAGEMENT (53%)
Company:  PIONEER PE HOLDING LLC (54%)
Industry: NAICS211130 NATURAL GAS EXTRACTION (54%); NAICS211120 CRUDE PETROLEUM EXTRACTION (54%); SIC1311 CRUDE PETROLEUM & NATURAL GAS (54%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); RISK MANAGEMENT (53%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (93%)
Load-Date: September 12, 2024",neutral,0.6791443824768066,balanced/neutral,[],[],"['regulation', 'policy', 'compliance']",[],0,0,3,0
2024,Unknown Title,"Body
Link to Image
Link to Story
The declaration of Helsinki recently turned 60, but don't feel bad if you missed the celebrations. It probably passed unnoticed by most people not working in the medical field - and possibly even a good few in the field.If you're not familiar with the declaration - adopted by the World Medical Association on October 19 1964 - here is an explainer on this highly influential document: how it emerged, how it evolved and where it may be heading.
What is the declaration of Helsinki?The World Medical Association was set up in the late 1940s in response to atrocities committed in the name of medical research during the second world war. It was focused on promoting and safeguarding medical ethics and human rights.
Agreed at a meeting in Finland in 1964, the first version of the declaration included principles that have become the cornerstone of global research ethics. These include the importance of carefully assessing the risks and benefits of research projects, and seeking informed consent from those taking part in research.
The declaration has been hugely influential and has been incorporated into national guidelines relating to medical research around the world. (For example, in the UK it is cited in legislation and policy relating to research.)
However, it is not legally binding. It has also, at times, been the focus of controversy. For example, following an intense debate in the early 2000s - about the use of placebos in drug trials and the ethics of conducting research in low-income countries - the US Food and Drug Administration removed reference to the declaration in its own guidance.
The declaration updatedIt has been revised several times (the new version is the eighth edition), reflecting an evolving understanding of medical ethics, contemporary debates about when research would be ethical, as well changes in the nature and landscape of research.
Some of these reflect important shifts in values and language. In 1964 , the declaration stated that clinical research""should be conducted ... under the supervision of a qualified medical man"" - sexist language that has long since gone by the wayside.
The 2024 version refers to""research participants"" rather than""research subjects"" - in response to a wider shift to greater inclusion of patients and research volunteers as partners in research. There are also new references to concern for the environment and sustainability, as well as attention to issues relating to stored data and biomaterial, such as tissue samples.
Continuing uncertaintySome questions remain. One change in the recent document emphasises the importance of including participants from different backgrounds in research, including those who are potentially""vulnerable"" in one or more ways.
Older versions of the declaration emphasised avoiding research wherever possible involving children, older patients, pregnant women, those with mental illness and prisoners. This came from a need to learn from past scandals and avoid exploiting vulnerable groups.
However, more recently, it has been recognised that excluding these groups can cause even greater harm, since it leads to a lack of evidence on how best to treat some patients. This then leads to disparities in health. For example, a large proportion of medicines commonly used for children lack high-quality evidence to support them.
The 2024 declaration tries to balance the priority to include vulnerable groups in research with the need to protect and avoid research that could be feasibly performed in other groups.
However, this highlights a deeper problem. Ethical problems arise when research is inhibited or discouraged.
Regulation of research (as encouraged by the declaration) is hugely important, but it can also make it extremely difficult, time consuming and resource intensive to perform. Doctors may change practice based on experience, intuition or inspiration. If they do so outside of a trial, they are not required to seek the approval of any review body.
As noted by a British paediatrician Richard Smithells in the 1970s:""I need permission to give a drug to half of my patients [to find out whether it does more good than harm], but not [if I want] to give it to them all.""
One particular form of research that can be important to drive improvements in care are so-called comparative effectiveness trials. Within many areas of medicine, there are variations in practice, where some professionals will take one approach, while others will take another.
Depending on which doctor you happen to see, (perhaps which clinic you attend, or which day of the week you become unwell), you might receive one treatment or the other.
Since variations like this affect many patients, it would be important to determine which is the better option, potentially involving a randomised controlled trial, where one group of patients is randomly selected to receive the treatment and another group (the control group), a placebo. These trials take years to conduct and are very expensive to run.
However, the declaration seems to encourage a one-size-fits-all approach and potentially implies that such trials should go through a formal and lengthy research ethics approval process, with participants providing explicit informed consent. However, many ethicists and researchers have argued in favour of a more slimmed-down regulatory approach focusing on what matters : do trials meaningfully add risk or burden to those that patients would have encountered outside the trial. And would taking part in research restrict patients' ability to make meaningful decisions, and to make choices that would ordinarily have been offered?
For example, imagine a trial of two different antiseptics that are commonly used for surgery. Being involved in the trial wouldn't impose additional risk (since patients ordinarily receive those antiseptics), and it wouldn't remove an ordinary choice, since it would be rare for medical professionals to ask patients which antiseptic they would like.
The Declaration of Helsinki may be 60 years old, but it continues to both stimulate debate and inspire ethical practice in medical research. It has been newly revised but it is likely that innovations in research, such as the growing use of AI in medicine , will require further changes in the years ahead. It isn't time to retire it yet.
MENAFN24102024000199003603ID1108815835
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (91%); HUMAN SUBJECTS (90%); INTERNATIONAL ORGANIZATIONS & BODIES (90%); MEDICAL ETHICS (90%); MEDICAL RESEARCH (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (89%); CLINICAL TRIALS (87%); RESEARCH & DEVELOPMENT (78%); DISEASES & DISORDERS (77%); EXPERIMENTATION & RESEARCH (77%); PATIENT CONSENT (77%); SEX & GENDER ISSUES (77%); ASSOCIATIONS & ORGANIZATIONS (76%); NEGATIVE NEWS (74%); GENDER & SEX DISCRIMINATION (73%); NEGATIVE MISC NEWS (73%); NEGATIVE SOCIETAL NEWS (73%); WORLD WAR II (69%); HUMAN RIGHTS (68%); WOMEN'S HEALTH (61%); BIOMATERIALS (60%); MENTAL ILLNESS (60%); PREGNANCY & CHILDBIRTH (60%); CHILDREN, ADOLESCENTS & TEENS (50%)
Industry: CLINICAL TRIALS (87%); BIOMEDICAL & DENTAL MATERIALS (77%); PATIENT CONSENT (77%); BIOMATERIALS (60%)
Geographic: HELSINKI, FINLAND (88%); UNITED STATES (79%); UNITED KINGDOM (55%)
Load-Date: March 5, 2025","Link to Image
Link to Story
The declaration of Helsinki recently turned 60, but don't feel bad if you missed the celebrations. It probably passed unnoticed by most people not working in the medical field - and possibly even a good few in the field.If you're not familiar with the declaration - adopted by the World Medical Association on October 19 1964 - here is an explainer on this highly influential document: how it emerged, how it evolved and where it may be heading.
What is the declaration of Helsinki?The World Medical Association was set up in the late 1940s in response to atrocities committed in the name of medical research during the second world war. It was focused on promoting and safeguarding medical ethics and human rights.
Agreed at a meeting in Finland in 1964, the first version of the declaration included principles that have become the cornerstone of global research ethics. These include the importance of carefully assessing the risks and benefits of research projects, and seeking informed consent from those taking part in research.
The declaration has been hugely influential and has been incorporated into national guidelines relating to medical research around the world. (For example, in the UK it is cited in legislation and policy relating to research.)
However, it is not legally binding. It has also, at times, been the focus of controversy. For example, following an intense debate in the early 2000s - about the use of placebos in drug trials and the ethics of conducting research in low-income countries - the US Food and Drug Administration removed reference to the declaration in its own guidance.
The declaration updatedIt has been revised several times (the new version is the eighth edition), reflecting an evolving understanding of medical ethics, contemporary debates about when research would be ethical, as well changes in the nature and landscape of research.
Some of these reflect important shifts in values and language. In 1964 , the declaration stated that clinical research""should be conducted ... under the supervision of a qualified medical man"" - sexist language that has long since gone by the wayside.
The 2024 version refers to""research participants"" rather than""research subjects"" - in response to a wider shift to greater inclusion of patients and research volunteers as partners in research. There are also new references to concern for the environment and sustainability, as well as attention to issues relating to stored data and biomaterial, such as tissue samples.
Continuing uncertaintySome questions remain. One change in the recent document emphasises the importance of including participants from different backgrounds in research, including those who are potentially""vulnerable"" in one or more ways.
Older versions of the declaration emphasised avoiding research wherever possible involving children, older patients, pregnant women, those with mental illness and prisoners. This came from a need to learn from past scandals and avoid exploiting vulnerable groups.
However, more recently, it has been recognised that excluding these groups can cause even greater harm, since it leads to a lack of evidence on how best to treat some patients. This then leads to disparities in health. For example, a large proportion of medicines commonly used for children lack high-quality evidence to support them.
The 2024 declaration tries to balance the priority to include vulnerable groups in research with the need to protect and avoid research that could be feasibly performed in other groups.
However, this highlights a deeper problem. Ethical problems arise when research is inhibited or discouraged.
Regulation of research (as encouraged by the declaration) is hugely important, but it can also make it extremely difficult, time consuming and resource intensive to perform. Doctors may change practice based on experience, intuition or inspiration. If they do so outside of a trial, they are not required to seek the approval of any review body.
As noted by a British paediatrician Richard Smithells in the 1970s:""I need permission to give a drug to half of my patients [to find out whether it does more good than harm], but not [if I want] to give it to them all.""
One particular form of research that can be important to drive improvements in care are so-called comparative effectiveness trials. Within many areas of medicine, there are variations in practice, where some professionals will take one approach, while others will take another.
Depending on which doctor you happen to see, (perhaps which clinic you attend, or which day of the week you become unwell), you might receive one treatment or the other.
Since variations like this affect many patients, it would be important to determine which is the better option, potentially involving a randomised controlled trial, where one group of patients is randomly selected to receive the treatment and another group (the control group), a placebo. These trials take years to conduct and are very expensive to run.
However, the declaration seems to encourage a one-size-fits-all approach and potentially implies that such trials should go through a formal and lengthy research ethics approval process, with participants providing explicit informed consent. However, many ethicists and researchers have argued in favour of a more slimmed-down regulatory approach focusing on what matters : do trials meaningfully add risk or burden to those that patients would have encountered outside the trial. And would taking part in research restrict patients' ability to make meaningful decisions, and to make choices that would ordinarily have been offered?
For example, imagine a trial of two different antiseptics that are commonly used for surgery. Being involved in the trial wouldn't impose additional risk (since patients ordinarily receive those antiseptics), and it wouldn't remove an ordinary choice, since it would be rare for medical professionals to ask patients which antiseptic they would like.
The Declaration of Helsinki may be 60 years old, but it continues to both stimulate debate and inspire ethical practice in medical research. It has been newly revised but it is likely that innovations in research, such as the growing use of AI in medicine , will require further changes in the years ahead. It isn't time to retire it yet.
MENAFN24102024000199003603ID1108815835
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (91%); HUMAN SUBJECTS (90%); INTERNATIONAL ORGANIZATIONS & BODIES (90%); MEDICAL ETHICS (90%); MEDICAL RESEARCH (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (89%); CLINICAL TRIALS (87%); RESEARCH & DEVELOPMENT (78%); DISEASES & DISORDERS (77%); EXPERIMENTATION & RESEARCH (77%); PATIENT CONSENT (77%); SEX & GENDER ISSUES (77%); ASSOCIATIONS & ORGANIZATIONS (76%); NEGATIVE NEWS (74%); GENDER & SEX DISCRIMINATION (73%); NEGATIVE MISC NEWS (73%); NEGATIVE SOCIETAL NEWS (73%); WORLD WAR II (69%); HUMAN RIGHTS (68%); WOMEN'S HEALTH (61%); BIOMATERIALS (60%); MENTAL ILLNESS (60%); PREGNANCY & CHILDBIRTH (60%); CHILDREN, ADOLESCENTS & TEENS (50%)
Industry: CLINICAL TRIALS (87%); BIOMEDICAL & DENTAL MATERIALS (77%); PATIENT CONSENT (77%); BIOMATERIALS (60%)
Geographic: HELSINKI, FINLAND (88%); UNITED STATES (79%); UNITED KINGDOM (55%)
Load-Date: March 5, 2025",neutral,0.6325178146362305,balanced/neutral,"['discrimination', 'human rights', 'consent']",[],"['regulation', 'policy', 'guidelines', 'legislation', 'should', 'need to']",[],3,0,6,0
2024,Unknown Title,"Body
December 9, 2024
Release date- 09122024 - Godfather of AI' Yoshua Bengio and FPT's Truong Gia Binh on Charting the Course for Ethical AI Innovation.
In a recent insightful dialogue themed 'AI Safety - Shaping Responsible Innovation,' Dr. Truong Gia Binh, Founder and Chairman of FPT Corporation, and the Turing Award laureate Prof. Yoshua Bengio, Founder and Scientific Director of Mila - Quebec Artificial Intelligence Institute, discussed the future of Artificial Intelligence, exploring how to harness AI for societal benefit while ensuring it evolves within ethical boundaries and with full accountability.
Addressing over 15,000 in-person and online audiences, including tech leaders, practitioners, and young IT enthusiasts, the discussion explored a shared vision of AI as a powerful tool for human advancement.
(L-R) Hosted by Dr. Phong Nguyen, Chief AI Officer of FPT Software, FPT Corporation, Prof. Yoshua Bengio, and Dr. Truong Gia Binh joined a fireside chat on AI safety and innovation
The Ethical Imperative: Safeguarding AI's Future
Reflecting on AI's rapid evolution, Prof. Yoshua Bengio shared that AI systems are advancing faster than anticipated, raising the question: What happens when AI surpasses human capabilities? He emphasized the urgent need for caution, advocating for the precautionary principle in AI development. 'If we build machines smarter than us, we must ensure they remain tools that serve humanity, not autonomous agents with their own goals,' he stated, underscoring the risk of AI-controlled scenarios that could potentially be catastrophic.
Prof. Yoshua Bengio, Founder and Scientific Director of Mila - Quebec Artificial Intelligence Institute, also widely regarded as one of the 'Godfathers of AI'
Both leaders agreed that AI must remain a tool that augments human decision-making and well-being, not an independent force with unpredictable objectives. Ethical frameworks are needed to guide the development of AI, ensuring it aligns with human values and contributes to societal welfare. The conversation further delved into the importance of AI transparency, accountability, and the development of safeguards against malicious uses, such as AI-driven cyberattacks or weaponization.
Intelligent Automation Is Transforming Job Markets
As AI-powered automation continues to reshape industries, both leaders discussed the challenges and opportunities posed by intelligent automation. Prof. Bengio clarified that while AI can drive efficiency, it should not be viewed as a threat to jobs. Instead, AI is an opportunity for growth and human collaboration.
Dr. Truong Gia Binh, Founder and Chairman of FPT Corporation
Echoing this sentiment, Dr. Truong Gia Binh shared: 'In the future, the old jobs will be gone, but new jobs will require significant technological expertise. You need to master AI, understand how it works, and adapt to its revolution. Those who have these kinds of skills will not be left behind. We are a new way of working: human-AI collaboration.'
As the landscape evolves, the key to navigating this transformation lies in re-skilling and up-skilling workers in AI-related fields. Collaboration between humans and AI will become essential in driving innovation and sustaining competitive advantage.
'A lot of application domains are very complex, requiring social and human factors. These aspects will likely stay in human hands, but you will need ones who understand how to apply AI and technology in these situations,' Prof. Bengio added.
Nurturing the Next Generation of AI Talent
A focus of the discussion was the importance of AI education, especially for Vietnam's young generations. Prof. Bengio emphasized while they boast great potential, to remain competitive globally, Vietnamese students must be equipped with foundational AI literacy, blending technical expertise with an understanding of other social sciences and the ethical implications of AI.
'We need our engineers to understand the aspects of society and humanities so that they can apply AI and other technologies in a mindful way,' he said.
Both leaders also stressed that AI curricula in schools and universities are essential for cultivating a future-ready workforce capable of leading AI innovation. As Vietnam continues to build its digital economy, the country's youth represents a powerful asset. By fostering a culture of innovation, creativity, and ethical AI practices, Vietnam can cultivate a new generation of AI leaders poised to lead on the world stage.
'The current global geopolitics situation sets a very special opportunity for Vietnam's growth. And I want to further push that momentum through the power of AI and AI education, cementing our position on the global stage,' Dr. Binh stated.
The event took place in FPT Tower - FPT Headquarters in Hanoi, Vietnam
Standing as a driving force behind Vietnam's ambitious agenda, FPT has aligned its strategic direction with the government's vision of an AI-driven nation. With over 1,500 AI engineers and a robust ecosystem integrating education, innovation, and global collaborations, the company is committed to fostering a new generation of AI-enabled engineers and delivering cutting-edge AI solutions.
In the future, FPT will continue to promote the development of ethical and responsible AI practices globally. Recent initiatives include the launch of the FPT AI Factory, a comprehensive AI platform designed to support the end-to-end AI product lifecycle, the AI partner ecosystem with global technology pioneers, and most recently, its participation in Vietnam's Ethical AI Committee during the event.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]     
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: M2PW
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SAFETY (90%); SMART TECHNOLOGY (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); HUMAN IN THE LOOP (78%); TECHNOLOGY (78%); EXECUTIVES (76%); CYBERCRIME (75%); NEGATIVE TECHNOLOGY NEWS (75%); LABOR SECTOR PERFORMANCE (65%); EMPLOYMENT GROWTH (63%); CYBERATTACKS (60%); LABOR MARKET (60%)
Company:  FPT CORP (93%);  AI SYSTEMS (55%)
Ticker: FPT (HOSE) (93%)
Industry: SIC7375 INFORMATION RETRIEVAL SERVICES (93%); SIC7373 COMPUTER INTEGRATED SYSTEMS DESIGN (93%); SIC6531 REAL ESTATE AGENTS & MANAGERS (93%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SMART TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); CYBERCRIME (75%); CYBERATTACKS (60%)
Load-Date: December 9, 2024","December 9, 2024
Release date- 09122024 - Godfather of AI' Yoshua Bengio and FPT's Truong Gia Binh on Charting the Course for Ethical AI Innovation.
In a recent insightful dialogue themed 'AI Safety - Shaping Responsible Innovation,' Dr. Truong Gia Binh, Founder and Chairman of FPT Corporation, and the Turing Award laureate Prof. Yoshua Bengio, Founder and Scientific Director of Mila - Quebec Artificial Intelligence Institute, discussed the future of Artificial Intelligence, exploring how to harness AI for societal benefit while ensuring it evolves within ethical boundaries and with full accountability.
Addressing over 15,000 in-person and online audiences, including tech leaders, practitioners, and young IT enthusiasts, the discussion explored a shared vision of AI as a powerful tool for human advancement.
(L-R) Hosted by Dr. Phong Nguyen, Chief AI Officer of FPT Software, FPT Corporation, Prof. Yoshua Bengio, and Dr. Truong Gia Binh joined a fireside chat on AI safety and innovation
The Ethical Imperative: Safeguarding AI's Future
Reflecting on AI's rapid evolution, Prof. Yoshua Bengio shared that AI systems are advancing faster than anticipated, raising the question: What happens when AI surpasses human capabilities? He emphasized the urgent need for caution, advocating for the precautionary principle in AI development. 'If we build machines smarter than us, we must ensure they remain tools that serve humanity, not autonomous agents with their own goals,' he stated, underscoring the risk of AI-controlled scenarios that could potentially be catastrophic.
Prof. Yoshua Bengio, Founder and Scientific Director of Mila - Quebec Artificial Intelligence Institute, also widely regarded as one of the 'Godfathers of AI'
Both leaders agreed that AI must remain a tool that augments human decision-making and well-being, not an independent force with unpredictable objectives. Ethical frameworks are needed to guide the development of AI, ensuring it aligns with human values and contributes to societal welfare. The conversation further delved into the importance of AI transparency, accountability, and the development of safeguards against malicious uses, such as AI-driven cyberattacks or weaponization.
Intelligent Automation Is Transforming Job Markets
As AI-powered automation continues to reshape industries, both leaders discussed the challenges and opportunities posed by intelligent automation. Prof. Bengio clarified that while AI can drive efficiency, it should not be viewed as a threat to jobs. Instead, AI is an opportunity for growth and human collaboration.
Dr. Truong Gia Binh, Founder and Chairman of FPT Corporation
Echoing this sentiment, Dr. Truong Gia Binh shared: 'In the future, the old jobs will be gone, but new jobs will require significant technological expertise. You need to master AI, understand how it works, and adapt to its revolution. Those who have these kinds of skills will not be left behind. We are a new way of working: human-AI collaboration.'
As the landscape evolves, the key to navigating this transformation lies in re-skilling and up-skilling workers in AI-related fields. Collaboration between humans and AI will become essential in driving innovation and sustaining competitive advantage.
'A lot of application domains are very complex, requiring social and human factors. These aspects will likely stay in human hands, but you will need ones who understand how to apply AI and technology in these situations,' Prof. Bengio added.
Nurturing the Next Generation of AI Talent
A focus of the discussion was the importance of AI education, especially for Vietnam's young generations. Prof. Bengio emphasized while they boast great potential, to remain competitive globally, Vietnamese students must be equipped with foundational AI literacy, blending technical expertise with an understanding of other social sciences and the ethical implications of AI.
'We need our engineers to understand the aspects of society and humanities so that they can apply AI and other technologies in a mindful way,' he said.
Both leaders also stressed that AI curricula in schools and universities are essential for cultivating a future-ready workforce capable of leading AI innovation. As Vietnam continues to build its digital economy, the country's youth represents a powerful asset. By fostering a culture of innovation, creativity, and ethical AI practices, Vietnam can cultivate a new generation of AI leaders poised to lead on the world stage.
'The current global geopolitics situation sets a very special opportunity for Vietnam's growth. And I want to further push that momentum through the power of AI and AI education, cementing our position on the global stage,' Dr. Binh stated.
The event took place in FPT Tower - FPT Headquarters in Hanoi, Vietnam
Standing as a driving force behind Vietnam's ambitious agenda, FPT has aligned its strategic direction with the government's vision of an AI-driven nation. With over 1,500 AI engineers and a robust ecosystem integrating education, innovation, and global collaborations, the company is committed to fostering a new generation of AI-enabled engineers and delivering cutting-edge AI solutions.
In the future, FPT will continue to promote the development of ethical and responsible AI practices globally. Recent initiatives include the launch of the FPT AI Factory, a comprehensive AI platform designed to support the end-to-end AI product lifecycle, the AI partner ecosystem with global technology pioneers, and most recently, its participation in Vietnam's Ethical AI Committee during the event.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]     
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: M2PW
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); SAFETY (90%); SMART TECHNOLOGY (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); HUMAN IN THE LOOP (78%); TECHNOLOGY (78%); EXECUTIVES (76%); CYBERCRIME (75%); NEGATIVE TECHNOLOGY NEWS (75%); LABOR SECTOR PERFORMANCE (65%); EMPLOYMENT GROWTH (63%); CYBERATTACKS (60%); LABOR MARKET (60%)
Company:  FPT CORP (93%);  AI SYSTEMS (55%)
Ticker: FPT (HOSE) (93%)
Industry: SIC7375 INFORMATION RETRIEVAL SERVICES (93%); SIC7373 COMPUTER INTEGRATED SYSTEMS DESIGN (93%); SIC6531 REAL ESTATE AGENTS & MANAGERS (93%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SMART TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (78%); CYBERCRIME (75%); CYBERATTACKS (60%)
Load-Date: December 9, 2024",neutral,0.7156218886375427,balanced/neutral,"['transparency', 'accountability', 'safety']",[],"['should', 'must', 'need to']",[],3,0,3,0
2024,Unknown Title,"Body
 01 Dec 2024 (Saudi Press Agency) In September 2024, at the third edition of the Global AI Summit organized by the Saudi Data and AI Authority (SDAIA), the authority unveiled the AI Adoption Framework Document.
SDAIA also announced the activation of AI offices in government entities, with 23 government entities establishing AI offices in a strategic move to align with Saudi Vision 2030. This initiative aims to integrate AI across all critical and developmental sectors in the Kingdom while guiding efforts toward the ethical and responsible use of advanced AI technologies.
The document serves as a guiding reference, providing a comprehensive framework for adopting AI in both public and private sectors. It contributes to building an innovation-driven knowledge society, offering essential guidelines and practical steps based on global best practices. The framework ensures optimal and responsible AI adoption, fostering a successful transition to AI-powered tools for maximum benefit.
Targeting leaders, executives, business unit managers, and professionals involved in AI transformation, the document reflects SDAIA's ongoing commitment to raising awareness of data and AI technologies and maximizing their potential as the national authority overseeing data and AI development and governance.
The framework outlines a comprehensive process starting with the foundational phase, which includes defining priorities, establishing AI units, and assessing maturity and readiness. These steps ensure alignment between AI strategies and organizational objectives, define AI-driven services, and evaluate preparedness to adopt AI solutions while identifying areas requiring development.
The document highlights key enablers for effective AI adoption, emphasizing the importance of data as the foundation for developing models and training algorithms. It also underscores the role of advanced technologies, supporting infrastructure, and human capital through training and preparing specialists to manage and operate AI systems. Furthermore, the framework stresses the importance of responsible AI use and outlines maturity levels: Emerging, Developed, Proficient, and Advanced.
Additionally, the document revisits the AI Ethics Principles issued by SDAIA in 2023, offering organizations clear guidelines for the safe and responsible use of AI technologies. These principles include integrity and fairness, privacy and security, reliability and safety, transparency and interpretability, accountability and responsibility, human-centric values, and social and environmental benefits.
The document emphasizes the importance of raising awareness among government and private entities about AI's significance and applications to ensure effective acceptance and implementation of these rapidly evolving technologies across all areas of modern life.
The framework supports digital transformation in the Kingdom by offering practical guidance for identifying the most effective AI use cases and delivering innovative solutions that enhance business efficiency and improve service quality. SDAIA oversees the application of these guidelines, ensuring compliance and ethical AI adoption that prioritizes individual safety and personal rights.
Classification
Language: English US
Publication-Type: Newspaper
Subject: TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); GOVERNMENT BODIES & OFFICES (89%); BEST PRACTICES (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); MANAGERS & SUPERVISORS (74%); SAFETY (69%); SAFETY, ACCIDENTS & DISASTERS (69%); REGULATORY COMPLIANCE (68%); ENVIRONMENT & NATURAL RESOURCES (50%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); INFORMATION SECURITY & PRIVACY (78%)
Geographic: SAUDI ARABIA (95%)
Load-Date: December 2, 2024","01 Dec 2024 (Saudi Press Agency) In September 2024, at the third edition of the Global AI Summit organized by the Saudi Data and AI Authority (SDAIA), the authority unveiled the AI Adoption Framework Document.
SDAIA also announced the activation of AI offices in government entities, with 23 government entities establishing AI offices in a strategic move to align with Saudi Vision 2030. This initiative aims to integrate AI across all critical and developmental sectors in the Kingdom while guiding efforts toward the ethical and responsible use of advanced AI technologies.
The document serves as a guiding reference, providing a comprehensive framework for adopting AI in both public and private sectors. It contributes to building an innovation-driven knowledge society, offering essential guidelines and practical steps based on global best practices. The framework ensures optimal and responsible AI adoption, fostering a successful transition to AI-powered tools for maximum benefit.
Targeting leaders, executives, business unit managers, and professionals involved in AI transformation, the document reflects SDAIA's ongoing commitment to raising awareness of data and AI technologies and maximizing their potential as the national authority overseeing data and AI development and governance.
The framework outlines a comprehensive process starting with the foundational phase, which includes defining priorities, establishing AI units, and assessing maturity and readiness. These steps ensure alignment between AI strategies and organizational objectives, define AI-driven services, and evaluate preparedness to adopt AI solutions while identifying areas requiring development.
The document highlights key enablers for effective AI adoption, emphasizing the importance of data as the foundation for developing models and training algorithms. It also underscores the role of advanced technologies, supporting infrastructure, and human capital through training and preparing specialists to manage and operate AI systems. Furthermore, the framework stresses the importance of responsible AI use and outlines maturity levels: Emerging, Developed, Proficient, and Advanced.
Additionally, the document revisits the AI Ethics Principles issued by SDAIA in 2023, offering organizations clear guidelines for the safe and responsible use of AI technologies. These principles include integrity and fairness, privacy and security, reliability and safety, transparency and interpretability, accountability and responsibility, human-centric values, and social and environmental benefits.
The document emphasizes the importance of raising awareness among government and private entities about AI's significance and applications to ensure effective acceptance and implementation of these rapidly evolving technologies across all areas of modern life.
The framework supports digital transformation in the Kingdom by offering practical guidance for identifying the most effective AI use cases and delivering innovative solutions that enhance business efficiency and improve service quality. SDAIA oversees the application of these guidelines, ensuring compliance and ethical AI adoption that prioritizes individual safety and personal rights.
Classification
Language: English US
Publication-Type: Newspaper
Subject: TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); GOVERNMENT BODIES & OFFICES (89%); BEST PRACTICES (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); MANAGERS & SUPERVISORS (74%); SAFETY (69%); SAFETY, ACCIDENTS & DISASTERS (69%); REGULATORY COMPLIANCE (68%); ENVIRONMENT & NATURAL RESOURCES (50%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); INFORMATION SECURITY & PRIVACY (78%)
Geographic: SAUDI ARABIA (95%)
Load-Date: December 2, 2024",neutral,0.5970169901847839,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'safety', 'security', 'agency']",['fairness'],"['governance', 'guidelines', 'framework', 'compliance', 'emphasizes the importance']",[],7,1,5,0
2024,Unknown Title,"Byline: Society of Corporate Compliance and Ethics
Body
December 5th, 2024 ( JD Supra  - Delivered by  Newstex )
March 10th - 12th, 2025
8:00 AM - 5:00 PM WET
Marriott Lisbon
Avenida dos Combatentes 45
Lisboa, Portugal 1600-042
Join us in Lisbon, Portugal for the 13th annual European Compliance and Ethics Institute, 10-12 March 2025! We look forward to gathering once again to share insights and strategies on the unique challenges of European compliance management. Get up to date on the latest best practices and emerging trends from industry leaders while making face-to-face connections with your peers from across Europe and around the world.
This 3-day conference offers a broad selection of breakout sessions that will allow you to focus on topics most relevant to your needs. Sessions are led by experienced compliance professionals from Europe and beyond, and categorized by knowledge level - basic, intermediate, and advanced - so you can choose the content that will be most beneficial for you.
Topics include:
Third-party risk
Metrics and analytics
Anti-corruption
Internal investigations
Ethics
Global compliance management
Compliance training
Corporate culture
Sanctions and export controls
The risks and opportunities of AI
Who should attend?
Compliance and ethics professionals
In-house and outside counsel
Audit managers/officers
Information and privacy officers
Regulators and other government personnel
Risk managers
Corporate executives and leaders
Researchers and policy makers
Human resource managers
Learn more and Register
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: BUSINESS ETHICS (90%); ETHICS (90%); INVESTIGATIONS (90%); MANAGERS & SUPERVISORS (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); BEST PRACTICES (77%); CONFERENCES & CONVENTIONS (77%); CORRUPTION (77%); REGULATORY COMPLIANCE (77%); DATA ANALYTICS (76%); EXECUTIVES (76%); HUMAN RESOURCES (76%); HUMAN RESOURCES & PERSONNEL MANAGEMENT (76%); RISK MANAGEMENT (76%); TALKS & MEETINGS (76%); GOVERNMENT & PUBLIC ADMINISTRATION (75%); CORPORATE CULTURE (72%); EXPORT CONTROLS (72%); NEGATIVE MISC NEWS (71%); NEGATIVE NEWS (71%); TRENDS (70%); ANTI-CORRUPTION (67%); INTERNAL INVESTIGATIONS (66%); EXPORT TRADE (51%)
Industry: DATA ANALYTICS (76%); RISK MANAGEMENT (76%)
Geographic: LISBON, PORTUGAL (93%); EUROPE (90%); PORTUGAL (88%)
Load-Date: December 5, 2024","December 5th, 2024 ( JD Supra  - Delivered by  Newstex )
March 10th - 12th, 2025
8:00 AM - 5:00 PM WET
Marriott Lisbon
Avenida dos Combatentes 45
Lisboa, Portugal 1600-042
Join us in Lisbon, Portugal for the 13th annual European Compliance and Ethics Institute, 10-12 March 2025! We look forward to gathering once again to share insights and strategies on the unique challenges of European compliance management. Get up to date on the latest best practices and emerging trends from industry leaders while making face-to-face connections with your peers from across Europe and around the world.
This 3-day conference offers a broad selection of breakout sessions that will allow you to focus on topics most relevant to your needs. Sessions are led by experienced compliance professionals from Europe and beyond, and categorized by knowledge level - basic, intermediate, and advanced - so you can choose the content that will be most beneficial for you.
Topics include:
Third-party risk
Metrics and analytics
Anti-corruption
Internal investigations
Ethics
Global compliance management
Compliance training
Corporate culture
Sanctions and export controls
The risks and opportunities of AI
Who should attend?
Compliance and ethics professionals
In-house and outside counsel
Audit managers/officers
Information and privacy officers
Regulators and other government personnel
Risk managers
Corporate executives and leaders
Researchers and policy makers
Human resource managers
Learn more and Register
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: BUSINESS ETHICS (90%); ETHICS (90%); INVESTIGATIONS (90%); MANAGERS & SUPERVISORS (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); BEST PRACTICES (77%); CONFERENCES & CONVENTIONS (77%); CORRUPTION (77%); REGULATORY COMPLIANCE (77%); DATA ANALYTICS (76%); EXECUTIVES (76%); HUMAN RESOURCES (76%); HUMAN RESOURCES & PERSONNEL MANAGEMENT (76%); RISK MANAGEMENT (76%); TALKS & MEETINGS (76%); GOVERNMENT & PUBLIC ADMINISTRATION (75%); CORPORATE CULTURE (72%); EXPORT CONTROLS (72%); NEGATIVE MISC NEWS (71%); NEGATIVE NEWS (71%); TRENDS (70%); ANTI-CORRUPTION (67%); INTERNAL INVESTIGATIONS (66%); EXPORT TRADE (51%)
Industry: DATA ANALYTICS (76%); RISK MANAGEMENT (76%)
Geographic: LISBON, PORTUGAL (93%); EUROPE (90%); PORTUGAL (88%)
Load-Date: December 5, 2024",neutral,0.6967295408248901,balanced/neutral,['privacy'],[],"['policy', 'compliance', 'audit', 'should']",[],1,0,4,0
2024,Unknown Title,"Body
2024 OCT 01 (NewsRx) -- By a News Reporter-Staff News Editor at Defense & Aerospace Daily -- New study results on military medicine have been published. According to news originating from Uniformed Services University of the Health Sciences by NewsRx correspondents, research stated, ""Recent advances in artificial intelligence (AI) created powerful tools for research, particularly for extracting meaningful insights from extremely large data sets."" 
 Our news editors obtained a quote from the research from Uniformed Services University of the Health Sciences: ""These developments increase research benefits of big data and risks posed to individual privacy, forcing a re-examination of ethics in research which is of particular importance to the Military Health System. To advance discussion of research ethics in this context, the Forum on Health and National Security: Ethical Use of Big Data for Healthy Communities and a Strong Nation was held in December 2018. The workshop was designed to identify ethical questions relevant to population and health research studies using difficult to access, health-related data in the Department of Defense (DoD). Discussions explored researchers' ethical obligations to research subjects, particularly in the areas of privacy, trust, and consent, as well as potential methods to improve researchers' ability to collect, access, and share data while protecting privacy and potential risks to national security. These include creating risk management frameworks and data governance policies, improving education and workplace training, and increasing community involvement in research design and practice. While the workshop was conducted in 2018, the discussion of data ethics is still relevant today."" 
 According to the news editors, the research concluded: ""The research agenda of the nation is best served by building ethics into the research ecosystem. There are substantial challenges to fully realizing this goal including commitments of time and funding to address the ethical complexities, train others to understand them, and create appropriate ethical frameworks before research begins."" 
 For more information on this research see: Ethical use of big data for healthy communities and a strong nation: unique challenges for the Military Health System. BMC Proceedings, 2024,18(S21):1-6. (BMC Proceedings - http://www.biomedcentral.com/bmcproc/). The publisher for BMC Proceedings is BMC. 
 A free version of this journal article is available at https://doi.org/10.1186/s12919-024-00308-y. 
 Our news journalists report that additional information may be obtained by contacting Tracey Perez Koehlmoos, Uniformed Services University of the Health Sciences. 
 Keywords for this news article include: Uniformed Services University of the Health Sciences, Military Medicine, Military and Defense. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); NATIONAL SECURITY & FOREIGN RELATIONS (92%); MEDICAL SCIENCE (91%); COLLEGES & UNIVERSITIES (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); MEDICINE & HEALTH (90%); MILITARY BENEFITS (90%); MILITARY SCHOOLS & ACADEMIES (90%); PRIVACY RIGHTS (90%); RESEARCH REPORTS (89%); NATIONAL SECURITY (79%); EMPLOYEE TRAINING (78%); EMPLOYEE TRAINING & ASSISTANCE (78%); EXPERIMENTATION & RESEARCH (78%); JOURNALISM (78%); LABOR & EMPLOYMENT (78%); EDUCATION & TRAINING (77%); RISK MANAGEMENT (75%); DEFENSE DEPARTMENTS (74%); TALKS & MEETINGS (74%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (71%); Military Medicine;Military and Defense (%)
Organization: UNIFORMED SERVICES UNIVERSITY OF THE HEALTH SCIENCES (93%)
Industry: BIG DATA (90%); COLLEGES & UNIVERSITIES (90%); MILITARY BENEFITS (90%); MILITARY SCHOOLS & ACADEMIES (90%); PUBLISHING (78%); DATA GOVERNANCE & STEWARDSHIP (76%); RISK MANAGEMENT (75%); DEFENSE DEPARTMENTS (74%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (71%)
Load-Date: November 1, 2024","2024 OCT 01 (NewsRx) -- By a News Reporter-Staff News Editor at Defense & Aerospace Daily -- New study results on military medicine have been published. According to news originating from Uniformed Services University of the Health Sciences by NewsRx correspondents, research stated, ""Recent advances in artificial intelligence (AI) created powerful tools for research, particularly for extracting meaningful insights from extremely large data sets."" 
 Our news editors obtained a quote from the research from Uniformed Services University of the Health Sciences: ""These developments increase research benefits of big data and risks posed to individual privacy, forcing a re-examination of ethics in research which is of particular importance to the Military Health System. To advance discussion of research ethics in this context, the Forum on Health and National Security: Ethical Use of Big Data for Healthy Communities and a Strong Nation was held in December 2018. The workshop was designed to identify ethical questions relevant to population and health research studies using difficult to access, health-related data in the Department of Defense (DoD). Discussions explored researchers' ethical obligations to research subjects, particularly in the areas of privacy, trust, and consent, as well as potential methods to improve researchers' ability to collect, access, and share data while protecting privacy and potential risks to national security. These include creating risk management frameworks and data governance policies, improving education and workplace training, and increasing community involvement in research design and practice. While the workshop was conducted in 2018, the discussion of data ethics is still relevant today."" 
 According to the news editors, the research concluded: ""The research agenda of the nation is best served by building ethics into the research ecosystem. There are substantial challenges to fully realizing this goal including commitments of time and funding to address the ethical complexities, train others to understand them, and create appropriate ethical frameworks before research begins."" 
 For more information on this research see: Ethical use of big data for healthy communities and a strong nation: unique challenges for the Military Health System. BMC Proceedings, 2024,18(S21):1-6. (BMC Proceedings - http://www.biomedcentral.com/bmcproc/). The publisher for BMC Proceedings is BMC. 
 A free version of this journal article is available at https://doi.org/10.1186/s12919-024-00308-y. 
 Our news journalists report that additional information may be obtained by contacting Tracey Perez Koehlmoos, Uniformed Services University of the Health Sciences. 
 Keywords for this news article include: Uniformed Services University of the Health Sciences, Military Medicine, Military and Defense. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2024, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (93%); NATIONAL SECURITY & FOREIGN RELATIONS (92%); MEDICAL SCIENCE (91%); COLLEGES & UNIVERSITIES (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); MEDICINE & HEALTH (90%); MILITARY BENEFITS (90%); MILITARY SCHOOLS & ACADEMIES (90%); PRIVACY RIGHTS (90%); RESEARCH REPORTS (89%); NATIONAL SECURITY (79%); EMPLOYEE TRAINING (78%); EMPLOYEE TRAINING & ASSISTANCE (78%); EXPERIMENTATION & RESEARCH (78%); JOURNALISM (78%); LABOR & EMPLOYMENT (78%); EDUCATION & TRAINING (77%); RISK MANAGEMENT (75%); DEFENSE DEPARTMENTS (74%); TALKS & MEETINGS (74%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (71%); Military Medicine;Military and Defense (%)
Organization: UNIFORMED SERVICES UNIVERSITY OF THE HEALTH SCIENCES (93%)
Industry: BIG DATA (90%); COLLEGES & UNIVERSITIES (90%); MILITARY BENEFITS (90%); MILITARY SCHOOLS & ACADEMIES (90%); PUBLISHING (78%); DATA GOVERNANCE & STEWARDSHIP (76%); RISK MANAGEMENT (75%); DEFENSE DEPARTMENTS (74%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (71%)
Load-Date: November 1, 2024",neutral,0.7859348654747009,balanced/neutral,"['privacy', 'security', 'consent', 'access']",[],['governance'],[],4,0,1,0
2024,Unknown Title,"Body
Link to Story
LONDON, Nov. 19, 2024PRNewswire/ -- Vault Platform , a leader in AI-driven ethics and compliance solutions and category leader in Active Integrity, proudly introduces EthicsChat , an innovative new product designed to make Ethics accessible to employees, streamline compliance queries, and enhance workplace integrity. EthicsChat can even be used inside Vault's apps for Slack and Microsoft Teams, offering real-time, AI-powered guidance on ethics, reporting, and resolution, right where work happens.
Vault is developing EthicsChat to empower employees and managers to navigate complex ethical issues confidently, offering consistent, accessible answers to questions on workplace ethics based on the company's policies and Code of Conduct.
Vault's EthicsChat includes expanding its ability to guide employees in understanding complex ethical situations, such as identifying potential Conflicts of Interest or determining whether certain behaviors and events should be reported under company policies.
""EthicsChat is designed to transform an organization's code of conduct into a dynamic, real-time resource, which can be used wherever work happens, in the office or on-the-go"" says Neta Meidav, Vault CEO & Co-Founder. ""It enables employees to act with integrity in every situation and equips leadership with the information they need to identify trends and proactively manage risks.""
EthicsChat is part of Vault's broader Active Integrity product suite including various mobile and AI-powered misconduct reporting channels and the Resolution Hub, collectively supporting both ethical reporting and case resolution workflow. Vault's suite of AI-driven tools positions the company at the forefront of innovation in the compliance tech space, offering scalable, flexible solutions to meet growing demands for transparency and accountability in the workplace.
As Vault continues to lead in AI innovation for ethics and compliance, EthicsChat represents a significant step forward in enabling companies to meet compliance challenges while building a culture of integrity.
For more information on EthicsChat and Vault's full suite of compliance tools, visit vautlplatform
About Vault Platform
Vault Platform is the Active Integrity platform, modernizing Speak Up programs with digital, AI-enabled tools to consolidate Speak Up, investigations, and data reporting, providing organizations with the tools they need to reduce risk, and create a culture of Active Integrity.
SOURCE Vault Platform
WANT YOUR COMPANY'S NEWS FEATURED ON PRNEWSWIRE?
440k+
Newsrooms &
Influencers
9k+
Digital Media
Outlets
270k+
Journalists
Opted In
GET STARTEDMENAFN19112024003732001241ID1108902623
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (97%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS (90%); NEW PRODUCTS (90%); PRODUCT INNOVATION (89%); EXECUTIVES (78%); INVESTIGATIONS (78%); JOURNALISM (78%); MANAGERS & SUPERVISORS (78%); MISCONDUCT (78%); NEGATIVE PERSONAL NEWS (78%); REGULATORY COMPLIANCE (78%); TRENDS (74%); CONFLICTS OF INTEREST (73%); NEGATIVE MISC NEWS (73%); NEGATIVE NEWS (73%); WRITERS (73%); RISK MANAGEMENT (70%)
Company:  MICROSOFT CORP (57%)
Ticker: MSFT (NASDAQ) (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); WRITERS (73%); RISK MANAGEMENT (70%)
Load-Date: March 5, 2025","Link to Story
LONDON, Nov. 19, 2024PRNewswire/ -- Vault Platform , a leader in AI-driven ethics and compliance solutions and category leader in Active Integrity, proudly introduces EthicsChat , an innovative new product designed to make Ethics accessible to employees, streamline compliance queries, and enhance workplace integrity. EthicsChat can even be used inside Vault's apps for Slack and Microsoft Teams, offering real-time, AI-powered guidance on ethics, reporting, and resolution, right where work happens.
Vault is developing EthicsChat to empower employees and managers to navigate complex ethical issues confidently, offering consistent, accessible answers to questions on workplace ethics based on the company's policies and Code of Conduct.
Vault's EthicsChat includes expanding its ability to guide employees in understanding complex ethical situations, such as identifying potential Conflicts of Interest or determining whether certain behaviors and events should be reported under company policies.
""EthicsChat is designed to transform an organization's code of conduct into a dynamic, real-time resource, which can be used wherever work happens, in the office or on-the-go"" says Neta Meidav, Vault CEO & Co-Founder. ""It enables employees to act with integrity in every situation and equips leadership with the information they need to identify trends and proactively manage risks.""
EthicsChat is part of Vault's broader Active Integrity product suite including various mobile and AI-powered misconduct reporting channels and the Resolution Hub, collectively supporting both ethical reporting and case resolution workflow. Vault's suite of AI-driven tools positions the company at the forefront of innovation in the compliance tech space, offering scalable, flexible solutions to meet growing demands for transparency and accountability in the workplace.
As Vault continues to lead in AI innovation for ethics and compliance, EthicsChat represents a significant step forward in enabling companies to meet compliance challenges while building a culture of integrity.
For more information on EthicsChat and Vault's full suite of compliance tools, visit vautlplatform
About Vault Platform
Vault Platform is the Active Integrity platform, modernizing Speak Up programs with digital, AI-enabled tools to consolidate Speak Up, investigations, and data reporting, providing organizations with the tools they need to reduce risk, and create a culture of Active Integrity.
SOURCE Vault Platform
WANT YOUR COMPANY'S NEWS FEATURED ON PRNEWSWIRE?
440k+
Newsrooms &
Influencers
9k+
Digital Media
Outlets
270k+
Journalists
Opted In
GET STARTEDMENAFN19112024003732001241ID1108902623
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (97%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS (90%); NEW PRODUCTS (90%); PRODUCT INNOVATION (89%); EXECUTIVES (78%); INVESTIGATIONS (78%); JOURNALISM (78%); MANAGERS & SUPERVISORS (78%); MISCONDUCT (78%); NEGATIVE PERSONAL NEWS (78%); REGULATORY COMPLIANCE (78%); TRENDS (74%); CONFLICTS OF INTEREST (73%); NEGATIVE MISC NEWS (73%); NEGATIVE NEWS (73%); WRITERS (73%); RISK MANAGEMENT (70%)
Company:  MICROSOFT CORP (57%)
Ticker: MSFT (NASDAQ) (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); WRITERS (73%); RISK MANAGEMENT (70%)
Load-Date: March 5, 2025",positive,0.6263967156410217,balanced/neutral,"['transparency', 'accountability']",[],"['compliance', 'should', 'need to']",[],2,0,3,0
2024,Unknown Title,"Body
With the launch of its cutting-edge self-assessment tool to evaluate ethical compliance in AI development, the Saudi Data & AI Authority (SDAIA) is demonstrating the Kingdom's commitment to leading the development of safe and ethical AI technologies. Available through the National Data Governance Platform, this comprehensive solution helps organizations measure their adherence to established ethical AI principles.
Aligned with Saudi Vision 2030's goals, global human rights standards, and UNESCO's recommendations on AI ethics, the tool helps organizations raise AI maturity and enhance ethical AI compliance. It will also encourage investment and drive economic growth.
The tool serves as a crucial resource for government agencies, private companies, and independent developers. It offers a systematic framework for assessing and analyzing how well their AI products align with ethical guidelines. Organizations can now effectively measure their commitment to responsible AI development, implementation, and adoption through detailed evaluation metrics.
Comprising 81 key questions that are aligned with global standards, the assessment framework evaluates AI ethics compliance through seven fundamental principles: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits. As a result of responses to the questions, which use a simple 1-to-5 rating scale, detailed reports are generated that highlight strengths and identify areas for improvement.
These seven principles aim to advance ethical AI development while maintaining a balance between innovation and responsibility.
The framework emphasizes fairness in AI applications to prevent bias and discrimination while ensuring human-centric development that protects rights and promotes well-being.
Key aspects of the assessment include evaluating data privacy and protection while maintaining system reliability and safety. The framework also emphasizes transparency in AI operations, making complex algorithms and decision-making processes more understandable and accountable.
A key component of the framework focuses on accountability, ensuring transparent mechanisms for AI implementation and decision-making. Together, these principles foster responsible innovation that aligns with human values and societal needs.
Organizations can use the tool multiple times to raise their maturity in AI ethics compliance and monitor their ethical development journey. This iterative approach provides flexibility to strengthen ethical commitments continuously and align practices with emerging technological trends.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INTERNET PRIVACY (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SAFETY (77%); TECHNOLOGY TRENDS (77%); DISCRIMINATION (76%); HUMAN RIGHTS (76%); NEGATIVE SOCIETAL NEWS (76%); STANDARDS & MEASUREMENTS (76%); PRIVACY RIGHTS (72%); SAFETY, ACCIDENTS & DISASTERS (72%); GOVERNMENT BODIES & OFFICES (54%); ENVIRONMENT & NATURAL RESOURCES (51%); Ciencia y Tecnología (%);  Inteligencia Artificial (%);  Arabia Saudita (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (78%); DATA SECURITY (78%)
Geographic: SAUDI ARABIA (91%)
Load-Date: January 27, 2025","With the launch of its cutting-edge self-assessment tool to evaluate ethical compliance in AI development, the Saudi Data & AI Authority (SDAIA) is demonstrating the Kingdom's commitment to leading the development of safe and ethical AI technologies. Available through the National Data Governance Platform, this comprehensive solution helps organizations measure their adherence to established ethical AI principles.
Aligned with Saudi Vision 2030's goals, global human rights standards, and UNESCO's recommendations on AI ethics, the tool helps organizations raise AI maturity and enhance ethical AI compliance. It will also encourage investment and drive economic growth.
The tool serves as a crucial resource for government agencies, private companies, and independent developers. It offers a systematic framework for assessing and analyzing how well their AI products align with ethical guidelines. Organizations can now effectively measure their commitment to responsible AI development, implementation, and adoption through detailed evaluation metrics.
Comprising 81 key questions that are aligned with global standards, the assessment framework evaluates AI ethics compliance through seven fundamental principles: fairness, privacy and security, reliability and safety, transparency and explainability, accountability and responsibility, humanity, and social and environmental benefits. As a result of responses to the questions, which use a simple 1-to-5 rating scale, detailed reports are generated that highlight strengths and identify areas for improvement.
These seven principles aim to advance ethical AI development while maintaining a balance between innovation and responsibility.
The framework emphasizes fairness in AI applications to prevent bias and discrimination while ensuring human-centric development that protects rights and promotes well-being.
Key aspects of the assessment include evaluating data privacy and protection while maintaining system reliability and safety. The framework also emphasizes transparency in AI operations, making complex algorithms and decision-making processes more understandable and accountable.
A key component of the framework focuses on accountability, ensuring transparent mechanisms for AI implementation and decision-making. Together, these principles foster responsible innovation that aligns with human values and societal needs.
Organizations can use the tool multiple times to raise their maturity in AI ethics compliance and monitor their ethical development journey. This iterative approach provides flexibility to strengthen ethical commitments continuously and align practices with emerging technological trends.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); BUSINESS ETHICS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INTERNET PRIVACY (89%); TECHNOLOGY (89%); EMERGING TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); SAFETY (77%); TECHNOLOGY TRENDS (77%); DISCRIMINATION (76%); HUMAN RIGHTS (76%); NEGATIVE SOCIETAL NEWS (76%); STANDARDS & MEASUREMENTS (76%); PRIVACY RIGHTS (72%); SAFETY, ACCIDENTS & DISASTERS (72%); GOVERNMENT BODIES & OFFICES (54%); ENVIRONMENT & NATURAL RESOURCES (51%); Ciencia y Tecnología (%);  Inteligencia Artificial (%);  Arabia Saudita (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE GOVERNANCE (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE TRANSPARENCY (89%); INFORMATION SECURITY & PRIVACY (89%); INTERNET PRIVACY (89%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA PRIVACY (78%); DATA SECURITY (78%)
Geographic: SAUDI ARABIA (91%)
Load-Date: January 27, 2025",positive,0.720720112323761,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'human rights']",['fairness'],"['governance', 'standards', 'guidelines', 'framework', 'compliance']",[],10,1,5,0
2024,Unknown Title,"Body
Agency: ""National Telecommunications and Information Administration (NTIA), Department of Commerce.""
SUMMARY: The National Telecommunications and Information Administration (NTIA) is seeking public input on the potential writing of ethical guidelines for the use of ""pervasive data"" in research. ""Pervasive data"" refers to data about people gathered through online services. NTIA will rely on these comments, along with stakeholder engagements, in considering whether to draft and issue non-binding guidelines to assist researchers working with pervasive data. Such guidelines, if warranted, would detail how researchers can work with pervasive data while meeting ethical expectations of research and protecting individuals' privacy and other rights.
DATES: Interested persons are invited to submit comments on or before January 15, 2025.
ADDRESSES: All electronic public comments on this action, identified by Regulations.gov docket number NTIA-2024-0004, may be submitted through the Federal eRulemaking Portal at www.regulations.gov. The docket established for this request for comments can be found at www.regulations.gov, NTIA-2024-0004. Please do not include in your comments information of a confidential nature, such as sensitive personal information or proprietary information. All comments received are a part of the public record and will generally be posted to Regulations.gov without change. All personally identifiable information (e.g., name, address) voluntarily submitted by the commenter may be publicly accessible. Information obtained as a result of this notice may be used by the federal government for program planning on a non-attribution basis.
FOR FURTHER INFORMATION CONTACT: Please direct questions regarding this Request for Comments to Emma Llanso, NTIA, 1401 Constitution Avenue NW, Washington, DC 20230, at ellanso@ntia.gov or 202-482-3821. Please direct media inquiries to NTIA's Office of Public Affairs, telephone: (202) 482-7002; email: press@ntia.gov
SUPPLEMENTARY INFORMATION:
Overview The National Telecommunications and Information Administration (NTIA) is seeking input from the public on the potential writing of ethical guidelines for the use of ""pervasive data"" in research. ""Pervasive data"" refers to data about people gathered through online services. /1/ Researchers have leveraged pervasive data to better understand human behavior, societal forces, public health, and the impact of the technology that surrounds us. These insights are essential for informing policy in the digital age, and researchers and organizations have called for ethical guidelines to help ensure this work is done responsibly. /2/ Such guidelines, if warranted, would detail how independent third-party researchers /3/ can work with pervasive data while meeting ethical expectations of research and protecting individuals' privacy and other rights. The goal of ethical guidelines would be to outline principles and best practices that researchers, research institutions, data intermediaries, /4/ and online service providers can choose to follow when involved in research with pervasive data. Any such ethical guidelines may be a reference for research conducted solely within the United States (U.S.) or through international collaborations.
FOOTNOTE 1 The term pervasive data is intended to mean data about people--user-contributed, observed, derived, or inferred--collected through online services regardless of the extent to which the data is publicly available, is aggregated, or could lead to the identification of an individual. Pervasive data may include text, images, videos, biometric information, information about a data subject's behavior (purchases, financial standing, media consumption, search history, medical conditions, location, etc.), and other information that makes up a person's digital footprint. Online services may include a wide range of information technologies throughout the technology stack/technical infrastructure, including but not limited to web-based monitoring tools, content delivery networks, blockchain technology, digital labor platforms, education technology, Internet of Things devices, connected cars, wearable devices, mobile sensors, data brokers, streaming services, search engines, online marketplaces, social media platforms, and AI systems. The term pervasive data is informed by research conducted under NSF Grant Award Number 1144934 (https://www.nsf.gov/awardsearch/showAward?AWD_ID=1144934). END FOOTNOTE
FOOTNOTE 2 See e.g. Michael Zimmer, Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity, Social Media + Society 4, no. 2 (2018), https://doi.org/10.1177/2056305118768300; aline shakti franzke et al., internet Research: Ethical Guidelines 3.0, Association of internet Researchers (2020), https://aoir.org/reports/ethics3.pdf. END FOOTNOTE
FOOTNOTE 3 The ethics and privacy guidelines described for consideration in this Request for Comments focus on the flow of data from online service providers to independent researchers that operate outside of the online service provider and are often affiliated with an academic or non-profit institution. END FOOTNOTE
FOOTNOTE 4 The term data intermediary is intended to describe an independent entity that is operated specifically to facilitate data access and sharing under commercial or non-commercial agreements between researchers and online service providers or that evaluates and approves researcher requests for access to designated subsets of stored pervasive data. See Organisation for Economic Co-operation and Development, Data Stewardship, Access, Sharing, and Control: A Going Digital III module synthesis report, DSTI/CDEP(2022)6/FINAL (2023) at 37. END FOOTNOTE
NTIA will rely on these comments, along with engagements with researchers, civil society, research institutions, industry, and other government bodies, to consider whether to draft and issue guidelines to assist researchers working with pervasive data. The ethical guidelines outlined for consideration in this Request for Comments would be non-binding and would not supersede any existing laws or regulations, or pre-empt future laws. For example, human subjects research conducted or supported by one of the U.S. government departments or agencies that have adopted the Federal Policy for the Protection of Human Subjects ('Common Rule') /5/ would need to adhere to any applicable regulatory requirements. Federal agencies and federal data are bound by additional laws and regulations, which these voluntary ethical guidelines would not supersede. /6/
FOOTNOTE 5 See Office for Human Research Protections (OHRP), Federal Policy for the Protection of Human Subjects ('Common Rule'), OHRP (June 23, 2009), https://www.hhs.gov/ohrp/regulations-and-policy/regulations/common-rule/index.html. END FOOTNOTE
FOOTNOTE 6 See, e.g., the Privacy Act of 1974, 5 U.S.C. 552a (1974); the Paperwork Reduction Act of 1980, 44 U.S.C. 3501-3521 (1980); the Federal Information Security Modernization Act of 2014, Public Law 113-283 (2014); the E-Government Act of 2002, 44 U.S.C. 101 (2002). END FOOTNOTE
Background
Research with pervasive data is essential in efforts to understand the impact of technology on society. For example, the Kids Online Health and Safety Task Force Report and the Surgeon General's Youth Mental Health Advisory both emphasize that access to pervasive data, paired with privacy safeguards and ethical research guidelines, is essential to understanding technology's impact on children. /7/ Pervasive data is also crucial to enabling responsible research in other fast-moving technologies. For example, the National Artificial Intelligence (AI) Initiative Act of 2020, along with the CHIPS and Science Act of 2022, include landmark investments in AI research to advance the use of trustworthy AI. /8/ Such research often relies on pervasive data and should be conducted ethically. /9/
FOOTNOTE 7 Kids Online Health and Safety Task Force, Online Health and Safety for Children and Youth: Best Practices for Families and Guidance for Industry, Substance Abuse and Mental Health Services Administration (July 19, 2024), https://www.samhsa.gov/kids-online-health-safety-task-force/kohs-report-safe-internet-use; Office of the Assistant Secretary for Health (OASH). Surgeon General Issues New Advisory About Effects Social Media Use Has on Youth Mental Health, OASH (May 23, 2023), https://www.hhs.gov/about/news/2023/05/23/surgeon-general-issues-new-advisory-about-effects-social-media-use-has-youth-mental-health.html. END FOOTNOTE
FOOTNOTE 8 William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Public Law 116-283, SEC Division E (2021). https://www.congress.gov/bill/116th-congress/house-bill/6395/text; CHIPS and Science, Public Law 117-167 (2022). https://www.congress.gov/bill/117th-congress/house-bill/4346/text. END FOOTNOTE
FOOTNOTE 9 See e.g. National Institute of Science and Technology, NIST Researchers Suggest Historical Precedent for Ethical AI Research, NIST (February 15, 2024), https://www.nist.gov/news-events/news/2024/02/nist-researchers-suggest-historical-precedent-ethical-ai-research. END FOOTNOTE
Research with pervasive data is widespread and in high demand. To better understand the impact of technology on society, researchers have developed methods for accessing pervasive data, including large-scale collection of publicly available information, entering into agreements with online service providers, and managing collections of user-contributed data. /10/ Policymakers in the U.S. and globally have called for providers of online services to make data available to researchers. /11/ European regulators recently enacted the Digital Services Act, which mandates that Very Large Online Platforms share pervasive data with researchers to study systemic risks in the information environment. /12/ However, the risks to the rights and welfare of individuals associated with the use of pervasive data for research are nuanced and context-specific. This Request for Comments aims to explore these complexities and work toward more ethical practices for researchers working with pervasive data.
--This is a summary of a Federal Register article originally published on the page number listed below--
Notice, request for public comments.
RIN Number: ""RIN 0660-XC064""
Citation: ""89 FR 99844""
Document Number: ""Docket No. 241204-0309""
Federal Register Page Number: ""99844""
""Notices""
Classification
Language: ENGLISH
Journal Code: CD
Subject: ETHICS (92%); COMMERCE DEPARTMENTS (90%); GOVERNMENT BODIES & OFFICES (89%); BEST PRACTICES (78%); PUBLIC RECORDS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CALENDARS (73%); ASSOCIATIONS & ORGANIZATIONS (70%); GOVERNMENT & PUBLIC ADMINISTRATION (68%)
Organization: NATIONAL TELECOMMUNICATIONS & INFORMATION ADMINISTRATION (93%)
Industry: COMMUNICATIONS REGULATION & POLICY (90%); TELECOMMUNICATIONS (90%)
Geographic: WASHINGTON DC, USA (92%); UNITED STATES (79%)
Load-Date: December 11, 2024","Agency: ""National Telecommunications and Information Administration (NTIA), Department of Commerce.""
SUMMARY: The National Telecommunications and Information Administration (NTIA) is seeking public input on the potential writing of ethical guidelines for the use of ""pervasive data"" in research. ""Pervasive data"" refers to data about people gathered through online services. NTIA will rely on these comments, along with stakeholder engagements, in considering whether to draft and issue non-binding guidelines to assist researchers working with pervasive data. Such guidelines, if warranted, would detail how researchers can work with pervasive data while meeting ethical expectations of research and protecting individuals' privacy and other rights.
DATES: Interested persons are invited to submit comments on or before January 15, 2025.
ADDRESSES: All electronic public comments on this action, identified by Regulations.gov docket number NTIA-2024-0004, may be submitted through the Federal eRulemaking Portal at www.regulations.gov. The docket established for this request for comments can be found at www.regulations.gov, NTIA-2024-0004. Please do not include in your comments information of a confidential nature, such as sensitive personal information or proprietary information. All comments received are a part of the public record and will generally be posted to Regulations.gov without change. All personally identifiable information (e.g., name, address) voluntarily submitted by the commenter may be publicly accessible. Information obtained as a result of this notice may be used by the federal government for program planning on a non-attribution basis.
FOR FURTHER INFORMATION CONTACT: Please direct questions regarding this Request for Comments to Emma Llanso, NTIA, 1401 Constitution Avenue NW, Washington, DC 20230, at ellanso@ntia.gov or 202-482-3821. Please direct media inquiries to NTIA's Office of Public Affairs, telephone: (202) 482-7002; email: press@ntia.gov
SUPPLEMENTARY INFORMATION:
Overview The National Telecommunications and Information Administration (NTIA) is seeking input from the public on the potential writing of ethical guidelines for the use of ""pervasive data"" in research. ""Pervasive data"" refers to data about people gathered through online services. /1/ Researchers have leveraged pervasive data to better understand human behavior, societal forces, public health, and the impact of the technology that surrounds us. These insights are essential for informing policy in the digital age, and researchers and organizations have called for ethical guidelines to help ensure this work is done responsibly. /2/ Such guidelines, if warranted, would detail how independent third-party researchers /3/ can work with pervasive data while meeting ethical expectations of research and protecting individuals' privacy and other rights. The goal of ethical guidelines would be to outline principles and best practices that researchers, research institutions, data intermediaries, /4/ and online service providers can choose to follow when involved in research with pervasive data. Any such ethical guidelines may be a reference for research conducted solely within the United States (U.S.) or through international collaborations.
FOOTNOTE 1 The term pervasive data is intended to mean data about people--user-contributed, observed, derived, or inferred--collected through online services regardless of the extent to which the data is publicly available, is aggregated, or could lead to the identification of an individual. Pervasive data may include text, images, videos, biometric information, information about a data subject's behavior (purchases, financial standing, media consumption, search history, medical conditions, location, etc.), and other information that makes up a person's digital footprint. Online services may include a wide range of information technologies throughout the technology stack/technical infrastructure, including but not limited to web-based monitoring tools, content delivery networks, blockchain technology, digital labor platforms, education technology, Internet of Things devices, connected cars, wearable devices, mobile sensors, data brokers, streaming services, search engines, online marketplaces, social media platforms, and AI systems. The term pervasive data is informed by research conducted under NSF Grant Award Number 1144934 (https://www.nsf.gov/awardsearch/showAward?AWD_ID=1144934). END FOOTNOTE
FOOTNOTE 2 See e.g. Michael Zimmer, Addressing Conceptual Gaps in Big Data Research Ethics: An Application of Contextual Integrity, Social Media + Society 4, no. 2 (2018), https://doi.org/10.1177/2056305118768300; aline shakti franzke et al., internet Research: Ethical Guidelines 3.0, Association of internet Researchers (2020), https://aoir.org/reports/ethics3.pdf. END FOOTNOTE
FOOTNOTE 3 The ethics and privacy guidelines described for consideration in this Request for Comments focus on the flow of data from online service providers to independent researchers that operate outside of the online service provider and are often affiliated with an academic or non-profit institution. END FOOTNOTE
FOOTNOTE 4 The term data intermediary is intended to describe an independent entity that is operated specifically to facilitate data access and sharing under commercial or non-commercial agreements between researchers and online service providers or that evaluates and approves researcher requests for access to designated subsets of stored pervasive data. See Organisation for Economic Co-operation and Development, Data Stewardship, Access, Sharing, and Control: A Going Digital III module synthesis report, DSTI/CDEP(2022)6/FINAL (2023) at 37. END FOOTNOTE
NTIA will rely on these comments, along with engagements with researchers, civil society, research institutions, industry, and other government bodies, to consider whether to draft and issue guidelines to assist researchers working with pervasive data. The ethical guidelines outlined for consideration in this Request for Comments would be non-binding and would not supersede any existing laws or regulations, or pre-empt future laws. For example, human subjects research conducted or supported by one of the U.S. government departments or agencies that have adopted the Federal Policy for the Protection of Human Subjects ('Common Rule') /5/ would need to adhere to any applicable regulatory requirements. Federal agencies and federal data are bound by additional laws and regulations, which these voluntary ethical guidelines would not supersede. /6/
FOOTNOTE 5 See Office for Human Research Protections (OHRP), Federal Policy for the Protection of Human Subjects ('Common Rule'), OHRP (June 23, 2009), https://www.hhs.gov/ohrp/regulations-and-policy/regulations/common-rule/index.html. END FOOTNOTE
FOOTNOTE 6 See, e.g., the Privacy Act of 1974, 5 U.S.C. 552a (1974); the Paperwork Reduction Act of 1980, 44 U.S.C. 3501-3521 (1980); the Federal Information Security Modernization Act of 2014, Public Law 113-283 (2014); the E-Government Act of 2002, 44 U.S.C. 101 (2002). END FOOTNOTE
Background
Research with pervasive data is essential in efforts to understand the impact of technology on society. For example, the Kids Online Health and Safety Task Force Report and the Surgeon General's Youth Mental Health Advisory both emphasize that access to pervasive data, paired with privacy safeguards and ethical research guidelines, is essential to understanding technology's impact on children. /7/ Pervasive data is also crucial to enabling responsible research in other fast-moving technologies. For example, the National Artificial Intelligence (AI) Initiative Act of 2020, along with the CHIPS and Science Act of 2022, include landmark investments in AI research to advance the use of trustworthy AI. /8/ Such research often relies on pervasive data and should be conducted ethically. /9/
FOOTNOTE 7 Kids Online Health and Safety Task Force, Online Health and Safety for Children and Youth: Best Practices for Families and Guidance for Industry, Substance Abuse and Mental Health Services Administration (July 19, 2024), https://www.samhsa.gov/kids-online-health-safety-task-force/kohs-report-safe-internet-use; Office of the Assistant Secretary for Health (OASH). Surgeon General Issues New Advisory About Effects Social Media Use Has on Youth Mental Health, OASH (May 23, 2023), https://www.hhs.gov/about/news/2023/05/23/surgeon-general-issues-new-advisory-about-effects-social-media-use-has-youth-mental-health.html. END FOOTNOTE
FOOTNOTE 8 William M. (Mac) Thornberry National Defense Authorization Act for Fiscal Year 2021, Public Law 116-283, SEC Division E (2021). https://www.congress.gov/bill/116th-congress/house-bill/6395/text; CHIPS and Science, Public Law 117-167 (2022). https://www.congress.gov/bill/117th-congress/house-bill/4346/text. END FOOTNOTE
FOOTNOTE 9 See e.g. National Institute of Science and Technology, NIST Researchers Suggest Historical Precedent for Ethical AI Research, NIST (February 15, 2024), https://www.nist.gov/news-events/news/2024/02/nist-researchers-suggest-historical-precedent-ethical-ai-research. END FOOTNOTE
Research with pervasive data is widespread and in high demand. To better understand the impact of technology on society, researchers have developed methods for accessing pervasive data, including large-scale collection of publicly available information, entering into agreements with online service providers, and managing collections of user-contributed data. /10/ Policymakers in the U.S. and globally have called for providers of online services to make data available to researchers. /11/ European regulators recently enacted the Digital Services Act, which mandates that Very Large Online Platforms share pervasive data with researchers to study systemic risks in the information environment. /12/ However, the risks to the rights and welfare of individuals associated with the use of pervasive data for research are nuanced and context-specific. This Request for Comments aims to explore these complexities and work toward more ethical practices for researchers working with pervasive data.
--This is a summary of a Federal Register article originally published on the page number listed below--
Notice, request for public comments.
RIN Number: ""RIN 0660-XC064""
Citation: ""89 FR 99844""
Document Number: ""Docket No. 241204-0309""
Federal Register Page Number: ""99844""
""Notices""
Classification
Language: ENGLISH
Journal Code: CD
Subject: ETHICS (92%); COMMERCE DEPARTMENTS (90%); GOVERNMENT BODIES & OFFICES (89%); BEST PRACTICES (78%); PUBLIC RECORDS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CALENDARS (73%); ASSOCIATIONS & ORGANIZATIONS (70%); GOVERNMENT & PUBLIC ADMINISTRATION (68%)
Organization: NATIONAL TELECOMMUNICATIONS & INFORMATION ADMINISTRATION (93%)
Industry: COMMUNICATIONS REGULATION & POLICY (90%); TELECOMMUNICATIONS (90%)
Geographic: WASHINGTON DC, USA (92%); UNITED STATES (79%)
Load-Date: December 11, 2024",neutral,0.9086084961891174,balanced/neutral,"['privacy', 'safety', 'security', 'agency', 'access']",[],"['regulation', 'policy', 'guidelines', 'law', 'should', 'need to', 'suggest']",[],5,0,7,0
