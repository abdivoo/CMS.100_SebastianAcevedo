year,title,body,clean_body,sentiment_label,sentiment_score,tone,ethical_issues,ethical_principles,recommendations,technologies,issue_count,principle_count,recommendation_count,technology_count
2023,Unknown Title,"Byline: The Korea Herald, Seoul / Asia News Network
Body
Nov. 27—SEOUL ( The Korea Herald/ANN) — LG AI Research, LG Group's artificial intelligence think tank, said Sunday it has signed a letter of intent with UNESCO in Seoul to jointly foster knowledge and awareness of the ethics of AI.
LG highlighted the agreement as the first of its kind, where UNESCO has partnered with a Korean firm to promote the ethical development and use of AI technology.
Under the letter of intent, the two sides agreed to advance AI technology that would contribute to both humanity and sustainable development, seeking the implementation of AI ethical impact assessments and the development of effective governance models to ensure data privacy and security.
LG and UNESCO are planning to strengthen the capabilities of both the public and private sectors through massive open online courses, and produce educational materials on AI ethics. They will also work to promote awareness of AI ethics by hosting global events together.
In November 2021, UNESCO produced the first-ever global framework for the ethical use of AI, dubbed ""The Recommendation on the Ethics of Artificial Intelligence,"" which was adopted by all 193 member states at its general conference. The United Nations scientific agency aims to shape the ethical development and deployment of AI technology while protecting human rights and dignity based on fundamental principles such as transparency and fairness.
LG's think tank also announced its AI ethics principles in August 2022 to build more responsible AI systems and has been running a task force for AI impact assessment and a working group for AI ethics with other group affiliates as the company puts more value on customers over technology.
""We look forward to fruitful outcomes through collaboration and across businesses, international organizations, academia and civil society to ensure AI's responsible and trustworthy development within a framework of global trust,"" LG AI Research chief Bae Kyung-hoon said.
""Our joint efforts will drive inclusive, multi-stakeholder collaboration, sharing diverse experiences and best practices to harness the power of AI for good,"" said Kim Soo-hyun, director of the UNESCO Asia and Pacific Regional Bureau.
___ (c)2023 the Asia News Network (Hamburg, Germany) Visit the Asia News Network (Hamburg, Germany) at www.asianewsnet.net/home/ Distributed by Tribune Content Agency, LLC.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: ANN
Acc-No: 20231127-ANN-LG-UNESCO-partner-to-promote-AI-ethics-1127
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RESEARCH INSTITUTES (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (89%); AGREEMENTS (78%); ALLIANCES & PARTNERSHIPS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BEST PRACTICES (75%); CORPORATE GOVERNANCE (74%); INTERNET PRIVACY (74%); ASSOCIATIONS & ORGANIZATIONS (73%); SUSTAINABLE DEVELOPMENT (71%); HUMAN RIGHTS (70%); PRIVACY RIGHTS (69%); DISTANCE LEARNING (68%); TRENDS & EVENTS (68%); SUSTAINABILITY (55%); TEACHING MATERIALS & MEDIA (53%)
Company:  LG CORP (91%);  AI SYSTEMS (53%)
Ticker: 003550 (KSE) (91%)
Industry: NAICS551112 OFFICES OF OTHER HOLDING COMPANIES (91%); NAICS334419 OTHER ELECTRONIC COMPONENT MANUFACTURING (91%); SIC6719 OFFICES OF HOLDING COMPANIES, NEC (91%); SIC3651 HOUSEHOLD AUDIO & VIDEO EQUIPMENT (91%); SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); INTERNET PRIVACY (74%); SUSTAINABLE DEVELOPMENT (71%); DATA SECURITY (69%); INFORMATION SECURITY & PRIVACY (69%)
Geographic: HAMBURG, GERMANY (92%); DHAKA, BANGLADESH (90%); ASIA (94%); SOUTH KOREA (92%); BANGLADESH (88%); GERMANY (88%)
Load-Date: November 28, 2023","Nov. 27—SEOUL ( The Korea Herald/ANN) — LG AI Research, LG Group's artificial intelligence think tank, said Sunday it has signed a letter of intent with UNESCO in Seoul to jointly foster knowledge and awareness of the ethics of AI.
LG highlighted the agreement as the first of its kind, where UNESCO has partnered with a Korean firm to promote the ethical development and use of AI technology.
Under the letter of intent, the two sides agreed to advance AI technology that would contribute to both humanity and sustainable development, seeking the implementation of AI ethical impact assessments and the development of effective governance models to ensure data privacy and security.
LG and UNESCO are planning to strengthen the capabilities of both the public and private sectors through massive open online courses, and produce educational materials on AI ethics. They will also work to promote awareness of AI ethics by hosting global events together.
In November 2021, UNESCO produced the first-ever global framework for the ethical use of AI, dubbed ""The Recommendation on the Ethics of Artificial Intelligence,"" which was adopted by all 193 member states at its general conference. The United Nations scientific agency aims to shape the ethical development and deployment of AI technology while protecting human rights and dignity based on fundamental principles such as transparency and fairness.
LG's think tank also announced its AI ethics principles in August 2022 to build more responsible AI systems and has been running a task force for AI impact assessment and a working group for AI ethics with other group affiliates as the company puts more value on customers over technology.
""We look forward to fruitful outcomes through collaboration and across businesses, international organizations, academia and civil society to ensure AI's responsible and trustworthy development within a framework of global trust,"" LG AI Research chief Bae Kyung-hoon said.
""Our joint efforts will drive inclusive, multi-stakeholder collaboration, sharing diverse experiences and best practices to harness the power of AI for good,"" said Kim Soo-hyun, director of the UNESCO Asia and Pacific Regional Bureau.
___ (c)2023 the Asia News Network (Hamburg, Germany) Visit the Asia News Network (Hamburg, Germany) at www.asianewsnet.net/home/ Distributed by Tribune Content Agency, LLC.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: ANN
Acc-No: 20231127-ANN-LG-UNESCO-partner-to-promote-AI-ethics-1127
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); RESEARCH INSTITUTES (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (89%); AGREEMENTS (78%); ALLIANCES & PARTNERSHIPS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BEST PRACTICES (75%); CORPORATE GOVERNANCE (74%); INTERNET PRIVACY (74%); ASSOCIATIONS & ORGANIZATIONS (73%); SUSTAINABLE DEVELOPMENT (71%); HUMAN RIGHTS (70%); PRIVACY RIGHTS (69%); DISTANCE LEARNING (68%); TRENDS & EVENTS (68%); SUSTAINABILITY (55%); TEACHING MATERIALS & MEDIA (53%)
Company:  LG CORP (91%);  AI SYSTEMS (53%)
Ticker: 003550 (KSE) (91%)
Industry: NAICS551112 OFFICES OF OTHER HOLDING COMPANIES (91%); NAICS334419 OTHER ELECTRONIC COMPONENT MANUFACTURING (91%); SIC6719 OFFICES OF HOLDING COMPANIES, NEC (91%); SIC3651 HOUSEHOLD AUDIO & VIDEO EQUIPMENT (91%); SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); INTERNET PRIVACY (74%); SUSTAINABLE DEVELOPMENT (71%); DATA SECURITY (69%); INFORMATION SECURITY & PRIVACY (69%)
Geographic: HAMBURG, GERMANY (92%); DHAKA, BANGLADESH (90%); ASIA (94%); SOUTH KOREA (92%); BANGLADESH (88%); GERMANY (88%)
Load-Date: November 28, 2023",neutral,0.5600435733795166,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security', 'human rights', 'agency']","['fairness', 'dignity']","['governance', 'framework']",[],6,2,2,0
2023,Unknown Title,"Byline: Targeted News Service
Dateline: JOHANNESBURG, South Africa 
Body
(TNSres) -- The University of the Witwatersrand issued the following news:
While polarisation has emerged as a defining characteristic of our age, 'good' ethics can navigate differences to tackle shared challenges.
With multiple wars waging and intersecting with threats of climate change, poverty, and inequality, research ethics and integrity - as an academic and practical concept - can turn anxiety into action.
This was the overriding message at the 3rd SARIMA Carnegie Global Ethics Day webinar themed, Empower Ethics as a Force for Good.
Co-hosted by Wits' Research Integrity Office and the Southern African Research and Innovation Management Association (SARIMA) Community of Practice for Research Ethics and Integrity (CoP), this annual event has become a critical one for SARIMA's CoP.
Ethics as a force for good
""We need to empower our institutions, research committees and researchers to do good work in the realm of ethics. We need to dispel misconceptions about ethics. Ethics is not just an abstract area of study for philosophers and academics. It is a process that each of us can engage in to improve our lives, strengthen our communities, and build a better world,"" said Eleni Flack-Davison, Head of the Research Integrity Office, and Research Compliance Manager at Wits University.
Flack-Davison emphasised that ethics is not necessarily about agreement or tied to a single set of values. ""We can use ethics to guide personal decisions, mitigate harmful outcomes, create a more respectful structure for debate, develop helpful public policy, build and deploy technologies responsibly, and address some of the world's most pressing challenges.""
Partnerships for sustainable development in research ethics
The 17th Sustainable Development Goal (SDG) is Partnerships for the Goals. Francis Kombe of the African Research Integrity Network (ARIN) presented ways to empower research partnerships, particularly in low and middle-income countries.
""The International Science Council highlights the importance of scientists and policymakers to come together to implement the SDGs in Africa. Partnerships allow stakeholders to identify solutions to problems and take advantage of the enormous opportunities in our context,"" said Kombe.
He stipulated the importance of diverse and integrated knowledge in research decision-making. This is particularly pertinent to research that crosses the Global North-South divide and where partners hail from both high- and lower-income countries.
Kombe referred to the various research partnership guidelines, particularly those published by the Swiss Commission for Research Partnership with Developing Countries. These guidelines contain eleven principles that are designed to contribute to sustainable development and help solve local and global challenges. Essentially, the Global South must be integral in crafting research integrity and ethics guidelines:
""Africa is poorly represented in global health research. However, the continent has the highest burden of disease,"" said Kombe. ""ARIN was established to rectify this poor representation and to nurture and support research integrity in African researchers, institutions, and decision-makers, guided by African perspectives, values and inclusive thinking.""
Dr Retha Visagie, UNISA's Research Integrity Manager, said that research institutions should serve as a vital space for collaboration and growing intellectual property. ""One of the competencies of a research manager should be to create and expand partnering opportunities and balance complex stakeholder relationships,"" she said.
In addition to advancing partnerships to empower research ethics and integrity, ethics-based documents, such as the Cape Town Statement on Fairness, Equity and Diversity, should move beyond theory: ""Our obligation as research managers and administrators is to go beyond simple awareness and to make the Cape Town Statement a 'living' document,"" she said.
Artificial Intelligence and enabling ethics
Artificial intelligence (AI) presents challenges for research ethics and integrity. Sidney Engelbrecht of the Research Compliance Department at King Abdullah University of Science and Technology, Kingdom of Saudi Arabia, noted that the research community should collaboratively promote a culture of responsible conduct regarding the use of AI tools.
""Indeed, AI can be useful in healthcare and medical applications. It is also becoming more sophisticated. Recently, researchers entered questions into Chat GPT that were traditionally answered at Master's and PhD levels. Surprisingly, the study showed that Chat GPT could respond adequately to really complex questions. It was thought that AI could never replace critical thinking, but this is no longer certain,"" said Engelbrecht.
He stressed the ""mindful"" use of AI and commended the various AI regulations on the table, even if they are in their infancy. Specifically, in November 2021, all 193 UNESCO Member States adopted the Recommendation on the Ethics of Artificial Intelligence, highlighting that concrete policy actions needed to ensure that the development, deployment, and use of AI is done ethically.
From statements to implementation
Paula Saner, University of Cape Town's Research Integrity Manager, noted that while there are ethics and integrity best practice guidelines and statements, they are not legally embedded. ""Yes, there are regulations, and we can leverage these regulations to influence policy development. How we do this is to place research integrity as the starting point for research. A responsible researcher is more than an ethical researcher. Responsible research practices filter into all research stages. Most of our institutions already have mechanisms in place to support this,"" said Saner.
* * *
Original text here: https://www.wits.ac.za/news/latest-news/research-news/2023/2023-12/research-ethics-and-integrity-as-a-force-for-good.html
MSTRUCK-8418781 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); ALLIANCES & PARTNERSHIPS (89%); COLLABORATIVE RESEARCH & DEVELOPMENT (89%); RESEARCH & DEVELOPMENT (89%); SUSTAINABILITY (89%); SUSTAINABLE DEVELOPMENT (89%); SUSTAINABLE DEVELOPMENT GOALS (89%); AGREEMENTS (78%); PHILOSOPHY (78%); HEALTH SERVICES RESEARCH (77%); LOW INCOME PERSONS (77%); NEGATIVE NEWS (77%); POVERTY & HOMELESSNESS (77%); SCIENCE POLICY (77%); ASSOCIATIONS & ORGANIZATIONS (74%); DEVELOPING COUNTRIES (73%); TRENDS & EVENTS (72%); BUSINESS & PROFESSIONAL ASSOCIATIONS (69%); PUBLIC POLICY (69%); MEDICINE & HEALTH (60%)
Industry: SUSTAINABLE DEVELOPMENT (89%); SUSTAINABLE DEVELOPMENT GOALS (89%); HEALTH SERVICES RESEARCH (77%); KNOWLEDGE MANAGEMENT (77%); TELECONFERENCING (70%)
Geographic: JOHANNESBURG, SOUTH AFRICA (79%); AFRICA (92%); SOUTH AFRICA (79%); SOUTHERN AFRICA (58%)
Load-Date: December 19, 2023","(TNSres) -- The University of the Witwatersrand issued the following news:
While polarisation has emerged as a defining characteristic of our age, 'good' ethics can navigate differences to tackle shared challenges.
With multiple wars waging and intersecting with threats of climate change, poverty, and inequality, research ethics and integrity - as an academic and practical concept - can turn anxiety into action.
This was the overriding message at the 3rd SARIMA Carnegie Global Ethics Day webinar themed, Empower Ethics as a Force for Good.
Co-hosted by Wits' Research Integrity Office and the Southern African Research and Innovation Management Association (SARIMA) Community of Practice for Research Ethics and Integrity (CoP), this annual event has become a critical one for SARIMA's CoP.
Ethics as a force for good
""We need to empower our institutions, research committees and researchers to do good work in the realm of ethics. We need to dispel misconceptions about ethics. Ethics is not just an abstract area of study for philosophers and academics. It is a process that each of us can engage in to improve our lives, strengthen our communities, and build a better world,"" said Eleni Flack-Davison, Head of the Research Integrity Office, and Research Compliance Manager at Wits University.
Flack-Davison emphasised that ethics is not necessarily about agreement or tied to a single set of values. ""We can use ethics to guide personal decisions, mitigate harmful outcomes, create a more respectful structure for debate, develop helpful public policy, build and deploy technologies responsibly, and address some of the world's most pressing challenges.""
Partnerships for sustainable development in research ethics
The 17th Sustainable Development Goal (SDG) is Partnerships for the Goals. Francis Kombe of the African Research Integrity Network (ARIN) presented ways to empower research partnerships, particularly in low and middle-income countries.
""The International Science Council highlights the importance of scientists and policymakers to come together to implement the SDGs in Africa. Partnerships allow stakeholders to identify solutions to problems and take advantage of the enormous opportunities in our context,"" said Kombe.
He stipulated the importance of diverse and integrated knowledge in research decision-making. This is particularly pertinent to research that crosses the Global North-South divide and where partners hail from both high- and lower-income countries.
Kombe referred to the various research partnership guidelines, particularly those published by the Swiss Commission for Research Partnership with Developing Countries. These guidelines contain eleven principles that are designed to contribute to sustainable development and help solve local and global challenges. Essentially, the Global South must be integral in crafting research integrity and ethics guidelines:
""Africa is poorly represented in global health research. However, the continent has the highest burden of disease,"" said Kombe. ""ARIN was established to rectify this poor representation and to nurture and support research integrity in African researchers, institutions, and decision-makers, guided by African perspectives, values and inclusive thinking.""
Dr Retha Visagie, UNISA's Research Integrity Manager, said that research institutions should serve as a vital space for collaboration and growing intellectual property. ""One of the competencies of a research manager should be to create and expand partnering opportunities and balance complex stakeholder relationships,"" she said.
In addition to advancing partnerships to empower research ethics and integrity, ethics-based documents, such as the Cape Town Statement on Fairness, Equity and Diversity, should move beyond theory: ""Our obligation as research managers and administrators is to go beyond simple awareness and to make the Cape Town Statement a 'living' document,"" she said.
Artificial Intelligence and enabling ethics
Artificial intelligence (AI) presents challenges for research ethics and integrity. Sidney Engelbrecht of the Research Compliance Department at King Abdullah University of Science and Technology, Kingdom of Saudi Arabia, noted that the research community should collaboratively promote a culture of responsible conduct regarding the use of AI tools.
""Indeed, AI can be useful in healthcare and medical applications. It is also becoming more sophisticated. Recently, researchers entered questions into Chat GPT that were traditionally answered at Master's and PhD levels. Surprisingly, the study showed that Chat GPT could respond adequately to really complex questions. It was thought that AI could never replace critical thinking, but this is no longer certain,"" said Engelbrecht.
He stressed the ""mindful"" use of AI and commended the various AI regulations on the table, even if they are in their infancy. Specifically, in November 2021, all 193 UNESCO Member States adopted the Recommendation on the Ethics of Artificial Intelligence, highlighting that concrete policy actions needed to ensure that the development, deployment, and use of AI is done ethically.
From statements to implementation
Paula Saner, University of Cape Town's Research Integrity Manager, noted that while there are ethics and integrity best practice guidelines and statements, they are not legally embedded. ""Yes, there are regulations, and we can leverage these regulations to influence policy development. How we do this is to place research integrity as the starting point for research. A responsible researcher is more than an ethical researcher. Responsible research practices filter into all research stages. Most of our institutions already have mechanisms in place to support this,"" said Saner.
* * *
Original text here: https://www.wits.ac.za/news/latest-news/research-news/2023/2023-12/research-ethics-and-integrity-as-a-force-for-good.html
MSTRUCK-8418781 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); ALLIANCES & PARTNERSHIPS (89%); COLLABORATIVE RESEARCH & DEVELOPMENT (89%); RESEARCH & DEVELOPMENT (89%); SUSTAINABILITY (89%); SUSTAINABLE DEVELOPMENT (89%); SUSTAINABLE DEVELOPMENT GOALS (89%); AGREEMENTS (78%); PHILOSOPHY (78%); HEALTH SERVICES RESEARCH (77%); LOW INCOME PERSONS (77%); NEGATIVE NEWS (77%); POVERTY & HOMELESSNESS (77%); SCIENCE POLICY (77%); ASSOCIATIONS & ORGANIZATIONS (74%); DEVELOPING COUNTRIES (73%); TRENDS & EVENTS (72%); BUSINESS & PROFESSIONAL ASSOCIATIONS (69%); PUBLIC POLICY (69%); MEDICINE & HEALTH (60%)
Industry: SUSTAINABLE DEVELOPMENT (89%); SUSTAINABLE DEVELOPMENT GOALS (89%); HEALTH SERVICES RESEARCH (77%); KNOWLEDGE MANAGEMENT (77%); TELECONFERENCING (70%)
Geographic: JOHANNESBURG, SOUTH AFRICA (79%); AFRICA (92%); SOUTH AFRICA (79%); SOUTHERN AFRICA (58%)
Load-Date: December 19, 2023",neutral,0.8140420913696289,balanced/neutral,"['fairness', 'inequality']","['fairness', 'equity']","['policy', 'guidelines', 'compliance', 'should', 'must', 'need to']",['gpt'],2,2,6,1
2023,Unknown Title,"Byline: Thomas Fox - Compliance Evangelist
Body
December 11th, 2023 ( JD Supra  — Delivered by  Newstex )
What you'll learn on this podcast episode
Artificial intelligence has become the topic du jour—from national news outlets to trade publications. The very term can elicit feelings of uncertainty and dissonance about how it will be applied in our daily lives. One thing is certain: AI will transform the way we do business. With such innovative technology comes the responsibility to use it wisely and ethically. In this episode of the Principled Podcast, host Susan Divers discusses how organizations can approach AI in a responsible and ethical way with Jim Byrne, the vice president for ethics and business conduct at Lockheed Martin.
Guest: Jim Byrne
The Honorable James M. Byrne currently serves as Vice President, Ethics and Business Conduct, for Lockheed Martin Corporation. He is responsible for the strategic direction and operational excellence of Lockheed Martin's award-winning domestic and international ethics program and execution of the Corporation's compliance training across the enterprise. Jim is also on the Corporate Artificial Intelligence (AI) Executive Steering Committee and Corporate Vice Presidents Contributions Committee of Lockheed Martin, established and authorized to review and approve large charitable contributions. He previously served as Lockheed Martin's Chief Privacy Officer and Associate General Counsel leading teams supporting information security, counterintelligence, electronic discovery and records management. Jim also served for several years on the board of directors for Pacific Architects & Engineers (PAE), then a wholly-owned subsidiary of Lockheed Martin.
Jim is a Secretary of the Navy Distinguished Midshipman Graduate of the U.S. Naval Academy, where he received an engineering degree and held the top leadership position of Brigade Commander. He holds a law degree from Stetson University College of Law, where he was awarded a public service fellowship.
In his current role, Jim draws upon his experiences as a deployed Marine Corps combat arms officer, U.S. Department of Justice international narcotics prosecutor, and service at the highest levels of the federal government. He was forward-deployed as an anti-corruption advisor to senior Iraqi officials while leading a team of dedicated and experienced federal law enforcement officers investigating criminal fraud and other misuses of funds supporting the $52B U.S. reconstruction effort in Iraq. Prior to rejoining Lockheed Martin, Jim was nominated by the President and confirmed by the U.S. Senate as General Counsel and then as the 8th Deputy Secretary of Veterans Affairs—the designated chief operating officer of the second largest U.S. cabinet agency.
Jim's past professional engagements include director and advisory board positions on several startup companies, and service on the U.S. Department of Homeland Security Data Privacy & Integrity Advisory Committee and the International Association of Privacy Professionals Board of Directors (Chairman). He currently serves as a proxy holder-outside board director for Rancher Government Solutions, a subsidiary of FWB: SUSE. Jim is active in his church and community, and prioritizes mentoring veterans. He currently volunteers on the American Association of Suicidology Board of Directors, the Navy-Marine Corps Relief Society Advisory Board, Veterans Moving Forward Board of Directors, Maternal Mental Health Leadership Alliance Board of Directors and the Give an Hour Executive Board of Directors.
Host: Susan Divers
Susan Divers is a senior advisor with LRN Corporation. In that capacity, Ms. Divers brings her 30+ years' accomplishments and experience in the ethics and compliance area to LRN partners and colleagues. This expertise includes building state-of-the-art compliance programs infused with values, designing user-friendly means of engaging and informing employees, fostering an embedded culture of compliance and substantial subject matter expertise in anti-corruption, export controls, sanctions, and other key areas of compliance.
Prior to joining LRN, Mrs. Divers served as AECOM's Assistant General for Global Ethics & Compliance and Chief Ethics & Compliance Officer. Under her leadership, AECOM's ethics and compliance program garnered six external awards in recognition of its effectiveness and Mrs. Divers' thought leadership in the ethics field. In 2011, Mrs. Divers received the AECOM CEO Award of Excellence, which recognized her work in advancing the company's ethics and compliance program.
Mrs. Divers has over 30 years of experience in law, including working at SAIC and Lockheed Martin, Sonnenschein, Nath & Rosenthal, and Sonnenschein, Nath & Rosenthal. She is a Solicitor to the High Court of England and Wales and has served as an attorney in the Department of State and the UN. Diver is a member of the DC Bar, Trinity College, and George Washington University. She is a frequent speaker, writer, and commentator on ethics and compliance topics. See less -
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EXECUTIVES (90%); CERTIFICATES, DEGREES & DIPLOMAS (89%); GOVERNMENT BODIES & OFFICES (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); US FEDERAL GOVERNMENT (89%); BOARDS OF DIRECTORS (88%); DEFENSE CONTRACTING (88%); NATIONAL SECURITY & FOREIGN RELATIONS (88%); LAW ENFORCEMENT (87%); NAVIES (87%); ARMED FORCES (86%); NEGATIVE NEWS (86%); PROFESSIONAL WORKERS (86%); CRIME, LAW ENFORCEMENT & CORRECTIONS (85%); LAW SCHOOLS (78%); LEGAL TECHNOLOGY (78%); NATIONAL SECURITY (78%); SPECIAL INVESTIGATIVE FORCES (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (77%); CORRUPTION (77%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); ENGINEERING (76%); TECHNICIANS & TECHNOLOGICAL WORKERS (76%); ASSOCIATIONS & ORGANIZATIONS (75%); INVESTIGATIONS (74%); LEGISLATIVE BODIES (72%); NEW BUSINESSES (72%); OPERATIONAL EXCELLENCE (71%); CORPORATE COUNSEL (70%); JUSTICE DEPARTMENTS (70%); LAWYERS (70%); EMPLOYMENT HISTORY (69%); US NAVY (69%); MILITARY SCHOOLS & ACADEMIES (68%); US CONGRESS (68%); ANTI-CORRUPTION (67%); CHARITABLE GIVING (66%); CRIMINAL INVESTIGATIONS (66%); FRAUD & FINANCIAL CRIME (66%); NEGATIVE MISC NEWS (65%); PRIVACY RIGHTS (65%); PUBLIC PROSECUTORS (61%)
Company:  LOCKHEED MARTIN CORP (92%);  PAE INC (54%)
Ticker: LMT (NYSE) (92%); PAE (NASDAQ) (54%)
Industry: NAICS336414 GUIDED MISSILE & SPACE VEHICLE MANUFACTURING (92%); NAICS336411 AIRCRAFT MANUFACTURING (92%); NAICS334511 SEARCH, DETECTION, NAVIGATION, GUIDANCE, AERONAUTICAL & NAUTICAL SYSTEM & INSTRUMENT MFG (92%); SIC5088 TRANSPORTATION EQUIPMENT & SUPPLIES, EXCEPT MOTOR VEHICLES (92%); SIC3812 SEARCH, DETECTION, NAVIGATION, GUIDANCE, AERONAUTICAL & NAUTICAL SYSTEMS & INSTRUMENTS (92%); SIC3728 AIRCRAFT PARTS & AUXILIARY EQUIPMENT, NEC (92%); SIC3721 AIRCRAFT (92%); NAICS541310 ARCHITECTURAL SERVICES (54%); SIC8712 ARCHITECTURAL SERVICES (54%); SIC7372 PREPACKAGED SOFTWARE (54%); PODCASTING (91%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (88%); NAVIES (87%); ARMED FORCES (86%); LAW SCHOOLS (78%); LEGAL TECHNOLOGY (78%); ENGINEERING (76%); CORPORATE COUNSEL (70%); INFORMATION SECURITY & PRIVACY (70%); LAWYERS (70%); US NAVY (69%); MILITARY SCHOOLS & ACADEMIES (68%); PUBLIC PROSECUTORS (61%)
Geographic: UNITED STATES (94%); IRAQ (91%)
Load-Date: December 11, 2023","December 11th, 2023 ( JD Supra  — Delivered by  Newstex )
What you'll learn on this podcast episode
Artificial intelligence has become the topic du jour—from national news outlets to trade publications. The very term can elicit feelings of uncertainty and dissonance about how it will be applied in our daily lives. One thing is certain: AI will transform the way we do business. With such innovative technology comes the responsibility to use it wisely and ethically. In this episode of the Principled Podcast, host Susan Divers discusses how organizations can approach AI in a responsible and ethical way with Jim Byrne, the vice president for ethics and business conduct at Lockheed Martin.
Guest: Jim Byrne
The Honorable James M. Byrne currently serves as Vice President, Ethics and Business Conduct, for Lockheed Martin Corporation. He is responsible for the strategic direction and operational excellence of Lockheed Martin's award-winning domestic and international ethics program and execution of the Corporation's compliance training across the enterprise. Jim is also on the Corporate Artificial Intelligence (AI) Executive Steering Committee and Corporate Vice Presidents Contributions Committee of Lockheed Martin, established and authorized to review and approve large charitable contributions. He previously served as Lockheed Martin's Chief Privacy Officer and Associate General Counsel leading teams supporting information security, counterintelligence, electronic discovery and records management. Jim also served for several years on the board of directors for Pacific Architects & Engineers (PAE), then a wholly-owned subsidiary of Lockheed Martin.
Jim is a Secretary of the Navy Distinguished Midshipman Graduate of the U.S. Naval Academy, where he received an engineering degree and held the top leadership position of Brigade Commander. He holds a law degree from Stetson University College of Law, where he was awarded a public service fellowship.
In his current role, Jim draws upon his experiences as a deployed Marine Corps combat arms officer, U.S. Department of Justice international narcotics prosecutor, and service at the highest levels of the federal government. He was forward-deployed as an anti-corruption advisor to senior Iraqi officials while leading a team of dedicated and experienced federal law enforcement officers investigating criminal fraud and other misuses of funds supporting the $52B U.S. reconstruction effort in Iraq. Prior to rejoining Lockheed Martin, Jim was nominated by the President and confirmed by the U.S. Senate as General Counsel and then as the 8th Deputy Secretary of Veterans Affairs—the designated chief operating officer of the second largest U.S. cabinet agency.
Jim's past professional engagements include director and advisory board positions on several startup companies, and service on the U.S. Department of Homeland Security Data Privacy & Integrity Advisory Committee and the International Association of Privacy Professionals Board of Directors (Chairman). He currently serves as a proxy holder-outside board director for Rancher Government Solutions, a subsidiary of FWB: SUSE. Jim is active in his church and community, and prioritizes mentoring veterans. He currently volunteers on the American Association of Suicidology Board of Directors, the Navy-Marine Corps Relief Society Advisory Board, Veterans Moving Forward Board of Directors, Maternal Mental Health Leadership Alliance Board of Directors and the Give an Hour Executive Board of Directors.
Host: Susan Divers
Susan Divers is a senior advisor with LRN Corporation. In that capacity, Ms. Divers brings her 30+ years' accomplishments and experience in the ethics and compliance area to LRN partners and colleagues. This expertise includes building state-of-the-art compliance programs infused with values, designing user-friendly means of engaging and informing employees, fostering an embedded culture of compliance and substantial subject matter expertise in anti-corruption, export controls, sanctions, and other key areas of compliance.
Prior to joining LRN, Mrs. Divers served as AECOM's Assistant General for Global Ethics & Compliance and Chief Ethics & Compliance Officer. Under her leadership, AECOM's ethics and compliance program garnered six external awards in recognition of its effectiveness and Mrs. Divers' thought leadership in the ethics field. In 2011, Mrs. Divers received the AECOM CEO Award of Excellence, which recognized her work in advancing the company's ethics and compliance program.
Mrs. Divers has over 30 years of experience in law, including working at SAIC and Lockheed Martin, Sonnenschein, Nath & Rosenthal, and Sonnenschein, Nath & Rosenthal. She is a Solicitor to the High Court of England and Wales and has served as an attorney in the Department of State and the UN. Diver is a member of the DC Bar, Trinity College, and George Washington University. She is a frequent speaker, writer, and commentator on ethics and compliance topics. See less -
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 105411
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EXECUTIVES (90%); CERTIFICATES, DEGREES & DIPLOMAS (89%); GOVERNMENT BODIES & OFFICES (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); US FEDERAL GOVERNMENT (89%); BOARDS OF DIRECTORS (88%); DEFENSE CONTRACTING (88%); NATIONAL SECURITY & FOREIGN RELATIONS (88%); LAW ENFORCEMENT (87%); NAVIES (87%); ARMED FORCES (86%); NEGATIVE NEWS (86%); PROFESSIONAL WORKERS (86%); CRIME, LAW ENFORCEMENT & CORRECTIONS (85%); LAW SCHOOLS (78%); LEGAL TECHNOLOGY (78%); NATIONAL SECURITY (78%); SPECIAL INVESTIGATIVE FORCES (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (77%); CORRUPTION (77%); GOVERNMENT & PUBLIC ADMINISTRATION (77%); ENGINEERING (76%); TECHNICIANS & TECHNOLOGICAL WORKERS (76%); ASSOCIATIONS & ORGANIZATIONS (75%); INVESTIGATIONS (74%); LEGISLATIVE BODIES (72%); NEW BUSINESSES (72%); OPERATIONAL EXCELLENCE (71%); CORPORATE COUNSEL (70%); JUSTICE DEPARTMENTS (70%); LAWYERS (70%); EMPLOYMENT HISTORY (69%); US NAVY (69%); MILITARY SCHOOLS & ACADEMIES (68%); US CONGRESS (68%); ANTI-CORRUPTION (67%); CHARITABLE GIVING (66%); CRIMINAL INVESTIGATIONS (66%); FRAUD & FINANCIAL CRIME (66%); NEGATIVE MISC NEWS (65%); PRIVACY RIGHTS (65%); PUBLIC PROSECUTORS (61%)
Company:  LOCKHEED MARTIN CORP (92%);  PAE INC (54%)
Ticker: LMT (NYSE) (92%); PAE (NASDAQ) (54%)
Industry: NAICS336414 GUIDED MISSILE & SPACE VEHICLE MANUFACTURING (92%); NAICS336411 AIRCRAFT MANUFACTURING (92%); NAICS334511 SEARCH, DETECTION, NAVIGATION, GUIDANCE, AERONAUTICAL & NAUTICAL SYSTEM & INSTRUMENT MFG (92%); SIC5088 TRANSPORTATION EQUIPMENT & SUPPLIES, EXCEPT MOTOR VEHICLES (92%); SIC3812 SEARCH, DETECTION, NAVIGATION, GUIDANCE, AERONAUTICAL & NAUTICAL SYSTEMS & INSTRUMENTS (92%); SIC3728 AIRCRAFT PARTS & AUXILIARY EQUIPMENT, NEC (92%); SIC3721 AIRCRAFT (92%); NAICS541310 ARCHITECTURAL SERVICES (54%); SIC8712 ARCHITECTURAL SERVICES (54%); SIC7372 PREPACKAGED SOFTWARE (54%); PODCASTING (91%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE CONTRACTING (88%); NAVIES (87%); ARMED FORCES (86%); LAW SCHOOLS (78%); LEGAL TECHNOLOGY (78%); ENGINEERING (76%); CORPORATE COUNSEL (70%); INFORMATION SECURITY & PRIVACY (70%); LAWYERS (70%); US NAVY (69%); MILITARY SCHOOLS & ACADEMIES (68%); PUBLIC PROSECUTORS (61%)
Geographic: UNITED STATES (94%); IRAQ (91%)
Load-Date: December 11, 2023",neutral,0.8486822843551636,balanced/neutral,"['privacy', 'security', 'agency']","['justice', 'justice']","['law', 'compliance', 'should']",[],3,2,3,0
2023,Unknown Title,"Byline: States News Service
Dateline: LONDON 
Body
The following information was released by the UK Government:
The Home Office is looking for 6 new members to join the Biometrics and Forensics Ethics Group (BFEG).
From:
Biometrics and Forensics Ethics Group
Published
10 August 2023
The Home Office is recruiting up to 6 new members with knowledge or experience in the following areas to join the independent scientific advisory committee, the Biometrics and Forensics Ethics Group (BFEG):
the law, with experience in relevant areas such as criminal law, forensic science, biometrics, and data
social sciences, with experience of considering the social and ethical implications of technological innovations, such as in forensics, biometrics or use of data
data ethics, with experience of considering the issues in the use of large data sets across the biometric, forensic and criminal justice arena or other relevant fields (experience in considering the application of data within industry, enforcement or medicine is desirable)
artificial intelligence, with experience of considering the regulation of or ethical application of artificial intelligence tools/systems
biometrics, with experience of considering the ethical use of biometric systems on society
medical ethics, experience of review or evaluation of ethics in regard to medical decision making
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); FORENSICS (93%); BIOMETRICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CRIMINAL JUSTICE (78%); MEDICAL ETHICS (78%); CRIMINAL LAW (75%); CLINICAL DECISION SUPPORT (72%); HUMANITIES & SOCIAL SCIENCE (71%); CRIME, LAW ENFORCEMENT & CORRECTIONS (70%); ARTIFICIAL INTELLIGENCE (67%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (78%); CLINICAL DECISION SUPPORT (72%); BIG DATA (70%); ARTIFICIAL INTELLIGENCE (67%)
Geographic: LONDON, ENGLAND (74%); UNITED KINGDOM (74%)
Load-Date: August 10, 2023","The following information was released by the UK Government:
The Home Office is looking for 6 new members to join the Biometrics and Forensics Ethics Group (BFEG).
From:
Biometrics and Forensics Ethics Group
Published
10 August 2023
The Home Office is recruiting up to 6 new members with knowledge or experience in the following areas to join the independent scientific advisory committee, the Biometrics and Forensics Ethics Group (BFEG):
the law, with experience in relevant areas such as criminal law, forensic science, biometrics, and data
social sciences, with experience of considering the social and ethical implications of technological innovations, such as in forensics, biometrics or use of data
data ethics, with experience of considering the issues in the use of large data sets across the biometric, forensic and criminal justice arena or other relevant fields (experience in considering the application of data within industry, enforcement or medicine is desirable)
artificial intelligence, with experience of considering the regulation of or ethical application of artificial intelligence tools/systems
biometrics, with experience of considering the ethical use of biometric systems on society
medical ethics, experience of review or evaluation of ethics in regard to medical decision making
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); FORENSICS (93%); BIOMETRICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CRIMINAL JUSTICE (78%); MEDICAL ETHICS (78%); CRIMINAL LAW (75%); CLINICAL DECISION SUPPORT (72%); HUMANITIES & SOCIAL SCIENCE (71%); CRIME, LAW ENFORCEMENT & CORRECTIONS (70%); ARTIFICIAL INTELLIGENCE (67%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (78%); CLINICAL DECISION SUPPORT (72%); BIG DATA (70%); ARTIFICIAL INTELLIGENCE (67%)
Geographic: LONDON, ENGLAND (74%); UNITED KINGDOM (74%)
Load-Date: August 10, 2023",neutral,0.8940445184707642,balanced/neutral,[],"['justice', 'justice']","['regulation', 'law']",[],0,2,2,0
2023,Unknown Title,"Body
Create company culture of ethics in technology
By Staff Writer  Johannesburg, 10 Oct 2023  Read time 6min 10sec
In this article
    The University of Pretoria's Dr Hanlie Smuts and Dr Lizette Weilbach.
The importance of ethics in technology is seeing renewed hot debate, with artificial intelligence (AI), in particular, under the global spotlight since the release of OpenAI's ChatGPT, the AI-powered large language chatbot, at the end of last year.
Dr Hanlie Smuts, associate professor at the Department of Informatics, University of Pretoria, and Dr Lizette Weilbach, a senior lecturer in the Department of Informatics, University of Pretoria, have researched ethics in technology, and packaged some of their findings for ITWeb readers.
""We live in a ubiquitous computing world transformed by the evolution of digital technologies. The growing application of digital technologies resulted in a highly-integrated cyber-physical space. A key enabler to the viability of cyber-physical systems is the availability of data and the extraction of value from data. Inevitably, data-driven organisations apply data for their decision-making, rather than intuition,"" they comment.
See also Humanising tech, from UX to impactful human experience
Feeding a knowledge-intensive society
""One of the key demands of the cyber-physical world is the need to provide safety and security for such systems. Through digital transformation, organisations integrate technology into business processes, products and services, emphasising potential ethical considerations.
""These considerations include aspects such as how organisations use information, how employees are engaged and empowered to be able to deal with ethical dilemmas in their day-to-day work, how organisations manage resources and how they approach sustainability,"" Dr Smuts andDr Weilbach state.
Based on their analysis of key concepts of ethics in technology, the academics provide 10 principles and checkpoints to support organisations to navigate the world of computer, cyber, robot and human ethics.
Computer (internet) ethics
1. Be ethically-driven from the start: Organisations need to be proactive and stay at the forefront of potential ethical technology challenges. From the start, organisations need to design technology-driven products and services with ethical principles in mind. This can assist them to anticipate and avoid situations, rather than being reactive after the effect.
2. Embrace an ethical technical technology mindset: Ethical technology recognition, awareness and decision-making frameworks should not only be perceived as a compliance or policy action, but should be inherent to the organisation's fabric. Adoption of the technology disruption vocabulary and syntax is not sufficient; companies should be aware of the ethical decision-makers' role regarding technology disruptors.
3. Create a culture of shared responsibility: Engage all functions and champion it from the top. Leaving shared responsibility to a few teams or departments, promotes the impression that the whole organisation is not required to consider it. Companies need to be able to distinguish the ethical issues technology disruption may introduce and apply consistent means of pinpointing ethical courses of action. By promoting a culture that supports these courses of action, ethical decision-making will be endorsed.
4. Ensure an approach that can evolve: Approaches to ethical technology in organisations should be assessed and revised as needed due to the unpredictable and rapid way in which technology is evolving. Policies developed in recent years may no longer directly address current risks based on the rate at which markets are changing, Companies must therefore develop policies and frameworks to guide technology decisions, with the expectation that they will likely require adjustment and adaptation as markets evolve and technologies change.
5. Equip employees with the resources to respond: Employees, teams and departments should have the resources they require to make ethical decisions regarding technology. It is therefore important that organisations provide employees with applicable resources, assets and tools. These resources will assist employees to recognise ethical dilemmas, to appraise alternatives, to make and to test ethical technology decisions.
Cyber ethics
6. Moral use of data and resources: Data is of great value in refining product offerings and implementing new marketing strategies. However, such strategies can also be invasive in terms of privacy, highlighting many ethical issues. To ensure data is not leaked or used inappropriately, data protection measures and compliance procedures may be defined and applied in order to guide moral use of data.
7. Design the organisation for ethical technology: Ethical technology policies are not intended to replace business ethics or general compliance, but rather to strengthen them. Hence, avoid creating functional silos in the context of ethics or establish a separate, standalone ethics programme. Rather expand departments' objectives to include ethical technology considerations. Encourage and teach employees to distinguish among professional ethics concerns, technology-related ethical issues and broader corporate matters.
Robot ethics (including AI ethics)
8. Responsible adoption of disruptive technologies: Digital growth is a business reality, yet such digital transformation should not cause ethical challenges. To ensure the technologies the business adopts have ethics considerations and protection in place, it should do due diligence prior to technology acquisition. Due diligence may be supported by the development of a guiding framework that is inclusive of technology use cases specific to the company and aligned to its culture.
Human ethics
9. Respect for employees and customers: Organisations that engage in good ethical technology practices, and understand that customers and employees are their greatest asset, maintain a strong moral sense of the rights of their employees and the protection of their customers. The value of data is therefore considered within a frame of responsible protection of employees and customers alike.
10. Make ethical technology part of a holistic, technology know-how approach: It is important the whole business recognises potentially technology-related ethical predicaments. Employees that are not directly involved with, or responsible for technology, must be trained and empowered to recognise ethical technology issues; even when these technology issues are less obvious. This may especially be important for less digitally transformed organisations, where the implications of technology for day-to-day operations are less obvious to employees.
About the research authors
Dr Hanlie Smuts has been an associate professor at the Department of Informatics, University of Pretoria, since 2017. Her lecturing and research role focuses on IT and the organisation, with particular emphasis on Society 5.0, digital transformation, big data management, artificial intelligence and knowledge management.
Dr Smuts is deputy chair of the Knowledge Management South Africa board and has published several papers and book chapters in her field of study.
Dr Lizette Weilbach is a senior lecturer in the Department of Informatics, University of Pretoria. She has 21 years of expertise in information systems analysis and design education within the realm of higher education. Over the course of her career, she has dedicated 14 years to instructing the Informatics Capstone project, which is designed to produce industry-ready graduates.
Dr Weilbach's research primarily revolves around IT in education, with a strong focus on enhancing the pedagogy related to business and systems analysis. Additionally, she maintains a secondary research interest in IT and organisational dynamics, particularly concentrating on areas such as Society 5.0, disruptive technologies, and its impact on SMEs and innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); CORPORATE CULTURE (90%); GENERATIVE AI (90%); DISRUPTIVE INNOVATION (89%); ASSOCIATIONS & ORGANIZATIONS (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EMERGING TECHNOLOGY (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); LARGE LANGUAGE MODELS (72%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); LARGE LANGUAGE MODELS (72%)
Geographic: PRETORIA, SOUTH AFRICA (88%)
Load-Date: October 17, 2023","Create company culture of ethics in technology
By Staff Writer  Johannesburg, 10 Oct 2023  Read time 6min 10sec
In this article
    The University of Pretoria's Dr Hanlie Smuts and Dr Lizette Weilbach.
The importance of ethics in technology is seeing renewed hot debate, with artificial intelligence (AI), in particular, under the global spotlight since the release of OpenAI's ChatGPT, the AI-powered large language chatbot, at the end of last year.
Dr Hanlie Smuts, associate professor at the Department of Informatics, University of Pretoria, and Dr Lizette Weilbach, a senior lecturer in the Department of Informatics, University of Pretoria, have researched ethics in technology, and packaged some of their findings for ITWeb readers.
""We live in a ubiquitous computing world transformed by the evolution of digital technologies. The growing application of digital technologies resulted in a highly-integrated cyber-physical space. A key enabler to the viability of cyber-physical systems is the availability of data and the extraction of value from data. Inevitably, data-driven organisations apply data for their decision-making, rather than intuition,"" they comment.
See also Humanising tech, from UX to impactful human experience
Feeding a knowledge-intensive society
""One of the key demands of the cyber-physical world is the need to provide safety and security for such systems. Through digital transformation, organisations integrate technology into business processes, products and services, emphasising potential ethical considerations.
""These considerations include aspects such as how organisations use information, how employees are engaged and empowered to be able to deal with ethical dilemmas in their day-to-day work, how organisations manage resources and how they approach sustainability,"" Dr Smuts andDr Weilbach state.
Based on their analysis of key concepts of ethics in technology, the academics provide 10 principles and checkpoints to support organisations to navigate the world of computer, cyber, robot and human ethics.
Computer (internet) ethics
1. Be ethically-driven from the start: Organisations need to be proactive and stay at the forefront of potential ethical technology challenges. From the start, organisations need to design technology-driven products and services with ethical principles in mind. This can assist them to anticipate and avoid situations, rather than being reactive after the effect.
2. Embrace an ethical technical technology mindset: Ethical technology recognition, awareness and decision-making frameworks should not only be perceived as a compliance or policy action, but should be inherent to the organisation's fabric. Adoption of the technology disruption vocabulary and syntax is not sufficient; companies should be aware of the ethical decision-makers' role regarding technology disruptors.
3. Create a culture of shared responsibility: Engage all functions and champion it from the top. Leaving shared responsibility to a few teams or departments, promotes the impression that the whole organisation is not required to consider it. Companies need to be able to distinguish the ethical issues technology disruption may introduce and apply consistent means of pinpointing ethical courses of action. By promoting a culture that supports these courses of action, ethical decision-making will be endorsed.
4. Ensure an approach that can evolve: Approaches to ethical technology in organisations should be assessed and revised as needed due to the unpredictable and rapid way in which technology is evolving. Policies developed in recent years may no longer directly address current risks based on the rate at which markets are changing, Companies must therefore develop policies and frameworks to guide technology decisions, with the expectation that they will likely require adjustment and adaptation as markets evolve and technologies change.
5. Equip employees with the resources to respond: Employees, teams and departments should have the resources they require to make ethical decisions regarding technology. It is therefore important that organisations provide employees with applicable resources, assets and tools. These resources will assist employees to recognise ethical dilemmas, to appraise alternatives, to make and to test ethical technology decisions.
Cyber ethics
6. Moral use of data and resources: Data is of great value in refining product offerings and implementing new marketing strategies. However, such strategies can also be invasive in terms of privacy, highlighting many ethical issues. To ensure data is not leaked or used inappropriately, data protection measures and compliance procedures may be defined and applied in order to guide moral use of data.
7. Design the organisation for ethical technology: Ethical technology policies are not intended to replace business ethics or general compliance, but rather to strengthen them. Hence, avoid creating functional silos in the context of ethics or establish a separate, standalone ethics programme. Rather expand departments' objectives to include ethical technology considerations. Encourage and teach employees to distinguish among professional ethics concerns, technology-related ethical issues and broader corporate matters.
Robot ethics (including AI ethics)
8. Responsible adoption of disruptive technologies: Digital growth is a business reality, yet such digital transformation should not cause ethical challenges. To ensure the technologies the business adopts have ethics considerations and protection in place, it should do due diligence prior to technology acquisition. Due diligence may be supported by the development of a guiding framework that is inclusive of technology use cases specific to the company and aligned to its culture.
Human ethics
9. Respect for employees and customers: Organisations that engage in good ethical technology practices, and understand that customers and employees are their greatest asset, maintain a strong moral sense of the rights of their employees and the protection of their customers. The value of data is therefore considered within a frame of responsible protection of employees and customers alike.
10. Make ethical technology part of a holistic, technology know-how approach: It is important the whole business recognises potentially technology-related ethical predicaments. Employees that are not directly involved with, or responsible for technology, must be trained and empowered to recognise ethical technology issues; even when these technology issues are less obvious. This may especially be important for less digitally transformed organisations, where the implications of technology for day-to-day operations are less obvious to employees.
About the research authors
Dr Hanlie Smuts has been an associate professor at the Department of Informatics, University of Pretoria, since 2017. Her lecturing and research role focuses on IT and the organisation, with particular emphasis on Society 5.0, digital transformation, big data management, artificial intelligence and knowledge management.
Dr Smuts is deputy chair of the Knowledge Management South Africa board and has published several papers and book chapters in her field of study.
Dr Lizette Weilbach is a senior lecturer in the Department of Informatics, University of Pretoria. She has 21 years of expertise in information systems analysis and design education within the realm of higher education. Over the course of her career, she has dedicated 14 years to instructing the Informatics Capstone project, which is designed to produce industry-ready graduates.
Dr Weilbach's research primarily revolves around IT in education, with a strong focus on enhancing the pedagogy related to business and systems analysis. Additionally, she maintains a secondary research interest in IT and organisational dynamics, particularly concentrating on areas such as Society 5.0, disruptive technologies, and its impact on SMEs and innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); CORPORATE CULTURE (90%); GENERATIVE AI (90%); DISRUPTIVE INNOVATION (89%); ASSOCIATIONS & ORGANIZATIONS (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EMERGING TECHNOLOGY (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); LARGE LANGUAGE MODELS (72%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); COLLEGE & UNIVERSITY PROFESSORS (73%); LARGE LANGUAGE MODELS (72%)
Geographic: PRETORIA, SOUTH AFRICA (88%)
Load-Date: October 17, 2023",neutral,0.7814498543739319,balanced/neutral,"['privacy', 'safety', 'security']",[],"['policy', 'framework', 'compliance', 'should', 'must', 'need to']","['generative ai', 'chatgpt', 'robot']",3,0,6,3
2023,Unknown Title,"Byline: Globaltimes.cn
Body
Photo: VCG
Chinese authorities released on Sunday the pilot review measures of science and technology ethics. As the new round of scientific and technological revolution and industrial transformation accelerate progress, ethical issues have become a common challenge facing the whole world. 
China's Ministry of Science and Technology together with nine other government departments such as the Ministry of Education and the Ministry of Industry and Information Technology, released the comprehensive and universal review measures that cover ethical reviews on science and technologies activities, in a bid to focus on solving a series of problems such as unclear responsibilities and lack of universal review standards. 
A series of measures and relevant provisions were proposed from the perspectives of improving the system, standardizing procedures, strict standards and strengthening supervision. 
The review methods define the main scope of the ethical reviews on science and technology, specify the responsible entities for ethical review, the criteria for establishing the science and technology ethics (review) committees and their organizational and operational mechanisms. The measures also outline the basic procedures for ethical reviews, and determine the content and standards for ethical reviews. 
According to the pilot measures, scientific and technological activities involving human participants, including research activities such as testing, surveys, and observations using human beings as research objects, as well as scientific activities using human biological samples and personal information data, shall be subject to ethical review in accordance with these measures. 
Meanwhile, scientific and technological activities involving laboratory animals shall be subject to the ethical review as well. 
Besides, science and technology activities that do not directly involve humans or laboratory animals but may pose ethical risks and challenges in areas such as life and health, ecological environment, public order and sustainable development shall also be subject to ethical review. 
The pilot measures also stipulate that institutions and units engaged in scientific activities in life sciences, medicine, artificial intelligence and other fields, whose research content involves sensitive areas of science and technology ethics, should establish a review committee on scientific and technological ethics. 
The review committee on scientific and technological ethics should conduct reviews if the scientific activities involve humans participants, to make sure fair and reasonable recruitment programs, lawful and compliant collection, storage, use and disposal of biological samples, and the processing of personal privacy data, biometric information and other information complied with the relevant provisions on the protection of personal information. 
The committee also should make sure the reasonable and appropriate protection plan for the legal rights and interests of research participants, including compensation, treatment for injuries, as well as the special protection of vulnerable groups. 
Scientific and technological activities involving laboratory animals should adhere to the principles of replacement, reduction and refinement and make sure the lawful and reasonable source of the laboratory animals. The technical operations of breeding, using, and disposing laboratory animals should comply with animal welfare standards. 
Technological activities involving data and algorithms, including activities related to the collection, storage, processing and use of data, as well as the research and development of new data technologies, should comply with relevant national regulations on data security and the protection of personal information. 
Risk monitoring and emergency response plans of data security must be appropriate. 
The design, implementation and application of algorithms, models and systems should adhere to principles such as fairness, justice, transparency, reliability and controllability, in accordance with relevant national requirements. 
The review measures also outline a list of emerging scientific and technological activities that may pose greater ethical risk and challenges, which have to be revalued by experts. 
Activities include the researches on the synthetic creation of new species that has a significant impact on human life and health, values, ecological environment, researches involving the introduction of human stem cells into animal embryos or fetuses and further gestation of the individual in an animal uterus, and basic researches that involve altering the genetic material or genetic characteristics of human germ cells, fertilized eggs and pre-implantation embryos. 
Clinical researches on invasive brain-machine interfaces for the treatment of neurological and psychiatric disorders and development of human-machine fusion systems with a strong impact on human subjective behaviors, psychological emotions and overall health, should also be revalued by experts, according to the review measures. 
This list will be dynamically adjusted according to needs. 
Global Times
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1448
Subject: ETHICS (97%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); ANIMAL EXPERIMENTS (89%); ANIMALS (89%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); SUSTAINABLE DEVELOPMENT (77%); COMMERCE DEPARTMENTS (72%); EDUCATION DEPARTMENTS (72%); GOVERNMENT & PUBLIC ADMINISTRATION (72%); LIFE FORMS (70%); PRIVACY RIGHTS (70%); ANIMAL WELFARE (69%); PHARMACEUTICALS & BIOTECHNOLOGY REGULATORY COMPLIANCE (67%); SUSTAINABILITY (63%); ARTIFICIAL INTELLIGENCE (62%); BIOMETRICS (60%)
Industry: SUSTAINABLE DEVELOPMENT (77%); INFORMATION SECURITY & PRIVACY (76%); PHARMACEUTICALS & BIOTECHNOLOGY REGULATORY COMPLIANCE (67%); ARTIFICIAL INTELLIGENCE (62%)
Geographic: CHINA (94%)
Load-Date: October 15, 2023","Photo: VCG
Chinese authorities released on Sunday the pilot review measures of science and technology ethics. As the new round of scientific and technological revolution and industrial transformation accelerate progress, ethical issues have become a common challenge facing the whole world. 
China's Ministry of Science and Technology together with nine other government departments such as the Ministry of Education and the Ministry of Industry and Information Technology, released the comprehensive and universal review measures that cover ethical reviews on science and technologies activities, in a bid to focus on solving a series of problems such as unclear responsibilities and lack of universal review standards. 
A series of measures and relevant provisions were proposed from the perspectives of improving the system, standardizing procedures, strict standards and strengthening supervision. 
The review methods define the main scope of the ethical reviews on science and technology, specify the responsible entities for ethical review, the criteria for establishing the science and technology ethics (review) committees and their organizational and operational mechanisms. The measures also outline the basic procedures for ethical reviews, and determine the content and standards for ethical reviews. 
According to the pilot measures, scientific and technological activities involving human participants, including research activities such as testing, surveys, and observations using human beings as research objects, as well as scientific activities using human biological samples and personal information data, shall be subject to ethical review in accordance with these measures. 
Meanwhile, scientific and technological activities involving laboratory animals shall be subject to the ethical review as well. 
Besides, science and technology activities that do not directly involve humans or laboratory animals but may pose ethical risks and challenges in areas such as life and health, ecological environment, public order and sustainable development shall also be subject to ethical review. 
The pilot measures also stipulate that institutions and units engaged in scientific activities in life sciences, medicine, artificial intelligence and other fields, whose research content involves sensitive areas of science and technology ethics, should establish a review committee on scientific and technological ethics. 
The review committee on scientific and technological ethics should conduct reviews if the scientific activities involve humans participants, to make sure fair and reasonable recruitment programs, lawful and compliant collection, storage, use and disposal of biological samples, and the processing of personal privacy data, biometric information and other information complied with the relevant provisions on the protection of personal information. 
The committee also should make sure the reasonable and appropriate protection plan for the legal rights and interests of research participants, including compensation, treatment for injuries, as well as the special protection of vulnerable groups. 
Scientific and technological activities involving laboratory animals should adhere to the principles of replacement, reduction and refinement and make sure the lawful and reasonable source of the laboratory animals. The technical operations of breeding, using, and disposing laboratory animals should comply with animal welfare standards. 
Technological activities involving data and algorithms, including activities related to the collection, storage, processing and use of data, as well as the research and development of new data technologies, should comply with relevant national regulations on data security and the protection of personal information. 
Risk monitoring and emergency response plans of data security must be appropriate. 
The design, implementation and application of algorithms, models and systems should adhere to principles such as fairness, justice, transparency, reliability and controllability, in accordance with relevant national requirements. 
The review measures also outline a list of emerging scientific and technological activities that may pose greater ethical risk and challenges, which have to be revalued by experts. 
Activities include the researches on the synthetic creation of new species that has a significant impact on human life and health, values, ecological environment, researches involving the introduction of human stem cells into animal embryos or fetuses and further gestation of the individual in an animal uterus, and basic researches that involve altering the genetic material or genetic characteristics of human germ cells, fertilized eggs and pre-implantation embryos. 
Clinical researches on invasive brain-machine interfaces for the treatment of neurological and psychiatric disorders and development of human-machine fusion systems with a strong impact on human subjective behaviors, psychological emotions and overall health, should also be revalued by experts, according to the review measures. 
This list will be dynamically adjusted according to needs. 
Global Times
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1448
Subject: ETHICS (97%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); ANIMAL EXPERIMENTS (89%); ANIMALS (89%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); SUSTAINABLE DEVELOPMENT (77%); COMMERCE DEPARTMENTS (72%); EDUCATION DEPARTMENTS (72%); GOVERNMENT & PUBLIC ADMINISTRATION (72%); LIFE FORMS (70%); PRIVACY RIGHTS (70%); ANIMAL WELFARE (69%); PHARMACEUTICALS & BIOTECHNOLOGY REGULATORY COMPLIANCE (67%); SUSTAINABILITY (63%); ARTIFICIAL INTELLIGENCE (62%); BIOMETRICS (60%)
Industry: SUSTAINABLE DEVELOPMENT (77%); INFORMATION SECURITY & PRIVACY (76%); PHARMACEUTICALS & BIOTECHNOLOGY REGULATORY COMPLIANCE (67%); ARTIFICIAL INTELLIGENCE (62%)
Geographic: CHINA (94%)
Load-Date: October 15, 2023",neutral,0.8320345282554626,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security']","['justice', 'fairness', 'justice']","['standards', 'compliance', 'should', 'must']",[],4,3,4,0
2023,Unknown Title,"Byline: Benson Mawira
Body
Sep 26, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Boston Dynamics' AI Institute, a prominent research organization specializing in robotics and artificial intelligence, has announced the appointment of Dr. Kate Darling as the head of its Ethics and Society research team. In her new role, Dr. Darling will spearhead a group of researchers dedicated to exploring the ethical and societal implications of robotics and AI. This strategic move aligns with the institute's mission to maximize the benefits of intelligent machines while mitigating associated risks. 
Balancing opportunities and risks 
Marc Raibert, the executive director of Boston Dynamics' AI Institute, emphasized the importance of addressing the ethical dimensions of AI and robotics. He stated, 'All new technologies offer opportunities and risks. Our goal in establishing the ethics team at the Institute is to maximize the opportunities that robotics and AI can offer while minimizing the risks.' 
The rapid advancements in robotics and AI have raised critical issues concerning public perception, technical literacy, government policies, and media coverage. Scientific research is essential to provide a solid foundation for discussions and guide the responsible development of these technologies. 
Boston Dynamics' AI Institute, based in Cambridge, Massachusetts, brings together top talent from various fields, including robotics, AI[1], machine learning, computer science, and engineering. Its primary aim is to pave the way for the next generation of intelligent machines. The institute's research encompasses four core areas: cognitive AI, athletic AI, organic hardware design, and ethics and society. It aims to combine the strengths of university research labs with the innovation of corporate development labs. 
Creating the 'Bell Labs of Robotics and AI' 
The Boston Dynamics' AI Institute has set[2] an ambitious goal of becoming the 'Bell Labs of robotics and AI.' This aspiration underscores its commitment to pushing the boundaries of knowledge in these fields while fostering a collaborative and innovative environment. 
Dr. Kate Darling is a distinguished expert in technology, ethics, and policy. Prior to joining Boston Dynamics' AI Institute, she had a decade-long tenure at the MIT Media Lab. Her work has focused on anticipating and addressing complex questions that lawmakers, engineers, and the broader public must confront in the era of rapid technological advancement. 
With a background in law and economics, Dr. Darling has also served as a fellow at the Harvard Berkman Klein Center for Internet & Society and the Yale Information Society Project. Additionally, she holds an affiliation with the Institute for Ethics and Emerging Technologies. 
Dr. Darling's team will undertake a comprehensive exploration of immediate and long-term questions related to the implementation and use of robots. Their research will encompass various aspects, including the impact of robotics on the workplace, infrastructure, and more. Through rigorous studies and experiments, they aim to generate essential data to inform ethical and policy decisions. 
In addition to conducting research, the Ethics and Society team, led by Dr. Darling, will organize a series of talks and workshops at the intersection of ethics, law, economics, and robotics. These events will provide a platform for inclusive discussions, allowing experts and the public to engage in meaningful dialogues about the ethical implications of AI and robotics. 
The Ethics and Society team at Boston Dynamics' AI Institute is actively seeking to expand its roster of social scientists. This recruitment effort reflects the institute's commitment to interdisciplinary collaboration and its recognition of the diverse expertise required to address the multifaceted challenges posed by advanced technologies. 
 [ 1]: https://www.cryptopolitan.com/tsmc-boosts-cowos-packaging-machine/ [ 2]: https://theaiinstitute.com/news/ai-institute-launches-ethics-research 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (92%); APPOINTMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ROBOTICS (90%); EMERGING TECHNOLOGY (89%); EMPLOYMENT HISTORY (89%); ENGINEERING (89%); PERSONNEL CHANGES (89%); RESEARCH INSTITUTES (89%); PUBLIC POLICY (87%); ASSOCIATIONS & ORGANIZATIONS (78%); BLOGS & MESSAGE BOARDS (78%); COGNITIVE COMPUTING (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); COMPUTER SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); SCIENCE & TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); MACHINE LEARNING (73%); BUSINESS NEWS (71%); EXECUTIVES (70%); GOVERNMENT & PUBLIC ADMINISTRATION (67%); Trending News (%); Boston Dynamics' (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INDUSTRIAL AUTOMATION (90%); ROBOTICS (90%); ENGINEERING (89%); BLOGS & MESSAGE BOARDS (78%); COGNITIVE COMPUTING (78%); COMPUTER SCIENCE (78%); TEST LABORATORIES (78%); MACHINE LEARNING (73%)
Geographic: BOSTON, MA, USA (94%); MASSACHUSETTS, USA (79%)
Load-Date: September 26, 2023","Sep 26, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Boston Dynamics' AI Institute, a prominent research organization specializing in robotics and artificial intelligence, has announced the appointment of Dr. Kate Darling as the head of its Ethics and Society research team. In her new role, Dr. Darling will spearhead a group of researchers dedicated to exploring the ethical and societal implications of robotics and AI. This strategic move aligns with the institute's mission to maximize the benefits of intelligent machines while mitigating associated risks. 
Balancing opportunities and risks 
Marc Raibert, the executive director of Boston Dynamics' AI Institute, emphasized the importance of addressing the ethical dimensions of AI and robotics. He stated, 'All new technologies offer opportunities and risks. Our goal in establishing the ethics team at the Institute is to maximize the opportunities that robotics and AI can offer while minimizing the risks.' 
The rapid advancements in robotics and AI have raised critical issues concerning public perception, technical literacy, government policies, and media coverage. Scientific research is essential to provide a solid foundation for discussions and guide the responsible development of these technologies. 
Boston Dynamics' AI Institute, based in Cambridge, Massachusetts, brings together top talent from various fields, including robotics, AI[1], machine learning, computer science, and engineering. Its primary aim is to pave the way for the next generation of intelligent machines. The institute's research encompasses four core areas: cognitive AI, athletic AI, organic hardware design, and ethics and society. It aims to combine the strengths of university research labs with the innovation of corporate development labs. 
Creating the 'Bell Labs of Robotics and AI' 
The Boston Dynamics' AI Institute has set[2] an ambitious goal of becoming the 'Bell Labs of robotics and AI.' This aspiration underscores its commitment to pushing the boundaries of knowledge in these fields while fostering a collaborative and innovative environment. 
Dr. Kate Darling is a distinguished expert in technology, ethics, and policy. Prior to joining Boston Dynamics' AI Institute, she had a decade-long tenure at the MIT Media Lab. Her work has focused on anticipating and addressing complex questions that lawmakers, engineers, and the broader public must confront in the era of rapid technological advancement. 
With a background in law and economics, Dr. Darling has also served as a fellow at the Harvard Berkman Klein Center for Internet & Society and the Yale Information Society Project. Additionally, she holds an affiliation with the Institute for Ethics and Emerging Technologies. 
Dr. Darling's team will undertake a comprehensive exploration of immediate and long-term questions related to the implementation and use of robots. Their research will encompass various aspects, including the impact of robotics on the workplace, infrastructure, and more. Through rigorous studies and experiments, they aim to generate essential data to inform ethical and policy decisions. 
In addition to conducting research, the Ethics and Society team, led by Dr. Darling, will organize a series of talks and workshops at the intersection of ethics, law, economics, and robotics. These events will provide a platform for inclusive discussions, allowing experts and the public to engage in meaningful dialogues about the ethical implications of AI and robotics. 
The Ethics and Society team at Boston Dynamics' AI Institute is actively seeking to expand its roster of social scientists. This recruitment effort reflects the institute's commitment to interdisciplinary collaboration and its recognition of the diverse expertise required to address the multifaceted challenges posed by advanced technologies. 
 [ 1]: https://www.cryptopolitan.com/tsmc-boosts-cowos-packaging-machine/ [ 2]: https://theaiinstitute.com/news/ai-institute-launches-ethics-research 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (92%); APPOINTMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ROBOTICS (90%); EMERGING TECHNOLOGY (89%); EMPLOYMENT HISTORY (89%); ENGINEERING (89%); PERSONNEL CHANGES (89%); RESEARCH INSTITUTES (89%); PUBLIC POLICY (87%); ASSOCIATIONS & ORGANIZATIONS (78%); BLOGS & MESSAGE BOARDS (78%); COGNITIVE COMPUTING (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); COMPUTER SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); SCIENCE & TECHNOLOGY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); MACHINE LEARNING (73%); BUSINESS NEWS (71%); EXECUTIVES (70%); GOVERNMENT & PUBLIC ADMINISTRATION (67%); Trending News (%); Boston Dynamics' (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INDUSTRIAL AUTOMATION (90%); ROBOTICS (90%); ENGINEERING (89%); BLOGS & MESSAGE BOARDS (78%); COGNITIVE COMPUTING (78%); COMPUTER SCIENCE (78%); TEST LABORATORIES (78%); MACHINE LEARNING (73%)
Geographic: BOSTON, MA, USA (94%); MASSACHUSETTS, USA (79%)
Load-Date: September 26, 2023",neutral,0.6906884908676147,balanced/neutral,[],[],"['policy', 'law', 'should', 'must']","['machine learning', 'robotics']",0,0,4,2
2023,Unknown Title,"Byline: John Palmer
Body
Nov 22, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Artificial Intelligence (AI) has become increasingly pervasive in various industries, revolutionizing the way tasks are performed and data is processed. In the realm of event organizing, AI holds the potential to streamline processes, enhance attendee experiences, and optimize logistics. However, a recent survey conducted by The Hague & Partners Convention Bureau and Ottawa Tourism reveals that a significant portion of global association buyers are deeply concerned about the ethical implications of using AI in event planning. 
The concerns surrounding AI ethics 
The survey discovered that 63% of global association buyers express varying degrees of concern regarding the ethical implications of incorporating AI in event organizing. This sentiment underscores the growing awareness within the industry about the need to balance technological advancements with ethical considerations. The integration of AI can offer numerous advantages, but it also raises questions about data privacy, fairness, and accountability. 
Desire for government regulation 
Interestingly, an equal percentage (63%) of association respondents believe that governments should play a role in legislating the use of AI in event organizing. This suggests a desire for a regulatory framework that can establish ethical guidelines and ensure responsible AI usage. However, there is a stark contrast in these findings, as 65% of respondents doubt that governments possess the necessary knowledge to effectively legislate AI in this context. This raises the important issue of how to strike a balance between regulation and technological innovation. 
Data trustworthiness and provider reliability 
One of the primary concerns among survey participants is the handling of data by technology companies through AI. A notable 33% of respondents find AI technology providers to be untrustworthy, with 20% considering them 'not very trustworthy' and an additional 13% regarding them as 'not at all trustworthy.' In contrast, only 27% expressed 'mostly' trusting these data providers. This mistrust highlights the urgent need for transparency and accountability in data management within the AI industry. 
The call for an international standard 
To address the ethical concerns surrounding AI in event organizing, 52% of respondents are in favor of establishing an International Standard (ISO) that covers the usage of AI in events. This demonstrates a clear demand for a globally recognized framework that can guide the responsible implementation of AI technologies. Another 29% expressed a possibility with a 'maybe,' while only 7% outright rejected the idea of such a standard. The support for an ISO reflects the industry's recognition of the need for ethical best practices. 
Corporate event organizers' perspective 
While the survey primarily focused on global association buyers, it also included insights from corporate event organizers. Interestingly, 50% of corporate respondents expressed slight concern about the ethical implications of using AI in event organizing. Additionally, 71% of corporate event organizers believe that governments should legislate AI use in this context, mirroring the sentiments of the association respondents. However, a similar proportion (71%) doubts that governments possess the requisite knowledge to effectively regulate AI. 
The survey conducted by The Hague & Partners Convention Bureau and Ottawa Tourism sheds light on the ethical considerations that surround the integration of AI in event organizing. The findings indicate a genuine concern within the industry about data privacy, accountability, and the need for regulatory measures. While AI offers immense potential to improve event experiences and efficiency, stakeholders recognize the importance of ethical guidelines to ensure responsible AI usage. 
Moving forward, it is essential for the event industry to engage in thoughtful discussions and collaborations to establish a framework that addresses these ethical concerns. This framework should strike a balance between innovation and responsible AI development, promoting transparency, trustworthiness, and data privacy. As AI continues to shape the future of event organizing, finding ethical solutions becomes paramount to creating experiences that are both technologically advanced and ethically sound. 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); POLLS & SURVEYS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); CONVENTION & TRADE SHOW PLANNING (89%); BEST PRACTICES (77%); GOVERNMENT & PUBLIC ADMINISTRATION (72%); Trending News (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); CONVENTION & TRADE SHOW PLANNING (89%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); INFORMATION SECURITY & PRIVACY (77%)
Load-Date: November 22, 2023","Nov 22, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Artificial Intelligence (AI) has become increasingly pervasive in various industries, revolutionizing the way tasks are performed and data is processed. In the realm of event organizing, AI holds the potential to streamline processes, enhance attendee experiences, and optimize logistics. However, a recent survey conducted by The Hague & Partners Convention Bureau and Ottawa Tourism reveals that a significant portion of global association buyers are deeply concerned about the ethical implications of using AI in event planning. 
The concerns surrounding AI ethics 
The survey discovered that 63% of global association buyers express varying degrees of concern regarding the ethical implications of incorporating AI in event organizing. This sentiment underscores the growing awareness within the industry about the need to balance technological advancements with ethical considerations. The integration of AI can offer numerous advantages, but it also raises questions about data privacy, fairness, and accountability. 
Desire for government regulation 
Interestingly, an equal percentage (63%) of association respondents believe that governments should play a role in legislating the use of AI in event organizing. This suggests a desire for a regulatory framework that can establish ethical guidelines and ensure responsible AI usage. However, there is a stark contrast in these findings, as 65% of respondents doubt that governments possess the necessary knowledge to effectively legislate AI in this context. This raises the important issue of how to strike a balance between regulation and technological innovation. 
Data trustworthiness and provider reliability 
One of the primary concerns among survey participants is the handling of data by technology companies through AI. A notable 33% of respondents find AI technology providers to be untrustworthy, with 20% considering them 'not very trustworthy' and an additional 13% regarding them as 'not at all trustworthy.' In contrast, only 27% expressed 'mostly' trusting these data providers. This mistrust highlights the urgent need for transparency and accountability in data management within the AI industry. 
The call for an international standard 
To address the ethical concerns surrounding AI in event organizing, 52% of respondents are in favor of establishing an International Standard (ISO) that covers the usage of AI in events. This demonstrates a clear demand for a globally recognized framework that can guide the responsible implementation of AI technologies. Another 29% expressed a possibility with a 'maybe,' while only 7% outright rejected the idea of such a standard. The support for an ISO reflects the industry's recognition of the need for ethical best practices. 
Corporate event organizers' perspective 
While the survey primarily focused on global association buyers, it also included insights from corporate event organizers. Interestingly, 50% of corporate respondents expressed slight concern about the ethical implications of using AI in event organizing. Additionally, 71% of corporate event organizers believe that governments should legislate AI use in this context, mirroring the sentiments of the association respondents. However, a similar proportion (71%) doubts that governments possess the requisite knowledge to effectively regulate AI. 
The survey conducted by The Hague & Partners Convention Bureau and Ottawa Tourism sheds light on the ethical considerations that surround the integration of AI in event organizing. The findings indicate a genuine concern within the industry about data privacy, accountability, and the need for regulatory measures. While AI offers immense potential to improve event experiences and efficiency, stakeholders recognize the importance of ethical guidelines to ensure responsible AI usage. 
Moving forward, it is essential for the event industry to engage in thoughtful discussions and collaborations to establish a framework that addresses these ethical concerns. This framework should strike a balance between innovation and responsible AI development, promoting transparency, trustworthiness, and data privacy. As AI continues to shape the future of event organizing, finding ethical solutions becomes paramount to creating experiences that are both technologically advanced and ethically sound. 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); POLLS & SURVEYS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); CONVENTION & TRADE SHOW PLANNING (89%); BEST PRACTICES (77%); GOVERNMENT & PUBLIC ADMINISTRATION (72%); Trending News (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); CONVENTION & TRADE SHOW PLANNING (89%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); INFORMATION SECURITY & PRIVACY (77%)
Load-Date: November 22, 2023",neutral,0.7956182956695557,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'security']",['fairness'],"['regulation', 'policy', 'guidelines', 'framework', 'should', 'need to']",[],5,1,6,0
2023,Unknown Title,"Byline: Glory Kaburu
Body
Sep 01, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Mustafa Suleyman, renowned for his co-founding of Google DeepMind and his current role as the CEO of Inflection AI, has put forth a compelling proposition that urges the United States to institute measures that regulate the sale of Nvidia's AI chips. The core of Suleyman's recommendation revolves around ethical AI utilization, suggesting that access to these advanced chips should be granted exclusively to buyers who pledge to deploy the capabilities of AI technology responsibly and ethically. 
Championing responsible AI implementation 
Suleyman's proposal underscores the significance of responsible AI implementation. He asserts that the sale of Nvidia's AI chips should be contingent upon purchasers' commitment to harnessing AI's potential for ethical purposes. In a landscape where AI's capabilities continue to expand, ensuring its applications align with societal values and ethical considerations becomes increasingly critical. 
Global ethical standards for AI deployment 
Furthermore, Suleyman emphasizes the importance of establishing comprehensive global standards that govern the ethical deployment of AI. With the United States being a prominent player in the AI industry, his call for international cooperation in setting ethical guidelines resonates strongly. This move would bolster responsible AI adoption within the U.S. and encourage a broader commitment to ethical AI use on a global scale. 
Extending AI chip export restrictions 
Suleyman's proposal aligns with recent developments in AI chip export regulations. The United States has recently expanded its restrictions on exporting advanced AI chips, expanding beyond China to encompass other regions, including select Middle Eastern countries. This expansion reflects a growing awareness of the potential ramifications of unchecked AI proliferation and underscores the need for a structured approach to regulating AI technologies. 
Aligning with existing ethical commitments 
Suleyman advocates for companies to align themselves with the ethical commitments made by leading AI firms to the White House. This alignment signifies a collective effort to ensure that ethical considerations are woven into the AI development and deployment fabric. Notably, major AI companies such as OpenAI, Alphabet, and Meta Platforms have voluntarily committed to enhancing AI's safety and responsible usage, as seen through measures like watermarking AI-generated content. 
Industry's call for collaborative governance 
The call for collaboration between AI developers and policymakers to establish robust governance and regulatory frameworks continues to gain momentum. Industry executives and experts increasingly recognize the need for a concerted effort to balance innovation and ethics in AI technology. As AI's influence permeates diverse aspects of society, the emphasis on ethical considerations and responsible AI use becomes an imperative that cannot be overlooked. 
NVIDIA and Google Cloud partnership advanced AI computing 
NVIDIA and Google Cloud's recent partnership expansion aims to advance AI computing, software, and services. During the Google Cloud Next event, Thomas Kurian, Google Cloud's CEO, and Jensen Huang, NVIDIA's CEO, discussed the integration of NVIDIA's H100 and A100 GPUs in Google's internal research and inference operations, particularly within divisions such as DeepMind. This collaboration underscores the industry's continuous pursuit of refining AI capabilities while adhering to ethical principles. 
Inflection AI and ethical AI investment 
In a noteworthy turn of events, NVIDIA and Microsoft supported Suleyman's Inflection AI in a funding round that garnered $1.3 billion. Inflection AI, led by Suleyman, has introduced a 'personal chatbot' named Pi, which employs generative AI technology to engage users in meaningful conversations. Pi empowers users to ask questions and share interests, positioning itself as a valuable tool for communication, information sharing, and engagement. 
Mustafa Suleyman's advocacy for the ethical use of Nvidia's AI chips calls for responsible AI deployment. His proposal to restrict the sale of AI chips to ethically committed purchasers aligns with the broader industry movement toward ethical AI use. The alignment of major AI companies with White House ethical commitments and the collaboration between industry giants like NVIDIA and Google Cloud underscores the industry's dedication to shaping AI's trajectory with a strong ethical foundation. As AI continues to weave itself into the fabric of society, the significance of ethical considerations in AI development and deployment cannot be overstated. 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); EXECUTIVES (89%); EXPORT & IMPORT LAW (89%); EXPORT CONTROLS (89%); EXPORT TRADE (87%); PUBLIC POLICY (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); GENERATIVE AI (72%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (72%); STANDARDS & MEASUREMENTS (72%); INTERNATIONAL RELATIONS (68%); Trending News (%)
Company:  NVIDIA CORP (97%);  GOOGLE LLC (85%)
Ticker: NVDA (NASDAQ) (97%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (97%); NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (97%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (97%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (97%); NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); SOFTWARE SERVICES & APPLICATIONS (77%); COMPUTER SOFTWARE (73%); GENERATIVE AI (72%)
Person: JEN-HSUN HUANG (57%)
Geographic: UNITED STATES (90%); MIDDLE EAST (79%)
Load-Date: September 1, 2023","Sep 01, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 Mustafa Suleyman, renowned for his co-founding of Google DeepMind and his current role as the CEO of Inflection AI, has put forth a compelling proposition that urges the United States to institute measures that regulate the sale of Nvidia's AI chips. The core of Suleyman's recommendation revolves around ethical AI utilization, suggesting that access to these advanced chips should be granted exclusively to buyers who pledge to deploy the capabilities of AI technology responsibly and ethically. 
Championing responsible AI implementation 
Suleyman's proposal underscores the significance of responsible AI implementation. He asserts that the sale of Nvidia's AI chips should be contingent upon purchasers' commitment to harnessing AI's potential for ethical purposes. In a landscape where AI's capabilities continue to expand, ensuring its applications align with societal values and ethical considerations becomes increasingly critical. 
Global ethical standards for AI deployment 
Furthermore, Suleyman emphasizes the importance of establishing comprehensive global standards that govern the ethical deployment of AI. With the United States being a prominent player in the AI industry, his call for international cooperation in setting ethical guidelines resonates strongly. This move would bolster responsible AI adoption within the U.S. and encourage a broader commitment to ethical AI use on a global scale. 
Extending AI chip export restrictions 
Suleyman's proposal aligns with recent developments in AI chip export regulations. The United States has recently expanded its restrictions on exporting advanced AI chips, expanding beyond China to encompass other regions, including select Middle Eastern countries. This expansion reflects a growing awareness of the potential ramifications of unchecked AI proliferation and underscores the need for a structured approach to regulating AI technologies. 
Aligning with existing ethical commitments 
Suleyman advocates for companies to align themselves with the ethical commitments made by leading AI firms to the White House. This alignment signifies a collective effort to ensure that ethical considerations are woven into the AI development and deployment fabric. Notably, major AI companies such as OpenAI, Alphabet, and Meta Platforms have voluntarily committed to enhancing AI's safety and responsible usage, as seen through measures like watermarking AI-generated content. 
Industry's call for collaborative governance 
The call for collaboration between AI developers and policymakers to establish robust governance and regulatory frameworks continues to gain momentum. Industry executives and experts increasingly recognize the need for a concerted effort to balance innovation and ethics in AI technology. As AI's influence permeates diverse aspects of society, the emphasis on ethical considerations and responsible AI use becomes an imperative that cannot be overlooked. 
NVIDIA and Google Cloud partnership advanced AI computing 
NVIDIA and Google Cloud's recent partnership expansion aims to advance AI computing, software, and services. During the Google Cloud Next event, Thomas Kurian, Google Cloud's CEO, and Jensen Huang, NVIDIA's CEO, discussed the integration of NVIDIA's H100 and A100 GPUs in Google's internal research and inference operations, particularly within divisions such as DeepMind. This collaboration underscores the industry's continuous pursuit of refining AI capabilities while adhering to ethical principles. 
Inflection AI and ethical AI investment 
In a noteworthy turn of events, NVIDIA and Microsoft supported Suleyman's Inflection AI in a funding round that garnered $1.3 billion. Inflection AI, led by Suleyman, has introduced a 'personal chatbot' named Pi, which employs generative AI technology to engage users in meaningful conversations. Pi empowers users to ask questions and share interests, positioning itself as a valuable tool for communication, information sharing, and engagement. 
Mustafa Suleyman's advocacy for the ethical use of Nvidia's AI chips calls for responsible AI deployment. His proposal to restrict the sale of AI chips to ethically committed purchasers aligns with the broader industry movement toward ethical AI use. The alignment of major AI companies with White House ethical commitments and the collaboration between industry giants like NVIDIA and Google Cloud underscores the industry's dedication to shaping AI's trajectory with a strong ethical foundation. As AI continues to weave itself into the fabric of society, the significance of ethical considerations in AI development and deployment cannot be overstated. 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); EXECUTIVES (89%); EXPORT & IMPORT LAW (89%); EXPORT CONTROLS (89%); EXPORT TRADE (87%); PUBLIC POLICY (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); GENERATIVE AI (72%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (72%); STANDARDS & MEASUREMENTS (72%); INTERNATIONAL RELATIONS (68%); Trending News (%)
Company:  NVIDIA CORP (97%);  GOOGLE LLC (85%)
Ticker: NVDA (NASDAQ) (97%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (97%); NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (97%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (97%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (97%); NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); SOFTWARE SERVICES & APPLICATIONS (77%); COMPUTER SOFTWARE (73%); GENERATIVE AI (72%)
Person: JEN-HSUN HUANG (57%)
Geographic: UNITED STATES (90%); MIDDLE EAST (79%)
Load-Date: September 1, 2023",neutral,0.7058582901954651,balanced/neutral,"['safety', 'security', 'access']",[],"['regulation', 'policy', 'governance', 'standards', 'guidelines', 'law', 'should', 'calls for', 'urges', 'emphasizes the importance']",['generative ai'],3,0,10,1
2023,Unknown Title,"Body
The Ethical AI in Insurance Consortium (EAIC), a collaborative platform dedicated to promoting responsible and ethical adoption of artificial intelligence (AI) across the insurance sector, has added five new members to help advance responsible use of AI across the industry.
Joining the EAIC are: MS Transverse Insurance Group, the Pennsylvania Compensation Rating Bureau (PCRB), Geospatial expert from Verisk Analytics Todd Barr, Connected Car and Next Generation Auto Insurance expert from Telenav and Novo Insurance Kumar Maddali, and Ogon Consulting.
Each of these new members bring a deep level of expertise that can help drive the EAIC platform further.
Following these five additions, the EAIC now has 17 members.
The Consortium also noted that it remains committed towards its core objectives, which includes the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, as well as promoting standardization across the sector.
John Williams, Senior Vice President and Head of Operations at MS Transverse Insurance Group, commented: We are pleased to join the Ethical AI in Insurance Consortium, a collective force shaping the future of responsible AI adoption in our industry. Our company believes that fostering transparency, ethical guidelines, and collaboration is critical in ensuring the responsible integration of AI. By uniting with other industry leaders in the EAIC, we will drive a vision of using AI to enhance operational efficiency and effectiveness while upholding the highest standards of integrity, fairness, and accountability.
Bill Taylor, President and CEO of PCRB said: As a data collection organization for the workers compensation industry, we are always interested in how technology is evolving. With the emergence of AI, we all have different levels of interest and concerns. The Consortiums mission is focused on the ethical use of AI tools and components, which is a philosophy that aligns closely with our mission of more than 100 years to be a trusted, essential, and objective industry resource.
Todd Barr, Director of Geospatial Product and Solutions at Verisk, added: With over two decades of experience in the Geospatial field, including roles in Intelligence and Defense, Emergency Response, and Public Health, I have witnessed the transformative power of geospatial analytics in understanding and mitigating the impact of natural and man-made events. My expertise collaborating with scientists and risk analysts to model the financial impact of extreme insurance events including natural disasters and impacts of climate change will provide another unique angle to the importance of ethical AI in the insurance industry.
Kumar Maddali, Vice President of Product Development at Telenav and Novo Insurance added: For nearly 30 years I have sparked innovation for leading insurtech and enterprise technologies companies. While focusing on developing next generation Connected Car solutions and Auto Insurance products, I have seen the responsibility the insured has entrusted the industry with as companies work to responsibly leverage AI. The EAIC is an innovative organization that can foster the trust the insured demands by developing rigorous standards and guidelines, complete with checks and balances, for entities that create AI services.
Karthick Gopalakrishnan, Director of Technical Consulting for Ogon Consulting, commented: Our participation in the Ethical AI in Insurance Consortium collaborative platform enables us to collaborate with industry leaders. Together, we aim to set industry-wide standards and work closely with our customer base to guarantee the equitable and responsible deployment of artificial intelligence technologies within the insurance sector.
Michael Schwabrow, EVP of Sales and Marketing for Cloverleaf Analytics, stated: We are thrilled to welcome these outstanding organizations and technology thought leaders to the EAIC. Their diverse expertise and commitment to ethical AI practices will undoubtedly strengthen our collective efforts to address the challenges and opportunities associated with AI across the insurance sector. As we continue to expand our membership, we are confident that the EAIC will play a pivotal role in shaping the future of responsible AI adoption in insurance.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1630
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INSURANCE TECHNOLOGY (90%); DATA ANALYTICS (89%); EXECUTIVES (89%); RISK MANAGEMENT (79%); GEOSPATIAL DATA (78%); NEGATIVE NEWS (78%); PRODUCT DEVELOPMENT (78%); INTELLIGENCE SERVICES (73%); PUBLIC HEALTH (73%); WORKERS COMPENSATION (73%); SAFETY, ACCIDENTS & DISASTERS (68%); ACCIDENTS & DISASTERS (60%); CLIMATE CHANGE (60%); NATURAL DISASTERS (60%)
Company:  VERISK ANALYTICS INC (57%);  TELENAV INC (57%)
Ticker: VRSK (NASDAQ) (57%)
Industry: NAICS518210 COMPUTING INFRASTRUCTURE PROVIDERS, DATA PROCESSING, WEB HOSTING, AND RELATED SERVICES (57%); SIC4899 COMMUNICATIONS SERVICES, NEC (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INSURANCE (90%); INSURANCE TECHNOLOGY (90%); AUTOMOBILE INSURANCE (89%); DATA ANALYTICS (89%); PROPERTY & CASUALTY INSURANCE (89%); BANKING & FINANCE (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); RISK MANAGEMENT (79%); GEOSPATIAL DATA (78%)
Load-Date: December 30, 2023","The Ethical AI in Insurance Consortium (EAIC), a collaborative platform dedicated to promoting responsible and ethical adoption of artificial intelligence (AI) across the insurance sector, has added five new members to help advance responsible use of AI across the industry.
Joining the EAIC are: MS Transverse Insurance Group, the Pennsylvania Compensation Rating Bureau (PCRB), Geospatial expert from Verisk Analytics Todd Barr, Connected Car and Next Generation Auto Insurance expert from Telenav and Novo Insurance Kumar Maddali, and Ogon Consulting.
Each of these new members bring a deep level of expertise that can help drive the EAIC platform further.
Following these five additions, the EAIC now has 17 members.
The Consortium also noted that it remains committed towards its core objectives, which includes the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, as well as promoting standardization across the sector.
John Williams, Senior Vice President and Head of Operations at MS Transverse Insurance Group, commented: We are pleased to join the Ethical AI in Insurance Consortium, a collective force shaping the future of responsible AI adoption in our industry. Our company believes that fostering transparency, ethical guidelines, and collaboration is critical in ensuring the responsible integration of AI. By uniting with other industry leaders in the EAIC, we will drive a vision of using AI to enhance operational efficiency and effectiveness while upholding the highest standards of integrity, fairness, and accountability.
Bill Taylor, President and CEO of PCRB said: As a data collection organization for the workers compensation industry, we are always interested in how technology is evolving. With the emergence of AI, we all have different levels of interest and concerns. The Consortiums mission is focused on the ethical use of AI tools and components, which is a philosophy that aligns closely with our mission of more than 100 years to be a trusted, essential, and objective industry resource.
Todd Barr, Director of Geospatial Product and Solutions at Verisk, added: With over two decades of experience in the Geospatial field, including roles in Intelligence and Defense, Emergency Response, and Public Health, I have witnessed the transformative power of geospatial analytics in understanding and mitigating the impact of natural and man-made events. My expertise collaborating with scientists and risk analysts to model the financial impact of extreme insurance events including natural disasters and impacts of climate change will provide another unique angle to the importance of ethical AI in the insurance industry.
Kumar Maddali, Vice President of Product Development at Telenav and Novo Insurance added: For nearly 30 years I have sparked innovation for leading insurtech and enterprise technologies companies. While focusing on developing next generation Connected Car solutions and Auto Insurance products, I have seen the responsibility the insured has entrusted the industry with as companies work to responsibly leverage AI. The EAIC is an innovative organization that can foster the trust the insured demands by developing rigorous standards and guidelines, complete with checks and balances, for entities that create AI services.
Karthick Gopalakrishnan, Director of Technical Consulting for Ogon Consulting, commented: Our participation in the Ethical AI in Insurance Consortium collaborative platform enables us to collaborate with industry leaders. Together, we aim to set industry-wide standards and work closely with our customer base to guarantee the equitable and responsible deployment of artificial intelligence technologies within the insurance sector.
Michael Schwabrow, EVP of Sales and Marketing for Cloverleaf Analytics, stated: We are thrilled to welcome these outstanding organizations and technology thought leaders to the EAIC. Their diverse expertise and commitment to ethical AI practices will undoubtedly strengthen our collective efforts to address the challenges and opportunities associated with AI across the insurance sector. As we continue to expand our membership, we are confident that the EAIC will play a pivotal role in shaping the future of responsible AI adoption in insurance.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1630
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INSURANCE TECHNOLOGY (90%); DATA ANALYTICS (89%); EXECUTIVES (89%); RISK MANAGEMENT (79%); GEOSPATIAL DATA (78%); NEGATIVE NEWS (78%); PRODUCT DEVELOPMENT (78%); INTELLIGENCE SERVICES (73%); PUBLIC HEALTH (73%); WORKERS COMPENSATION (73%); SAFETY, ACCIDENTS & DISASTERS (68%); ACCIDENTS & DISASTERS (60%); CLIMATE CHANGE (60%); NATURAL DISASTERS (60%)
Company:  VERISK ANALYTICS INC (57%);  TELENAV INC (57%)
Ticker: VRSK (NASDAQ) (57%)
Industry: NAICS518210 COMPUTING INFRASTRUCTURE PROVIDERS, DATA PROCESSING, WEB HOSTING, AND RELATED SERVICES (57%); SIC4899 COMMUNICATIONS SERVICES, NEC (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INSURANCE (90%); INSURANCE TECHNOLOGY (90%); AUTOMOBILE INSURANCE (89%); DATA ANALYTICS (89%); PROPERTY & CASUALTY INSURANCE (89%); BANKING & FINANCE (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); RISK MANAGEMENT (79%); GEOSPATIAL DATA (78%)
Load-Date: December 30, 2023",positive,0.5807287693023682,balanced/neutral,"['fairness', 'transparency', 'accountability', 'safety']",['fairness'],"['standards', 'guidelines']",[],4,1,2,0
2023,Unknown Title,"Byline: States News Service
Dateline: GARRISON, NY 
Body
The following information was released by the Hastings Center:
The Hastings Center is pleased to announce the election of 12 new fellows. Hastings Center fellows are a group of more than 200 individuals of outstanding accomplishment whose work has informed scholarship and public understanding of complex ethical issues in health, health care, science, and technology. The new fellows focus on a broad range of topics, including disability and justice, legal history of the American eugenics movement, gender and reproductive medicine, transplantation, ethics consultation, theological ethics, global health and research ethics, mental health care, and dilemmas posed by neurological impairments.
Jennifer Blumenthal-Barby, PhD, MA, is the Cullen Professor of Medical Ethics and associate director of the Center for Medical Ethics and Health Policy at Baylor College of Medicine. She is a philosopher bioethicist whose research focuses primarily on decision-making and ethics. She has been principal investigator on four awards from the Patient Centered Outcomes Research Institute to study and improve decision-making in advanced heart failure. She has also received funding as principal investigator from the Agency for Healthcare Research and Quality to study adding an AI/machine learning system that predicts personalized risks to a patient decision aid. She is a co-PI on a study of ethics and decision-making in pediatric deep brain stimulation, funded by the National Institutes of Health's BRAIN initiative. She is the author of Good Ethics and Bad Choices: The Relevance of Behavioral Economics for Medical Ethics (MIT Press). Blumenthal-Barby is launching and leading a multi-institutional Philosophical Bioethics Consortium in partnership with The Oxford Uehiro Centre for Practical Ethics, The Kennedy Institute of Ethics at Georgetown University, the New York University Center for Bioethics, and Rice University. The consortium is creating an online hub with resources to promote conceptual and normative work in the field of bioethics. https://jenniferblumenthalbarby.wordpress.com/
Denise M. Dudzinski, PhD, HEC-C is professor in the departments of bioethics and humanities and pediatrics in the division of bioethics and palliative care at the University of Washington School of Medicine She was chair of the department of bioethics and humanities from 2014 to 2022. She directs UW Medicine's Ethics Consultation Service and the Organizational Ethics Service at Seattle Children's Hospital. She was a member of the board of directors at the American Society for Bioethics and Humanities and has served on two ASBH task forces to update the Core Competencies in Healthcare Ethics Consultation. She is on the editorial boards of the American Journal of Bioethics and Cambridge Quarterly of Healthcare Ethics. Dudzinski co-edited Complex Ethics Consultations: Cases that Haunt Us (Cambridge University Press). She teaches bioethics to health care providers as well as medical, nursing, and graduate students. Her scholarship addresses ethical issues in transplantation and mechanical circulatory support, clinical and organizational ethics, methods and practices in ethics consultation, pandemic ethics, largescale adverse event disclosure, competent refusal of nursing care, moral distress, and ethical issues in end-of-life care. https://depts.washington.edu/bhdept/denise-m-dudzinski-phd-hec-c
Emily A. Largent, PhD, RN, is the Emanuel and Robert Hart Assistant Professor of Medical Ethics and Health Policy at the University of Pennsylvania's Perelman School of Medicine, and she holds a secondary appointment at the University of Pennsylvania Law School. Her research examines ethical and regulatory issues arising in human subjects research, with a particular focus on Alzheimer's disease research. Her work is supported by grant awards from the National Institute on Aging. She is a member of the Greenwall Faculty Scholars Program class of 2023 and the 2023 recipient of the Baruch A. Brody Award and Lecture in Bioethics. Her work has been published in leading bioethics and biomedical journals, including the Hastings Center Report, American Journal of Bioethics, New England Journal of Medicine, and JAMA. She is co-author of Clinical Research Ethics Consultation: A Casebook (Oxford University Press). https://medicalethicshealthpolicy.med.upenn.edu/faculty-all/emily-largent
Paul A. Lombardo, PhD, JD, MA, is the Regents' Professor and Bobby Lee Cook Professor of Law at Georgia State University. He is a lawyer and a historian. Lombardo has published extensively on topics in health law, medico-legal history, and bioethics. He is best known for his work on the legal history of the American eugenics movement. He served from 2011 to 2016 as a senior advisor to the Presidential Commission for the Study of Bioethical Issues. He is an elected member of the American Law Institute and a fellow of the American Bar Foundation. In 2021 he received the Jay Healey Health Law Professor of the Year, from the American Society of Law, Medicine, and Ethics, and in 2019 he was named a Fulbright Specialist. He testified as an expert witness in Lowe v. Atlas, a landmark federal genetic discrimination case, and his work was cited in a 2019 U.S. Supreme Court opinion, (Kristina Box, Commissioner, Indiana Department of Health, et al. v. Planned Parenthood of Indiana and Kentucky, Inc., et al (587 U.S.). His books include: Three Generations, No Imbeciles: Eugenics, the Supreme Court and Buck v. Bell (Johns Hopkins University Press) and A Century of Eugenics in America: From the Indiana Experiment to the Human Genome Era (Indiana University Press). He was also an editor for three editions of Fletcher's Introduction to Clinical Ethics. https://law.gsu.edu/profile/paul-lombardo/
Anne Drapkin Lyerly, MD, MA, is a professor of social medicine, research professor of obstetrics and gynecology, and core faculty in the Center for Bioethics at the University of North Carolina at Chapel Hill. A board-certified obstetrician-gynecologist and a bioethicist, she studies ethically complex issues around gender and reproductive medicine. She cofounded the Second Wave Initiative, an effort to ensure that the health interests of pregnant people are fairly represented in biomedical research and in drug and device policies. She is PI on two projects funded by the National Institutes of Health: the PHASES Project, which addresses the ethics of HIV research and pregnancy, and the PREPARE Project, which is examining the ethics of research engaging pregnant adolescents. She was co-PI on the Wellcome Trust-funded PREVENT project on research, pregnancy, and public health emergencies. Lyerly is an alumna of the Greenwall Foundation's Faculty Scholars Program and Fellowship in Bioethics and Health Policy. She chaired the American College of Obstetricians and Gynecologists Committee on Ethics and has served as an advisor for organizations including the U.S. Food and Drug Administration, National Institutes of Health, and the World Health Organization. She is author of A Good Birth (Penguin Random House). https://www.med.unc.edu/socialmed/directory/anne-lyerly/
Debjani Mukherjee, PhD, HEC-C, is an associate professor of medical ethics in clinical medicine and clinical rehabilitation medicine at Weill Cornell Medicine and a senior clinical ethicist at New York Presbyterian Weill Cornell Medical Center. She is a clinical-community psychologist with expertise in qualitative methods and a clinical ethicist who has been involved in over 750 ethics consultations. Her scholarship and practice are informed by more than 30 years of clinical experience working in nine hospitals in New York City; Buffalo.; Boston; Urbana, Ill.; Chicago, Paris, and Kolkata in several roles, including psychometrist, brain injury support group facilitator, psychotherapist, researcher, ethics consultant, and director of an ethics program. Her scholarly interests are in the ethical dilemmas posed by neurological impairments, the emotional impact of medical decisions, the practice of clinical ethics consultation, and ethical concerns in rehabilitation medicine. https://vivo.weill.cornell.edu/display/cwid-dem9199
Thaddeus Pope, JD, PhD, HEC-C, is a professor at Mitchell Hamline School of Law. A former Fulbright Chair and Brocher Foundation researcher, he uses the law both to improve medical decision-making and to protect the rights of patients at the end of life. He works to balance liberty and public health; to assure adequate informed consent; and to develop fair internal dispute resolution mechanisms. His topics of research include medical futility, advance directives, aid in dying, VSED, ethics committees, and brain death. He explores these issues in nearly 250 publications in leading medical journals, law reviews, bar journals, nursing journals, bioethics journals, and book chapters. He is a coauthor of the The Right to Die: The Law of End-of-Life Decisionmaking (Wolters Kluwer), the definitive textbook on the subject, and he runs the Medical Futility Blog, which has had nearly five million page views since it was initiated in 2007. Pope's engagement with health law and bioethics goes beyond academic scholarship. He bridges thought and action with amicus briefs, legislative testimony, and professional organization policy statements. https://thaddeuspope.com/
Peter Reese, MD, PhD, is professor of medicine at the University of Pennsylvania's Perelman School of Medicine. He a transplant nephrologist, bioethicist, clinical trialist, and an advocate for equitable health care. He is a leader in research on transplantation, in empirical and conceptual work on the applied ethics of transplantation, and in mentoring trainees and junior faculty working on the ethical dimensions of transplantation. He has received research awards from the American Society of Nephrology and the American Society of Transplantation. In 2011, he received the Presidential Early Career Award for Scientists and Engineers, the highest honor bestowed by the U.S. government to early-stage scientists. More recently, he was elected to the American Society of Clinical Investigation. He served as chair of the ethics committee and on multiple other policy-making committees for the United Network for Organ Sharing the organization responsible for U.S. organ transplantation policy, providing fundamental ethics guidance related to a range of problems, including refinement of the organ allocation system and the treatment of living organ donors. His research has often combined ethics and epidemiology to demonstrate that, with a robust informed consent process, many patients can benefit from transplantation using organs that were previously discarded, such as organs from donors with hepatitis C virus infection. https://www.med.upenn.edu/apps/faculty/index.php/g275/p6153261
Joel Michael Reynolds, PhD, is an assistant professor of philosophy and disability studies at Georgetown University, a senior research scholar in the Kennedy Institute of Ethics, a senior advisor to The Hastings Center, and a faculty scholar of The Greenwall Foundation. He is the founder of The Journal of Philosophy of Disability and co-editor of Oxford Studies in Disability, Ethics, and Society, a book series from Oxford University Press. At the broadest level, his work examines foundational issues at the intersection of ethics, biomedicine, and society. He is especially concerned with the meaning of disability, the issue of ableism, and how philosophical inquiry into each might improve the lives of people with disabilities and the justness of practices in medicine, science, politics, and law. Reynolds is the author or co-editor of The Life Worth Living:Disability, Pain, and Morality (University of Minnesota Press) and The DisabilityBioethics Reader (Routledge) and three forthcoming booksThe Art of Flourishing: Conversations on Disability, Technology, and Belonging (Oxford University Press, 2023), The Meaning of Disability (Oxford University Press, 2024), and Philosophy of Disability: An Introduction (Polity, 2024). In 2020, he co-edited a Hastings Center special report, ""For All of Us? On the Weight of Genomic Knowledge."" Reynolds regularly speaks with medical students and practitioners across specialties concerning how to improve the quality and equity of care for patients with disabilities. https://gufaculty360.georgetown.edu/s/contact/0031Q00002G0rLMQAZ/joel-michael-reynolds
Seema K. Shah, JD, is an associate professor in pediatrics at Northwestern University Feinberg School of Medicine and the Founder's Board Professor of Medical Ethics and director of research ethics at Ann and Robert H. Lurie Children's Hospital of Chicago. She is an expert in the fields of pediatrics and global health research ethics, as well as on ethical issues in the determination of death. Shah was previously on faculty at the University of Washington's Seattle Children's Hospital and at the National Institutes of Health Clinical Center Department of Bioethics. Shah chaired an NIH committee on ethical considerations in conducting Zika virus human challenge trials, consulted with the World Health Organization on ethical guidance for human challenge trials, and lectured on the ethics of clinical research at around the world. Her research is focused on the following question: When is it ethically and legally acceptable to expose some people to risk for the benefit of others? She has examined this question in different domains, including HIV/AIDS research, pediatric research, and the ethics of human challenge trials. https://www.feinberg.northwestern.edu/faculty-profiles/az/profile.html?xid=42926
Dominic Sisti, PhD, is an associate professor in the department of medical ethics and health policy at the University of Pennsylvania. He directs the Scattergood Program for the Applied Ethics of Behavioral Health Care and holds secondary appointments in the department of psychiatry, where he directs the ethics curriculum in the residency program, and in the department of philosophy. He examines ethical and policy challenges in mental health care, including long-term psychiatric care for individuals with serious mental illness and clinical ethics issues in correctional settings. Sisti's research also explores ethical issues in psychedelic research and clinical application. His writing has appeared in medical and bioethics journals such as JAMA, JAMA Psychiatry, Psychiatric Services, the Hastings Center Report, and the Journal of Medical Ethics. He is co-editor of three books, including Applied Ethics in Mental Healthcare: An Interdisciplinary Reader (MIT Press). https://medicalethicshealthpolicy.med.upenn.edu/faculty-all/dominic-sisti
Patrick T. Smith, PhD, is an associate research professor of theological ethics and bioethics and a senior fellow at the Kenan Institute for Ethics at Duke University. Along with his work in the Divinity School, Smith is the director of the bioethics program for the Trent Center for Bioethics, Humanities, and History of Medicine and associate professor in population health sciences in the department of health sciences at Duke University School of Medicine. His current research and writing are in the areas of moral philosophy, bioethics, theological ethics, end-of-life care, and religious social ethics. He was named one of the 2016-17 Henry Luce III Fellows in Theology and in 2022 received the Pellegrino Medal in health care ethics. Smith was a lecturer at Harvard Medical School in the department of global health and social medicine and served as core faculty for the Master of Bioethics program. He also worked professionally for eight years as the ethics coordinator for Angela Hospice Care Center in Livonia, Mich. During some of that time he served on the Ethics Advisory Council of the National Hospice and Palliative Care Organization and as a board member for the Hospice Palliative Care Association of Michigan. https://divinity.duke.edu/faculty/patrick-smith
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); HUMAN SUBJECTS (92%); INVESTIGATIONS (90%); MEDICAL ETHICS (90%); MENTAL HEALTH (90%); RESEARCH INSTITUTES (90%); BIOETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH DEPARTMENTS (89%); HUMANITIES & SOCIAL SCIENCE (89%); SCHOLARSHIPS & GRANTS (89%); STUDENT EXPENSES & FINANCING (89%); TEACHING & TEACHERS (89%); HEALTH CARE POLICY (78%); CLINICAL DECISION SUPPORT (77%); HEALTH CARE PROFESSIONALS (77%); HEALTH CARE REGULATION & POLICY (77%); HEALTH SERVICES RESEARCH (77%); LEVELS OF CARE (77%); MEDICAL SCIENCE (77%); MEDICINE & HEALTH (77%); NEUROSCIENCE (77%); PALLIATIVE CARE (77%); SCIENCE FUNDING (77%); SEXUAL & REPRODUCTIVE HEALTH (77%); STUDENT FINANCIAL AID (77%); STUDENTS & STUDENT LIFE (77%); COLLEGE STUDENTS (75%); BOARDS OF DIRECTORS (73%); ECONOMICS (71%); NEUROLOGICAL DISORDERS & INJURIES (70%); THEOLOGY (70%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); RELIGION (55%)
Organization: HASTINGS CENTER (94%); NATIONAL INSTITUTES OF HEALTH (54%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE (89%); HEALTH DEPARTMENTS (89%); HEALTH CARE POLICY (78%); ACADEMIC MEDICAL CENTERS (77%); CLINICAL DECISION SUPPORT (77%); HEALTH CARE PROFESSIONALS (77%); HEALTH CARE REGULATION & POLICY (77%); HEALTH SERVICES RESEARCH (77%); COLLEGE STUDENTS (75%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); CHILDREN'S HOSPITALS (65%)
Geographic: SEATTLE, WA, USA (79%); CAMBRIDGE, ENGLAND (54%); NEW YORK, USA (79%); WASHINGTON, USA (79%); UNITED STATES (94%)
Load-Date: February 15, 2023","The following information was released by the Hastings Center:
The Hastings Center is pleased to announce the election of 12 new fellows. Hastings Center fellows are a group of more than 200 individuals of outstanding accomplishment whose work has informed scholarship and public understanding of complex ethical issues in health, health care, science, and technology. The new fellows focus on a broad range of topics, including disability and justice, legal history of the American eugenics movement, gender and reproductive medicine, transplantation, ethics consultation, theological ethics, global health and research ethics, mental health care, and dilemmas posed by neurological impairments.
Jennifer Blumenthal-Barby, PhD, MA, is the Cullen Professor of Medical Ethics and associate director of the Center for Medical Ethics and Health Policy at Baylor College of Medicine. She is a philosopher bioethicist whose research focuses primarily on decision-making and ethics. She has been principal investigator on four awards from the Patient Centered Outcomes Research Institute to study and improve decision-making in advanced heart failure. She has also received funding as principal investigator from the Agency for Healthcare Research and Quality to study adding an AI/machine learning system that predicts personalized risks to a patient decision aid. She is a co-PI on a study of ethics and decision-making in pediatric deep brain stimulation, funded by the National Institutes of Health's BRAIN initiative. She is the author of Good Ethics and Bad Choices: The Relevance of Behavioral Economics for Medical Ethics (MIT Press). Blumenthal-Barby is launching and leading a multi-institutional Philosophical Bioethics Consortium in partnership with The Oxford Uehiro Centre for Practical Ethics, The Kennedy Institute of Ethics at Georgetown University, the New York University Center for Bioethics, and Rice University. The consortium is creating an online hub with resources to promote conceptual and normative work in the field of bioethics. https://jenniferblumenthalbarby.wordpress.com/
Denise M. Dudzinski, PhD, HEC-C is professor in the departments of bioethics and humanities and pediatrics in the division of bioethics and palliative care at the University of Washington School of Medicine She was chair of the department of bioethics and humanities from 2014 to 2022. She directs UW Medicine's Ethics Consultation Service and the Organizational Ethics Service at Seattle Children's Hospital. She was a member of the board of directors at the American Society for Bioethics and Humanities and has served on two ASBH task forces to update the Core Competencies in Healthcare Ethics Consultation. She is on the editorial boards of the American Journal of Bioethics and Cambridge Quarterly of Healthcare Ethics. Dudzinski co-edited Complex Ethics Consultations: Cases that Haunt Us (Cambridge University Press). She teaches bioethics to health care providers as well as medical, nursing, and graduate students. Her scholarship addresses ethical issues in transplantation and mechanical circulatory support, clinical and organizational ethics, methods and practices in ethics consultation, pandemic ethics, largescale adverse event disclosure, competent refusal of nursing care, moral distress, and ethical issues in end-of-life care. https://depts.washington.edu/bhdept/denise-m-dudzinski-phd-hec-c
Emily A. Largent, PhD, RN, is the Emanuel and Robert Hart Assistant Professor of Medical Ethics and Health Policy at the University of Pennsylvania's Perelman School of Medicine, and she holds a secondary appointment at the University of Pennsylvania Law School. Her research examines ethical and regulatory issues arising in human subjects research, with a particular focus on Alzheimer's disease research. Her work is supported by grant awards from the National Institute on Aging. She is a member of the Greenwall Faculty Scholars Program class of 2023 and the 2023 recipient of the Baruch A. Brody Award and Lecture in Bioethics. Her work has been published in leading bioethics and biomedical journals, including the Hastings Center Report, American Journal of Bioethics, New England Journal of Medicine, and JAMA. She is co-author of Clinical Research Ethics Consultation: A Casebook (Oxford University Press). https://medicalethicshealthpolicy.med.upenn.edu/faculty-all/emily-largent
Paul A. Lombardo, PhD, JD, MA, is the Regents' Professor and Bobby Lee Cook Professor of Law at Georgia State University. He is a lawyer and a historian. Lombardo has published extensively on topics in health law, medico-legal history, and bioethics. He is best known for his work on the legal history of the American eugenics movement. He served from 2011 to 2016 as a senior advisor to the Presidential Commission for the Study of Bioethical Issues. He is an elected member of the American Law Institute and a fellow of the American Bar Foundation. In 2021 he received the Jay Healey Health Law Professor of the Year, from the American Society of Law, Medicine, and Ethics, and in 2019 he was named a Fulbright Specialist. He testified as an expert witness in Lowe v. Atlas, a landmark federal genetic discrimination case, and his work was cited in a 2019 U.S. Supreme Court opinion, (Kristina Box, Commissioner, Indiana Department of Health, et al. v. Planned Parenthood of Indiana and Kentucky, Inc., et al (587 U.S.). His books include: Three Generations, No Imbeciles: Eugenics, the Supreme Court and Buck v. Bell (Johns Hopkins University Press) and A Century of Eugenics in America: From the Indiana Experiment to the Human Genome Era (Indiana University Press). He was also an editor for three editions of Fletcher's Introduction to Clinical Ethics. https://law.gsu.edu/profile/paul-lombardo/
Anne Drapkin Lyerly, MD, MA, is a professor of social medicine, research professor of obstetrics and gynecology, and core faculty in the Center for Bioethics at the University of North Carolina at Chapel Hill. A board-certified obstetrician-gynecologist and a bioethicist, she studies ethically complex issues around gender and reproductive medicine. She cofounded the Second Wave Initiative, an effort to ensure that the health interests of pregnant people are fairly represented in biomedical research and in drug and device policies. She is PI on two projects funded by the National Institutes of Health: the PHASES Project, which addresses the ethics of HIV research and pregnancy, and the PREPARE Project, which is examining the ethics of research engaging pregnant adolescents. She was co-PI on the Wellcome Trust-funded PREVENT project on research, pregnancy, and public health emergencies. Lyerly is an alumna of the Greenwall Foundation's Faculty Scholars Program and Fellowship in Bioethics and Health Policy. She chaired the American College of Obstetricians and Gynecologists Committee on Ethics and has served as an advisor for organizations including the U.S. Food and Drug Administration, National Institutes of Health, and the World Health Organization. She is author of A Good Birth (Penguin Random House). https://www.med.unc.edu/socialmed/directory/anne-lyerly/
Debjani Mukherjee, PhD, HEC-C, is an associate professor of medical ethics in clinical medicine and clinical rehabilitation medicine at Weill Cornell Medicine and a senior clinical ethicist at New York Presbyterian Weill Cornell Medical Center. She is a clinical-community psychologist with expertise in qualitative methods and a clinical ethicist who has been involved in over 750 ethics consultations. Her scholarship and practice are informed by more than 30 years of clinical experience working in nine hospitals in New York City; Buffalo.; Boston; Urbana, Ill.; Chicago, Paris, and Kolkata in several roles, including psychometrist, brain injury support group facilitator, psychotherapist, researcher, ethics consultant, and director of an ethics program. Her scholarly interests are in the ethical dilemmas posed by neurological impairments, the emotional impact of medical decisions, the practice of clinical ethics consultation, and ethical concerns in rehabilitation medicine. https://vivo.weill.cornell.edu/display/cwid-dem9199
Thaddeus Pope, JD, PhD, HEC-C, is a professor at Mitchell Hamline School of Law. A former Fulbright Chair and Brocher Foundation researcher, he uses the law both to improve medical decision-making and to protect the rights of patients at the end of life. He works to balance liberty and public health; to assure adequate informed consent; and to develop fair internal dispute resolution mechanisms. His topics of research include medical futility, advance directives, aid in dying, VSED, ethics committees, and brain death. He explores these issues in nearly 250 publications in leading medical journals, law reviews, bar journals, nursing journals, bioethics journals, and book chapters. He is a coauthor of the The Right to Die: The Law of End-of-Life Decisionmaking (Wolters Kluwer), the definitive textbook on the subject, and he runs the Medical Futility Blog, which has had nearly five million page views since it was initiated in 2007. Pope's engagement with health law and bioethics goes beyond academic scholarship. He bridges thought and action with amicus briefs, legislative testimony, and professional organization policy statements. https://thaddeuspope.com/
Peter Reese, MD, PhD, is professor of medicine at the University of Pennsylvania's Perelman School of Medicine. He a transplant nephrologist, bioethicist, clinical trialist, and an advocate for equitable health care. He is a leader in research on transplantation, in empirical and conceptual work on the applied ethics of transplantation, and in mentoring trainees and junior faculty working on the ethical dimensions of transplantation. He has received research awards from the American Society of Nephrology and the American Society of Transplantation. In 2011, he received the Presidential Early Career Award for Scientists and Engineers, the highest honor bestowed by the U.S. government to early-stage scientists. More recently, he was elected to the American Society of Clinical Investigation. He served as chair of the ethics committee and on multiple other policy-making committees for the United Network for Organ Sharing the organization responsible for U.S. organ transplantation policy, providing fundamental ethics guidance related to a range of problems, including refinement of the organ allocation system and the treatment of living organ donors. His research has often combined ethics and epidemiology to demonstrate that, with a robust informed consent process, many patients can benefit from transplantation using organs that were previously discarded, such as organs from donors with hepatitis C virus infection. https://www.med.upenn.edu/apps/faculty/index.php/g275/p6153261
Joel Michael Reynolds, PhD, is an assistant professor of philosophy and disability studies at Georgetown University, a senior research scholar in the Kennedy Institute of Ethics, a senior advisor to The Hastings Center, and a faculty scholar of The Greenwall Foundation. He is the founder of The Journal of Philosophy of Disability and co-editor of Oxford Studies in Disability, Ethics, and Society, a book series from Oxford University Press. At the broadest level, his work examines foundational issues at the intersection of ethics, biomedicine, and society. He is especially concerned with the meaning of disability, the issue of ableism, and how philosophical inquiry into each might improve the lives of people with disabilities and the justness of practices in medicine, science, politics, and law. Reynolds is the author or co-editor of The Life Worth Living:Disability, Pain, and Morality (University of Minnesota Press) and The DisabilityBioethics Reader (Routledge) and three forthcoming booksThe Art of Flourishing: Conversations on Disability, Technology, and Belonging (Oxford University Press, 2023), The Meaning of Disability (Oxford University Press, 2024), and Philosophy of Disability: An Introduction (Polity, 2024). In 2020, he co-edited a Hastings Center special report, ""For All of Us? On the Weight of Genomic Knowledge."" Reynolds regularly speaks with medical students and practitioners across specialties concerning how to improve the quality and equity of care for patients with disabilities. https://gufaculty360.georgetown.edu/s/contact/0031Q00002G0rLMQAZ/joel-michael-reynolds
Seema K. Shah, JD, is an associate professor in pediatrics at Northwestern University Feinberg School of Medicine and the Founder's Board Professor of Medical Ethics and director of research ethics at Ann and Robert H. Lurie Children's Hospital of Chicago. She is an expert in the fields of pediatrics and global health research ethics, as well as on ethical issues in the determination of death. Shah was previously on faculty at the University of Washington's Seattle Children's Hospital and at the National Institutes of Health Clinical Center Department of Bioethics. Shah chaired an NIH committee on ethical considerations in conducting Zika virus human challenge trials, consulted with the World Health Organization on ethical guidance for human challenge trials, and lectured on the ethics of clinical research at around the world. Her research is focused on the following question: When is it ethically and legally acceptable to expose some people to risk for the benefit of others? She has examined this question in different domains, including HIV/AIDS research, pediatric research, and the ethics of human challenge trials. https://www.feinberg.northwestern.edu/faculty-profiles/az/profile.html?xid=42926
Dominic Sisti, PhD, is an associate professor in the department of medical ethics and health policy at the University of Pennsylvania. He directs the Scattergood Program for the Applied Ethics of Behavioral Health Care and holds secondary appointments in the department of psychiatry, where he directs the ethics curriculum in the residency program, and in the department of philosophy. He examines ethical and policy challenges in mental health care, including long-term psychiatric care for individuals with serious mental illness and clinical ethics issues in correctional settings. Sisti's research also explores ethical issues in psychedelic research and clinical application. His writing has appeared in medical and bioethics journals such as JAMA, JAMA Psychiatry, Psychiatric Services, the Hastings Center Report, and the Journal of Medical Ethics. He is co-editor of three books, including Applied Ethics in Mental Healthcare: An Interdisciplinary Reader (MIT Press). https://medicalethicshealthpolicy.med.upenn.edu/faculty-all/dominic-sisti
Patrick T. Smith, PhD, is an associate research professor of theological ethics and bioethics and a senior fellow at the Kenan Institute for Ethics at Duke University. Along with his work in the Divinity School, Smith is the director of the bioethics program for the Trent Center for Bioethics, Humanities, and History of Medicine and associate professor in population health sciences in the department of health sciences at Duke University School of Medicine. His current research and writing are in the areas of moral philosophy, bioethics, theological ethics, end-of-life care, and religious social ethics. He was named one of the 2016-17 Henry Luce III Fellows in Theology and in 2022 received the Pellegrino Medal in health care ethics. Smith was a lecturer at Harvard Medical School in the department of global health and social medicine and served as core faculty for the Master of Bioethics program. He also worked professionally for eight years as the ethics coordinator for Angela Hospice Care Center in Livonia, Mich. During some of that time he served on the Ethics Advisory Council of the National Hospice and Palliative Care Organization and as a board member for the Hospice Palliative Care Association of Michigan. https://divinity.duke.edu/faculty/patrick-smith
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); HUMAN SUBJECTS (92%); INVESTIGATIONS (90%); MEDICAL ETHICS (90%); MENTAL HEALTH (90%); RESEARCH INSTITUTES (90%); BIOETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH DEPARTMENTS (89%); HUMANITIES & SOCIAL SCIENCE (89%); SCHOLARSHIPS & GRANTS (89%); STUDENT EXPENSES & FINANCING (89%); TEACHING & TEACHERS (89%); HEALTH CARE POLICY (78%); CLINICAL DECISION SUPPORT (77%); HEALTH CARE PROFESSIONALS (77%); HEALTH CARE REGULATION & POLICY (77%); HEALTH SERVICES RESEARCH (77%); LEVELS OF CARE (77%); MEDICAL SCIENCE (77%); MEDICINE & HEALTH (77%); NEUROSCIENCE (77%); PALLIATIVE CARE (77%); SCIENCE FUNDING (77%); SEXUAL & REPRODUCTIVE HEALTH (77%); STUDENT FINANCIAL AID (77%); STUDENTS & STUDENT LIFE (77%); COLLEGE STUDENTS (75%); BOARDS OF DIRECTORS (73%); ECONOMICS (71%); NEUROLOGICAL DISORDERS & INJURIES (70%); THEOLOGY (70%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); RELIGION (55%)
Organization: HASTINGS CENTER (94%); NATIONAL INSTITUTES OF HEALTH (54%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); HEALTH CARE (89%); HEALTH DEPARTMENTS (89%); HEALTH CARE POLICY (78%); ACADEMIC MEDICAL CENTERS (77%); CLINICAL DECISION SUPPORT (77%); HEALTH CARE PROFESSIONALS (77%); HEALTH CARE REGULATION & POLICY (77%); HEALTH SERVICES RESEARCH (77%); COLLEGE STUDENTS (75%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); CHILDREN'S HOSPITALS (65%)
Geographic: SEATTLE, WA, USA (79%); CAMBRIDGE, ENGLAND (54%); NEW YORK, USA (79%); WASHINGTON, USA (79%); UNITED STATES (94%)
Load-Date: February 15, 2023",positive,0.7180547714233398,balanced/neutral,"['discrimination', 'agency', 'consent']","['justice', 'equity', 'justice']","['regulation', 'policy', 'law', 'advocate']",['machine learning'],3,3,4,1
2023,Unknown Title,"Body
2023 NOV 27 (NewsRx) -- By a News Reporter-Staff News Editor at Education Daily Report -- New research on Artificial Intelligence is the subject of a report. According to news originating from Seoul, South Korea, by NewsRx correspondents, research stated, ""As the use of artificial intelligence (AI) technologies, particularly generative AI (Gen AI), becomes increasingly prevalent in nursing education, it is paramount to address the ethical implications of their implementation. This article explores the realm of cyberethics (a field of applied ethics that focuses on the ethical, legal, and social implications of cybertechnology), highlighting the ethical principles of autonomy, nonmaleficence, beneficence, justice, and explicability as a roadmap for facilitating AI integration into nursing education."" 
 Our news journalists obtained a quote from the research from Ewha Womans University, ""Research findings suggest that ethical dilemmas that challenge these five principles can emerge within the context of nursing education; however, adherence to these very principles, which is essential to improving patient care, can offer solutions to these dilemmas. To ensure the ethical and responsible use of Gen AI in nursing education, these principles must be woven into the fabric of curricula, and appropriate guidelines must be developed. Nurse educators have a pivotal role in strategizing comprehensive approaches for ethical AI integration, establishing clear guidelines, and instilling critical thinking among students. Fostering lifelong learning and adaptability is key to ensuring that future nurses can successfully navigate the constantly evolving landscape of health care technology."" 
 According to the news editors, the research concluded: ""Future research should investigate the long-term impacts of AI utilization on learning outcomes and ethical decision-making."" 
 This research has been peer-reviewed. 
 For more information on this research see: Cyberethics In Nursing Education: Ethical Implications of Artificial Intelligence. Nursing Ethics, 2023. Nursing Ethics can be contacted at: Sage Publications Ltd, 1 Olivers Yard, 55 City Road, London EC1Y 1SP, England. (Sage Publications - www.sagepub.com/; Nursing Ethics - nej.sagepub.com) 
 The news correspondents report that additional information may be obtained from Hyeyoung Hwang, Ewha Womans University, Seoul, South Korea. Additional authors for this research include Jennie C. De Gagne and Dukyoo Jung. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1177/09697330231201901. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Seoul, South Korea, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning, Ewha Womans University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (96%); NURSES & NURSING (96%); MEDICAL EDUCATION (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); GENERATIVE AI (90%); RESEARCH REPORTS (90%); COLLEGES & UNIVERSITIES (89%); MEDICAL ETHICS (89%); CURRICULA (79%); EMERGING TECHNOLOGY (79%); JOURNALISM (78%); WRITERS (78%); MACHINE LEARNING (74%); MEDICAL TECHNOLOGY (73%); CONTINUING EDUCATION (72%); Seoul;South Korea;Asia;Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: NURSES & NURSING (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (78%); MACHINE LEARNING (74%); MEDICAL TECHNOLOGY (73%); HEALTH CARE (71%)
Geographic: LONDON, ENGLAND (53%); SOUTH KOREA (92%); ASIA (73%); ENGLAND (53%)
Load-Date: November 27, 2023","2023 NOV 27 (NewsRx) -- By a News Reporter-Staff News Editor at Education Daily Report -- New research on Artificial Intelligence is the subject of a report. According to news originating from Seoul, South Korea, by NewsRx correspondents, research stated, ""As the use of artificial intelligence (AI) technologies, particularly generative AI (Gen AI), becomes increasingly prevalent in nursing education, it is paramount to address the ethical implications of their implementation. This article explores the realm of cyberethics (a field of applied ethics that focuses on the ethical, legal, and social implications of cybertechnology), highlighting the ethical principles of autonomy, nonmaleficence, beneficence, justice, and explicability as a roadmap for facilitating AI integration into nursing education."" 
 Our news journalists obtained a quote from the research from Ewha Womans University, ""Research findings suggest that ethical dilemmas that challenge these five principles can emerge within the context of nursing education; however, adherence to these very principles, which is essential to improving patient care, can offer solutions to these dilemmas. To ensure the ethical and responsible use of Gen AI in nursing education, these principles must be woven into the fabric of curricula, and appropriate guidelines must be developed. Nurse educators have a pivotal role in strategizing comprehensive approaches for ethical AI integration, establishing clear guidelines, and instilling critical thinking among students. Fostering lifelong learning and adaptability is key to ensuring that future nurses can successfully navigate the constantly evolving landscape of health care technology."" 
 According to the news editors, the research concluded: ""Future research should investigate the long-term impacts of AI utilization on learning outcomes and ethical decision-making."" 
 This research has been peer-reviewed. 
 For more information on this research see: Cyberethics In Nursing Education: Ethical Implications of Artificial Intelligence. Nursing Ethics, 2023. Nursing Ethics can be contacted at: Sage Publications Ltd, 1 Olivers Yard, 55 City Road, London EC1Y 1SP, England. (Sage Publications - www.sagepub.com/; Nursing Ethics - nej.sagepub.com) 
 The news correspondents report that additional information may be obtained from Hyeyoung Hwang, Ewha Womans University, Seoul, South Korea. Additional authors for this research include Jennie C. De Gagne and Dukyoo Jung. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1177/09697330231201901. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Seoul, South Korea, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning, Ewha Womans University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (96%); NURSES & NURSING (96%); MEDICAL EDUCATION (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); GENERATIVE AI (90%); RESEARCH REPORTS (90%); COLLEGES & UNIVERSITIES (89%); MEDICAL ETHICS (89%); CURRICULA (79%); EMERGING TECHNOLOGY (79%); JOURNALISM (78%); WRITERS (78%); MACHINE LEARNING (74%); MEDICAL TECHNOLOGY (73%); CONTINUING EDUCATION (72%); Seoul;South Korea;Asia;Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: NURSES & NURSING (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); COLLEGES & UNIVERSITIES (89%); WRITERS (78%); MACHINE LEARNING (74%); MEDICAL TECHNOLOGY (73%); HEALTH CARE (71%)
Geographic: LONDON, ENGLAND (53%); SOUTH KOREA (92%); ASIA (73%); ENGLAND (53%)
Load-Date: November 27, 2023",neutral,0.878227174282074,balanced/neutral,['autonomy'],"['justice', 'autonomy', 'beneficence', 'justice']","['guidelines', 'should', 'must', 'suggest']","['machine learning', 'generative ai']",1,4,4,2
2023,Unknown Title,"Body
(GlobeNewswire) - Intetics, a leading American technology company, dives into approaches to building a framework for successfully integrating AI systems from the U.S. and Europe. In a recent publication, Boris Kontsevoi, Intetics CEO and President provides expert insights on the importance of harmonizing AI systems and the ethical implications of their integration.
The ethical link between U.S. and European AI systems is worrisome. AI continues to advance, and it will be important to address emerging ethical issues. It should take into account ethical differences in different cultures and try to harmonize these systems.
The development of artificial intelligence (AI) is advancing rapidly and with it comes some points, one of them is moral dilemma. The integration of AI systems developed outside of Europe and America presents unique challenges. The potential for conflict between AI systems in the United States, Europe, and other countries is high due to the conflicting cultural, legal, and ethical policies that govern their development.
In the new article, Intetics CEO and President examines the consequences of the integration of AI and ethics. By referring to Isaac Asimov's Three Laws of Robotics, the importance of ethical concerns in AI and the conflicts that may arise from them are emphasized.
The Convergence Challenge
Convergence challenges are multifaceted. It includes different advertising, technology and marketing practices to create new products and services. This combination requires a careful balance of creativity and technology, as well as an understanding of market and customer needs. To succeed in the challenge of convergence, companies need to be willing to take risks, try new ideas and collaborate with partners in different fields. The ultimate goal is to create a cohesive and engaging experience for end users that combines the best of all worlds.
The ethical implications of the amalgamation of AI systems created by all nations with those from other countries are of utmost importance.
AI systems can pose potential conflicts when they interact or operate together due to their varied training datasets, contrasting regulatory frameworks, and distinct cultural norms.
In order to solve ethical dilemmas related to AI, common values should be agreed upon that everyone can follow, but also respect the differences between cultures. This necessitates constant cooperation between countries, scholars, decision-makers, and those affected by the technology to establish ethical standards and conventions that can govern the creation and use of AI systems on a global scale.
The Three Laws of Robotics
Intelligence and the ethics of robotics, also known as the three laws of robotics, were articulated more than half a century ago in the story of Isaac Azimov. These laws are designed to ensure that robots and AI work in ways that are beneficial to humans and not harmful to humans. The First Law states that a robot cannot directly harm or injure a human.
The Second Law requires robots to follow orders given to humans as long as they do not conflict with the First Law.
The third law states that the robot must protect itself as long as it does not interfere with the first two laws. Discussion of these laws remains an important topic in the field of AI ethics.
Isaac Asimov's three laws of robotics were created for his sci-fi study, and they hold important insights into the ethics of intelligence and the problems that may arise. Regarding the integration of various national AI systems, it is worth looking at how these laws reflect this issue.
The initial and most critical law of robotics and AI is as follows: under no circumstances shall a robot or AI cause harm to a human being, nor shall it, through lack of action, allow any harm to come to a human being.
1. The First Law emphasizes the importance of human health and safety. The development of AI systems can lead to conflict if the ethical standards for their creation differ between regions. If AI systems in Eastern European countries prioritize business over user privacy and data protection, it could lead to conflicts with Western European or U.S. AI systems operating under other ethical standards. An agreement on ethical standards is necessary to prevent damage from conflicting AI systems and ensure personal safety.
2. The Second Law of Robotics states that any robot or AI must obey all orders given by humans, unless directly related to the First Law. The importance of the Second Law lies in its emphasis on the need for AI systems to operate within the limits set by human control. A global ethical framework for AI is required to ensure that AI systems abide by human values, rights and laws wherever they come from.
3. This is what the three laws of robotics mean: the robot/AI must protect its own life as long as it does not violate the first or second law. The third rule states that AI systems should care about their own survival, but not more than people's well-being. AI systems in Eastern countries must be proven to follow the same ethics as everyone else, even if they want to keep themselves safe.
The integration of AI systems from different countries and cultures is a complex and important issue. As AI becomes more and more powerful, it should be driven by ethics that respect human values, rights and the law.
Three Laws in Robotics provides an important framework to guide the development and use of AI systems and to avoid conflicts that may arise from their differences. By applying these laws to the integration of the systems, AI can work in the interests of humanity without harming anyone.
The future of AI depends on the ability to bridge the ethics of different intelligences and create a unified and effective integration of these systems. It must harness the power of AI and ensure that it abides by values and rules everywhere.
About Intetics
Intetics Inc. is a leading American technology company providing custom software application development, distributed professional teams creation, software product quality assessment, and all-things-digital solutions built with SMAC, RPA, AI/ML, IoT, blockchain, and GIS/UAV/LBS technologies. Based on proprietary pioneering business models of Offshore Dedicated Team and Remote In-Sourcing, an advanced Technical Debt Reduction Platform (TETRA) and measurable SLAs for software engineering, Intetics helps innovative organizations capitalize on global talent with our in-depth engineering expertise based on our Predictive Software Engineering framework. At Intetics, our outcomes do not just meet clients expectations, they have been exceeding them for a quarter of a century. Intetics is ISO 9001 (quality) and ISO 27001 (security) certified and a Microsoft Gold, Amazon, and UiPath Silver partner. The companys innovation and growth achievements are reflected in winning prestigious titles and awards, including Inc5000, Software 500, CRN 100, American Business, Deloitte Fast 50, European IT Excellence, Best European BPO, Stevie Peoples Choice, Clutch and ACQ5 Awards, IAOP Global Outsourcing 100 and Fortune Innovative 300 lists. You can find more information at https://intetics.com .
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1633
Subject: ETHICS (96%); EXECUTIVES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ROBOTICS (89%); APPOINTMENTS (79%); EXECUTIVE MOVES (79%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); NEW PRODUCTS (65%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ROBOTICS (89%); NEW PRODUCTS (65%)
Geographic: UNITED STATES (94%); EUROPE (93%)
Load-Date: October 13, 2023","(GlobeNewswire) - Intetics, a leading American technology company, dives into approaches to building a framework for successfully integrating AI systems from the U.S. and Europe. In a recent publication, Boris Kontsevoi, Intetics CEO and President provides expert insights on the importance of harmonizing AI systems and the ethical implications of their integration.
The ethical link between U.S. and European AI systems is worrisome. AI continues to advance, and it will be important to address emerging ethical issues. It should take into account ethical differences in different cultures and try to harmonize these systems.
The development of artificial intelligence (AI) is advancing rapidly and with it comes some points, one of them is moral dilemma. The integration of AI systems developed outside of Europe and America presents unique challenges. The potential for conflict between AI systems in the United States, Europe, and other countries is high due to the conflicting cultural, legal, and ethical policies that govern their development.
In the new article, Intetics CEO and President examines the consequences of the integration of AI and ethics. By referring to Isaac Asimov's Three Laws of Robotics, the importance of ethical concerns in AI and the conflicts that may arise from them are emphasized.
The Convergence Challenge
Convergence challenges are multifaceted. It includes different advertising, technology and marketing practices to create new products and services. This combination requires a careful balance of creativity and technology, as well as an understanding of market and customer needs. To succeed in the challenge of convergence, companies need to be willing to take risks, try new ideas and collaborate with partners in different fields. The ultimate goal is to create a cohesive and engaging experience for end users that combines the best of all worlds.
The ethical implications of the amalgamation of AI systems created by all nations with those from other countries are of utmost importance.
AI systems can pose potential conflicts when they interact or operate together due to their varied training datasets, contrasting regulatory frameworks, and distinct cultural norms.
In order to solve ethical dilemmas related to AI, common values should be agreed upon that everyone can follow, but also respect the differences between cultures. This necessitates constant cooperation between countries, scholars, decision-makers, and those affected by the technology to establish ethical standards and conventions that can govern the creation and use of AI systems on a global scale.
The Three Laws of Robotics
Intelligence and the ethics of robotics, also known as the three laws of robotics, were articulated more than half a century ago in the story of Isaac Azimov. These laws are designed to ensure that robots and AI work in ways that are beneficial to humans and not harmful to humans. The First Law states that a robot cannot directly harm or injure a human.
The Second Law requires robots to follow orders given to humans as long as they do not conflict with the First Law.
The third law states that the robot must protect itself as long as it does not interfere with the first two laws. Discussion of these laws remains an important topic in the field of AI ethics.
Isaac Asimov's three laws of robotics were created for his sci-fi study, and they hold important insights into the ethics of intelligence and the problems that may arise. Regarding the integration of various national AI systems, it is worth looking at how these laws reflect this issue.
The initial and most critical law of robotics and AI is as follows: under no circumstances shall a robot or AI cause harm to a human being, nor shall it, through lack of action, allow any harm to come to a human being.
1. The First Law emphasizes the importance of human health and safety. The development of AI systems can lead to conflict if the ethical standards for their creation differ between regions. If AI systems in Eastern European countries prioritize business over user privacy and data protection, it could lead to conflicts with Western European or U.S. AI systems operating under other ethical standards. An agreement on ethical standards is necessary to prevent damage from conflicting AI systems and ensure personal safety.
2. The Second Law of Robotics states that any robot or AI must obey all orders given by humans, unless directly related to the First Law. The importance of the Second Law lies in its emphasis on the need for AI systems to operate within the limits set by human control. A global ethical framework for AI is required to ensure that AI systems abide by human values, rights and laws wherever they come from.
3. This is what the three laws of robotics mean: the robot/AI must protect its own life as long as it does not violate the first or second law. The third rule states that AI systems should care about their own survival, but not more than people's well-being. AI systems in Eastern countries must be proven to follow the same ethics as everyone else, even if they want to keep themselves safe.
The integration of AI systems from different countries and cultures is a complex and important issue. As AI becomes more and more powerful, it should be driven by ethics that respect human values, rights and the law.
Three Laws in Robotics provides an important framework to guide the development and use of AI systems and to avoid conflicts that may arise from their differences. By applying these laws to the integration of the systems, AI can work in the interests of humanity without harming anyone.
The future of AI depends on the ability to bridge the ethics of different intelligences and create a unified and effective integration of these systems. It must harness the power of AI and ensure that it abides by values and rules everywhere.
About Intetics
Intetics Inc. is a leading American technology company providing custom software application development, distributed professional teams creation, software product quality assessment, and all-things-digital solutions built with SMAC, RPA, AI/ML, IoT, blockchain, and GIS/UAV/LBS technologies. Based on proprietary pioneering business models of Offshore Dedicated Team and Remote In-Sourcing, an advanced Technical Debt Reduction Platform (TETRA) and measurable SLAs for software engineering, Intetics helps innovative organizations capitalize on global talent with our in-depth engineering expertise based on our Predictive Software Engineering framework. At Intetics, our outcomes do not just meet clients expectations, they have been exceeding them for a quarter of a century. Intetics is ISO 9001 (quality) and ISO 27001 (security) certified and a Microsoft Gold, Amazon, and UiPath Silver partner. The companys innovation and growth achievements are reflected in winning prestigious titles and awards, including Inc5000, Software 500, CRN 100, American Business, Deloitte Fast 50, European IT Excellence, Best European BPO, Stevie Peoples Choice, Clutch and ACQ5 Awards, IAOP Global Outsourcing 100 and Fortune Innovative 300 lists. You can find more information at https://intetics.com .
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1633
Subject: ETHICS (96%); EXECUTIVES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ROBOTICS (89%); APPOINTMENTS (79%); EXECUTIVE MOVES (79%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); NEW PRODUCTS (65%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ROBOTICS (89%); NEW PRODUCTS (65%)
Geographic: UNITED STATES (94%); EUROPE (93%)
Load-Date: October 13, 2023",neutral,0.8000686764717102,balanced/neutral,"['privacy', 'safety', 'security']",[],"['standards', 'framework', 'law', 'should', 'must', 'need to', 'emphasizes the importance']","['robot', 'robotics']",3,0,7,2
2023,Unknown Title,"Byline: Lauren Stoneman
Body
Each time I go to an information session or a job fair on campus, I find myself asking the same question:
What about ethics? Do ethicists have a role to play at your company?
Usually, the presenter will respond with a diplomatic ""no"" - something to the effect of: ""While it isn't a department here, per se, the ethical implications of what we do are always in the back of our minds.""
Other times, I will be told that ethics is really more of a subcategory of the legal or compliance departments. In other cases, the ""no"" will not be diplomatic at all.
Ultimately, whether the ""no"" is proudly said or muttered under one's breath, it's a ""no"" that should not be tolerated anymore.
Ethics has never been a priority for emerging industries. Talking about the exciting developments of artificial intelligence or the potential of space explorations is, to put it simply, more fun than policing innovation.
The problems created by emerging industries, though, are real and unavoidable. A healthcare algorithm used to determine follow-up care was found to disproportionately favor its white patients. A political consulting firm manipulated voters by mining the data of 50 million Facebook users. A self-driving car killed a woman.
Suddenly, talking about innovation doesn't feel so ""fun.""
All of these cases - cases where innovation concerns humanity - are why ethicists need to be seen as essential.
""The greater the threat to a minimally decent life... the higher the need for ethicists,"" said Reid Blackman, a technical ethics consultant. ""There are difficult ethical decisions to make, and there are decisions being made in highly complex environments wherein it might be difficult to see the ethical implications. Ethicists are good at figuring those things out.""
The reality, though, is that there are very few ethicists in decision-making roles in fields like tech. This, in part, has to do with the fact that we don't really know what ""practical ethics"" looks like.
It can't be written off as an issue of compliance, and it can't be regarded as just an aspect of law, so determining what is legal is an entirely different question from determining what is just. It may be legal to cheat on your spouse, for instance, but it certainly isn't moral. If companies believe that they are being appropriately policed by the legal department and nothing else, they're going to continue to run into ethical issues.
Enjoy what you're reading? Get content from The Daily Cardinal delivered to your inbox
Email
If it isn't law and it is compliance, though, then what is practical ethics? To some, it might seem like an oxymoron - there's nothing ""practical"" about a class of college freshmen debating the ethics of the trolley problem for the umpteenth time and coming to no conclusion. While that may be true, the study of philosophy nonetheless brings out skills that are uniquely and decisively practical.
""Philosophers, all else equal, are trained to analyze and break down and critique at a deeper level than any other discipline,"" Blackman said.
In fields where the potential limits and pitfalls of an idea are still being discovered, it is essential to have someone in your corner who is thinking about every implication and can work with you every step of the way.
There is still an issue, though, with expecting an ethicist to just stand over the shoulders of a software engineer or a data scientist and make suggestions. Ethics is perceived as a soft, subjective discipline that puts parameters on creativity, so it is something developers are eager to ignore.
Practical ethicists need to be more than ""commenters."" They need to be a part of an institutional system of checks and balances. To create this system, we can reference the one practical discipline that is properly engaging ethicists: medicine.
Bioethicists have put ethics ""into process in the right sort of way,"" Blackman said. ""There are requirements about when you have to see an institutional review board , there are standards you have to meet for the IRB to approve you, and it's an everyday operation to get approval before you start your experiment.""
Of course, when the experiment in question involves the immediate life or death of a human being (as is often the case with medical ethics), these ethical review processes do not feel trivial at all. We are a long way from respecting ethics to the same degree in industries like tech.
It's time we realize that these other industries are every bit as life and death and start letting ethicists in on the conversation.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (91%); DATA MINING (78%); REGULATORY COMPLIANCE (78%); EMPLOYMENT FAIRS (73%); CRIME, LAW ENFORCEMENT & CORRECTIONS (72%); ARTIFICIAL INTELLIGENCE (68%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%)
Company:  META PLATFORMS INC (55%)
Ticker: META (NASDAQ) (55%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (55%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (55%); DATA MINING (78%); ARTIFICIAL INTELLIGENCE (68%); CONSULTING SERVICES (66%); AUTONOMOUS MOTOR VEHICLES (51%)
Geographic: MADISON, WI, USA (74%); WISCONSIN, USA (92%); Madison; WI
Load-Date: October 5, 2023","Each time I go to an information session or a job fair on campus, I find myself asking the same question:
What about ethics? Do ethicists have a role to play at your company?
Usually, the presenter will respond with a diplomatic ""no"" - something to the effect of: ""While it isn't a department here, per se, the ethical implications of what we do are always in the back of our minds.""
Other times, I will be told that ethics is really more of a subcategory of the legal or compliance departments. In other cases, the ""no"" will not be diplomatic at all.
Ultimately, whether the ""no"" is proudly said or muttered under one's breath, it's a ""no"" that should not be tolerated anymore.
Ethics has never been a priority for emerging industries. Talking about the exciting developments of artificial intelligence or the potential of space explorations is, to put it simply, more fun than policing innovation.
The problems created by emerging industries, though, are real and unavoidable. A healthcare algorithm used to determine follow-up care was found to disproportionately favor its white patients. A political consulting firm manipulated voters by mining the data of 50 million Facebook users. A self-driving car killed a woman.
Suddenly, talking about innovation doesn't feel so ""fun.""
All of these cases - cases where innovation concerns humanity - are why ethicists need to be seen as essential.
""The greater the threat to a minimally decent life... the higher the need for ethicists,"" said Reid Blackman, a technical ethics consultant. ""There are difficult ethical decisions to make, and there are decisions being made in highly complex environments wherein it might be difficult to see the ethical implications. Ethicists are good at figuring those things out.""
The reality, though, is that there are very few ethicists in decision-making roles in fields like tech. This, in part, has to do with the fact that we don't really know what ""practical ethics"" looks like.
It can't be written off as an issue of compliance, and it can't be regarded as just an aspect of law, so determining what is legal is an entirely different question from determining what is just. It may be legal to cheat on your spouse, for instance, but it certainly isn't moral. If companies believe that they are being appropriately policed by the legal department and nothing else, they're going to continue to run into ethical issues.
Enjoy what you're reading? Get content from The Daily Cardinal delivered to your inbox
Email
If it isn't law and it is compliance, though, then what is practical ethics? To some, it might seem like an oxymoron - there's nothing ""practical"" about a class of college freshmen debating the ethics of the trolley problem for the umpteenth time and coming to no conclusion. While that may be true, the study of philosophy nonetheless brings out skills that are uniquely and decisively practical.
""Philosophers, all else equal, are trained to analyze and break down and critique at a deeper level than any other discipline,"" Blackman said.
In fields where the potential limits and pitfalls of an idea are still being discovered, it is essential to have someone in your corner who is thinking about every implication and can work with you every step of the way.
There is still an issue, though, with expecting an ethicist to just stand over the shoulders of a software engineer or a data scientist and make suggestions. Ethics is perceived as a soft, subjective discipline that puts parameters on creativity, so it is something developers are eager to ignore.
Practical ethicists need to be more than ""commenters."" They need to be a part of an institutional system of checks and balances. To create this system, we can reference the one practical discipline that is properly engaging ethicists: medicine.
Bioethicists have put ethics ""into process in the right sort of way,"" Blackman said. ""There are requirements about when you have to see an institutional review board , there are standards you have to meet for the IRB to approve you, and it's an everyday operation to get approval before you start your experiment.""
Of course, when the experiment in question involves the immediate life or death of a human being (as is often the case with medical ethics), these ethical review processes do not feel trivial at all. We are a long way from respecting ethics to the same degree in industries like tech.
It's time we realize that these other industries are every bit as life and death and start letting ethicists in on the conversation.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (91%); DATA MINING (78%); REGULATORY COMPLIANCE (78%); EMPLOYMENT FAIRS (73%); CRIME, LAW ENFORCEMENT & CORRECTIONS (72%); ARTIFICIAL INTELLIGENCE (68%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%)
Company:  META PLATFORMS INC (55%)
Ticker: META (NASDAQ) (55%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (55%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (55%); DATA MINING (78%); ARTIFICIAL INTELLIGENCE (68%); CONSULTING SERVICES (66%); AUTONOMOUS MOTOR VEHICLES (51%)
Geographic: MADISON, WI, USA (74%); WISCONSIN, USA (92%); Madison; WI
Load-Date: October 5, 2023",neutral,0.646808922290802,balanced/neutral,[],[],"['standards', 'law', 'compliance', 'should', 'need to']","['self-driving car', 'algorithm', 'data mining']",0,0,5,3
2023,Unknown Title,"Body
December 8th, 2023 ( Al Jazeera English  — Delivered by  Newstex )
Tech companies that have promised to support the ethical development of artificial intelligence (AI) are failing to live up to their pledges as safety takes a back seat to performance metrics and product launches, according to a new report by Stanford University researchers.
Despite publishing AI principles and employing social scientists and engineers to conduct research and develop technical solutions related to AI ethics, many private companies have yet to prioritise the adoption of ethical safeguards, Stanford's Institute for Human-Centered Artificial Intelligence said in the report released on Thursday.
""Companies often 'talk the talk' of AI ethics but rarely 'walk the walk' by adequately resourcing and empowering teams that work on responsible AI,"" researchers Sanna J Ali, Angele Christin, Andrew Smart and Riitta Katila said in the report titled Walking the Walk of AI Ethics in Technology Companies.
Drawing on the experiences of 25 ""AI ethics practitioners"", the report said workers involved in promoting AI ethics complained of lacking institutional support and being siloed off from other teams within large organisations despite promises to the contrary.
Employees reported a culture of indifference or hostility due to product managers who see their work as damaging to a company's productivity, revenue or product launch timeline, the report said.
'Being very loud about putting more brakes on [AI development] was a risky thing to do,"" one person surveyed for the report said. ""It was not built into the process.""
The report did not name the companies where the surveyed employees worked.
Governments and academics have expressed concerns about the speed of AI development, with ethical questions touching on everything from the use of private data to racial discrimination and copyright infringement.
Such concerns have grown louder since OpenAI's release of ChatGPT last year and the subsequent development of rival platforms such as Google's Gemini.
Employees told the Stanford researchers that ethical issues are often only considered very late in the game, making it difficult to make adjustments to new apps or software, and that ethical considerations are often disrupted by the frequent reorganisation of teams.
""Metrics around engagement or the performance of AI models are so highly prioritised that ethics-related recommendations that might negatively affect those metrics require irrefutable quantitative evidence,"" the report said.
""Yet quantitative metrics of ethics or fairness are hard to come by and challenging to define given that companies' existing data infrastructures are not tailored to such metrics.""
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 136341
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS METRICS (78%); CHATBOTS (78%); COPYRIGHT (78%); GENERATIVE AI (78%); PRIVATELY HELD COMPANIES (78%); RACISM & XENOPHOBIA (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); NEGATIVE SOCIETAL NEWS (77%); RESEARCH REPORTS (77%); SAFETY (77%); COLLEGES & UNIVERSITIES (73%); COPYRIGHT INFRINGEMENT (73%); COPYRIGHT LAW (73%); NEW PRODUCTS (72%); HUMANITIES & SOCIAL SCIENCE (71%); MANAGERS & SUPERVISORS (69%); COMPANY REVENUES (66%); DISCRIMINATION (66%); RACE & ETHNICITY (66%); News (%); United States (%); US & Canada (%); Technology (%)
Company:  GOOGLE LLC (82%)
Organization: STANFORD UNIVERSITY (83%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (82%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (78%); GENERATIVE AI (78%); COLLEGES & UNIVERSITIES (73%); NEW PRODUCTS (72%); COMPUTER SOFTWARE (60%)
Geographic: CANADA (79%); UNITED STATES (73%)
Load-Date: December 8, 2023","December 8th, 2023 ( Al Jazeera English  — Delivered by  Newstex )
Tech companies that have promised to support the ethical development of artificial intelligence (AI) are failing to live up to their pledges as safety takes a back seat to performance metrics and product launches, according to a new report by Stanford University researchers.
Despite publishing AI principles and employing social scientists and engineers to conduct research and develop technical solutions related to AI ethics, many private companies have yet to prioritise the adoption of ethical safeguards, Stanford's Institute for Human-Centered Artificial Intelligence said in the report released on Thursday.
""Companies often 'talk the talk' of AI ethics but rarely 'walk the walk' by adequately resourcing and empowering teams that work on responsible AI,"" researchers Sanna J Ali, Angele Christin, Andrew Smart and Riitta Katila said in the report titled Walking the Walk of AI Ethics in Technology Companies.
Drawing on the experiences of 25 ""AI ethics practitioners"", the report said workers involved in promoting AI ethics complained of lacking institutional support and being siloed off from other teams within large organisations despite promises to the contrary.
Employees reported a culture of indifference or hostility due to product managers who see their work as damaging to a company's productivity, revenue or product launch timeline, the report said.
'Being very loud about putting more brakes on [AI development] was a risky thing to do,"" one person surveyed for the report said. ""It was not built into the process.""
The report did not name the companies where the surveyed employees worked.
Governments and academics have expressed concerns about the speed of AI development, with ethical questions touching on everything from the use of private data to racial discrimination and copyright infringement.
Such concerns have grown louder since OpenAI's release of ChatGPT last year and the subsequent development of rival platforms such as Google's Gemini.
Employees told the Stanford researchers that ethical issues are often only considered very late in the game, making it difficult to make adjustments to new apps or software, and that ethical considerations are often disrupted by the frequent reorganisation of teams.
""Metrics around engagement or the performance of AI models are so highly prioritised that ethics-related recommendations that might negatively affect those metrics require irrefutable quantitative evidence,"" the report said.
""Yet quantitative metrics of ethics or fairness are hard to come by and challenging to define given that companies' existing data infrastructures are not tailored to such metrics.""
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 136341
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS METRICS (78%); CHATBOTS (78%); COPYRIGHT (78%); GENERATIVE AI (78%); PRIVATELY HELD COMPANIES (78%); RACISM & XENOPHOBIA (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); NEGATIVE SOCIETAL NEWS (77%); RESEARCH REPORTS (77%); SAFETY (77%); COLLEGES & UNIVERSITIES (73%); COPYRIGHT INFRINGEMENT (73%); COPYRIGHT LAW (73%); NEW PRODUCTS (72%); HUMANITIES & SOCIAL SCIENCE (71%); MANAGERS & SUPERVISORS (69%); COMPANY REVENUES (66%); DISCRIMINATION (66%); RACE & ETHNICITY (66%); News (%); United States (%); US & Canada (%); Technology (%)
Company:  GOOGLE LLC (82%)
Organization: STANFORD UNIVERSITY (83%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (82%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (78%); GENERATIVE AI (78%); COLLEGES & UNIVERSITIES (73%); NEW PRODUCTS (72%); COMPUTER SOFTWARE (60%)
Geographic: CANADA (79%); UNITED STATES (73%)
Load-Date: December 8, 2023",neutral,0.6015374660491943,balanced/neutral,"['discrimination', 'fairness', 'safety']",['fairness'],"['law', 'should']","['generative ai', 'chatgpt']",3,1,2,2
2023,Unknown Title,"Body
 In the ever-evolving landscape of artificial intelligence, where innovation often outpaces ethics, one young woman stands out as a beacon of hope and change. Inioluwa Deborah Raji, a 27-year-old Nigerian-Canadian computer scientist and activist, has made an indelible mark in the world of AI through her tireless efforts to combat algorithmic bias and promote accountability.
In a testament to her influence and impact, Raji was recently honoured as one of the inaugural members of Time Magazine's 100 list of the most influential people in Artificial Intelligence (AI). Placed in the 'thinkers' category, Raji's recognition is well-deserved, given her unwavering commitment to making AI more fair and equitable.
Raji's journey into the world of AI activism began when she was a fellow at the Mozilla Foundation, focusing her research on algorithmic auditing and evaluation. It was during this time that she stumbled upon a critical issue: a content moderation model she was assisting in training was disproportionately flagging content containing people of colour as explicit, even when it wasn't. This revelation shook Raji to her core, as it highlighted the stark reality that AI systems were inadvertently perpetuating biases, rendering the world 'whiter' than it truly is.
Read also:Ogoina, Nigerian Prof recognised among TIME's most influential
This pivotal moment marked a shift in Raji's career trajectory. She redirected her passion and expertise towards the mission of ensuring that AI companies take responsibility for the harm their models may cause. Raji believes that transparency and accountability are crucial, and it's up to developers to provide a clear evaluation of their products and the potential harm they may inflict.
Raji's commitment to ethical AI has taken her to some of the most esteemed institutions in the field. She has worked closely with Google's Ethical AI team and served as a research fellow at both the Partnership on AI and the AI Now Institute at New York University. Her focus has been on operationalizing ethical considerations in machine learning engineering practices, contributing to the development of ethical AI standards.
One of the most noteworthy collaborations in Raji's career has been with Joy Buolamwini, a Ghanaian-Canadian computer scientist, and Timnit Gebru. Together with the Algorithmic Justice League, they conducted groundbreaking research on gender and racial bias in facial recognition technology. Their efforts have had far-reaching consequences, prompting IBM and Amazon to not only support facial recognition regulation but also temporarily halt the sale of their products to police.
Read also: Nigerian physician Tunji Funsho named among TIME's Most Influential People in the world
Raji's dedication to creating a more ethical AI ecosystem has garnered her widespread recognition and accolades. She has been named one of the world's top young innovators by both MIT Technology Review and Forbes. Her work on auditing commercial facial recognition technologies from tech giants like Microsoft, Amazon, IBM, Face++, and Kairos was prominently featured in the eye-opening 2020 documentary, 'Coded Bias,' directed by Shalini Kantayya.
In the past year, Raji's contributions to the AI field have earned her a slew of awards, including the 2019 VentureBeat AI Innovations Award in the category of AI for Good, shared with Joy Buolamwini and Timnit Gebru. She also received the 2020 MIT Technology Review 35 Under 35 Innovator Award, the 2020 EFF Pioneer Award, the 2021 Forbes 30 Under 30 Award in Enterprise Technology, and the prestigious honour of being named a 2021 100 Brilliant Women in AI Ethics Hall of Fame Honoree.
Read also: Artificial intelligence will force lawyers to be tech-literate
Inioluwa Deborah Raji is not just a rising star in AI; she is a guiding light steering the industry toward a more ethical and inclusive future. Her unwavering commitment to addressing bias, promoting accountability, and advocating for transparency makes her a true pioneer in the world of artificial intelligence. As AI continues to shape our world, Raji's work stands as a testament to the power of individuals to drive meaningful change in technology for the benefit of all.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); COMPUTER SCIENCE (89%); TECHNICIANS & TECHNOLOGICAL WORKERS (89%); GENDER & WOMEN'S STUDIES (78%); IDENTIFICATION TECHNOLOGIES (78%); ENGINEERING (77%); RACE & ETHNICITY (76%); BIOMETRICS (74%); MACHINE LEARNING (73%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Company:  GOOGLE LLC (82%);  AI SYSTEMS (55%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (82%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); COMPUTER SCIENCE (89%); PATTERN RECOGNITION (89%); ENGINEERING (77%); MACHINE LEARNING (73%); COLLEGE & UNIVERSITY PROFESSORS (65%); INTERNET BROWSERS (53%)
Load-Date: September 13, 2023","In the ever-evolving landscape of artificial intelligence, where innovation often outpaces ethics, one young woman stands out as a beacon of hope and change. Inioluwa Deborah Raji, a 27-year-old Nigerian-Canadian computer scientist and activist, has made an indelible mark in the world of AI through her tireless efforts to combat algorithmic bias and promote accountability.
In a testament to her influence and impact, Raji was recently honoured as one of the inaugural members of Time Magazine's 100 list of the most influential people in Artificial Intelligence (AI). Placed in the 'thinkers' category, Raji's recognition is well-deserved, given her unwavering commitment to making AI more fair and equitable.
Raji's journey into the world of AI activism began when she was a fellow at the Mozilla Foundation, focusing her research on algorithmic auditing and evaluation. It was during this time that she stumbled upon a critical issue: a content moderation model she was assisting in training was disproportionately flagging content containing people of colour as explicit, even when it wasn't. This revelation shook Raji to her core, as it highlighted the stark reality that AI systems were inadvertently perpetuating biases, rendering the world 'whiter' than it truly is.
Read also:Ogoina, Nigerian Prof recognised among TIME's most influential
This pivotal moment marked a shift in Raji's career trajectory. She redirected her passion and expertise towards the mission of ensuring that AI companies take responsibility for the harm their models may cause. Raji believes that transparency and accountability are crucial, and it's up to developers to provide a clear evaluation of their products and the potential harm they may inflict.
Raji's commitment to ethical AI has taken her to some of the most esteemed institutions in the field. She has worked closely with Google's Ethical AI team and served as a research fellow at both the Partnership on AI and the AI Now Institute at New York University. Her focus has been on operationalizing ethical considerations in machine learning engineering practices, contributing to the development of ethical AI standards.
One of the most noteworthy collaborations in Raji's career has been with Joy Buolamwini, a Ghanaian-Canadian computer scientist, and Timnit Gebru. Together with the Algorithmic Justice League, they conducted groundbreaking research on gender and racial bias in facial recognition technology. Their efforts have had far-reaching consequences, prompting IBM and Amazon to not only support facial recognition regulation but also temporarily halt the sale of their products to police.
Read also: Nigerian physician Tunji Funsho named among TIME's Most Influential People in the world
Raji's dedication to creating a more ethical AI ecosystem has garnered her widespread recognition and accolades. She has been named one of the world's top young innovators by both MIT Technology Review and Forbes. Her work on auditing commercial facial recognition technologies from tech giants like Microsoft, Amazon, IBM, Face++, and Kairos was prominently featured in the eye-opening 2020 documentary, 'Coded Bias,' directed by Shalini Kantayya.
In the past year, Raji's contributions to the AI field have earned her a slew of awards, including the 2019 VentureBeat AI Innovations Award in the category of AI for Good, shared with Joy Buolamwini and Timnit Gebru. She also received the 2020 MIT Technology Review 35 Under 35 Innovator Award, the 2020 EFF Pioneer Award, the 2021 Forbes 30 Under 30 Award in Enterprise Technology, and the prestigious honour of being named a 2021 100 Brilliant Women in AI Ethics Hall of Fame Honoree.
Read also: Artificial intelligence will force lawyers to be tech-literate
Inioluwa Deborah Raji is not just a rising star in AI; she is a guiding light steering the industry toward a more ethical and inclusive future. Her unwavering commitment to addressing bias, promoting accountability, and advocating for transparency makes her a true pioneer in the world of artificial intelligence. As AI continues to shape our world, Raji's work stands as a testament to the power of individuals to drive meaningful change in technology for the benefit of all.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); COMPUTER SCIENCE (89%); TECHNICIANS & TECHNOLOGICAL WORKERS (89%); GENDER & WOMEN'S STUDIES (78%); IDENTIFICATION TECHNOLOGIES (78%); ENGINEERING (77%); RACE & ETHNICITY (76%); BIOMETRICS (74%); MACHINE LEARNING (73%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Company:  GOOGLE LLC (82%);  AI SYSTEMS (55%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (82%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); COMPUTER SCIENCE (89%); PATTERN RECOGNITION (89%); ENGINEERING (77%); MACHINE LEARNING (73%); COLLEGE & UNIVERSITY PROFESSORS (65%); INTERNET BROWSERS (53%)
Load-Date: September 13, 2023",positive,0.8750854730606079,balanced/neutral,"['bias', 'transparency', 'accountability']","['justice', 'justice']","['regulation', 'standards']","['machine learning', 'facial recognition']",3,2,2,2
2023,Unknown Title,"Body
NAPLES: Intetics, a leading American technology company, dives into approaches to building a framework for successfully integrating AI systems from the U.S and Europe. In a recent publication, Boris Kontsevoi, Intetics CEO and President provides expert insights on the importance of harmonizing AI systems and the ethical implications of their integration. The ethical link between U.S and European AI systems is worrisome. AI continues to advance, and it will be important to address emerging ethical issues. It should take into account ethical differences in different cultures and try to harmonize these systems.
The development of artificial intelligence (AI) is advancing rapidly and with it comes some points, one of them is moral dilemma. The integration of AI systems developed outside of Europe and America presents unique challenges. The potential for conflict between AI systems in the United States, Europe, and other countries is high due to the conflicting cultural, legal, and ethical policies that govern their development. In the new article, Intetics CEO and President examines the consequences of the integration of AI and ethics. By referring to Isaac Asimov's Three Laws of Robotics, the importance of ethical concerns in AI and the conflicts that may arise from them are emphasized.
Convergence challenges are multifaceted. It includes different advertising, technology and marketing practices to create new products and services. This combination requires a careful balance of creativity and technology, as well as an understanding of market and customer needs. To succeed in the challenge of convergence, companies need to be willing to take risks, try new ideas and collaborate with partners in different fields. The ultimate goal is to create a cohesive and engaging experience for end users that combine the best of all worlds. The ethical implications of the amalgamation of AI systems created by all nations with those from other countries are of utmost importance.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS NEWS (90%); EXECUTIVES (90%); ROBOTICS (73%); NEW PRODUCTS (65%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ROBOTICS (73%); NEW PRODUCTS (65%)
Geographic: UNITED STATES (94%); EUROPE (93%)
Load-Date: October 16, 2023","NAPLES: Intetics, a leading American technology company, dives into approaches to building a framework for successfully integrating AI systems from the U.S and Europe. In a recent publication, Boris Kontsevoi, Intetics CEO and President provides expert insights on the importance of harmonizing AI systems and the ethical implications of their integration. The ethical link between U.S and European AI systems is worrisome. AI continues to advance, and it will be important to address emerging ethical issues. It should take into account ethical differences in different cultures and try to harmonize these systems.
The development of artificial intelligence (AI) is advancing rapidly and with it comes some points, one of them is moral dilemma. The integration of AI systems developed outside of Europe and America presents unique challenges. The potential for conflict between AI systems in the United States, Europe, and other countries is high due to the conflicting cultural, legal, and ethical policies that govern their development. In the new article, Intetics CEO and President examines the consequences of the integration of AI and ethics. By referring to Isaac Asimov's Three Laws of Robotics, the importance of ethical concerns in AI and the conflicts that may arise from them are emphasized.
Convergence challenges are multifaceted. It includes different advertising, technology and marketing practices to create new products and services. This combination requires a careful balance of creativity and technology, as well as an understanding of market and customer needs. To succeed in the challenge of convergence, companies need to be willing to take risks, try new ideas and collaborate with partners in different fields. The ultimate goal is to create a cohesive and engaging experience for end users that combine the best of all worlds. The ethical implications of the amalgamation of AI systems created by all nations with those from other countries are of utmost importance.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS NEWS (90%); EXECUTIVES (90%); ROBOTICS (73%); NEW PRODUCTS (65%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ROBOTICS (73%); NEW PRODUCTS (65%)
Geographic: UNITED STATES (94%); EUROPE (93%)
Load-Date: October 16, 2023",neutral,0.7775854468345642,balanced/neutral,[],[],"['framework', 'should', 'need to']",['robotics'],0,0,3,1
2023,Unknown Title,"Body
--News Direct--
The Ethical Web Data Collection Initiative (EWDCI) is an industry-led consortium of web data collectors focused on strengthening public trust, promoting ethical guidelines, and helping businesses and their customers make informed data extraction choices. The association aims to raise the bar for ethics in the process widely known as “data scraping” with the goal of enhancing trust—a key component of a free, fair, and open Internet. This international, industry-led, and member-driven consortium is announcing an accreditation program developed to bring greater accountability and build consumer confidence in the data collection industry.
Over the past several months, the EWDCI has collaborated on a set of core web scraping principles that revolve around legality, ethics, ecosystem engagement, and social responsibility, inviting everyone from across the globe to participate in the development of these principles. The EWDCI launched a public comment period to gather insights that zero in on the most important concerns of companies and individuals about how data is gathered and used.
We are proud to announce the launch of the EWDCI accreditation program, wherein eligible companies can receive an EWDCI Certified designation. All companies that receive the EWDCI Certified designation are showing the world that they adhere to these agreed-upon principles and the highest degree of ethics when collecting public web data, while also further advancing the industry’s best practices and accountability.
Starting today, companies may apply to become EWDCI Certified. We encourage companies who collect and manage web data to join the consortium—and, most importantly, join the conversation to further develop these principles. The inaugural group of web data aggregators that have earned EWDCI accreditation includes Coresignal, Oxylabs, ProxyEmpire, Rayobyte, Smartproxy, and Zyte.
The EWDCI Certified designation isn’t so much the result of our work but rather the culmination of the first stage of a longer process. The web data collection industry is still young, but it’s growing very quickly. As more data-hungry AI tools fall into corporate and private hands, there is a limited opportunity to shape how data-collection practices are developed and perceived. This is why the EWDCI is dedicated to defining positive and beneficial uses of the important abilities and potential of data collection and aggregation at scale.
The EWDCI is now focused on furthering the consortium’s mission and scope of practice through the acquisition of public commentary on various topics, which include:
How scraped data can be used to ethically train large language models (LLMs) and generative AI models
Government access to data and due process
Balance between scrapers and target websites
Privacy compliance when scraping personal data
Preventing tactics that undermine consent and consumer choice
Anti-stalkerware efforts
“The EWDCI seal is a crucial stamp of approval, but it’s also a way to build industry-led influence with a clear goal of making the free and open Internet a better and safer place,” said Christian Dawson, Executive Director of the i2Coalition.
Companies working with web data collection can earn the EWDCI Certified designation by contacting Hilary Osborne at hilary@i2coalition.com
About the Ethical Web Data Aggregation Integrity Initiative
The Ethical Web Data Collection Initiative (EWDCI) seeks to foster cooperation in the web data collection and aggregation industry and leverage collective first-hand knowledge and insights to advocate for beneficial technical standards and business best practices regarding the extraction of web data. The EWDCI is dedicated to serving as the voice of the industry, collaboratively strengthening public trust in the practice of data scraping, promoting ethical guidelines, and helping businesses make informed data extraction choices. 
Learn more about the EWDCI: www.ethicalwebdata.com
About i2Coalition
The Internet Infrastructure Coalition (i2Coalition, i2C) is the leading voice for web hosting companies, data centers, domain registrars and registries, cloud infrastructure providers, managed services providers, and related tech. The i2C works with Internet infrastructure providers to advocate for sensible policies, design and reinforce best practices, help create industry standards, and build awareness of how the Internet works. The i2Coalition also spearheaded the creation of the VPN Trust Initiative to establish and promote best practices for that vital industry.
Learn more about the i2Coalition: www.i2coalition.com
Contact Details
Aaron Alberico
+1 202-744-0786
aalberico@raynoravenue.com
Company Website
https://ethicalwebdata.com/
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); ACCREDITATION (89%); BEST PRACTICES (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); CREDIT REGULATION (78%); DUE PROCESS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); AGENCY RULEMAKING (77%); PUBLIC HEARINGS (76%); CONSUMER CONFIDENCE (75%); ARTIFICIAL INTELLIGENCE (69%); GENERATIVE AI (66%); LARGE LANGUAGE MODELS (66%)
Industry: CONTENT AGGREGATORS (79%); CREDIT REGULATION (78%); ARTIFICIAL INTELLIGENCE (69%); GENERATIVE AI (66%); LARGE LANGUAGE MODELS (66%)
Load-Date: October 4, 2023","--News Direct--
The Ethical Web Data Collection Initiative (EWDCI) is an industry-led consortium of web data collectors focused on strengthening public trust, promoting ethical guidelines, and helping businesses and their customers make informed data extraction choices. The association aims to raise the bar for ethics in the process widely known as “data scraping” with the goal of enhancing trust—a key component of a free, fair, and open Internet. This international, industry-led, and member-driven consortium is announcing an accreditation program developed to bring greater accountability and build consumer confidence in the data collection industry.
Over the past several months, the EWDCI has collaborated on a set of core web scraping principles that revolve around legality, ethics, ecosystem engagement, and social responsibility, inviting everyone from across the globe to participate in the development of these principles. The EWDCI launched a public comment period to gather insights that zero in on the most important concerns of companies and individuals about how data is gathered and used.
We are proud to announce the launch of the EWDCI accreditation program, wherein eligible companies can receive an EWDCI Certified designation. All companies that receive the EWDCI Certified designation are showing the world that they adhere to these agreed-upon principles and the highest degree of ethics when collecting public web data, while also further advancing the industry’s best practices and accountability.
Starting today, companies may apply to become EWDCI Certified. We encourage companies who collect and manage web data to join the consortium—and, most importantly, join the conversation to further develop these principles. The inaugural group of web data aggregators that have earned EWDCI accreditation includes Coresignal, Oxylabs, ProxyEmpire, Rayobyte, Smartproxy, and Zyte.
The EWDCI Certified designation isn’t so much the result of our work but rather the culmination of the first stage of a longer process. The web data collection industry is still young, but it’s growing very quickly. As more data-hungry AI tools fall into corporate and private hands, there is a limited opportunity to shape how data-collection practices are developed and perceived. This is why the EWDCI is dedicated to defining positive and beneficial uses of the important abilities and potential of data collection and aggregation at scale.
The EWDCI is now focused on furthering the consortium’s mission and scope of practice through the acquisition of public commentary on various topics, which include:
How scraped data can be used to ethically train large language models (LLMs) and generative AI models
Government access to data and due process
Balance between scrapers and target websites
Privacy compliance when scraping personal data
Preventing tactics that undermine consent and consumer choice
Anti-stalkerware efforts
“The EWDCI seal is a crucial stamp of approval, but it’s also a way to build industry-led influence with a clear goal of making the free and open Internet a better and safer place,” said Christian Dawson, Executive Director of the i2Coalition.
Companies working with web data collection can earn the EWDCI Certified designation by contacting Hilary Osborne at hilary@i2coalition.com
About the Ethical Web Data Aggregation Integrity Initiative
The Ethical Web Data Collection Initiative (EWDCI) seeks to foster cooperation in the web data collection and aggregation industry and leverage collective first-hand knowledge and insights to advocate for beneficial technical standards and business best practices regarding the extraction of web data. The EWDCI is dedicated to serving as the voice of the industry, collaboratively strengthening public trust in the practice of data scraping, promoting ethical guidelines, and helping businesses make informed data extraction choices. 
Learn more about the EWDCI: www.ethicalwebdata.com
About i2Coalition
The Internet Infrastructure Coalition (i2Coalition, i2C) is the leading voice for web hosting companies, data centers, domain registrars and registries, cloud infrastructure providers, managed services providers, and related tech. The i2C works with Internet infrastructure providers to advocate for sensible policies, design and reinforce best practices, help create industry standards, and build awareness of how the Internet works. The i2Coalition also spearheaded the creation of the VPN Trust Initiative to establish and promote best practices for that vital industry.
Learn more about the i2Coalition: www.i2coalition.com
Contact Details
Aaron Alberico
+1 202-744-0786
aalberico@raynoravenue.com
Company Website
https://ethicalwebdata.com/
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); ACCREDITATION (89%); BEST PRACTICES (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); CREDIT REGULATION (78%); DUE PROCESS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); AGENCY RULEMAKING (77%); PUBLIC HEARINGS (76%); CONSUMER CONFIDENCE (75%); ARTIFICIAL INTELLIGENCE (69%); GENERATIVE AI (66%); LARGE LANGUAGE MODELS (66%)
Industry: CONTENT AGGREGATORS (79%); CREDIT REGULATION (78%); ARTIFICIAL INTELLIGENCE (69%); GENERATIVE AI (66%); LARGE LANGUAGE MODELS (66%)
Load-Date: October 4, 2023",neutral,0.6174347996711731,balanced/neutral,"['privacy', 'accountability', 'agency', 'consent', 'access']",[],"['regulation', 'standards', 'guidelines', 'compliance', 'advocate']",['generative ai'],5,0,5,1
2023,Unknown Title,"Body
Create company culture of ethics in technology
By Staff Writer, ITWeb  Johannesburg, 10 Oct 2023  Read time 6min 10sec
In this article  Comments (0)
    The University of Pretoria's Dr Hanlie Smuts and Dr Lizette Weilbach.
The importance of ethics in technology is seeing renewed hot debate, with artificial intelligence (AI), in particular, under the global spotlight since the release of OpenAI's ChatGPT, the AI-powered large language chatbot, at the end of last year.
Dr Hanlie Smuts, associate professor at the Department of Informatics, University of Pretoria, and Dr Lizette Weilbach, a senior lecturer in the Department of Informatics, University of Pretoria, have researched ethics in technology, and packaged some of their findings for ITWeb readers.
""We live in a ubiquitous computing world transformed by the evolution of digital technologies. The growing application of digital technologies resulted in a highly-integrated cyber-physical space. A key enabler to the viability of cyber-physical systems is the availability of data and the extraction of value from data. Inevitably, data-driven organisations apply data for their decision-making, rather than intuition,"" they comment.
See also Humanising tech, from UX to impactful human experience
Feeding a knowledge-intensive society
""One of the key demands of the cyber-physical world is the need to provide safety and security for such systems. Through digital transformation, organisations integrate technology into business processes, products and services, emphasising potential ethical considerations.
""These considerations include aspects such as how organisations use information, how employees are engaged and empowered to be able to deal with ethical dilemmas in their day-to-day work, how organisations manage resources and how they approach sustainability,"" Dr Smuts andDr Weilbach state.
Based on their analysis of key concepts of ethics in technology, the academics provide 10 principles and checkpoints to support organisations to navigate the world of computer, cyber, robot and human ethics.
Computer (internet) ethics
1. Be ethically-driven from the start: Organisations need to be proactive and stay at the forefront of potential ethical technology challenges. From the start, organisations need to design technology-driven products and services with ethical principles in mind. This can assist them to anticipate and avoid situations, rather than being reactive after the effect.
2. Embrace an ethical technical technology mindset: Ethical technology recognition, awareness and decision-making frameworks should not only be perceived as a compliance or policy action, but should be inherent to the organisation's fabric. Adoption of the technology disruption vocabulary and syntax is not sufficient; companies should be aware of the ethical decision-makers' role regarding technology disruptors.
3. Create a culture of shared responsibility: Engage all functions and champion it from the top. Leaving shared responsibility to a few teams or departments, promotes the impression that the whole organisation is not required to consider it. Companies need to be able to distinguish the ethical issues technology disruption may introduce and apply consistent means of pinpointing ethical courses of action. By promoting a culture that supports these courses of action, ethical decision-making will be endorsed.
4. Ensure an approach that can evolve: Approaches to ethical technology in organisations should be assessed and revised as needed due to the unpredictable and rapid way in which technology is evolving. Policies developed in recent years may no longer directly address current risks based on the rate at which markets are changing, Companies must therefore develop policies and frameworks to guide technology decisions, with the expectation that they will likely require adjustment and adaptation as markets evolve and technologies change.
5. Equip employees with the resources to respond: Employees, teams and departments should have the resources they require to make ethical decisions regarding technology. It is therefore important that organisations provide employees with applicable resources, assets and tools. These resources will assist employees to recognise ethical dilemmas, to appraise alternatives, to make and to test ethical technology decisions.
Cyber ethics
6. Moral use of data and resources: Data is of great value in refining product offerings and implementing new marketing strategies. However, such strategies can also be invasive in terms of privacy, highlighting many ethical issues. To ensure data is not leaked or used inappropriately, data protection measures and compliance procedures may be defined and applied in order to guide moral use of data.
7. Design the organisation for ethical technology: Ethical technology policies are not intended to replace business ethics or general compliance, but rather to strengthen them. Hence, avoid creating functional silos in the context of ethics or establish a separate, standalone ethics programme. Rather expand departments' objectives to include ethical technology considerations. Encourage and teach employees to distinguish among professional ethics concerns, technology-related ethical issues and broader corporate matters.
Robot ethics (including AI ethics)
8. Responsible adoption of disruptive technologies: Digital growth is a business reality, yet such digital transformation should not cause ethical challenges. To ensure the technologies the business adopts have ethics considerations and protection in place, it should do due diligence prior to technology acquisition. Due diligence may be supported by the development of a guiding framework that is inclusive of technology use cases specific to the company and aligned to its culture.
Human ethics
9. Respect for employees and customers: Organisations that engage in good ethical technology practices, and understand that customers and employees are their greatest asset, maintain a strong moral sense of the rights of their employees and the protection of their customers. The value of data is therefore considered within a frame of responsible protection of employees and customers alike.
10. Make ethical technology part of a holistic, technology know-how approach: It is important the whole business recognises potentially technology-related ethical predicaments. Employees that are not directly involved with, or responsible for technology, must be trained and empowered to recognise ethical technology issues; even when these technology issues are less obvious. This may especially be important for less digitally transformed organisations, where the implications of technology for day-to-day operations are less obvious to employees.
About the research authors
Dr Hanlie Smuts has been an associate professor at the Department of Informatics, University of Pretoria, since 2017. Her lecturing and research role focuses on IT and the organisation, with particular emphasis on Society 5.0, digital transformation, big data management, artificial intelligence and knowledge management.
Dr Smuts is deputy chair of the Knowledge Management South Africa board and has published several papers and book chapters in her field of study.
Dr Lizette Weilbach is a senior lecturer in the Department of Informatics, University of Pretoria. She has 21 years of expertise in information systems analysis and design education within the realm of higher education. Over the course of her career, she has dedicated 14 years to instructing the Informatics Capstone project, which is designed to produce industry-ready graduates.
Dr Weilbach's research primarily revolves around IT in education, with a strong focus on enhancing the pedagogy related to business and systems analysis. Additionally, she maintains a secondary research interest in IT and organisational dynamics, particularly concentrating on areas such as Society 5.0, disruptive technologies, and its impact on SMEs and innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); CORPORATE CULTURE (90%); ETHICS (90%); GENERATIVE AI (90%); DISRUPTIVE INNOVATION (89%); ASSOCIATIONS & ORGANIZATIONS (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EMERGING TECHNOLOGY (78%); COLLEGE & UNIVERSITY PROFESSORS (72%); LARGE LANGUAGE MODELS (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); COLLEGE & UNIVERSITY PROFESSORS (72%); LARGE LANGUAGE MODELS (71%)
Geographic: PRETORIA, SOUTH AFRICA (88%)
Load-Date: October 10, 2023","Create company culture of ethics in technology
By Staff Writer, ITWeb  Johannesburg, 10 Oct 2023  Read time 6min 10sec
In this article  Comments (0)
    The University of Pretoria's Dr Hanlie Smuts and Dr Lizette Weilbach.
The importance of ethics in technology is seeing renewed hot debate, with artificial intelligence (AI), in particular, under the global spotlight since the release of OpenAI's ChatGPT, the AI-powered large language chatbot, at the end of last year.
Dr Hanlie Smuts, associate professor at the Department of Informatics, University of Pretoria, and Dr Lizette Weilbach, a senior lecturer in the Department of Informatics, University of Pretoria, have researched ethics in technology, and packaged some of their findings for ITWeb readers.
""We live in a ubiquitous computing world transformed by the evolution of digital technologies. The growing application of digital technologies resulted in a highly-integrated cyber-physical space. A key enabler to the viability of cyber-physical systems is the availability of data and the extraction of value from data. Inevitably, data-driven organisations apply data for their decision-making, rather than intuition,"" they comment.
See also Humanising tech, from UX to impactful human experience
Feeding a knowledge-intensive society
""One of the key demands of the cyber-physical world is the need to provide safety and security for such systems. Through digital transformation, organisations integrate technology into business processes, products and services, emphasising potential ethical considerations.
""These considerations include aspects such as how organisations use information, how employees are engaged and empowered to be able to deal with ethical dilemmas in their day-to-day work, how organisations manage resources and how they approach sustainability,"" Dr Smuts andDr Weilbach state.
Based on their analysis of key concepts of ethics in technology, the academics provide 10 principles and checkpoints to support organisations to navigate the world of computer, cyber, robot and human ethics.
Computer (internet) ethics
1. Be ethically-driven from the start: Organisations need to be proactive and stay at the forefront of potential ethical technology challenges. From the start, organisations need to design technology-driven products and services with ethical principles in mind. This can assist them to anticipate and avoid situations, rather than being reactive after the effect.
2. Embrace an ethical technical technology mindset: Ethical technology recognition, awareness and decision-making frameworks should not only be perceived as a compliance or policy action, but should be inherent to the organisation's fabric. Adoption of the technology disruption vocabulary and syntax is not sufficient; companies should be aware of the ethical decision-makers' role regarding technology disruptors.
3. Create a culture of shared responsibility: Engage all functions and champion it from the top. Leaving shared responsibility to a few teams or departments, promotes the impression that the whole organisation is not required to consider it. Companies need to be able to distinguish the ethical issues technology disruption may introduce and apply consistent means of pinpointing ethical courses of action. By promoting a culture that supports these courses of action, ethical decision-making will be endorsed.
4. Ensure an approach that can evolve: Approaches to ethical technology in organisations should be assessed and revised as needed due to the unpredictable and rapid way in which technology is evolving. Policies developed in recent years may no longer directly address current risks based on the rate at which markets are changing, Companies must therefore develop policies and frameworks to guide technology decisions, with the expectation that they will likely require adjustment and adaptation as markets evolve and technologies change.
5. Equip employees with the resources to respond: Employees, teams and departments should have the resources they require to make ethical decisions regarding technology. It is therefore important that organisations provide employees with applicable resources, assets and tools. These resources will assist employees to recognise ethical dilemmas, to appraise alternatives, to make and to test ethical technology decisions.
Cyber ethics
6. Moral use of data and resources: Data is of great value in refining product offerings and implementing new marketing strategies. However, such strategies can also be invasive in terms of privacy, highlighting many ethical issues. To ensure data is not leaked or used inappropriately, data protection measures and compliance procedures may be defined and applied in order to guide moral use of data.
7. Design the organisation for ethical technology: Ethical technology policies are not intended to replace business ethics or general compliance, but rather to strengthen them. Hence, avoid creating functional silos in the context of ethics or establish a separate, standalone ethics programme. Rather expand departments' objectives to include ethical technology considerations. Encourage and teach employees to distinguish among professional ethics concerns, technology-related ethical issues and broader corporate matters.
Robot ethics (including AI ethics)
8. Responsible adoption of disruptive technologies: Digital growth is a business reality, yet such digital transformation should not cause ethical challenges. To ensure the technologies the business adopts have ethics considerations and protection in place, it should do due diligence prior to technology acquisition. Due diligence may be supported by the development of a guiding framework that is inclusive of technology use cases specific to the company and aligned to its culture.
Human ethics
9. Respect for employees and customers: Organisations that engage in good ethical technology practices, and understand that customers and employees are their greatest asset, maintain a strong moral sense of the rights of their employees and the protection of their customers. The value of data is therefore considered within a frame of responsible protection of employees and customers alike.
10. Make ethical technology part of a holistic, technology know-how approach: It is important the whole business recognises potentially technology-related ethical predicaments. Employees that are not directly involved with, or responsible for technology, must be trained and empowered to recognise ethical technology issues; even when these technology issues are less obvious. This may especially be important for less digitally transformed organisations, where the implications of technology for day-to-day operations are less obvious to employees.
About the research authors
Dr Hanlie Smuts has been an associate professor at the Department of Informatics, University of Pretoria, since 2017. Her lecturing and research role focuses on IT and the organisation, with particular emphasis on Society 5.0, digital transformation, big data management, artificial intelligence and knowledge management.
Dr Smuts is deputy chair of the Knowledge Management South Africa board and has published several papers and book chapters in her field of study.
Dr Lizette Weilbach is a senior lecturer in the Department of Informatics, University of Pretoria. She has 21 years of expertise in information systems analysis and design education within the realm of higher education. Over the course of her career, she has dedicated 14 years to instructing the Informatics Capstone project, which is designed to produce industry-ready graduates.
Dr Weilbach's research primarily revolves around IT in education, with a strong focus on enhancing the pedagogy related to business and systems analysis. Additionally, she maintains a secondary research interest in IT and organisational dynamics, particularly concentrating on areas such as Society 5.0, disruptive technologies, and its impact on SMEs and innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1504
Subject: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); CORPORATE CULTURE (90%); ETHICS (90%); GENERATIVE AI (90%); DISRUPTIVE INNOVATION (89%); ASSOCIATIONS & ORGANIZATIONS (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); EMERGING TECHNOLOGY (78%); COLLEGE & UNIVERSITY PROFESSORS (72%); LARGE LANGUAGE MODELS (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); COLLEGE & UNIVERSITY PROFESSORS (72%); LARGE LANGUAGE MODELS (71%)
Geographic: PRETORIA, SOUTH AFRICA (88%)
Load-Date: October 10, 2023",neutral,0.7995470762252808,balanced/neutral,"['privacy', 'safety', 'security']",[],"['policy', 'framework', 'compliance', 'should', 'must', 'need to']","['generative ai', 'chatgpt', 'robot']",3,0,6,3
2023,Unknown Title,"Dateline: LAS VEGAS, Oct. 31, 2023 
Body
PR NewswireCelina Insurance Group, Georgia Farm Bureau, Topa Insurance Company, Players Health, Co-operative Insurance Companies, Locke Lord, Five Sigma, reThoughtFlood, Douglas Benalan - a top industry influencer and CIO, and Elizabeth Foughty - an industry expert on AI, insurance, and climate joins the EAIC.LAS VEGAS, Oct. 31, 2023 /PRNewswire-PRWeb/ -- The Ethical AI in Insurance Consortium (EAIC), which aims to foster responsible and transparent adoption of artificial intelligence (AI) for decision management in the insurance sector, is proud to announce the addition of 10 founding members, significantly broadening its expertise and potential impact. Simultaneously, the Consortium is launching a groundbreaking survey of insurance and reinsurance executives determining attitudes, readiness, and use of AI including Generative AI, large language models, and machine vision. This research aims to provide valuable insights and guide the formulation of ethical AI practices in the insurance domain.The collective knowledge that is now represented within the EAIC means the Consortium will have broader reach and consideration for every aspect of the insurance distribution cycle and the ethical usage of AI.Brian Casey, Partner and Co-Chair of Regulatory & Transactional Insurance Practice Group for Locke Lord said, ""Locke Lord's Regulatory & Transactions Insurance Practice Group is honored to become a supporting legal services member of the Ethical AI in Insurance Consortium, a much-needed industry-lead group for the U.S. insurance business. 
We hope to help bridge the gap between AI technologists and the practical regulatory compliance requirements coming down the pike for fair and legitimate business uses of artificial intelligence in insurance underwriting, sales and claims and look forward to guiding the EAIC in establishing AI standards that work for all constituents in the insurance industry in the modern insurtech environment.""Douglas Benalan, CIO of CURE Insurance, who has been recognized in 2023 by the American Business Awards for digital transformation, ranked as one of the top 150 Business Transformation Executives by Constellation Research, is joining the EAIC, and had this to say, ""I am honored to join the Ethical AI in Insurance Consortium. It's crucial that as industry leaders, we prioritize responsible AI adoption to enhance our services while upholding ethical standards. Together, we will strive to create a sustainable and equitable future for the insurance sector through the judicious application of artificial intelligence.""""Ethical AI is an opportunity to design technology that respects , empowers humanity, and guides us towards a future where technology serves as a force for good, rather than harm,"" said Sandeep Bajaj, Group Chief Information Officer of Players Health. ""It is a foundation upon which we can construct a future to enhance our lives without compromising our values and a key to unlock full potential of artificial intelligence while preserving our moral compass in a digital age.""""I am honored to join the Ethical AI in Insurance Consortium and believe that it is our responsibility to ensure ethical practices are established and adhered to as we see the use of AI grow exponentially,"" Kim Holmbeck, Director – Program Management for Co-operative Insurance Companies. ""While we have all probably used some form of AI in some of our current practices, as we move forward and increase this usage, we must be aware of any biases that might be created. This is an exciting time to be in insurance and as we continue to explore and utilize AI we must also educate and make aware to those around us the ethical practice of AI.""Elizabeth Foughty is a strategic consultant whose experience with AI goes back to 2007 when she supported data mining researchers at NASA, followed by working for RMS and Cape Analytics commented, ""There are so many powerful use cases for artificial intelligence in the insurance industry that can help insurers close protection gaps, provide better underwriting and more fair pricing, as well as plan better. However, the ethical implications must be understood as well, to ensure these tools are being harnessed in ways that don't create more negative bias or other issues. I am delighted to support this effort.""""I am honored to join the Ethical AI in Insurance Consortium. It's crucial that, as industry leaders, we prioritize responsible AI adoption to enhance our services while upholding ethical standards. Together, we will strive to create a sustainable and equitable future for the insurance sector through the judicious application of artificial intelligence."" - Oded Barak, CEO of Five Sigma.CEO of reThought Flood, Cory Isaacson added, ""Our ethos is transparency, technology, and trust, so using our technology tools ethically is extremely important to us. AI can be a strong force for good if used well, such as helping to close the flood protection gap. We are excited to be a part of an effort to drive industry wide understanding of this very critical topic.""The inclusion of these new founding members marks a significant milestone in achieving the Consortium's mission to unite insurers, insurtechs, technology solution providers, regulators, and key influencers towards a common goal. This brings the total number of parties involved in the EAIC to 13 including the initial founding members Cloverleaf Analytics, Socotra, and Exavalu.With AI increasingly becoming an integral part of crucial functions such as underwriting, claims processing, and pricing in the insurance industry, ensuring fairness, transparency, and accountability is paramount. The Ethical AI in Insurance Consortium addresses critical challenges and opportunities associated with AI use in the sector, including addressing algorithmic bias, enhancing customer acceptance, upholding data integrity, and other essential aspects impacting product development, selling, servicing, and customer support.The EAIC's core objectives encompass the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, and promoting standardization within the sector.Founding members Socotra, Exavalu, and Cloverleaf Analytics expressed their enthusiasm for the Insurance AI research initiative and the expansion of the EAIC.Abby Hosseini, Chief Digital Officer at Exavalu, stated, ""This group of pioneering and like-minded companies are taking a pivotal step toward empowering insurers to harness the potential of AI while ensuring it aligns with ethical and responsible business practices with increased transparency and accelerated AI value realization.""Michael Benayoun, Director of Partnerships at Socotra, emphasized, ""We are committed to using research-based insights to drive meaningful change in the industry and leverage AI responsibly for the benefit of all stakeholders.""Michael Schwabrow, Executive Vice President of Sales and Marketing for Cloverleaf Analytics, highlighted the importance of the industry collaboration, stating, ""The collective knowledge that is now represented within the EAIC means the Consortium will have broader reach and consideration for every aspect of the insurance distribution cycle and the ethical usage of AI. We welcome the new members and encourage other organizations and influencers to join the mission to educate, guide, and protect the use of AI in insurance.""The EAIC will reveal the research findings and recommendations in Q1 2024, offering an opportunity for dialogue about the responsible integration of AI in insurance practices in a live webinar coinciding with the launch of the research report.More about the EAIC's new members:Celina Insurance GroupCelina Insurance Group is comprised of four mutual property and casualty insurance companies. The companies provide protection for autos, homes, businesses, and farms through more than 500 independent agencies in five states. Founded in 1914 with headquarters in Celina, Ohio, the organization is committed to supporting its policyholders and communities.Georgia Farm BureauGeorgia Farm Bureau Mutual Insurance Company is proud to offer a broad range of insurance products to serve families across the state of Georgia. Farm Bureau is truly a unique organization that represents the state of Georgia in a way that no other organization can. With offices strategically placed in 158 of Georgia's 159 counties, you're never far from an experienced agent and a friendly face. Georgia Farm Bureau Insurance was created by the Georgia Farm Bureau Federation in 1959 and has a strong tradition of supporting rural communities.Topa Insurance CompanyTopa Insurance Company is a boutique carrier, committed to strong relationships, aligned partnerships, excellent service, underwriting expertise, and quality products for our wholesale brokers, general agents, and MGAs.Players HealthMinneapolis-based Players Health is a sports technology platform providing digital risk management services, reporting tools, and insurance products to sports organizations to comply with the changing athletic environment and responsibilities. Working towards establishing the safest environment for athletes, Players Health views the health and safety of athletes as a priority in today's sports landscape.Co-operative Insurance CompaniesCo-operative Insurance Companies has been meeting property and casualty insurance needs since 1915, offering farm, home, auto, business, and other insurance to people in Vermont and New Hampshire. It is owned by its members and committed to protecting them with fast and fair claims service, loss prevention expertise, and local operations. The company has headquarters in Middlebury, Vermont, with regional claims offices and more than 100 agency locations across Vermont and New Hampshire.Locke LordLocke Lord is a premier full-service Am Law 100 law firm that has earned a solid reputation for complex litigation, regulatory and transactional work on behalf of clients in important and growing industry sectors around the world. Locke Lord's nearly 100 years of experience in the insurance and reinsurance industries has consistently placed the Firm as a leader with the breadth, depth and sophistication required to advance clients' business goals.Five SigmaFive Sigma is a cloud-native, data-driven claims management solution with embedded AI/ML capabilities to allow simple and smart claims processing for the insurance industry. Five Sigma simplifies claims management by adding automated claims processing workflows, using data modeling and AI to provide smart recommendations, improving adjusters' decision-making processes and reducing errors. Leading insurance carriers, insurtechs, TPAs, and self-insured companies use Five Sigma's CMS to modernize their claims operations, reduce claims leakage, enhance compliance, and improve their customers' experience.reThoughtFloodreThought Flood is a technology-forward MGA that leverages artificial intelligence to develop location specific risk understanding for flood underwriting. This allows reThought to provide stable, tailored pricing for flood insurance to homeowners and businesses alike.Media ContactMichael Schwabrow, Cloverleaf Analytics, 1 (949) 400-8345,mschwabrow@cloverleafanalytics.com,https://ethicalaiininsuranceconsortium.org/  View original content:https://www.prweb.com/releases/ethical-ai-in-insurance-consortium-expands-with-10-new-founding-members-and-launches-insurance-ai-research-project-301969949.htmlSOURCE Ethical AI in Insurance Consortium 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (90%); EXECUTIVES (90%); INSURANCE TECHNOLOGY (90%); MAJOR US LAW FIRMS (90%); PRESS RELEASES (90%); RESEARCH & DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE (89%); BUSINESS COOPERATIVES (78%); GENERATIVE AI (78%); INSURANCE REGULATORY COMPLIANCE (78%); LARGE LANGUAGE MODELS (73%); REGULATORY ACTIONS (71%); REGULATORY COMPLIANCE (71%); LAW & LEGAL SYSTEM (66%); PRWEB (%); PDT New Products and Services (%)
Company:  TOPA INSURANCE CO (91%);  GEORGIA FARM BUREAU MUTUAL INSURANCE CO (58%); Ethical AI in Insurance Consortium
Industry: SIC6411 INSURANCE AGENTS, BROKERS, & SERVICE (91%); ARTIFICIAL INTELLIGENCE ETHICS (92%); INSURANCE (91%); INSURANCE TECHNOLOGY (90%); MAJOR US LAW FIRMS (90%); ARTIFICIAL INTELLIGENCE (89%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GENERATIVE AI (78%); INSURANCE REGULATORY COMPLIANCE (78%); IMAGE PROCESSING & COMPUTER VISION (73%); INSURANCE UNDERWRITING (73%); LARGE LANGUAGE MODELS (73%); INS Insurance (%); CPR Computer; Electronics Products (%); FIN Banking; Financial Services (%)
Geographic: LAS VEGAS, NV, USA (90%); NEVADA, USA (79%); UNITED STATES (92%); Nevada
Load-Date: October 31, 2023","PR NewswireCelina Insurance Group, Georgia Farm Bureau, Topa Insurance Company, Players Health, Co-operative Insurance Companies, Locke Lord, Five Sigma, reThoughtFlood, Douglas Benalan - a top industry influencer and CIO, and Elizabeth Foughty - an industry expert on AI, insurance, and climate joins the EAIC.LAS VEGAS, Oct. 31, 2023 /PRNewswire-PRWeb/ -- The Ethical AI in Insurance Consortium (EAIC), which aims to foster responsible and transparent adoption of artificial intelligence (AI) for decision management in the insurance sector, is proud to announce the addition of 10 founding members, significantly broadening its expertise and potential impact. Simultaneously, the Consortium is launching a groundbreaking survey of insurance and reinsurance executives determining attitudes, readiness, and use of AI including Generative AI, large language models, and machine vision. This research aims to provide valuable insights and guide the formulation of ethical AI practices in the insurance domain.The collective knowledge that is now represented within the EAIC means the Consortium will have broader reach and consideration for every aspect of the insurance distribution cycle and the ethical usage of AI.Brian Casey, Partner and Co-Chair of Regulatory & Transactional Insurance Practice Group for Locke Lord said, ""Locke Lord's Regulatory & Transactions Insurance Practice Group is honored to become a supporting legal services member of the Ethical AI in Insurance Consortium, a much-needed industry-lead group for the U.S. insurance business. 
We hope to help bridge the gap between AI technologists and the practical regulatory compliance requirements coming down the pike for fair and legitimate business uses of artificial intelligence in insurance underwriting, sales and claims and look forward to guiding the EAIC in establishing AI standards that work for all constituents in the insurance industry in the modern insurtech environment.""Douglas Benalan, CIO of CURE Insurance, who has been recognized in 2023 by the American Business Awards for digital transformation, ranked as one of the top 150 Business Transformation Executives by Constellation Research, is joining the EAIC, and had this to say, ""I am honored to join the Ethical AI in Insurance Consortium. It's crucial that as industry leaders, we prioritize responsible AI adoption to enhance our services while upholding ethical standards. Together, we will strive to create a sustainable and equitable future for the insurance sector through the judicious application of artificial intelligence.""""Ethical AI is an opportunity to design technology that respects , empowers humanity, and guides us towards a future where technology serves as a force for good, rather than harm,"" said Sandeep Bajaj, Group Chief Information Officer of Players Health. ""It is a foundation upon which we can construct a future to enhance our lives without compromising our values and a key to unlock full potential of artificial intelligence while preserving our moral compass in a digital age.""""I am honored to join the Ethical AI in Insurance Consortium and believe that it is our responsibility to ensure ethical practices are established and adhered to as we see the use of AI grow exponentially,"" Kim Holmbeck, Director – Program Management for Co-operative Insurance Companies. ""While we have all probably used some form of AI in some of our current practices, as we move forward and increase this usage, we must be aware of any biases that might be created. This is an exciting time to be in insurance and as we continue to explore and utilize AI we must also educate and make aware to those around us the ethical practice of AI.""Elizabeth Foughty is a strategic consultant whose experience with AI goes back to 2007 when she supported data mining researchers at NASA, followed by working for RMS and Cape Analytics commented, ""There are so many powerful use cases for artificial intelligence in the insurance industry that can help insurers close protection gaps, provide better underwriting and more fair pricing, as well as plan better. However, the ethical implications must be understood as well, to ensure these tools are being harnessed in ways that don't create more negative bias or other issues. I am delighted to support this effort.""""I am honored to join the Ethical AI in Insurance Consortium. It's crucial that, as industry leaders, we prioritize responsible AI adoption to enhance our services while upholding ethical standards. Together, we will strive to create a sustainable and equitable future for the insurance sector through the judicious application of artificial intelligence."" - Oded Barak, CEO of Five Sigma.CEO of reThought Flood, Cory Isaacson added, ""Our ethos is transparency, technology, and trust, so using our technology tools ethically is extremely important to us. AI can be a strong force for good if used well, such as helping to close the flood protection gap. We are excited to be a part of an effort to drive industry wide understanding of this very critical topic.""The inclusion of these new founding members marks a significant milestone in achieving the Consortium's mission to unite insurers, insurtechs, technology solution providers, regulators, and key influencers towards a common goal. This brings the total number of parties involved in the EAIC to 13 including the initial founding members Cloverleaf Analytics, Socotra, and Exavalu.With AI increasingly becoming an integral part of crucial functions such as underwriting, claims processing, and pricing in the insurance industry, ensuring fairness, transparency, and accountability is paramount. The Ethical AI in Insurance Consortium addresses critical challenges and opportunities associated with AI use in the sector, including addressing algorithmic bias, enhancing customer acceptance, upholding data integrity, and other essential aspects impacting product development, selling, servicing, and customer support.The EAIC's core objectives encompass the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, and promoting standardization within the sector.Founding members Socotra, Exavalu, and Cloverleaf Analytics expressed their enthusiasm for the Insurance AI research initiative and the expansion of the EAIC.Abby Hosseini, Chief Digital Officer at Exavalu, stated, ""This group of pioneering and like-minded companies are taking a pivotal step toward empowering insurers to harness the potential of AI while ensuring it aligns with ethical and responsible business practices with increased transparency and accelerated AI value realization.""Michael Benayoun, Director of Partnerships at Socotra, emphasized, ""We are committed to using research-based insights to drive meaningful change in the industry and leverage AI responsibly for the benefit of all stakeholders.""Michael Schwabrow, Executive Vice President of Sales and Marketing for Cloverleaf Analytics, highlighted the importance of the industry collaboration, stating, ""The collective knowledge that is now represented within the EAIC means the Consortium will have broader reach and consideration for every aspect of the insurance distribution cycle and the ethical usage of AI. We welcome the new members and encourage other organizations and influencers to join the mission to educate, guide, and protect the use of AI in insurance.""The EAIC will reveal the research findings and recommendations in Q1 2024, offering an opportunity for dialogue about the responsible integration of AI in insurance practices in a live webinar coinciding with the launch of the research report.More about the EAIC's new members:Celina Insurance GroupCelina Insurance Group is comprised of four mutual property and casualty insurance companies. The companies provide protection for autos, homes, businesses, and farms through more than 500 independent agencies in five states. Founded in 1914 with headquarters in Celina, Ohio, the organization is committed to supporting its policyholders and communities.Georgia Farm BureauGeorgia Farm Bureau Mutual Insurance Company is proud to offer a broad range of insurance products to serve families across the state of Georgia. Farm Bureau is truly a unique organization that represents the state of Georgia in a way that no other organization can. With offices strategically placed in 158 of Georgia's 159 counties, you're never far from an experienced agent and a friendly face. Georgia Farm Bureau Insurance was created by the Georgia Farm Bureau Federation in 1959 and has a strong tradition of supporting rural communities.Topa Insurance CompanyTopa Insurance Company is a boutique carrier, committed to strong relationships, aligned partnerships, excellent service, underwriting expertise, and quality products for our wholesale brokers, general agents, and MGAs.Players HealthMinneapolis-based Players Health is a sports technology platform providing digital risk management services, reporting tools, and insurance products to sports organizations to comply with the changing athletic environment and responsibilities. Working towards establishing the safest environment for athletes, Players Health views the health and safety of athletes as a priority in today's sports landscape.Co-operative Insurance CompaniesCo-operative Insurance Companies has been meeting property and casualty insurance needs since 1915, offering farm, home, auto, business, and other insurance to people in Vermont and New Hampshire. It is owned by its members and committed to protecting them with fast and fair claims service, loss prevention expertise, and local operations. The company has headquarters in Middlebury, Vermont, with regional claims offices and more than 100 agency locations across Vermont and New Hampshire.Locke LordLocke Lord is a premier full-service Am Law 100 law firm that has earned a solid reputation for complex litigation, regulatory and transactional work on behalf of clients in important and growing industry sectors around the world. Locke Lord's nearly 100 years of experience in the insurance and reinsurance industries has consistently placed the Firm as a leader with the breadth, depth and sophistication required to advance clients' business goals.Five SigmaFive Sigma is a cloud-native, data-driven claims management solution with embedded AI/ML capabilities to allow simple and smart claims processing for the insurance industry. Five Sigma simplifies claims management by adding automated claims processing workflows, using data modeling and AI to provide smart recommendations, improving adjusters' decision-making processes and reducing errors. Leading insurance carriers, insurtechs, TPAs, and self-insured companies use Five Sigma's CMS to modernize their claims operations, reduce claims leakage, enhance compliance, and improve their customers' experience.reThoughtFloodreThought Flood is a technology-forward MGA that leverages artificial intelligence to develop location specific risk understanding for flood underwriting. This allows reThought to provide stable, tailored pricing for flood insurance to homeowners and businesses alike.Media ContactMichael Schwabrow, Cloverleaf Analytics, 1 (949) 400-8345,mschwabrow@cloverleafanalytics.com,https://ethicalaiininsuranceconsortium.org/  View original content:https://www.prweb.com/releases/ethical-ai-in-insurance-consortium-expands-with-10-new-founding-members-and-launches-insurance-ai-research-project-301969949.htmlSOURCE Ethical AI in Insurance Consortium 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (90%); EXECUTIVES (90%); INSURANCE TECHNOLOGY (90%); MAJOR US LAW FIRMS (90%); PRESS RELEASES (90%); RESEARCH & DEVELOPMENT (90%); ARTIFICIAL INTELLIGENCE (89%); BUSINESS COOPERATIVES (78%); GENERATIVE AI (78%); INSURANCE REGULATORY COMPLIANCE (78%); LARGE LANGUAGE MODELS (73%); REGULATORY ACTIONS (71%); REGULATORY COMPLIANCE (71%); LAW & LEGAL SYSTEM (66%); PRWEB (%); PDT New Products and Services (%)
Company:  TOPA INSURANCE CO (91%);  GEORGIA FARM BUREAU MUTUAL INSURANCE CO (58%); Ethical AI in Insurance Consortium
Industry: SIC6411 INSURANCE AGENTS, BROKERS, & SERVICE (91%); ARTIFICIAL INTELLIGENCE ETHICS (92%); INSURANCE (91%); INSURANCE TECHNOLOGY (90%); MAJOR US LAW FIRMS (90%); ARTIFICIAL INTELLIGENCE (89%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GENERATIVE AI (78%); INSURANCE REGULATORY COMPLIANCE (78%); IMAGE PROCESSING & COMPUTER VISION (73%); INSURANCE UNDERWRITING (73%); LARGE LANGUAGE MODELS (73%); INS Insurance (%); CPR Computer; Electronics Products (%); FIN Banking; Financial Services (%)
Geographic: LAS VEGAS, NV, USA (90%); NEVADA, USA (79%); UNITED STATES (92%); Nevada
Load-Date: October 31, 2023",neutral,0.6261126399040222,balanced/neutral,"['bias', 'fairness', 'transparency', 'accountability', 'safety', 'agency']",['fairness'],"['standards', 'guidelines', 'law', 'compliance', 'must']","['generative ai', 'computer vision', 'data mining']",6,1,5,3
2023,Unknown Title,"Body
Imitating the voice of a singer, combining the styles of his songs in a new song, producing almost perfect photomontages of a celebrity, digitally undressing people and placing them in racy videos, all this is possible and available to everyone thanks to Artificial Intelligence, but where are the limits of this technology? Where do people's rights over their image and voice begin?
A few weeks ago, Chilean producer Mauricio Bustos stirred the waters of the music world with the song 'Demo 5: NostalgIA"", which in a few days became one of the 100 most listened songs on Spotify, although it was later removed.
The particularity is that the song contained the voices of artists Bad Bunny, Daddy Yankee and Justin Bieber, but none of them collaborated with Bustos, their voices were recreated using AI.
The song went viral on social media and caused public anger from Bad Bunny himself. ""If you guys like that song that's going viral on TikTok, get out of this group right now. You don't deserve to be my friends,"" warned the famed Puerto Rican singer, in his official WhatsApp group.
But not all AI incursions into people's voices and likenesses are so innocent. For example, in the first days of November, several videos of singer Ángela Aguilar dancing sensually in a provocative top were spread on social networks.
However, fans of the famous singer discovered that it was a manipulation, a ""deepfake"" and that people used recordings of an Argentinean dancer to insert the face of Ángela Aguilar, since they supposedly look alike.
Thanks to Artificial Intelligence, the face of Ángela Aguilar was cut out to be used in the body of the Argentinean model.
Deepfakes are generated by live AI and their most common forms of application are in video or as an augmented reality filter.
Although there is a growing market for consumer applications that use deepfake technology for entertainment, such as FaceSwap, as the technology becomes more widespread and available, it could be deployed for nefarious purposes.
Legal implications
The use of artists' voices and their images in AI creations is just the tip of the iceberg of the challenges posed by AI, explains the dean of the Faculty of Legal and Social Sciences at Franz Tamayo University, Luis Enrique Paez, who points out that ownership of the content generated is going to depend on a number of factors.
""The ownership of content generated by an AI is a complex and evolving issue. There is no single answer that applies to all cases, as it depends on a number of factors, such as the type of content, the country in which it is generated and the applicable legislation,"" he says.
The jurist adds that, it is possible that AI can generate content protected by copyright, trademarks, patents or trade secrets, but where it really gets complex is when the user makes use of it to take credit for its creation.
""We would have to understand that intellectual property enforcement acts on the content generated by it, just as it applies to any other type of content. Given this, how to determine who owns the intellectual property rights. In some cases it may be difficult to determine whether the content generated is an original work of AI, but defined by a person's idea,"" he says.
In conclusion, Paez says, ownership of AI-generated content is a fairly complex issue that is continually evolving. There is no single answer that applies to all cases, as it depends on a number of factors and variables that the normative and regulatory systems have not yet been able to fill.
In this context, the ethics that should circumscribe all human activity is evoked, which helps to reflect on the principles that guide human conduct.
Ethical dangers
""Artificial Intelligence has the potential to revolutionize our world in ways we can hardly imagine, as is indeed happening. However, the rapid, breakneck development and deployment of AI technologies has also raised serious ethical concerns. One of the main concerns is that AI will be used in unfair, inequitable and fraudulent ways,"" says Paez.
For example, in several countries around the world, there have been allegations of AI being used to falsify politicians' voices and use these recordings to conduct dirty warfare.
Another misuse of AI technologies has been the creation of adult films and the manipulation of photographs using the image of showbiz personalities, in some cases or politicians, for the purpose of blackmail.
These episodes raise questions about the limits of this technology and also raise questions about the security of our data.
Carlos Draugialis, professor of Systems Engineering at Universidad Franz Tamayo, Unifranz, points out that the loss of privacy regarding the use and application of AI is another important risk.
""The collection and also the massive use of available data by AI systems can certainly eat away at people's privacy, which ends up raising ethical questions about the security of personal information on the network and its respective access, given that every day less paper is used and more information is digitized,"" he explains.
For the systems engineer, the integration of AI within the concept of ethics is a topic of great importance and relevance in these moments of development of humanity, since AI exposes specific ethical challenges due to many important elements such as transparency, privacy, the same autonomy of the machines to the ability to make autonomous decisions and a great influence that grows day by day within society.
""For all these reasons, in order to establish these limits, we must start by defining the ethical principles that guide the development of AI, such as transparency, equity, privacy, freedom, what is understood by justice, what is right, among others. This work should be done in conjunction with different areas such as philosophy, looking for experts who can work on it and not isolating this issue as something specific to computer science. We must work on ethical audits that allow us to analyze the impact of AI on society and its relationship with the ethical principles established for people,"" says the academic.
Paez believes that regulations and laws play an important role in defining the ethical limits of artificial intelligence. These regulations and laws can help ensure that AI is used responsibly and ethically, protecting human rights and public safety. Anticipating the commission of biases, regulations concerning privacy and data control should also be strengthened and updated and a protocol for its use created.
""States must create a legal system on technology, including the protection of personal data, fraudulent use, privacy, which covers all aspects in which technology intervenes, including, of course, provisions on the use of AI, since the intended purpose is that the regulatory framework can help ensure that AI and, in general, the use of technologies is used in a responsible and ethical manner, and thus its spirit is to protect human rights and fundamental freedoms,"" concludes the jurist. 
 Unifranz 
Alliances to regulate AI
In recent days, an agreement on how artificial intelligence should be regulated in the future was reached between Germany, France and Italy.  The European Parliament, for its part, presented the ""AI Law"" last June, with the aim of preventing the security risks of artificial intelligence applications and avoiding discriminatory effects; the regulation does not seek to curb the innovative power of this new technology, but simply to regulate it so that it is handled within an ethical framework.
And in the framework of the 4th European Assembly of the Artificial Intelligence Alliance, the Council of the European Union, under the Spanish presidency, promoted a declaration signed by Argentina, Colombia, Chile, Mexico, Uruguay, Panama, Dominican Republic, Germany, Slovenia, Estonia, Belgium and Spain that seeks to advance cooperation in Artificial Intelligence with countries in Europe, Latin America and the Caribbean.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: CELEBRITIES (90%); MUSIC (90%); SINGERS & MUSICIANS (90%); VIRAL VIDEOS (90%); ARTIFICIAL INTELLIGENCE (89%); DEEPFAKE TECHNOLOGY (89%); ETHICS (89%); FILM (89%); GENERATIVE AI (89%); ARTISTS & PERFORMERS (78%); COPYRIGHT (78%); PHOTO & VIDEO SHARING (78%); TRADE SECRETS LAW (78%); PATENTS (77%); SOCIAL MEDIA (75%); DANCERS (74%); HUMANITIES & SOCIAL SCIENCE (74%); SOCIAL NETWORKING (68%); LAW & LEGAL SYSTEM (65%); COLLEGE & UNIVERSITY PROFESSORS (60%)
Industry: CELEBRITIES (90%); SINGERS & MUSICIANS (90%); VIRAL VIDEOS (90%); ARTIFICIAL INTELLIGENCE (89%); DEEPFAKE TECHNOLOGY (89%); FILM (89%); GENERATIVE AI (89%); ARTISTS & PERFORMERS (78%); PHOTO & VIDEO SHARING (78%); SOCIAL MEDIA (75%); DANCERS (74%); MUSIC INDUSTRY (73%); AUGMENTED REALITY (72%); COLLEGE & UNIVERSITY PROFESSORS (60%)
Person: BAD BUNNY (92%); JUSTIN BIEBER (79%)
Load-Date: November 22, 2023","Imitating the voice of a singer, combining the styles of his songs in a new song, producing almost perfect photomontages of a celebrity, digitally undressing people and placing them in racy videos, all this is possible and available to everyone thanks to Artificial Intelligence, but where are the limits of this technology? Where do people's rights over their image and voice begin?
A few weeks ago, Chilean producer Mauricio Bustos stirred the waters of the music world with the song 'Demo 5: NostalgIA"", which in a few days became one of the 100 most listened songs on Spotify, although it was later removed.
The particularity is that the song contained the voices of artists Bad Bunny, Daddy Yankee and Justin Bieber, but none of them collaborated with Bustos, their voices were recreated using AI.
The song went viral on social media and caused public anger from Bad Bunny himself. ""If you guys like that song that's going viral on TikTok, get out of this group right now. You don't deserve to be my friends,"" warned the famed Puerto Rican singer, in his official WhatsApp group.
But not all AI incursions into people's voices and likenesses are so innocent. For example, in the first days of November, several videos of singer Ángela Aguilar dancing sensually in a provocative top were spread on social networks.
However, fans of the famous singer discovered that it was a manipulation, a ""deepfake"" and that people used recordings of an Argentinean dancer to insert the face of Ángela Aguilar, since they supposedly look alike.
Thanks to Artificial Intelligence, the face of Ángela Aguilar was cut out to be used in the body of the Argentinean model.
Deepfakes are generated by live AI and their most common forms of application are in video or as an augmented reality filter.
Although there is a growing market for consumer applications that use deepfake technology for entertainment, such as FaceSwap, as the technology becomes more widespread and available, it could be deployed for nefarious purposes.
Legal implications
The use of artists' voices and their images in AI creations is just the tip of the iceberg of the challenges posed by AI, explains the dean of the Faculty of Legal and Social Sciences at Franz Tamayo University, Luis Enrique Paez, who points out that ownership of the content generated is going to depend on a number of factors.
""The ownership of content generated by an AI is a complex and evolving issue. There is no single answer that applies to all cases, as it depends on a number of factors, such as the type of content, the country in which it is generated and the applicable legislation,"" he says.
The jurist adds that, it is possible that AI can generate content protected by copyright, trademarks, patents or trade secrets, but where it really gets complex is when the user makes use of it to take credit for its creation.
""We would have to understand that intellectual property enforcement acts on the content generated by it, just as it applies to any other type of content. Given this, how to determine who owns the intellectual property rights. In some cases it may be difficult to determine whether the content generated is an original work of AI, but defined by a person's idea,"" he says.
In conclusion, Paez says, ownership of AI-generated content is a fairly complex issue that is continually evolving. There is no single answer that applies to all cases, as it depends on a number of factors and variables that the normative and regulatory systems have not yet been able to fill.
In this context, the ethics that should circumscribe all human activity is evoked, which helps to reflect on the principles that guide human conduct.
Ethical dangers
""Artificial Intelligence has the potential to revolutionize our world in ways we can hardly imagine, as is indeed happening. However, the rapid, breakneck development and deployment of AI technologies has also raised serious ethical concerns. One of the main concerns is that AI will be used in unfair, inequitable and fraudulent ways,"" says Paez.
For example, in several countries around the world, there have been allegations of AI being used to falsify politicians' voices and use these recordings to conduct dirty warfare.
Another misuse of AI technologies has been the creation of adult films and the manipulation of photographs using the image of showbiz personalities, in some cases or politicians, for the purpose of blackmail.
These episodes raise questions about the limits of this technology and also raise questions about the security of our data.
Carlos Draugialis, professor of Systems Engineering at Universidad Franz Tamayo, Unifranz, points out that the loss of privacy regarding the use and application of AI is another important risk.
""The collection and also the massive use of available data by AI systems can certainly eat away at people's privacy, which ends up raising ethical questions about the security of personal information on the network and its respective access, given that every day less paper is used and more information is digitized,"" he explains.
For the systems engineer, the integration of AI within the concept of ethics is a topic of great importance and relevance in these moments of development of humanity, since AI exposes specific ethical challenges due to many important elements such as transparency, privacy, the same autonomy of the machines to the ability to make autonomous decisions and a great influence that grows day by day within society.
""For all these reasons, in order to establish these limits, we must start by defining the ethical principles that guide the development of AI, such as transparency, equity, privacy, freedom, what is understood by justice, what is right, among others. This work should be done in conjunction with different areas such as philosophy, looking for experts who can work on it and not isolating this issue as something specific to computer science. We must work on ethical audits that allow us to analyze the impact of AI on society and its relationship with the ethical principles established for people,"" says the academic.
Paez believes that regulations and laws play an important role in defining the ethical limits of artificial intelligence. These regulations and laws can help ensure that AI is used responsibly and ethically, protecting human rights and public safety. Anticipating the commission of biases, regulations concerning privacy and data control should also be strengthened and updated and a protocol for its use created.
""States must create a legal system on technology, including the protection of personal data, fraudulent use, privacy, which covers all aspects in which technology intervenes, including, of course, provisions on the use of AI, since the intended purpose is that the regulatory framework can help ensure that AI and, in general, the use of technologies is used in a responsible and ethical manner, and thus its spirit is to protect human rights and fundamental freedoms,"" concludes the jurist. 
 Unifranz 
Alliances to regulate AI
In recent days, an agreement on how artificial intelligence should be regulated in the future was reached between Germany, France and Italy.  The European Parliament, for its part, presented the ""AI Law"" last June, with the aim of preventing the security risks of artificial intelligence applications and avoiding discriminatory effects; the regulation does not seek to curb the innovative power of this new technology, but simply to regulate it so that it is handled within an ethical framework.
And in the framework of the 4th European Assembly of the Artificial Intelligence Alliance, the Council of the European Union, under the Spanish presidency, promoted a declaration signed by Argentina, Colombia, Chile, Mexico, Uruguay, Panama, Dominican Republic, Germany, Slovenia, Estonia, Belgium and Spain that seeks to advance cooperation in Artificial Intelligence with countries in Europe, Latin America and the Caribbean.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: CELEBRITIES (90%); MUSIC (90%); SINGERS & MUSICIANS (90%); VIRAL VIDEOS (90%); ARTIFICIAL INTELLIGENCE (89%); DEEPFAKE TECHNOLOGY (89%); ETHICS (89%); FILM (89%); GENERATIVE AI (89%); ARTISTS & PERFORMERS (78%); COPYRIGHT (78%); PHOTO & VIDEO SHARING (78%); TRADE SECRETS LAW (78%); PATENTS (77%); SOCIAL MEDIA (75%); DANCERS (74%); HUMANITIES & SOCIAL SCIENCE (74%); SOCIAL NETWORKING (68%); LAW & LEGAL SYSTEM (65%); COLLEGE & UNIVERSITY PROFESSORS (60%)
Industry: CELEBRITIES (90%); SINGERS & MUSICIANS (90%); VIRAL VIDEOS (90%); ARTIFICIAL INTELLIGENCE (89%); DEEPFAKE TECHNOLOGY (89%); FILM (89%); GENERATIVE AI (89%); ARTISTS & PERFORMERS (78%); PHOTO & VIDEO SHARING (78%); SOCIAL MEDIA (75%); DANCERS (74%); MUSIC INDUSTRY (73%); AUGMENTED REALITY (72%); COLLEGE & UNIVERSITY PROFESSORS (60%)
Person: BAD BUNNY (92%); JUSTIN BIEBER (79%)
Load-Date: November 22, 2023",neutral,0.6941243410110474,balanced/neutral,"['privacy', 'transparency', 'safety', 'security', 'human rights', 'autonomy', 'manipulation', 'access']","['justice', 'equity', 'autonomy', 'justice']","['regulation', 'framework', 'legislation', 'law', 'should', 'must']",['generative ai'],8,4,6,1
2023,Unknown Title,"Highlight: Putting the “ethical” label on every possible product (like soap) or social policy (like assisted dying) is a sign of our tendency to avoid questioning difficult issues
Body
La Croix International takes a summer break during the month of August. And during this month we bring you the best and most relevant articles published during the year that you may have missed or would like to read again.   
First published on March 18, 2023.
-----
Ethics has invaded the shelves of our stores and supermarkets. We buy ""ethical"" shampoo made of ""natural products"", recycled smartphones or T-shirts produced in the Global South without exploiting minors... Ethics has also infiltrated our places of employment with ""ethical management"", and our stock portfolios with  ""ethical investments""...
More worrying, ethics is now used to characterize societal practices. For instance, its promoters speak of an ""ethical surrogate motherhood"" if the surrogate mother is willing and well paid. GAFAM. The Web giants promise us an ""ethical artificial intelligence"" with algorithms that will protect us. Here in France, where a lively debate is underway on end of life legislation, some people recently coined the phrase ""ethical active assistance in dying"" as a way to make the idea of legalized euthanasia more acceptable.
The aim is to ease our consciences with a moral guarantee, no questions asked,  about certain products or  initiatives.. It’s not so important when we're talking about soap or shampoo. But when surrogacy, assisted dying, and AI are breezily described as “ethical” it shows, above all, the desire to avoid any serious debate or questioning.
Ethics is the opposite! Ethical reflection does not offer automatic certainty. On the contrary, it provokes and questions. It does not certify once and for all. It aims to determine the ""right thing to do"" in complex cases, taking into account all the factors and constraints. It is an approach that requires different points of view. Ethics is by definition open to discussion. It is done ""with"" others.  
""We truly enter into ethics when, in addition to the self-affirmation of freedom, we want the freedom of the other to exist. I want your freedom to be,"" said Paul Ricoeur (""Fondements de l'éthique"", Autre temps n° 3, 1984).
Ethics always provokes a debate. It does not have the value of being a law in itself, even if it can then help the legislator who writes the law. It is a method, and can only be consultative. It cannot become some kind of intangible, supra-legal, and sacred norm that is not allowed to be discussed anymore; something used to surreptitiously replace religious, moral or political dogmas. On the contrary, it is a complex and fragile process, a fragility that must be accepted. Ethics invites questioning, it does not end it...
Therefore, to affix in a definitive way – as we are accustomed to doing – the ""ethical"" label ( without any further precaution) to processes as complex as the end of life, surrogacy, or AI is seriously nonsensical. Beyond that, it is the sign of our incapacity to trust each other to confront difficult situations together, to give each other reference points, and to set limits by accepting areas of uncertainty and possible questioning. It is the mark of a society that, in a world of instability such as ours, avoids questioning by preferring its own certainties. Ethics has to be saved! 
Isabelle de Gaulmyn is a senior editor at La Croix and former Vatican correspondent.
Link to Image
https://international.la-croix.com/news/ethics/we-have-to-save-ethics/17471
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ASSISTED SUICIDE (94%); ETHICS (93%); PUBLIC POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DEATH & DYING (78%); ETHICAL INVESTING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); SURROGATE MOTHERHOOD (74%); ARTIFICIAL INTELLIGENCE (73%); ENVIRONMENTALLY FRIENDLY PRODUCTS (73%); EUTHANASIA (73%); LEGISLATION (72%); LEGISLATIVE BODIES (67%); RELIGION (60%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (78%); ETHICAL INVESTING (78%); ARTIFICIAL INTELLIGENCE (73%); ENVIRONMENTALLY FRIENDLY PRODUCTS (73%); GROCERY STORES & SUPERMARKETS (72%); MOBILE & CELLULAR TELEPHONES (56%)
Geographic: FRANCE (90%); France
Load-Date: August 10, 2023","La Croix International takes a summer break during the month of August. And during this month we bring you the best and most relevant articles published during the year that you may have missed or would like to read again.   
First published on March 18, 2023.
-----
Ethics has invaded the shelves of our stores and supermarkets. We buy ""ethical"" shampoo made of ""natural products"", recycled smartphones or T-shirts produced in the Global South without exploiting minors... Ethics has also infiltrated our places of employment with ""ethical management"", and our stock portfolios with  ""ethical investments""...
More worrying, ethics is now used to characterize societal practices. For instance, its promoters speak of an ""ethical surrogate motherhood"" if the surrogate mother is willing and well paid. GAFAM. The Web giants promise us an ""ethical artificial intelligence"" with algorithms that will protect us. Here in France, where a lively debate is underway on end of life legislation, some people recently coined the phrase ""ethical active assistance in dying"" as a way to make the idea of legalized euthanasia more acceptable.
The aim is to ease our consciences with a moral guarantee, no questions asked,  about certain products or  initiatives.. It’s not so important when we're talking about soap or shampoo. But when surrogacy, assisted dying, and AI are breezily described as “ethical” it shows, above all, the desire to avoid any serious debate or questioning.
Ethics is the opposite! Ethical reflection does not offer automatic certainty. On the contrary, it provokes and questions. It does not certify once and for all. It aims to determine the ""right thing to do"" in complex cases, taking into account all the factors and constraints. It is an approach that requires different points of view. Ethics is by definition open to discussion. It is done ""with"" others.  
""We truly enter into ethics when, in addition to the self-affirmation of freedom, we want the freedom of the other to exist. I want your freedom to be,"" said Paul Ricoeur (""Fondements de l'éthique"", Autre temps n° 3, 1984).
Ethics always provokes a debate. It does not have the value of being a law in itself, even if it can then help the legislator who writes the law. It is a method, and can only be consultative. It cannot become some kind of intangible, supra-legal, and sacred norm that is not allowed to be discussed anymore; something used to surreptitiously replace religious, moral or political dogmas. On the contrary, it is a complex and fragile process, a fragility that must be accepted. Ethics invites questioning, it does not end it...
Therefore, to affix in a definitive way – as we are accustomed to doing – the ""ethical"" label ( without any further precaution) to processes as complex as the end of life, surrogacy, or AI is seriously nonsensical. Beyond that, it is the sign of our incapacity to trust each other to confront difficult situations together, to give each other reference points, and to set limits by accepting areas of uncertainty and possible questioning. It is the mark of a society that, in a world of instability such as ours, avoids questioning by preferring its own certainties. Ethics has to be saved! 
Isabelle de Gaulmyn is a senior editor at La Croix and former Vatican correspondent.
Link to Image
https://international.la-croix.com/news/ethics/we-have-to-save-ethics/17471
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ASSISTED SUICIDE (94%); ETHICS (93%); PUBLIC POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DEATH & DYING (78%); ETHICAL INVESTING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); SURROGATE MOTHERHOOD (74%); ARTIFICIAL INTELLIGENCE (73%); ENVIRONMENTALLY FRIENDLY PRODUCTS (73%); EUTHANASIA (73%); LEGISLATION (72%); LEGISLATIVE BODIES (67%); RELIGION (60%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (78%); ETHICAL INVESTING (78%); ARTIFICIAL INTELLIGENCE (73%); ENVIRONMENTALLY FRIENDLY PRODUCTS (73%); GROCERY STORES & SUPERMARKETS (72%); MOBILE & CELLULAR TELEPHONES (56%)
Geographic: FRANCE (90%); France
Load-Date: August 10, 2023",positive,0.6203354597091675,balanced/neutral,[],[],"['policy', 'legislation', 'law', 'must']",[],0,0,4,0
2023,Unknown Title,"Body
PARIS - In a landmark decision, UNESCO's General Conference, during its 42nd session, has granted the International Center for AI Research and Ethics (ICAIRE) in Riyadh the coveted status of a Category 2 Center. This approval underscores Saudi Arabia's commitment to advancing artificial intelligence on both domestic and global fronts.
Led by Dr. Abdullah bin Sharaf Alghamdi, President of the Saudi Data and AI Authority (SDAIA), the event witnessed the participation of key figures from the Kingdom's permanent mission to UNESCO and the National Committee for Education, Culture, and Science.
This achievement aligns with Saudi Arabia's unwavering support for UNESCO's mission to enhance the positive impact of AI in people's lives. It also signifies the Kingdom's dedication to its international obligations and the promotion of AI for the benefit of nations, particularly in the developing world. ICAIRE's focus extends to supporting the UN Sustainable Development Goals 2030, with a particular emphasis on the Arab countries in the Middle East.
Notably, Saudi Arabia stands among the pioneers in adopting UNESCO's AI ethics recommendations, an initiative that saw the participation of 193 states in November 2021. The establishment of the ""International Center for AI Research and Ethics"" was officially approved by the Cabinet on July 25, 2023. This center, headquartered in Riyadh, attains legal personality, as well as financial and administrative independence, marking a significant milestone in the Kingdom's pursuit of leadership in the AI domain.
The center's multifaceted activities are concentrated in four key domains: facilitating AI research and development, fostering awareness on AI ethics, providing policy recommendations and support for AI capabilities development, and actively contributing to international endeavors that leverage AI for the greater good of humanity. This move solidifies Saudi Arabia's role as a frontrunner in AI, poised to enhance international and regional cooperation in the realms of AI policies, ethics, and research.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1526
Subject: CONFERENCES & CONVENTIONS (90%); ETHICS (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); APPROVALS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); RESEARCH & DEVELOPMENT (78%); CABINET OFFICES (76%); EMERGING MARKETS (76%); SUSTAINABLE DEVELOPMENT (73%); SUSTAINABLE DEVELOPMENT GOALS (70%); SUSTAINABILITY (53%)
Industry: ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SUSTAINABLE DEVELOPMENT (73%); SUSTAINABLE DEVELOPMENT GOALS (70%)
Geographic: RIYADH, SAUDI ARABIA (90%); SAUDI ARABIA (98%); MIDDLE EAST (79%)
Load-Date: November 17, 2023","PARIS - In a landmark decision, UNESCO's General Conference, during its 42nd session, has granted the International Center for AI Research and Ethics (ICAIRE) in Riyadh the coveted status of a Category 2 Center. This approval underscores Saudi Arabia's commitment to advancing artificial intelligence on both domestic and global fronts.
Led by Dr. Abdullah bin Sharaf Alghamdi, President of the Saudi Data and AI Authority (SDAIA), the event witnessed the participation of key figures from the Kingdom's permanent mission to UNESCO and the National Committee for Education, Culture, and Science.
This achievement aligns with Saudi Arabia's unwavering support for UNESCO's mission to enhance the positive impact of AI in people's lives. It also signifies the Kingdom's dedication to its international obligations and the promotion of AI for the benefit of nations, particularly in the developing world. ICAIRE's focus extends to supporting the UN Sustainable Development Goals 2030, with a particular emphasis on the Arab countries in the Middle East.
Notably, Saudi Arabia stands among the pioneers in adopting UNESCO's AI ethics recommendations, an initiative that saw the participation of 193 states in November 2021. The establishment of the ""International Center for AI Research and Ethics"" was officially approved by the Cabinet on July 25, 2023. This center, headquartered in Riyadh, attains legal personality, as well as financial and administrative independence, marking a significant milestone in the Kingdom's pursuit of leadership in the AI domain.
The center's multifaceted activities are concentrated in four key domains: facilitating AI research and development, fostering awareness on AI ethics, providing policy recommendations and support for AI capabilities development, and actively contributing to international endeavors that leverage AI for the greater good of humanity. This move solidifies Saudi Arabia's role as a frontrunner in AI, poised to enhance international and regional cooperation in the realms of AI policies, ethics, and research.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1526
Subject: CONFERENCES & CONVENTIONS (90%); ETHICS (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); APPROVALS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); RESEARCH & DEVELOPMENT (78%); CABINET OFFICES (76%); EMERGING MARKETS (76%); SUSTAINABLE DEVELOPMENT (73%); SUSTAINABLE DEVELOPMENT GOALS (70%); SUSTAINABILITY (53%)
Industry: ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); SUSTAINABLE DEVELOPMENT (73%); SUSTAINABLE DEVELOPMENT GOALS (70%)
Geographic: RIYADH, SAUDI ARABIA (90%); SAUDI ARABIA (98%); MIDDLE EAST (79%)
Load-Date: November 17, 2023",positive,0.7346647381782532,balanced/neutral,[],[],"['regulation', 'policy']",[],0,0,2,0
2023,Unknown Title,"Byline: Adil Husnain
Body
August 21st, 2023 ( TechBullion  — Delivered by  Newstex )
In an increasingly interconnected digital realm, the seemingly abstract lines of code weaved by developers manifest real-world consequences. Software doesn't merely make machines tick—it touches lives, molds societal structures, and raises pivotal ethical questions about its broader implications.
The Inherent Power of Code
Beyond the zeros and ones, coding has emerged as a potent force shaping our modern era. Think of sectors like finance, where  algorithms decide on loan approvals ; healthcare, where  digital tools predict patient outcomes ; or social media platforms that define our very perceptions. Such omnipresence makes coding not merely about what's possible technically but also what's justifiable ethically.
Bias in Algorithms
Bias isn't always overt; sometimes, it lurks in the background, coded into the algorithms that drive our digital interactions. There's a growing understanding that technology, previously deemed impartial, can inherit and even amplify societal biases.
One alarming example is the disparities seen in facial recognition technologies.  Research has shown  that some of these tools have higher error rates in identifying individuals from certain ethnic backgrounds compared to others. Such biases don't just emerge; they often stem from training data that doesn't adequately represent diverse populations or from underlying prejudices that inadvertently influence coding decisions. 
The fallout? 
A technology celebrated for its efficiency might perpetrate age-old biases, creating an uneven digital landscape.
Data Ethics and User Privacy
Data is the lifeblood of the digital age. It powers personalization, drives innovations, and unlocks new frontiers. However, with this power comes a significant ethical quandary for developers: balancing data utility with user privacy.
Instances like the Cambridge Analytica scandal have spotlighted the potential perils of unchecked data access. Here, personal data from millions of Facebook users was harvested without consent, then used for targeted political advertising. It's a grim reminder that in the quest for personalization and precision, ethical lines can blur.
Developers, hence, find themselves at this crossroad, deciding how to ethically source, use, and protect user data. It's not just about leveraging data for enhanced services but doing so in a manner that respects individual privacy and agency.
The Ethical Implications of AI and Automation
Artificial Intelligence (AI) and automation stand as testaments to human ingenuity. However, they also present ethical dilemmas that developers can't sidestep. One of the most pressing concerns revolves around job displacements. A report from the World Economic Forum projected that by 2025, automation would displace approximately 85 million jobs. Yet, it could also create 97 million new roles.
This transformative shift, driven by code, puts developers in a pivotal position. They aren't just creating tools that might replace traditional jobs; they're shaping the very nature of future work. It's essential, then, for developers to be conscientious, understanding the broader societal ramifications and ensuring their innovations offer value beyond mere efficiency.
Open Source and Its Ethical Dimensions
Open-source software, with its ethos of collaboration and transparency, has democratized development. Platforms like GitHub have fostered a sense of community where ideas and code are shared freely. However, this very openness can be a double-edged sword.
Take, for example, the Heartbleed bug. This security vulnerability in the OpenSSL cryptography library, which is open-source, endangered data for millions, showcasing the potential risks lurking even in the most revered open-source projects. Developers contributing to or leveraging open-source projects must, therefore, be hyper-vigilant. They should be proactive in identifying vulnerabilities and ethical in how they use or modify open-source tools.
Coding Skill Testing: An Ethical Dimension
While developers are usually assessed on their coding prowess, there's an increasing need to intertwine these technical evaluations with ethical awareness. Modern coding skill tests should challenge developers to spot biases, ensure data privacy, and ponder the ethical implications of their algorithms. It's not just about creating a functional solution but one that's fair and cognizant of real-world impacts. By integrating ethical dimensions into skill testing, we don't just craft proficient coders; we nurture developers who are poised to shoulder the profound responsibilities their role entails.
Creating an Ethical Framework
In a world where coding decisions can influence societal trajectories, it's imperative to have a guiding compass. Organizations like the ACM (Association for Computing Machinery) have proactively framed codes of conduct and ethical guidelines. These aren't just rulebooks but guiding lights, helping developers navigate the intricate maze of ethical challenges in their work. Embracing such frameworks ensures that the digital future we craft is not only innovative but also inclusive and just.
Conclusion
Coding, in its essence, is a dialogue between humans and machines. However, its reverberations echo far and wide, influencing societies, economies, and individual lives. Developers, the orchestrators of this dialogue, wield immense power. And as the age-old adage reminds us, with great power comes great responsibility. The call of the hour is for developers to not only stay technically adept but also ethically informed, ever-aware of the broader canvas on which their code leaves its indelible imprint.
Recommended for you
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 10009326
Subject: ETHICS (91%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE (89%); PRIVACY RIGHTS (86%); IDENTIFICATION TECHNOLOGIES (79%); INTERNET SOCIAL NETWORKING (78%); EMPLOYMENT GROWTH (73%); SOCIAL MEDIA (73%); ECONOMY & ECONOMIC INDICATORS (71%); BIOMETRICS (70%); NEGATIVE MISC NEWS (69%); RACE & ETHNICITY (69%); POLITICAL ADVERTISING (50%); Technology (%); coding (%); Ethical Coding (%)
Company:  META PLATFORMS INC (53%)
Ticker: META (NASDAQ) (53%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (53%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (53%); ARTIFICIAL INTELLIGENCE (89%); INTERNET SOCIAL NETWORKING (78%); HEALTH CARE (76%); SOCIAL MEDIA (73%); INFORMATION SECURITY & PRIVACY (71%); PATTERN RECOGNITION (67%); POLITICAL ADVERTISING (50%)
Load-Date: October 24, 2023","August 21st, 2023 ( TechBullion  — Delivered by  Newstex )
In an increasingly interconnected digital realm, the seemingly abstract lines of code weaved by developers manifest real-world consequences. Software doesn't merely make machines tick—it touches lives, molds societal structures, and raises pivotal ethical questions about its broader implications.
The Inherent Power of Code
Beyond the zeros and ones, coding has emerged as a potent force shaping our modern era. Think of sectors like finance, where  algorithms decide on loan approvals ; healthcare, where  digital tools predict patient outcomes ; or social media platforms that define our very perceptions. Such omnipresence makes coding not merely about what's possible technically but also what's justifiable ethically.
Bias in Algorithms
Bias isn't always overt; sometimes, it lurks in the background, coded into the algorithms that drive our digital interactions. There's a growing understanding that technology, previously deemed impartial, can inherit and even amplify societal biases.
One alarming example is the disparities seen in facial recognition technologies.  Research has shown  that some of these tools have higher error rates in identifying individuals from certain ethnic backgrounds compared to others. Such biases don't just emerge; they often stem from training data that doesn't adequately represent diverse populations or from underlying prejudices that inadvertently influence coding decisions. 
The fallout? 
A technology celebrated for its efficiency might perpetrate age-old biases, creating an uneven digital landscape.
Data Ethics and User Privacy
Data is the lifeblood of the digital age. It powers personalization, drives innovations, and unlocks new frontiers. However, with this power comes a significant ethical quandary for developers: balancing data utility with user privacy.
Instances like the Cambridge Analytica scandal have spotlighted the potential perils of unchecked data access. Here, personal data from millions of Facebook users was harvested without consent, then used for targeted political advertising. It's a grim reminder that in the quest for personalization and precision, ethical lines can blur.
Developers, hence, find themselves at this crossroad, deciding how to ethically source, use, and protect user data. It's not just about leveraging data for enhanced services but doing so in a manner that respects individual privacy and agency.
The Ethical Implications of AI and Automation
Artificial Intelligence (AI) and automation stand as testaments to human ingenuity. However, they also present ethical dilemmas that developers can't sidestep. One of the most pressing concerns revolves around job displacements. A report from the World Economic Forum projected that by 2025, automation would displace approximately 85 million jobs. Yet, it could also create 97 million new roles.
This transformative shift, driven by code, puts developers in a pivotal position. They aren't just creating tools that might replace traditional jobs; they're shaping the very nature of future work. It's essential, then, for developers to be conscientious, understanding the broader societal ramifications and ensuring their innovations offer value beyond mere efficiency.
Open Source and Its Ethical Dimensions
Open-source software, with its ethos of collaboration and transparency, has democratized development. Platforms like GitHub have fostered a sense of community where ideas and code are shared freely. However, this very openness can be a double-edged sword.
Take, for example, the Heartbleed bug. This security vulnerability in the OpenSSL cryptography library, which is open-source, endangered data for millions, showcasing the potential risks lurking even in the most revered open-source projects. Developers contributing to or leveraging open-source projects must, therefore, be hyper-vigilant. They should be proactive in identifying vulnerabilities and ethical in how they use or modify open-source tools.
Coding Skill Testing: An Ethical Dimension
While developers are usually assessed on their coding prowess, there's an increasing need to intertwine these technical evaluations with ethical awareness. Modern coding skill tests should challenge developers to spot biases, ensure data privacy, and ponder the ethical implications of their algorithms. It's not just about creating a functional solution but one that's fair and cognizant of real-world impacts. By integrating ethical dimensions into skill testing, we don't just craft proficient coders; we nurture developers who are poised to shoulder the profound responsibilities their role entails.
Creating an Ethical Framework
In a world where coding decisions can influence societal trajectories, it's imperative to have a guiding compass. Organizations like the ACM (Association for Computing Machinery) have proactively framed codes of conduct and ethical guidelines. These aren't just rulebooks but guiding lights, helping developers navigate the intricate maze of ethical challenges in their work. Embracing such frameworks ensures that the digital future we craft is not only innovative but also inclusive and just.
Conclusion
Coding, in its essence, is a dialogue between humans and machines. However, its reverberations echo far and wide, influencing societies, economies, and individual lives. Developers, the orchestrators of this dialogue, wield immense power. And as the age-old adage reminds us, with great power comes great responsibility. The call of the hour is for developers to not only stay technically adept but also ethically informed, ever-aware of the broader canvas on which their code leaves its indelible imprint.
Recommended for you
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 10009326
Subject: ETHICS (91%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE (89%); PRIVACY RIGHTS (86%); IDENTIFICATION TECHNOLOGIES (79%); INTERNET SOCIAL NETWORKING (78%); EMPLOYMENT GROWTH (73%); SOCIAL MEDIA (73%); ECONOMY & ECONOMIC INDICATORS (71%); BIOMETRICS (70%); NEGATIVE MISC NEWS (69%); RACE & ETHNICITY (69%); POLITICAL ADVERTISING (50%); Technology (%); coding (%); Ethical Coding (%)
Company:  META PLATFORMS INC (53%)
Ticker: META (NASDAQ) (53%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (53%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (53%); ARTIFICIAL INTELLIGENCE (89%); INTERNET SOCIAL NETWORKING (78%); HEALTH CARE (76%); SOCIAL MEDIA (73%); INFORMATION SECURITY & PRIVACY (71%); PATTERN RECOGNITION (67%); POLITICAL ADVERTISING (50%)
Load-Date: October 24, 2023",neutral,0.8136522769927979,balanced/neutral,"['privacy', 'bias', 'transparency', 'security', 'agency', 'consent', 'access']",[],"['guidelines', 'framework', 'should', 'must', 'need to']",['facial recognition'],7,0,5,1
2023,Unknown Title,"Body
Professor Joroen van den Hoven has worked in depth on the doubts we all have about the rise of artificial intelligence and other technologies that seem to escape human control, and if one thing has become clear from his years of study it is that ""we cannot face today's problems with the ethics we have developed over thousands of years"".
Van den Hoven explains, in this new episode of the ReImagine Talks videopodcast, that we are still using the ethical framework that we established ""around the campfire, when we were all very close."" In his view, the values from back then are in need of an update. ""We have to scale our ethics to deal with completely different problems"" than then, he says.
Van den Hoven is a professor of ethics and technology at Delft University in the Netherlands, where he also directs the Center for Digital Ethics. The European Commission has elected him as a permanent member of the European Group for Ethics in Science and New Technologies. Thanks to his work, the EU is a pioneer in ensuring the privacy of Internet users.
Van den Hoven believes that public administrations must better control the digital products and services offered on the market. ""We cannot assume,"" he says, ""that every person will be able to take responsibility for the acts they perform with innovative technology."" Therefore, ""we should not be throwing things into society that we have not carefully thought about and that we cannot defend in terms of intrinsic values.""
Artificial intelligence, for example, presents us with dilemmas we didn't have before, such as the possibility of impersonating a personality. Without reinforced ethics, Van den Hoven fears that the use of this technology will cause more problems than benefits. That is why he advocates that ""ethics and morals should have a preeminent place in the training of engineers and professionals in administration and business"".
La Vanguardia exclusively publishes the videopodcasts produced by the think tank ReImagine Europa, and this one dedicated to ethics bravely addresses the many moral shortcomings we have to make good use of the latest technical advances, especially in the digital sphere.
Just because a product is new and innovative,"" says Van den Hoven, ""does not mean that it is good for us, that is, that it prioritizes long-term collective progress over short-term private profit.
The professor, however, is optimistic and is convinced that with a new ethical framework, new technologies will strengthen our societies and our democracies.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: COLLEGE & UNIVERSITY PROFESSORS (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE (78%); EMERGING TECHNOLOGY (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); DEMOCRACIES (73%); EUROPEAN UNION (73%); EUROPEAN UNION INSTITUTIONS (73%); RESEARCH INSTITUTES (72%); TYPES OF GOVERNMENT (72%); PRODUCT INNOVATION (71%); GOVERNMENT & PUBLIC ADMINISTRATION (67%); INTERNATIONAL ECONOMIC ORGANIZATIONS (66%); INTERNET PRIVACY (66%); vida (%)
Company:  EUROPEAN GROUP (55%)
Organization: EUROPEAN COMMISSION (56%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (90%); ARTIFICIAL INTELLIGENCE (78%); INTERNET & WWW (73%); INTERNET PRIVACY (66%)
Geographic: EUROPEAN UNION MEMBER STATES (90%); EUROPE (56%); NETHERLANDS (56%)
Load-Date: September 23, 2023","Professor Joroen van den Hoven has worked in depth on the doubts we all have about the rise of artificial intelligence and other technologies that seem to escape human control, and if one thing has become clear from his years of study it is that ""we cannot face today's problems with the ethics we have developed over thousands of years"".
Van den Hoven explains, in this new episode of the ReImagine Talks videopodcast, that we are still using the ethical framework that we established ""around the campfire, when we were all very close."" In his view, the values from back then are in need of an update. ""We have to scale our ethics to deal with completely different problems"" than then, he says.
Van den Hoven is a professor of ethics and technology at Delft University in the Netherlands, where he also directs the Center for Digital Ethics. The European Commission has elected him as a permanent member of the European Group for Ethics in Science and New Technologies. Thanks to his work, the EU is a pioneer in ensuring the privacy of Internet users.
Van den Hoven believes that public administrations must better control the digital products and services offered on the market. ""We cannot assume,"" he says, ""that every person will be able to take responsibility for the acts they perform with innovative technology."" Therefore, ""we should not be throwing things into society that we have not carefully thought about and that we cannot defend in terms of intrinsic values.""
Artificial intelligence, for example, presents us with dilemmas we didn't have before, such as the possibility of impersonating a personality. Without reinforced ethics, Van den Hoven fears that the use of this technology will cause more problems than benefits. That is why he advocates that ""ethics and morals should have a preeminent place in the training of engineers and professionals in administration and business"".
La Vanguardia exclusively publishes the videopodcasts produced by the think tank ReImagine Europa, and this one dedicated to ethics bravely addresses the many moral shortcomings we have to make good use of the latest technical advances, especially in the digital sphere.
Just because a product is new and innovative,"" says Van den Hoven, ""does not mean that it is good for us, that is, that it prioritizes long-term collective progress over short-term private profit.
The professor, however, is optimistic and is convinced that with a new ethical framework, new technologies will strengthen our societies and our democracies.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: COLLEGE & UNIVERSITY PROFESSORS (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE (78%); EMERGING TECHNOLOGY (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); DEMOCRACIES (73%); EUROPEAN UNION (73%); EUROPEAN UNION INSTITUTIONS (73%); RESEARCH INSTITUTES (72%); TYPES OF GOVERNMENT (72%); PRODUCT INNOVATION (71%); GOVERNMENT & PUBLIC ADMINISTRATION (67%); INTERNATIONAL ECONOMIC ORGANIZATIONS (66%); INTERNET PRIVACY (66%); vida (%)
Company:  EUROPEAN GROUP (55%)
Organization: EUROPEAN COMMISSION (56%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (90%); ARTIFICIAL INTELLIGENCE (78%); INTERNET & WWW (73%); INTERNET PRIVACY (66%)
Geographic: EUROPEAN UNION MEMBER STATES (90%); EUROPE (56%); NETHERLANDS (56%)
Load-Date: September 23, 2023",neutral,0.8117371201515198,balanced/neutral,['privacy'],[],"['framework', 'should', 'must']",[],1,0,3,0
2023,Unknown Title,"Body
2023 JUL 21 (NewsRx) -- By a News Reporter-Staff News Editor at Information Technology Daily -- Investigators publish new report on artificial intelligence. According to news originating from Newcastle University by NewsRx correspondents, research stated, ""It has been argued that ethics review committees-e.g., Research Ethics Committees, Institutional Review Boards, etc.- have weaknesses in reviewing big data and artificial intelligence research."" 
 Financial supporters for this research include Uk Research And Innovation. 
 Our news editors obtained a quote from the research from Newcastle University: ""For instance, they may, due to the novelty of the area, lack the relevant expertise for judging collective risks and benefits of such research, or they may exempt it from review in instances involving de-identified data. Main body Focusing on the example of medical research databases we highlight here ethical issues around de-identified data sharing which motivate the need for review where oversight by ethics committees is weak. Though some argue for ethics committee reform to overcome these weaknesses, it is unclear whether or when that will happen. Hence, we argue that ethical review can be done by data access committees, since they have de facto purview of big data and artificial intelligence projects, relevant technical expertise and governance knowledge, and already take on some functions of ethical review. That said, like ethics committees, they may have functional weaknesses in their review capabilities. To strengthen that function, data access committees must think clearly about the kinds of ethical expertise, both professional and lay, that they draw upon to support their work."" 
 According to the news editors, the research concluded: ""Data access committees can undertake ethical review of medical research databases provided they enhance that review function through professional and lay ethical expertise."" 
 For more information on this research see: Artificial intelligence and medical research databases: ethical review by data access committees. BMC Medical Ethics, 2023,24(1):1-7. (BMC Medical Ethics - http://bmcmedethics.biomedcentral.com). The publisher for BMC Medical Ethics is BMC. 
 A free version of this journal article is available at https://doi.org/10.1186/s12910-023-00927-8. 
 Our news journalists report that additional information may be obtained by contacting Francis McKay, Population Health Sciences Institute, University of Newcastle. Additional authors for this research include Bethany J. Williams, Graham Prestwich, Daljeet Bansal, Darren Treanor, Nina Hallowell. 
 Keywords for this news article include: Newcastle University, Artificial Intelligence, Emerging Technologies, Information Technology, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); INVESTIGATIONS (90%); MEDICAL RESEARCH (90%); HUMAN SUBJECTS (89%); MEDICAL ETHICS (89%); MEDICINE & HEALTH (89%); EMERGING TECHNOLOGY (79%); JOURNALISM (78%); RESEARCH & DEVELOPMENT (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (77%); MEDICAL SCIENCE (77%); MACHINE LEARNING (74%); POPULATION HEALTH (71%); Artificial Intelligence;Emerging Technologies;Information Technology;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); PUBLISHING (78%); WRITERS (78%); MACHINE LEARNING (74%)
Load-Date: July 21, 2023","2023 JUL 21 (NewsRx) -- By a News Reporter-Staff News Editor at Information Technology Daily -- Investigators publish new report on artificial intelligence. According to news originating from Newcastle University by NewsRx correspondents, research stated, ""It has been argued that ethics review committees-e.g., Research Ethics Committees, Institutional Review Boards, etc.- have weaknesses in reviewing big data and artificial intelligence research."" 
 Financial supporters for this research include Uk Research And Innovation. 
 Our news editors obtained a quote from the research from Newcastle University: ""For instance, they may, due to the novelty of the area, lack the relevant expertise for judging collective risks and benefits of such research, or they may exempt it from review in instances involving de-identified data. Main body Focusing on the example of medical research databases we highlight here ethical issues around de-identified data sharing which motivate the need for review where oversight by ethics committees is weak. Though some argue for ethics committee reform to overcome these weaknesses, it is unclear whether or when that will happen. Hence, we argue that ethical review can be done by data access committees, since they have de facto purview of big data and artificial intelligence projects, relevant technical expertise and governance knowledge, and already take on some functions of ethical review. That said, like ethics committees, they may have functional weaknesses in their review capabilities. To strengthen that function, data access committees must think clearly about the kinds of ethical expertise, both professional and lay, that they draw upon to support their work."" 
 According to the news editors, the research concluded: ""Data access committees can undertake ethical review of medical research databases provided they enhance that review function through professional and lay ethical expertise."" 
 For more information on this research see: Artificial intelligence and medical research databases: ethical review by data access committees. BMC Medical Ethics, 2023,24(1):1-7. (BMC Medical Ethics - http://bmcmedethics.biomedcentral.com). The publisher for BMC Medical Ethics is BMC. 
 A free version of this journal article is available at https://doi.org/10.1186/s12910-023-00927-8. 
 Our news journalists report that additional information may be obtained by contacting Francis McKay, Population Health Sciences Institute, University of Newcastle. Additional authors for this research include Bethany J. Williams, Graham Prestwich, Daljeet Bansal, Darren Treanor, Nina Hallowell. 
 Keywords for this news article include: Newcastle University, Artificial Intelligence, Emerging Technologies, Information Technology, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); INVESTIGATIONS (90%); MEDICAL RESEARCH (90%); HUMAN SUBJECTS (89%); MEDICAL ETHICS (89%); MEDICINE & HEALTH (89%); EMERGING TECHNOLOGY (79%); JOURNALISM (78%); RESEARCH & DEVELOPMENT (78%); WRITERS (78%); EXPERIMENTATION & RESEARCH (77%); MEDICAL SCIENCE (77%); MACHINE LEARNING (74%); POPULATION HEALTH (71%); Artificial Intelligence;Emerging Technologies;Information Technology;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); PUBLISHING (78%); WRITERS (78%); MACHINE LEARNING (74%)
Load-Date: July 21, 2023",neutral,0.9067119359970093,balanced/neutral,['access'],[],"['governance', 'oversight', 'must']",['machine learning'],1,0,3,1
2023,Unknown Title,"Byline: Targeted News Service
Dateline: OSLO, Norway 
Body
(TNSres) -- The Peace Research Institute Oslo issued the following news:
A new report focused on the ethical aspects of digital competence in the defense sector is in the spotlight, after a seminar convened to discuss the topic by the Ministry of Defense.
The report, titled 'Ethical Aspects of Digital Competence in the Norwegian Defense Sector,' found that Norway's military is undergoing a rapid transformation into ""a digital age fighting force,"" and emphasized how ethical reflection must be embedded into all aspects of this change, from the design of new technologies to training staff who deploy these technologies on the battlefield. The report directed special attention to the ethical issues arising from military use of artificial intelligence and machine learning.
In the context of the Russia-Ukraine war, Norway must contend with new technology-based threats that include AI-amplified cyber intrusion, autonomous attack platforms that can carry out unmanned stealth operations e.g., against under-sea critical infrastructure, and space-based surveillance systems that can guide targeting in hard-to-defend areas such as Finnmark and Svalbard. Moreover, as a highly digitilized society, Norway must also contend with the exposure of its population to AI-enhanced cyber and disinformation campaigns.
The report's key recommendation was that a national advisory forum should be established with a mandate to examine the ethical aspects of AI military applications. The report was commissioned by the Ministry and written by PRIO in association the Norwegian Council for Digital Ethics and NTNU.
The seminar took place in Oslo on 6 September and was co-chaired by PRIO. ""With its longstanding commitment to ethics in national defense, Norway is poised to assume a key European role in setting normative standards for military AI,"" said PRIO Research Professor, Greg Reichberg, who led the team that wrote the report.
It was attended by representatives from the Norwegian Armed Forces and the Norwegian Defense Staff, the Ethical Council for the Defense Sector, the Defense Research Establishment, the National Security Authority, the Defense Estates Agency, the Defense Materiel Agency, the Defense University College, the Institute for Defense Studies, and Kongsberg Defense & Aerospace.
Read more about the Digital Competence for Defense (DIGICOMP) project here (https://www.prio.org/projects/1928).
* * *
Original text here: https://www.prio.org/news/3091
[Category: International]
MSTRUCK-8285161 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE DEPARTMENTS (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); RESEARCH INSTITUTES (89%); DEFENSE & MILITARY POLICY (77%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); MILITARY SURVEILLANCE (77%); ARMED FORCES (76%); MILITARY SCHOOLS & ACADEMIES (76%); SURVEILLANCE (76%); NEGATIVE TECHNOLOGY NEWS (75%); COLLEGE & UNIVERSITY PROFESSORS (73%); CYBERCRIME (73%); CRITICAL INFRASTRUCTURE (72%); GOVERNMENT BODIES & OFFICES (72%); NATIONAL SECURITY (72%); MACHINE LEARNING (69%); RUSSIA-UKRAINE CONFLICTS (68%); DISINFORMATION & MISINFORMATION (51%)
Company:  KONGSBERG DEFENSE & AEROSPACE AS (51%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DEFENSE & AEROSPACE (90%); DEFENSE INDUSTRY (90%); DEFENSE DEPARTMENTS (89%); DEFENSE & MILITARY POLICY (77%); MILITARY SURVEILLANCE (77%); ARMED FORCES (76%); MILITARY SCHOOLS & ACADEMIES (76%); COLLEGE & UNIVERSITY PROFESSORS (73%); CYBERCRIME (73%); MACHINE LEARNING (69%)
Geographic: OSLO, NORWAY (90%); NORWAY (97%); SVALBARD & JAN MAYEN (79%); UKRAINE (58%)
Load-Date: September 23, 2023","(TNSres) -- The Peace Research Institute Oslo issued the following news:
A new report focused on the ethical aspects of digital competence in the defense sector is in the spotlight, after a seminar convened to discuss the topic by the Ministry of Defense.
The report, titled 'Ethical Aspects of Digital Competence in the Norwegian Defense Sector,' found that Norway's military is undergoing a rapid transformation into ""a digital age fighting force,"" and emphasized how ethical reflection must be embedded into all aspects of this change, from the design of new technologies to training staff who deploy these technologies on the battlefield. The report directed special attention to the ethical issues arising from military use of artificial intelligence and machine learning.
In the context of the Russia-Ukraine war, Norway must contend with new technology-based threats that include AI-amplified cyber intrusion, autonomous attack platforms that can carry out unmanned stealth operations e.g., against under-sea critical infrastructure, and space-based surveillance systems that can guide targeting in hard-to-defend areas such as Finnmark and Svalbard. Moreover, as a highly digitilized society, Norway must also contend with the exposure of its population to AI-enhanced cyber and disinformation campaigns.
The report's key recommendation was that a national advisory forum should be established with a mandate to examine the ethical aspects of AI military applications. The report was commissioned by the Ministry and written by PRIO in association the Norwegian Council for Digital Ethics and NTNU.
The seminar took place in Oslo on 6 September and was co-chaired by PRIO. ""With its longstanding commitment to ethics in national defense, Norway is poised to assume a key European role in setting normative standards for military AI,"" said PRIO Research Professor, Greg Reichberg, who led the team that wrote the report.
It was attended by representatives from the Norwegian Armed Forces and the Norwegian Defense Staff, the Ethical Council for the Defense Sector, the Defense Research Establishment, the National Security Authority, the Defense Estates Agency, the Defense Materiel Agency, the Defense University College, the Institute for Defense Studies, and Kongsberg Defense & Aerospace.
Read more about the Digital Competence for Defense (DIGICOMP) project here (https://www.prio.org/projects/1928).
* * *
Original text here: https://www.prio.org/news/3091
[Category: International]
MSTRUCK-8285161 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DEFENSE DEPARTMENTS (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); RESEARCH INSTITUTES (89%); DEFENSE & MILITARY POLICY (77%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); MILITARY SURVEILLANCE (77%); ARMED FORCES (76%); MILITARY SCHOOLS & ACADEMIES (76%); SURVEILLANCE (76%); NEGATIVE TECHNOLOGY NEWS (75%); COLLEGE & UNIVERSITY PROFESSORS (73%); CYBERCRIME (73%); CRITICAL INFRASTRUCTURE (72%); GOVERNMENT BODIES & OFFICES (72%); NATIONAL SECURITY (72%); MACHINE LEARNING (69%); RUSSIA-UKRAINE CONFLICTS (68%); DISINFORMATION & MISINFORMATION (51%)
Company:  KONGSBERG DEFENSE & AEROSPACE AS (51%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DEFENSE & AEROSPACE (90%); DEFENSE INDUSTRY (90%); DEFENSE DEPARTMENTS (89%); DEFENSE & MILITARY POLICY (77%); MILITARY SURVEILLANCE (77%); ARMED FORCES (76%); MILITARY SCHOOLS & ACADEMIES (76%); COLLEGE & UNIVERSITY PROFESSORS (73%); CYBERCRIME (73%); MACHINE LEARNING (69%)
Geographic: OSLO, NORWAY (90%); NORWAY (97%); SVALBARD & JAN MAYEN (79%); UKRAINE (58%)
Load-Date: September 23, 2023",neutral,0.8468571901321411,balanced/neutral,"['surveillance', 'security', 'agency', 'misinformation', 'disinformation']",[],"['policy', 'standards', 'should', 'must']",['machine learning'],5,0,4,1
2023,Unknown Title,"Byline: Ipro Tech
Body
Jan 16, 2023( JD Supra: http://www.jdsupra.com Delivered by Newstex)  
 January 25th, 2023 9:00 AM MT 
Join this free webinar to learn about Artificial Intelligence in the legal sphere, and earn CLE credit in eligible states 
About the Webinar 
In this live webinar, IPRO's Chief Data Scientist Jan Scholtes will demonstrate to attendees how artificial intelligence can be used in the legal sphere, increasing accuracy, performance, and efficiency. Bobby Malhotra, Partner at Winston & Strawn LLP, will be on hand to offer his expertise from a legal perspective. 
What will be learned 
Webinar attendees can expect speakers to cover: 
 What AI is How AI can be applied and adopted ethically How to mitigate possible ethical objections to AI 
CLE Eligibility 
Based on your state, this webinar may qualify for continuing learning education (CLE) credit. View details below for eligibility information: 
 This course has been approved for Minimum Continuing Legal Education credit by the State Bar of Texas Committee on MCLE in the amount of 1 credit hour, of which 1 credit hour will apply to legal ethics/professional responsibility credit. This course has been approved for CLE credit by the State Bar of Illinois (1 hour, Professional Responsibility Type Legal Ethics). This course has been approved for CLE credit by the State Bar of California, including 1 subfield credit in Legal Ethics Hours. This course is pending approval for CLE credit in New York. 
Featured Speakers 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: JSUP-5263
Subject: CONTINUING LEGAL EDUCATION (99%); ETHICS (94%); PROFESSIONAL CONTINUING EDUCATION (92%); APPROVALS (90%); ARTIFICIAL INTELLIGENCE (90%); LEGAL ETHICS (90%); LEGAL EDUCATION (77%); DATA SCIENCE (72%)
Company:  WINSTON & STRAWN LLP (91%)
Organization: STATE BAR OF TEXAS (53%); ILLINOIS STATE BAR ASSOCIATION (52%); STATE BAR OF CALIFORNIA (51%)
Industry: NAICS541199 ALL OTHER LEGAL SERVICES (91%); NAICS541110 OFFICES OF LAWYERS (91%); SIC8111 LEGAL SERVICES (91%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (72%)
Geographic: CALIFORNIA, USA (79%); NEW YORK, USA (79%)
Load-Date: January 17, 2023","Jan 16, 2023( JD Supra: http://www.jdsupra.com Delivered by Newstex)  
 January 25th, 2023 9:00 AM MT 
Join this free webinar to learn about Artificial Intelligence in the legal sphere, and earn CLE credit in eligible states 
About the Webinar 
In this live webinar, IPRO's Chief Data Scientist Jan Scholtes will demonstrate to attendees how artificial intelligence can be used in the legal sphere, increasing accuracy, performance, and efficiency. Bobby Malhotra, Partner at Winston & Strawn LLP, will be on hand to offer his expertise from a legal perspective. 
What will be learned 
Webinar attendees can expect speakers to cover: 
 What AI is How AI can be applied and adopted ethically How to mitigate possible ethical objections to AI 
CLE Eligibility 
Based on your state, this webinar may qualify for continuing learning education (CLE) credit. View details below for eligibility information: 
 This course has been approved for Minimum Continuing Legal Education credit by the State Bar of Texas Committee on MCLE in the amount of 1 credit hour, of which 1 credit hour will apply to legal ethics/professional responsibility credit. This course has been approved for CLE credit by the State Bar of Illinois (1 hour, Professional Responsibility Type Legal Ethics). This course has been approved for CLE credit by the State Bar of California, including 1 subfield credit in Legal Ethics Hours. This course is pending approval for CLE credit in New York. 
Featured Speakers 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: JSUP-5263
Subject: CONTINUING LEGAL EDUCATION (99%); ETHICS (94%); PROFESSIONAL CONTINUING EDUCATION (92%); APPROVALS (90%); ARTIFICIAL INTELLIGENCE (90%); LEGAL ETHICS (90%); LEGAL EDUCATION (77%); DATA SCIENCE (72%)
Company:  WINSTON & STRAWN LLP (91%)
Organization: STATE BAR OF TEXAS (53%); ILLINOIS STATE BAR ASSOCIATION (52%); STATE BAR OF CALIFORNIA (51%)
Industry: NAICS541199 ALL OTHER LEGAL SERVICES (91%); NAICS541110 OFFICES OF LAWYERS (91%); SIC8111 LEGAL SERVICES (91%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (72%)
Geographic: CALIFORNIA, USA (79%); NEW YORK, USA (79%)
Load-Date: January 17, 2023",neutral,0.8225530982017517,balanced/neutral,[],[],['should'],[],0,0,1,0
2023,Unknown Title,"Byline: Ayushi Singh
Body
Ethical AI is important these days due to the growing influence and impact of artificial intelligence in various aspects of our lives.
AI, or artificial intelligence, refers to the development and implementation of computer systems that can perform tasks that typically require human intelligence. AI involves creating algorithms and models that enable machines to learn, reason, and make decisions based on data inputs.
AI technologies have a wide range of applications across industries, including healthcare, finance, transportation, manufacturing, and entertainment. They can automate tasks, provide insights from large datasets, enhance decision-making, and improve efficiency and productivity.
It's important to note that while AI systems can perform tasks that simulate human intelligence, they do not possess human-like consciousness or understanding. AI is a powerful tool that continues to advance and has the potential to transform numerous aspects of our lives.
Artificial intelligence (AI) is now a reality and is here to stay. These days, we rely on AI so heavily that we no longer perceive it as a threat to our way of life. Some individuals, however, think that AI is the most recent technology that will replace our employment and finally wipe off civilization. Even while it seems unlikely, what if they are correct? It is more important than ever to understand where AI is headed and what can be done to assure its ethical development.
Without comprehending the origins of AI and taking lessons from past errors, we won't be able to predict what the future holds. Many individuals believe that AI would eventually wipe out mankind and replace our employment. But before we fret excessively, we should be aware of where it is right now and what we can do to promote its ethical development. There have been numerous ethical discussions regarding how to handle AI ethically in recent years at conferences and in academia.
The ethical development of all AI-driven technology is essential, and industry self-regulation will be more effective than any governmental effort.
Ethical AI, also known as ethical artificial intelligence, refers to the development and use of artificial intelligence systems and technologies that adhere to ethical principles and values. It involves ensuring that AI systems are designed, implemented, and deployed in a way that respects and protects human rights, fairness, transparency, accountability, and other moral considerations.
Ethical AI is important these days due to the growing influence and impact of artificial intelligence in various aspects of our lives. AI systems are increasingly being used in areas such as healthcare, finance, transportation, education, and criminal justice, among others. These systems can have significant implications for individuals and society as a whole.
Here are a few reasons why ethical AI is important:
1. Fairness and Bias: AI systems have the potential to perpetuate or amplify biases present in the data used for their training. Ethical AI aims to mitigate these biases and ensure that AI systems make fair and unbiased decisions, without discriminating against individuals or groups based on factors such as race, gender, or socioeconomic status.
2. Transparency and Explainability: Ethical AI emphasizes the need for transparency and explainability in AI systems. It is important to understand how AI systems make decisions and the factors they consider. This allows for better accountability, trust-building, and the ability to address any potential errors or biases.
3. Privacy and Security: AI systems often require access to large amounts of personal data. Ethical AI emphasizes the importance of protecting individual privacy rights and ensuring that data is handled securely. It involves implementing robust data protection measures and obtaining informed consent from individuals whose data is being used.
4. Social Impact: AI technologies have the potential to greatly impact society, both positively and negatively. Ethical AI encourages considering the broader social implications of AI systems and ensuring that they align with societal values and goals. It involves actively seeking to avoid harmful consequences, promote social good, and address issues such as job displacement or economic inequality.
5. Accountability and Governance: Ethical AI promotes the establishment of clear frameworks and mechanisms for accountability and governance. This includes defining roles and responsibilities, setting ethical standards, and establishing oversight to ensure that AI systems are developed and used responsibly.
By incorporating ethical considerations into AI development and deployment, we can strive for AI systems that are more trustworthy, reliable, and aligned with human values. Ethical AI helps us navigate the challenges and complexities associated with AI technologies, ensuring that they are developed and used in ways that benefit humanity as a whole.
How Can We Reduce Potential AI Risks?
There is always a need to discuss the potential risks of AI and how to mitigate them because many people are worried about what it might do to the human species.
In order to determine which direction to guide AI in order for it to continue assisting civilization, we must first educate ourselves about what AI is and how it is progressing. Second, we must remove biases ingrained in AI systems and train them to avoid discrimination. Finally, in order to avoid any mistakes from hurting the human population, regulations that regulate AI use in society must be created.
Ethical AI matters because it ensures that AI technologies are developed and used in a way that aligns with human values, promotes fairness, respects individual rights, and contributes positively to society. By incorporating ethical considerations, we can harness the potential of AI while mitigating risks and maximizing its benefits.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); REGULATORY COMPLIANCE (77%); HUMAN RIGHTS (73%); CRIMINAL JUSTICE (72%); CRIME, LAW ENFORCEMENT & CORRECTIONS (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING (78%); BIG DATA (73%)
Load-Date: May 26, 2023","Ethical AI is important these days due to the growing influence and impact of artificial intelligence in various aspects of our lives.
AI, or artificial intelligence, refers to the development and implementation of computer systems that can perform tasks that typically require human intelligence. AI involves creating algorithms and models that enable machines to learn, reason, and make decisions based on data inputs.
AI technologies have a wide range of applications across industries, including healthcare, finance, transportation, manufacturing, and entertainment. They can automate tasks, provide insights from large datasets, enhance decision-making, and improve efficiency and productivity.
It's important to note that while AI systems can perform tasks that simulate human intelligence, they do not possess human-like consciousness or understanding. AI is a powerful tool that continues to advance and has the potential to transform numerous aspects of our lives.
Artificial intelligence (AI) is now a reality and is here to stay. These days, we rely on AI so heavily that we no longer perceive it as a threat to our way of life. Some individuals, however, think that AI is the most recent technology that will replace our employment and finally wipe off civilization. Even while it seems unlikely, what if they are correct? It is more important than ever to understand where AI is headed and what can be done to assure its ethical development.
Without comprehending the origins of AI and taking lessons from past errors, we won't be able to predict what the future holds. Many individuals believe that AI would eventually wipe out mankind and replace our employment. But before we fret excessively, we should be aware of where it is right now and what we can do to promote its ethical development. There have been numerous ethical discussions regarding how to handle AI ethically in recent years at conferences and in academia.
The ethical development of all AI-driven technology is essential, and industry self-regulation will be more effective than any governmental effort.
Ethical AI, also known as ethical artificial intelligence, refers to the development and use of artificial intelligence systems and technologies that adhere to ethical principles and values. It involves ensuring that AI systems are designed, implemented, and deployed in a way that respects and protects human rights, fairness, transparency, accountability, and other moral considerations.
Ethical AI is important these days due to the growing influence and impact of artificial intelligence in various aspects of our lives. AI systems are increasingly being used in areas such as healthcare, finance, transportation, education, and criminal justice, among others. These systems can have significant implications for individuals and society as a whole.
Here are a few reasons why ethical AI is important:
1. Fairness and Bias: AI systems have the potential to perpetuate or amplify biases present in the data used for their training. Ethical AI aims to mitigate these biases and ensure that AI systems make fair and unbiased decisions, without discriminating against individuals or groups based on factors such as race, gender, or socioeconomic status.
2. Transparency and Explainability: Ethical AI emphasizes the need for transparency and explainability in AI systems. It is important to understand how AI systems make decisions and the factors they consider. This allows for better accountability, trust-building, and the ability to address any potential errors or biases.
3. Privacy and Security: AI systems often require access to large amounts of personal data. Ethical AI emphasizes the importance of protecting individual privacy rights and ensuring that data is handled securely. It involves implementing robust data protection measures and obtaining informed consent from individuals whose data is being used.
4. Social Impact: AI technologies have the potential to greatly impact society, both positively and negatively. Ethical AI encourages considering the broader social implications of AI systems and ensuring that they align with societal values and goals. It involves actively seeking to avoid harmful consequences, promote social good, and address issues such as job displacement or economic inequality.
5. Accountability and Governance: Ethical AI promotes the establishment of clear frameworks and mechanisms for accountability and governance. This includes defining roles and responsibilities, setting ethical standards, and establishing oversight to ensure that AI systems are developed and used responsibly.
By incorporating ethical considerations into AI development and deployment, we can strive for AI systems that are more trustworthy, reliable, and aligned with human values. Ethical AI helps us navigate the challenges and complexities associated with AI technologies, ensuring that they are developed and used in ways that benefit humanity as a whole.
How Can We Reduce Potential AI Risks?
There is always a need to discuss the potential risks of AI and how to mitigate them because many people are worried about what it might do to the human species.
In order to determine which direction to guide AI in order for it to continue assisting civilization, we must first educate ourselves about what AI is and how it is progressing. Second, we must remove biases ingrained in AI systems and train them to avoid discrimination. Finally, in order to avoid any mistakes from hurting the human population, regulations that regulate AI use in society must be created.
Ethical AI matters because it ensures that AI technologies are developed and used in a way that aligns with human values, promotes fairness, respects individual rights, and contributes positively to society. By incorporating ethical considerations, we can harness the potential of AI while mitigating risks and maximizing its benefits.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); REGULATORY COMPLIANCE (77%); HUMAN RIGHTS (73%); CRIMINAL JUSTICE (72%); CRIME, LAW ENFORCEMENT & CORRECTIONS (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MANUFACTURING (78%); BIG DATA (73%)
Load-Date: May 26, 2023",positive,0.6379421949386597,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'human rights', 'consent', 'access', 'inequality']","['justice', 'fairness', 'justice']","['regulation', 'governance', 'oversight', 'standards', 'law', 'compliance', 'should', 'must', 'need to', 'emphasizes the importance']",[],12,3,10,0
2023,Unknown Title,"Dateline: New Delhi, 2023-11-01 16:03:02 
Body
 November 01 -- 2023 saw the ascent of Huge Language Models (LLMs); in any case, it didn't take the business long to understand that we quickly made such strong models available to the general population without carrying out powerful and sufficient protections. By and by, we have taken in our example, and this is the ideal opportunity to make it right. Numerous industry specialists and veterans accept that carrying out administration estimates will ensure computer based intelligence wellbeing and reliability. 2023 will be the time of Generative-computer based intelligence (GenAI), and 2024 will be the extended period of its Administration. Guidelines are advancing! Allow us to draw motivation from the EU artificial intelligence Act, the most thorough way to deal with artificial intelligence guideline up to this point. The Demonstration highlights the significance of arranging artificial intelligence applications as indicated by their gamble profiles and authorizes stricter measures proportionate with their possible effect, moderating serious outcomes.
The global consortium, comprising academic researchers, leading technology companies, and policymakers, increasingly emphasizes the need for robust governance of large models to ensure their responsible adoption.
The foundation model developers have also started demonstrating accountability for their models. It is evident by Microsoft's recent announcement to protect customers from legal repercussions stemming from copyright infringement related to their products.
Governance finds Its roots in ethics
As an AI Ethicist, one of the biggest challenges I often face is aligning everyone on the definition of ethics. Frequently, questions arise such as, ""Whose ethical principles, whose code of moral conduct, ethical according to which standards?""
The recent technological developments in the form of GenAI systems place even higher equity in enforcing ethical AI.
As the law becomes enforceable, it prompts a fundamental question: How can we guarantee that AI systems are built in a responsible and trustworthy manner, working for the greater good of society? This concern extends beyond just the organizations utilizing LLMs or the developers of foundational models; it encompasses all of us, including the users of these systems. 
The actual test lies in whether we would uphold the highest standards of responsibility and ethics, even in the absence of legal oversight. What actions and choices would we make when no one monitors or enforces compliance?
The rise of AI Governance
As we ponder these questions, the underlying theme of AI governance starts to surface.
Let us define it first. AI governance includes all things ethics, regulations, and policies. It places a significant responsibility on the policymakers and regulators. 
As the use of AI technologies becomes increasingly ubiquitous, the challenge lies in fostering innovation while upholding ethical considerations.
I have outlined five crucial components to balance innovation with governance: 
Having interoperable global regulations that transcend borders is vital for creating a shared foundation for evaluation and oversight. 
Ensuring industry-specific regulations are in place is equally important to address the unique risks associated with different sectors and domains.
Building an independent audit committee responsible for assessing the ethical implications of AI systems is a critical step. This committee can provide unbiased evaluations and recommendations. 
Establishing ethics review boards within organizations should assess potential biases, discrimination, privacy violations, and other ethical concerns, not just during the ideation phase but also throughout the development and deployment process.
Recognizing that risks in AI manifest in diverse ways, no single entity can foresee and manage them comprehensively. Therefore, all stakeholders in the AI governance ecosystem, including regulators, developers, data scientists, and decision-makers, should stay updated to understand the evolving implications of complex AI systems and make timely amendments. 
Such collaboration brings a diversity of perspectives that creates a robust governance framework. It helps address the challenge of ""unknown unknowns,"" where authorities may not even be aware of what they don't know, making it challenging to design comprehensive guardrails. 
Awareness
The formal processes and systems take time to develop and come to life; meanwhile, it is crucial to foster awareness and promote an ethical mindset.
It requires a thorough understanding of the technical aspects of what it means for a system to be fair and unbiased. This includes grasping the technical underpinnings of machine learning algorithms and how they can introduce bias. 
Ensuring future developers are well-versed in techniques to detect and mitigate bias in AI systems. 
The art of asking the right questions, overcoming impostor and self-doubt. Encourage developers to ask questions such as, ""How can I explain the internal workings of an algorithm to foster trust in its decision-making process?"" and ""How can I codify ethical expectations in the AI system?"" 
Conducting ethical and responsible AI awareness sessions, which include discussions about the social and ethical implications of AI technology. Providing real-world case studies and practical examples that illustrate the impact of AI on society helps developers understand the consequences of their work.
Encouraging diversity and inclusion in AI development teams, as they bring a more comprehensive range of perspectives and are more likely to identify and address potential biases.
To summarize, the journey to a responsible and ethical AI future is marked by two foundational factors - robust governance structures and cultivating an ethical mindset. While formal processes are underway, let us demonstrate accountability to ensure that AI-developed systems bring benefits to society and humanity at large.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); GENERATIVE AI (89%); PUBLIC POLICY (89%); COPYRIGHT (78%); COPYRIGHT LAW (78%); CORPORATE CULTURE (78%); COPYRIGHT INFRINGEMENT (73%); EUROPEAN UNION (69%)
Company:  MICROSOFT CORP (55%);  AI SYSTEMS (53%)
Ticker: MSFT (NASDAQ) (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); GENERATIVE AI (89%); INFORMATION TECHNOLOGY INDUSTRY (78%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: November 1, 2023","November 01 -- 2023 saw the ascent of Huge Language Models (LLMs); in any case, it didn't take the business long to understand that we quickly made such strong models available to the general population without carrying out powerful and sufficient protections. By and by, we have taken in our example, and this is the ideal opportunity to make it right. Numerous industry specialists and veterans accept that carrying out administration estimates will ensure computer based intelligence wellbeing and reliability. 2023 will be the time of Generative-computer based intelligence (GenAI), and 2024 will be the extended period of its Administration. Guidelines are advancing! Allow us to draw motivation from the EU artificial intelligence Act, the most thorough way to deal with artificial intelligence guideline up to this point. The Demonstration highlights the significance of arranging artificial intelligence applications as indicated by their gamble profiles and authorizes stricter measures proportionate with their possible effect, moderating serious outcomes.
The global consortium, comprising academic researchers, leading technology companies, and policymakers, increasingly emphasizes the need for robust governance of large models to ensure their responsible adoption.
The foundation model developers have also started demonstrating accountability for their models. It is evident by Microsoft's recent announcement to protect customers from legal repercussions stemming from copyright infringement related to their products.
Governance finds Its roots in ethics
As an AI Ethicist, one of the biggest challenges I often face is aligning everyone on the definition of ethics. Frequently, questions arise such as, ""Whose ethical principles, whose code of moral conduct, ethical according to which standards?""
The recent technological developments in the form of GenAI systems place even higher equity in enforcing ethical AI.
As the law becomes enforceable, it prompts a fundamental question: How can we guarantee that AI systems are built in a responsible and trustworthy manner, working for the greater good of society? This concern extends beyond just the organizations utilizing LLMs or the developers of foundational models; it encompasses all of us, including the users of these systems. 
The actual test lies in whether we would uphold the highest standards of responsibility and ethics, even in the absence of legal oversight. What actions and choices would we make when no one monitors or enforces compliance?
The rise of AI Governance
As we ponder these questions, the underlying theme of AI governance starts to surface.
Let us define it first. AI governance includes all things ethics, regulations, and policies. It places a significant responsibility on the policymakers and regulators. 
As the use of AI technologies becomes increasingly ubiquitous, the challenge lies in fostering innovation while upholding ethical considerations.
I have outlined five crucial components to balance innovation with governance: 
Having interoperable global regulations that transcend borders is vital for creating a shared foundation for evaluation and oversight. 
Ensuring industry-specific regulations are in place is equally important to address the unique risks associated with different sectors and domains.
Building an independent audit committee responsible for assessing the ethical implications of AI systems is a critical step. This committee can provide unbiased evaluations and recommendations. 
Establishing ethics review boards within organizations should assess potential biases, discrimination, privacy violations, and other ethical concerns, not just during the ideation phase but also throughout the development and deployment process.
Recognizing that risks in AI manifest in diverse ways, no single entity can foresee and manage them comprehensively. Therefore, all stakeholders in the AI governance ecosystem, including regulators, developers, data scientists, and decision-makers, should stay updated to understand the evolving implications of complex AI systems and make timely amendments. 
Such collaboration brings a diversity of perspectives that creates a robust governance framework. It helps address the challenge of ""unknown unknowns,"" where authorities may not even be aware of what they don't know, making it challenging to design comprehensive guardrails. 
Awareness
The formal processes and systems take time to develop and come to life; meanwhile, it is crucial to foster awareness and promote an ethical mindset.
It requires a thorough understanding of the technical aspects of what it means for a system to be fair and unbiased. This includes grasping the technical underpinnings of machine learning algorithms and how they can introduce bias. 
Ensuring future developers are well-versed in techniques to detect and mitigate bias in AI systems. 
The art of asking the right questions, overcoming impostor and self-doubt. Encourage developers to ask questions such as, ""How can I explain the internal workings of an algorithm to foster trust in its decision-making process?"" and ""How can I codify ethical expectations in the AI system?"" 
Conducting ethical and responsible AI awareness sessions, which include discussions about the social and ethical implications of AI technology. Providing real-world case studies and practical examples that illustrate the impact of AI on society helps developers understand the consequences of their work.
Encouraging diversity and inclusion in AI development teams, as they bring a more comprehensive range of perspectives and are more likely to identify and address potential biases.
To summarize, the journey to a responsible and ethical AI future is marked by two foundational factors - robust governance structures and cultivating an ethical mindset. While formal processes are underway, let us demonstrate accountability to ensure that AI-developed systems bring benefits to society and humanity at large.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); GENERATIVE AI (89%); PUBLIC POLICY (89%); COPYRIGHT (78%); COPYRIGHT LAW (78%); CORPORATE CULTURE (78%); COPYRIGHT INFRINGEMENT (73%); EUROPEAN UNION (69%)
Company:  MICROSOFT CORP (55%);  AI SYSTEMS (53%)
Ticker: MSFT (NASDAQ) (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); GENERATIVE AI (89%); INFORMATION TECHNOLOGY INDUSTRY (78%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: November 1, 2023",neutral,0.5063503980636597,balanced/neutral,"['privacy', 'bias', 'discrimination', 'accountability']",['equity'],"['policy', 'governance', 'oversight', 'standards', 'guidelines', 'framework', 'law', 'compliance', 'audit', 'should']","['machine learning', 'generative ai', 'algorithm']",4,1,10,3
2023,Unknown Title,"Body
Link to Story
(menafn - ein presswire) markkula center for applied ethics logo
logo for the institute for technology, ethics, and culture
cover image of the new resource: ""ethics in the age of disruptive technologies: an operational roadmap""
""ethics in the age of disruptive technologies: an operational roadmap"" offers organizations a strategic plan to enhance ethical management practices
by integrating ethical considerations into their strategies, policies, and practices, organizations can build trust, foster innovation, and create a positive societal impact."" - brian patrick green, markkula center for applied ethicssanta clara, calif., united states, june 28, 2023/einpresswire / -- santa clara university's markkula center for applied ethics announced the formation of the institute for technology, ethics, and culture , or itec, with support from and collaboration with the vatican. the inaugural product is a handbook, ""ethics in the age of disruptive technologies: an operational roadmap,"" or, more briefly, the""itec handbook."" this much-needed corporate primer offers a practical roadmap with specific recommendations to help organizations address the ethical complexities associated with disruptive technologies such as ai, machine learning, encryption, tracking, and others.
for 37 years, the markkula center has been known for its work helping corporations apply ethical thinking and create positive change, collaborating with companies like salesforce, ibm, and microsoft on efforts related to ethical standards in design, development, and deployment of technology. drawing on this work, the ethics center conducted primary research, interviews, and conferred with many corporations to produce the handbook.
""forming this initiative, and providing companies with a roadmap in the itec handbook is the fruit of a trusted collaboration between the markkula center for applied ethics, experienced professionals from bay area technology and management sectors, and the centre for digital culture of the vatican's dicastery for culture and education,"" said bishop paul tighe, secretary of the vatican's dicastery for culture and education.""since i have begun meeting and talking with senior representatives of silicon valley, especially those working in the area of artificial intelligence and machine learning, i have been impressed by their desire to maintain high ethical standards for themselves and for their industry.""
""it may come as a surprise to some to discover the vatican's engagement with this project but it is ultimately the result of meetings -""encounters"" to use one of pope francis' favorite words - between the vatican and the world of technology. the handbook is a concrete result of a desire to promote an inclusive conversation between the technology sector and the broader human community whose future will be shaped in so many ways by decisions made by those who are managing innovation.""
a deloitte study on trust and ethics in technology revealed that while business leaders are aggressively moving forward on implementing and using emerging technologies, nearly 90% of those surveyed lack a framework to support the implementation of ethical principles to guide its development and use. the itec initiative was created to fill that void and assist organizations.
""we are delighted to offer this resource to organizations striving to align their technological advancements with ethical principles,"" said brian patrick green, director of technology ethics, markkula center for applied ethics at santa clara university and a co-author of the handbook. ""by integrating ethical considerations into their strategies, policies, and practices, organizations can build trust, foster innovation, and create a positive societal impact.""
green's work focuses on the ethics of technology, including ai and ethics, and various aspects of the impact of technology and engineering on human life and society. green researched and wrote the handbook with josé roger flahaux, a former hands-on global technology executive in operations and supply chain at sandisk and other corporations; and ann gregg skeet, senior director of leadership ethics at the markkula center for applied ethics. josé is also an adjunct professor at san josé state university, where he teaches engineering management systems in a global society. ann's work focuses on the ethical dilemmas of leaders and followers, with a particular interest in healthy corporate culture, corporate governance, and ethical leadership practices.
in today's rapidly evolving technological landscape, organizations face unique ethical challenges around matters of privacy, equity, transparency, and accountability.
""the cornerstone of good governance is ethical conduct. ethical standards are necessary, more than ever, in this age of rapid technological development and disruption. this is particularly true as artificial intelligence and machine learning become embedded in the human experience,"" said larry sonsini, founding and senior partner, wilson sonsini.""this handbook provides a thoughtful and pragmatic roadmap for the adoption and implementation of ethical behavior. its focus on operational guidelines should prove to be invaluable to enterprises and institutions, private or public, small or large, for profit or not.""
""the contemporary situation demands a powerful response, and that is exactly what the itec handbook presents: a comprehensive and detailed plan for improving the ethical management of organizations from top to bottom,"" said steve milligan, former ceo, western digital corporation. certainly, many businesses already do so much to maintain their good reputations, but even the best businesses can learn from the ideas in this handbook.""
to learn more about ""ethics in the age of disruptive technologies: an operational roadmap"" or to obtain a copy, visit: .
about the institute for technology, ethics, and culture
the institute for technology, ethics and culture (itec), housed at the markkula center for applied ethics, is an initiative of the center which has been developed with support from the vatican's dicastery for culture and education. the institute convenes leaders from business, civil society, academia, government, and all faith and belief traditions, to promote deeper thought on technology's impact on humanity. for more information on itec and to access its many resources, see .
about the markkula center for applied ethics at santa clara university
founded in 1986 with a seed grant and initial endowment from linda and a.c.""mike"" markkula jr., the markkula center for applied ethics brings the traditions of ethical thinking to bear on real world problems. beyond a full range of programs for the santa clara university community, the center also serves professionals in fields from business to health care, from government to the social sector, providing innovative approaches to problems from fake news to privacy protection. through its website and international collaborations, the center brings ethical decision-making resources to the wider world. for more information, see .
about the centre for digital culture of the vatican's dicastery for culture and education
the dicastery for culture and education is one of the sixteen dicasteries of the roman curia at the holy see whose mission is the development of people's human values in the context of christian anthropology, contributing to the full realization of christian discipleship. the dicastery comprises the section for culture, dedicated to the promotion of culture, pastoral activity and the enhancement of cultural heritage, and the section for education, which develops the fundamental principles of education regarding schools, catholic and ecclesiastical institutes of higher education and research, and is competent for hierarchical resources in these matters. for more information on each of the sections, see and .joel dibble
markkula center for applied ethics at santa clara univ.
+1 408-554-5116
email us here
visit us on social media:
twitter
linkedin
youtube
instagram
facebook
MENAFN28062023003118003196ID1106512193
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (99%); BUSINESS ETHICS (91%); DISRUPTIVE INNOVATION (90%); EMERGING TECHNOLOGY (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); CATHOLICS & CATHOLICISM (89%); RELIGION (89%); ARTIFICIAL INTELLIGENCE (87%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); COMPANY STRATEGY (77%); STRATEGIC PLANNING (76%); CATHOLIC POPES (72%); MACHINE LEARNING (71%); POLLS & SURVEYS (67%)
Industry: ARTIFICIAL INTELLIGENCE (87%); INFORMATION TECHNOLOGY INDUSTRY (77%); MACHINE LEARNING (71%)
Person: POPE FRANCIS I (53%)
Geographic: SAN FRANCISCO BAY AREA, CA, USA (90%); SILICON VALLEY, CA, USA (79%); CALIFORNIA, USA (79%); VATICAN CITY (90%)
Load-Date: April 8, 2024","Link to Story
(menafn - ein presswire) markkula center for applied ethics logo
logo for the institute for technology, ethics, and culture
cover image of the new resource: ""ethics in the age of disruptive technologies: an operational roadmap""
""ethics in the age of disruptive technologies: an operational roadmap"" offers organizations a strategic plan to enhance ethical management practices
by integrating ethical considerations into their strategies, policies, and practices, organizations can build trust, foster innovation, and create a positive societal impact."" - brian patrick green, markkula center for applied ethicssanta clara, calif., united states, june 28, 2023/einpresswire / -- santa clara university's markkula center for applied ethics announced the formation of the institute for technology, ethics, and culture , or itec, with support from and collaboration with the vatican. the inaugural product is a handbook, ""ethics in the age of disruptive technologies: an operational roadmap,"" or, more briefly, the""itec handbook."" this much-needed corporate primer offers a practical roadmap with specific recommendations to help organizations address the ethical complexities associated with disruptive technologies such as ai, machine learning, encryption, tracking, and others.
for 37 years, the markkula center has been known for its work helping corporations apply ethical thinking and create positive change, collaborating with companies like salesforce, ibm, and microsoft on efforts related to ethical standards in design, development, and deployment of technology. drawing on this work, the ethics center conducted primary research, interviews, and conferred with many corporations to produce the handbook.
""forming this initiative, and providing companies with a roadmap in the itec handbook is the fruit of a trusted collaboration between the markkula center for applied ethics, experienced professionals from bay area technology and management sectors, and the centre for digital culture of the vatican's dicastery for culture and education,"" said bishop paul tighe, secretary of the vatican's dicastery for culture and education.""since i have begun meeting and talking with senior representatives of silicon valley, especially those working in the area of artificial intelligence and machine learning, i have been impressed by their desire to maintain high ethical standards for themselves and for their industry.""
""it may come as a surprise to some to discover the vatican's engagement with this project but it is ultimately the result of meetings -""encounters"" to use one of pope francis' favorite words - between the vatican and the world of technology. the handbook is a concrete result of a desire to promote an inclusive conversation between the technology sector and the broader human community whose future will be shaped in so many ways by decisions made by those who are managing innovation.""
a deloitte study on trust and ethics in technology revealed that while business leaders are aggressively moving forward on implementing and using emerging technologies, nearly 90% of those surveyed lack a framework to support the implementation of ethical principles to guide its development and use. the itec initiative was created to fill that void and assist organizations.
""we are delighted to offer this resource to organizations striving to align their technological advancements with ethical principles,"" said brian patrick green, director of technology ethics, markkula center for applied ethics at santa clara university and a co-author of the handbook. ""by integrating ethical considerations into their strategies, policies, and practices, organizations can build trust, foster innovation, and create a positive societal impact.""
green's work focuses on the ethics of technology, including ai and ethics, and various aspects of the impact of technology and engineering on human life and society. green researched and wrote the handbook with josé roger flahaux, a former hands-on global technology executive in operations and supply chain at sandisk and other corporations; and ann gregg skeet, senior director of leadership ethics at the markkula center for applied ethics. josé is also an adjunct professor at san josé state university, where he teaches engineering management systems in a global society. ann's work focuses on the ethical dilemmas of leaders and followers, with a particular interest in healthy corporate culture, corporate governance, and ethical leadership practices.
in today's rapidly evolving technological landscape, organizations face unique ethical challenges around matters of privacy, equity, transparency, and accountability.
""the cornerstone of good governance is ethical conduct. ethical standards are necessary, more than ever, in this age of rapid technological development and disruption. this is particularly true as artificial intelligence and machine learning become embedded in the human experience,"" said larry sonsini, founding and senior partner, wilson sonsini.""this handbook provides a thoughtful and pragmatic roadmap for the adoption and implementation of ethical behavior. its focus on operational guidelines should prove to be invaluable to enterprises and institutions, private or public, small or large, for profit or not.""
""the contemporary situation demands a powerful response, and that is exactly what the itec handbook presents: a comprehensive and detailed plan for improving the ethical management of organizations from top to bottom,"" said steve milligan, former ceo, western digital corporation. certainly, many businesses already do so much to maintain their good reputations, but even the best businesses can learn from the ideas in this handbook.""
to learn more about ""ethics in the age of disruptive technologies: an operational roadmap"" or to obtain a copy, visit: .
about the institute for technology, ethics, and culture
the institute for technology, ethics and culture (itec), housed at the markkula center for applied ethics, is an initiative of the center which has been developed with support from the vatican's dicastery for culture and education. the institute convenes leaders from business, civil society, academia, government, and all faith and belief traditions, to promote deeper thought on technology's impact on humanity. for more information on itec and to access its many resources, see .
about the markkula center for applied ethics at santa clara university
founded in 1986 with a seed grant and initial endowment from linda and a.c.""mike"" markkula jr., the markkula center for applied ethics brings the traditions of ethical thinking to bear on real world problems. beyond a full range of programs for the santa clara university community, the center also serves professionals in fields from business to health care, from government to the social sector, providing innovative approaches to problems from fake news to privacy protection. through its website and international collaborations, the center brings ethical decision-making resources to the wider world. for more information, see .
about the centre for digital culture of the vatican's dicastery for culture and education
the dicastery for culture and education is one of the sixteen dicasteries of the roman curia at the holy see whose mission is the development of people's human values in the context of christian anthropology, contributing to the full realization of christian discipleship. the dicastery comprises the section for culture, dedicated to the promotion of culture, pastoral activity and the enhancement of cultural heritage, and the section for education, which develops the fundamental principles of education regarding schools, catholic and ecclesiastical institutes of higher education and research, and is competent for hierarchical resources in these matters. for more information on each of the sections, see and .joel dibble
markkula center for applied ethics at santa clara univ.
+1 408-554-5116
email us here
visit us on social media:
twitter
linkedin
youtube
instagram
facebook
MENAFN28062023003118003196ID1106512193
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (99%); BUSINESS ETHICS (91%); DISRUPTIVE INNOVATION (90%); EMERGING TECHNOLOGY (90%); PRESS RELEASES (90%); TECHNOLOGY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); CATHOLICS & CATHOLICISM (89%); RELIGION (89%); ARTIFICIAL INTELLIGENCE (87%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); COMPANY STRATEGY (77%); STRATEGIC PLANNING (76%); CATHOLIC POPES (72%); MACHINE LEARNING (71%); POLLS & SURVEYS (67%)
Industry: ARTIFICIAL INTELLIGENCE (87%); INFORMATION TECHNOLOGY INDUSTRY (77%); MACHINE LEARNING (71%)
Person: POPE FRANCIS I (53%)
Geographic: SAN FRANCISCO BAY AREA, CA, USA (90%); SILICON VALLEY, CA, USA (79%); CALIFORNIA, USA (79%); VATICAN CITY (90%)
Load-Date: April 8, 2024",neutral,0.8242148160934448,balanced/neutral,"['privacy', 'transparency', 'accountability', 'access']",['equity'],"['governance', 'standards', 'guidelines', 'framework', 'should']",['machine learning'],4,1,5,1
2023,Unknown Title,"Body
Relatively few IT leaders spend much, if any, time pondering their organization's values and ethics. Yet as technology continues to integrate itself into virtually every aspect of business and personal life, establishing a moral code is rapidly becoming as important as creating security, employment, asset management, and other fundamental organization policies.No organization, including IT, can sustain successful operations over the long-term unless there's a solid consensus on basic rules governing team behavior. ""The purpose of ethics is to help people arrive at this consensus,"" says John Hooker, a professor of business ethics at Carnegie Mellon University's Tepper School of Business.IT is an integral part of all business operations, influencing virtually every enterprise sector. ""Because so many processes are reliant on IT infrastructure , the practices adopted by a company's IT department have a downstream effect,"" explains Srini Kadiyala, CTO of data governance consulting and technology firm OvalEdge . ""That's why developing an IT department based on ethical approaches is so important.""Establishing ethical oversight is crucially important, says Andrew Clark, CTO of Monitaur , an AI governance software company. 
He notes that it promotes trust and credibility among stakeholders who rely on IT systems, including customers, employees and partners. ""It also reduces the risk of legal and reputational damage caused by unethical practices, such as data breaches, cyberattacks, and intellectual property theft."" Perhaps most critically, ethical oversight creates a responsibility, accountability, and innovation culture that enhances operational efficiency and sustainability, he says.There are also financial implications to be considered. Failing to adopt data privacy policies and exposing customer information in the data space can lead to significant fines, Kadiyala says. At the other end of the spectrum is the reputational damage caused by unethical practices. ""When customers and investors become aware of unethical IT practices, they are less likely to support the organization,"" he explains.Ethics Policy PlanningEvery IT department should create and enforce a clearly defined ethics policy . ""It should state the organization's commitment to honesty, integrity, privacy, fairness, transparency, and social responsibility,"" advises Richard Baker, CTO of TWC IT Solutions .Read the rest of this article on InformationWeek.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); BUSINESS EDUCATION (90%); NEGATIVE TECHNOLOGY NEWS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY CRIME (78%); NEGATIVE BUSINESS NEWS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PRIVACY RIGHTS (77%); DATA BREACHES (73%); DATA THEFT (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); CYBERATTACKS (65%); CYBERCRIME (65%); PROPERTY CRIMES (50%)
Industry: COMPUTING & INFORMATION TECHNOLOGY (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); SOFTWARE SERVICES & APPLICATIONS (78%); DATA GOVERNANCE & STEWARDSHIP (77%); DATA SECURITY (77%); INFORMATION SECURITY & PRIVACY (77%); SOFTWARE MAKERS (74%); DATA BREACHES (73%); DATA THEFT (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); CYBERATTACKS (65%); CYBERCRIME (65%); COMPUTER SOFTWARE (52%)
Load-Date: October 3, 2023","Relatively few IT leaders spend much, if any, time pondering their organization's values and ethics. Yet as technology continues to integrate itself into virtually every aspect of business and personal life, establishing a moral code is rapidly becoming as important as creating security, employment, asset management, and other fundamental organization policies.No organization, including IT, can sustain successful operations over the long-term unless there's a solid consensus on basic rules governing team behavior. ""The purpose of ethics is to help people arrive at this consensus,"" says John Hooker, a professor of business ethics at Carnegie Mellon University's Tepper School of Business.IT is an integral part of all business operations, influencing virtually every enterprise sector. ""Because so many processes are reliant on IT infrastructure , the practices adopted by a company's IT department have a downstream effect,"" explains Srini Kadiyala, CTO of data governance consulting and technology firm OvalEdge . ""That's why developing an IT department based on ethical approaches is so important.""Establishing ethical oversight is crucially important, says Andrew Clark, CTO of Monitaur , an AI governance software company. 
He notes that it promotes trust and credibility among stakeholders who rely on IT systems, including customers, employees and partners. ""It also reduces the risk of legal and reputational damage caused by unethical practices, such as data breaches, cyberattacks, and intellectual property theft."" Perhaps most critically, ethical oversight creates a responsibility, accountability, and innovation culture that enhances operational efficiency and sustainability, he says.There are also financial implications to be considered. Failing to adopt data privacy policies and exposing customer information in the data space can lead to significant fines, Kadiyala says. At the other end of the spectrum is the reputational damage caused by unethical practices. ""When customers and investors become aware of unethical IT practices, they are less likely to support the organization,"" he explains.Ethics Policy PlanningEvery IT department should create and enforce a clearly defined ethics policy . ""It should state the organization's commitment to honesty, integrity, privacy, fairness, transparency, and social responsibility,"" advises Richard Baker, CTO of TWC IT Solutions .Read the rest of this article on InformationWeek.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); BUSINESS EDUCATION (90%); NEGATIVE TECHNOLOGY NEWS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY CRIME (78%); NEGATIVE BUSINESS NEWS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PRIVACY RIGHTS (77%); DATA BREACHES (73%); DATA THEFT (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); CYBERATTACKS (65%); CYBERCRIME (65%); PROPERTY CRIMES (50%)
Industry: COMPUTING & INFORMATION TECHNOLOGY (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); SOFTWARE SERVICES & APPLICATIONS (78%); DATA GOVERNANCE & STEWARDSHIP (77%); DATA SECURITY (77%); INFORMATION SECURITY & PRIVACY (77%); SOFTWARE MAKERS (74%); DATA BREACHES (73%); DATA THEFT (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); CYBERATTACKS (65%); CYBERCRIME (65%); COMPUTER SOFTWARE (52%)
Load-Date: October 3, 2023",neutral,0.773414134979248,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'security']",['fairness'],"['policy', 'governance', 'oversight', 'should']",[],5,1,4,0
2023,Unknown Title,"Byline: express news service
Dateline: Ahmedabad
Body
Ethical considerations and robust governance frameworks are essential as technology advances rapidly, asserted Dr BVR Mohan Reddy, founder chairman of Cyient, a multinational tech firm, on Saturday. Dr Reddy reasoned that such frameworks are ""essential for building trust, promoting equitable access, and safeguarding the well-being of individuals and society as a whole"".
Dr Reddy, who is also a board member of Cyient, was speaking at the 12th convocation of IIT Gandhinagar. The institute conferred a total of 456 degrees, which included students from PhD, MTech, BTech- MTech dual degree, MSc, MA, PGDIIT, BTech Dual Major, BTech, and BSc (engineering) courses.
Addressing the students, Dr Reddy advised them to ""explore the proper use, potential risks, and impacts of the rapidly evolving landscape of technology, addressing concerns such as bias, privacy, security, and accountability.""
""It is imperative that we reflect upon the ethical considerations associated with the astounding advancements in technology we have witnessed. The power of technology to transform lives is undeniable, but we must also recognise the ethical dilemmas that arise as we navigate this ever-evolving landscape. Therefore, I urge you... embrace innovation, but temper it with a strong moral compass,"" stressed Dr Reddy.
Noting that Artificial intelligence (AI) is a plausible ""ethical minefield"", Dr Reddy added, ""AI algorithms possess tremendous power, capable of making critical decisions that impact our lives... The ethical dilemma lies in ensuring that these AI systems are fair, unbiased, and accountable. We must prevent the perpetuation of discrimination, preserve human dignity, and ensure transparency in AI decision-making by holding AI systems accountable for their actions...""
""Ethical considerations extend to various facets of technology, including data privacy, surveillance, cybersecurity, intellectual property rights, and the digital divide,"" he added.
Meanwhile, Director of IIT Gandhinagar Prof Rajat Moona said that the institute, ""recognising the far-reaching impact of AI across various fields"", has introduced a new B Tech degree programme, starting from the academic year 2023-24.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); DISCRIMINATION (79%); DIGITAL DIVIDE (78%); ENGINEERING (78%); INTELLECTUAL PROPERTY (78%); NEGATIVE SOCIETAL NEWS (77%); PRIVACY RIGHTS (77%); CERTIFICATES, DEGREES & DIPLOMAS (75%); INTERNET PRIVACY (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); SURVEILLANCE (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ENGINEERING (78%); INFORMATION SECURITY & PRIVACY (73%); INTERNET PRIVACY (73%); COLLEGE & UNIVERSITY PROFESSORS (70%)
Geographic: AHMEDABAD, GUJARAT, INDIA (59%); GUJARAT, INDIA (74%)
Load-Date: July 30, 2023","Ethical considerations and robust governance frameworks are essential as technology advances rapidly, asserted Dr BVR Mohan Reddy, founder chairman of Cyient, a multinational tech firm, on Saturday. Dr Reddy reasoned that such frameworks are ""essential for building trust, promoting equitable access, and safeguarding the well-being of individuals and society as a whole"".
Dr Reddy, who is also a board member of Cyient, was speaking at the 12th convocation of IIT Gandhinagar. The institute conferred a total of 456 degrees, which included students from PhD, MTech, BTech- MTech dual degree, MSc, MA, PGDIIT, BTech Dual Major, BTech, and BSc (engineering) courses.
Addressing the students, Dr Reddy advised them to ""explore the proper use, potential risks, and impacts of the rapidly evolving landscape of technology, addressing concerns such as bias, privacy, security, and accountability.""
""It is imperative that we reflect upon the ethical considerations associated with the astounding advancements in technology we have witnessed. The power of technology to transform lives is undeniable, but we must also recognise the ethical dilemmas that arise as we navigate this ever-evolving landscape. Therefore, I urge you... embrace innovation, but temper it with a strong moral compass,"" stressed Dr Reddy.
Noting that Artificial intelligence (AI) is a plausible ""ethical minefield"", Dr Reddy added, ""AI algorithms possess tremendous power, capable of making critical decisions that impact our lives... The ethical dilemma lies in ensuring that these AI systems are fair, unbiased, and accountable. We must prevent the perpetuation of discrimination, preserve human dignity, and ensure transparency in AI decision-making by holding AI systems accountable for their actions...""
""Ethical considerations extend to various facets of technology, including data privacy, surveillance, cybersecurity, intellectual property rights, and the digital divide,"" he added.
Meanwhile, Director of IIT Gandhinagar Prof Rajat Moona said that the institute, ""recognising the far-reaching impact of AI across various fields"", has introduced a new B Tech degree programme, starting from the academic year 2023-24.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); DISCRIMINATION (79%); DIGITAL DIVIDE (78%); ENGINEERING (78%); INTELLECTUAL PROPERTY (78%); NEGATIVE SOCIETAL NEWS (77%); PRIVACY RIGHTS (77%); CERTIFICATES, DEGREES & DIPLOMAS (75%); INTERNET PRIVACY (73%); COLLEGE & UNIVERSITY PROFESSORS (70%); SURVEILLANCE (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ENGINEERING (78%); INFORMATION SECURITY & PRIVACY (73%); INTERNET PRIVACY (73%); COLLEGE & UNIVERSITY PROFESSORS (70%)
Geographic: AHMEDABAD, GUJARAT, INDIA (59%); GUJARAT, INDIA (74%)
Load-Date: July 30, 2023",neutral,0.5311106443405151,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'transparency', 'accountability', 'security', 'digital divide', 'access']",['dignity'],"['governance', 'must']",[],9,1,2,0
2023,Unknown Title,"Byline: Muddassar Nazar
Body
Currently, artificial intelligence (AI) is changing many sectors of the economy, including education. It provides several opportunities to improve teaching and learning, support unique instruction, improvise tests, and broaden access to high-quality education. In response, there has been a major investment in adopting AI-powered educational technology, leading to a notable expansion of this technology inside the education sector. In 2022, the education sector's AI market was valued at USD 4 billion, according to a survey by Global Market Research. This industry is expected to develop at a compound annual growth rate (CAGR) of 10% in the upcoming years.
Although artificial intelligence (AI) provides educational institutions with numerous benefits, it also has certain ethical consequences that participants must carefully consider. The main issues with educational technology are transparency, privacy, and statistical biases.
Biases and discrimination in algorithms
Biases pose a serious ethical problem for educators since they can result in judgment and stereotyping, which might hinder a student's advancement. Since AI systems are trained by humans, their biases and preconceptions are likely to be reflected in them. It could result in unfair and discriminatory consequences for some student or instructor groups. For example, recommendations and instructions may not be helpful for students from different backgrounds if AI is trained mostly on data from students in that group. Consequently, it may unintentionally maintain educational disparity.
Privacy and data security
When students and teachers interact with these platforms by submitting assignments, uploading educational content, engaging in online forums, and other activities, they leave digital imprints. As a result, AI systems tend to collect, store, evaluate, and interpret massive amounts of critical information, such as academic achievement, conduct, preferences, location, and so on. This could undermine data and privacy protection rights, especially if the data is used for other purposes other than teaching, such as marketing, profiling, and so on.
Accountability and disclosure
Accountability is another ethical issue that AI-powered education technology tackles. Since the outcomes are reliant on the data that is collected, the opacity makes it difficult to hold people accountable for their activities. Even though AI systems are dependable for a variety of functions, they remain a black box since their decision-making process is difficult for humans to grasp. AI may work in complex trends that students, instructors, or other participants will find difficult to comprehend. This may limit the ability to trust, validate, or even challenge the AI's outcomes.
Solutions to consider
To protect human rights and dignity, maintain educational efficiency, and create inclusion and equity, ethical issues associated with AI in terms of bias, privacy, accountability, and transparency must be properly addressed. This can be accomplished effectively by taking a multi-stakeholder strategy that includes effective collaboration among educators, policymakers, researchers, developers, and others. Collective decision-making must prioritise the development of ethical frameworks, the implementation of ethical norms, the promotion of awareness, and the strengthening of ethical governance and legislation. These phases are expected to assist decision-makers in addressing the ethical concerns of AI systems and upgrading them to make them reliable, trustworthy, and efficient.
Putting everything into consideration
AI in education has enormous potential for improving student learning; yet, ethical concerns should be addressed concurrently. The necessity of the hour is to apply cutting-edge AI-powered educational technology while respecting human rights, dignity, inclusivity, equity, and ethics. To create reliable solutions, regulations, structures, and norms, all parties must engage in discourse.
As we harness the power of AI in education, we must tread carefully in these ethical concerns by encouraging human intervention for the technology to be employed more compassionately and responsibly. We will ensure that AI-powered education not only safeguards students' rights, but also encourages a transparent, equal, and dependable learning environment.
(The author is Muddassar Nazar, CEO, Birla Brainiacs, and the views expressed in this article are his own)
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); EDUCATION & TRAINING (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ETHICS (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); NEGATIVE SOCIETAL NEWS (88%); EDUCATIONAL INSTITUTION EMPLOYEES (78%); TRENDS (78%); PRIVACY RIGHTS (77%); BUSINESS FORECASTS (75%); DISCRIMINATION (73%); HUMAN RIGHTS (73%); POLLS & SURVEYS (71%); BUSINESS REPORTS & FORECASTS (56%)
Industry: ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (88%); EDUCATIONAL SERVICES (78%); MARKET RESEARCH (77%); MARKET RESEARCH & ANALYSIS (77%); DATA SECURITY (70%)
Load-Date: November 3, 2023","Currently, artificial intelligence (AI) is changing many sectors of the economy, including education. It provides several opportunities to improve teaching and learning, support unique instruction, improvise tests, and broaden access to high-quality education. In response, there has been a major investment in adopting AI-powered educational technology, leading to a notable expansion of this technology inside the education sector. In 2022, the education sector's AI market was valued at USD 4 billion, according to a survey by Global Market Research. This industry is expected to develop at a compound annual growth rate (CAGR) of 10% in the upcoming years.
Although artificial intelligence (AI) provides educational institutions with numerous benefits, it also has certain ethical consequences that participants must carefully consider. The main issues with educational technology are transparency, privacy, and statistical biases.
Biases and discrimination in algorithms
Biases pose a serious ethical problem for educators since they can result in judgment and stereotyping, which might hinder a student's advancement. Since AI systems are trained by humans, their biases and preconceptions are likely to be reflected in them. It could result in unfair and discriminatory consequences for some student or instructor groups. For example, recommendations and instructions may not be helpful for students from different backgrounds if AI is trained mostly on data from students in that group. Consequently, it may unintentionally maintain educational disparity.
Privacy and data security
When students and teachers interact with these platforms by submitting assignments, uploading educational content, engaging in online forums, and other activities, they leave digital imprints. As a result, AI systems tend to collect, store, evaluate, and interpret massive amounts of critical information, such as academic achievement, conduct, preferences, location, and so on. This could undermine data and privacy protection rights, especially if the data is used for other purposes other than teaching, such as marketing, profiling, and so on.
Accountability and disclosure
Accountability is another ethical issue that AI-powered education technology tackles. Since the outcomes are reliant on the data that is collected, the opacity makes it difficult to hold people accountable for their activities. Even though AI systems are dependable for a variety of functions, they remain a black box since their decision-making process is difficult for humans to grasp. AI may work in complex trends that students, instructors, or other participants will find difficult to comprehend. This may limit the ability to trust, validate, or even challenge the AI's outcomes.
Solutions to consider
To protect human rights and dignity, maintain educational efficiency, and create inclusion and equity, ethical issues associated with AI in terms of bias, privacy, accountability, and transparency must be properly addressed. This can be accomplished effectively by taking a multi-stakeholder strategy that includes effective collaboration among educators, policymakers, researchers, developers, and others. Collective decision-making must prioritise the development of ethical frameworks, the implementation of ethical norms, the promotion of awareness, and the strengthening of ethical governance and legislation. These phases are expected to assist decision-makers in addressing the ethical concerns of AI systems and upgrading them to make them reliable, trustworthy, and efficient.
Putting everything into consideration
AI in education has enormous potential for improving student learning; yet, ethical concerns should be addressed concurrently. The necessity of the hour is to apply cutting-edge AI-powered educational technology while respecting human rights, dignity, inclusivity, equity, and ethics. To create reliable solutions, regulations, structures, and norms, all parties must engage in discourse.
As we harness the power of AI in education, we must tread carefully in these ethical concerns by encouraging human intervention for the technology to be employed more compassionately and responsibly. We will ensure that AI-powered education not only safeguards students' rights, but also encourages a transparent, equal, and dependable learning environment.
(The author is Muddassar Nazar, CEO, Birla Brainiacs, and the views expressed in this article are his own)
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); EDUCATION & TRAINING (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ETHICS (90%); STUDENTS & STUDENT LIFE (90%); TEACHING & TEACHERS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); NEGATIVE SOCIETAL NEWS (88%); EDUCATIONAL INSTITUTION EMPLOYEES (78%); TRENDS (78%); PRIVACY RIGHTS (77%); BUSINESS FORECASTS (75%); DISCRIMINATION (73%); HUMAN RIGHTS (73%); POLLS & SURVEYS (71%); BUSINESS REPORTS & FORECASTS (56%)
Industry: ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (88%); EDUCATIONAL SERVICES (78%); MARKET RESEARCH (77%); MARKET RESEARCH & ANALYSIS (77%); DATA SECURITY (70%)
Load-Date: November 3, 2023",positive,0.7086930871009827,balanced/neutral,"['privacy', 'bias', 'discrimination', 'transparency', 'accountability', 'security', 'human rights', 'inclusivity', 'access']","['equity', 'dignity']","['governance', 'legislation', 'should', 'must']",[],9,2,4,0
2023,Unknown Title,"Byline: Micheal Chukwube
Body
Jun 24, 2023( ReadWrite: https://readwrite.com/ Delivered by Newstex)  
 https://readwrite.com/the-ethics-of-chatgpt-ensuring-ai-responsibly-serves-humanity/ Artificial intelligence (AI)[1] is a rapidly evolving technology, and ChatGPT is an extraordinary creation that showcases the latest breakthroughs in natural language processing. However, we cannot ignore the ethical implications of its existence. This piece aims to explore the ethical considerations surrounding ChatGPT's role in serving humanity responsibly. 
Potential Benefits and Risks of ChatGPT 
ChatGPT[2] holds immense promise, enhancing customer service, personalizing recommendations, and transforming information accessibility. Its proficiency in processing data and generating coherent responses knows no bounds, enabling language translation, content creation, and virtual assistance[3]. ChatGPT paves the way for limitless human-machine collaboration. 
The Perils Lurking Beneath: 
Yet, we must confront the risks of ChatGPT. Misinformation and manipulation pose significant concerns, as it can unknowingly spread falsehoods and exacerbate fake news. Furthermore, malicious actors may exploit ChatGPT for harmful purposes, such as generating deep fakes or engaging in unethical practices. 
Ethical Implications: 
The ethical considerations surrounding ChatGPT are paramount. Developers and society at large share the responsibility of ensuring responsible use. Transparency, accountability, and fairness must guide its development. Addressing biases and privacy concerns is crucial to prevent discrimination and protect sensitive information. 
Navigating the Path Ahead: 
A collaborative approach is essential to unlocking ChatGPT's benefits while mitigating risks. Establishing guidelines and regulations, integrating ethical frameworks, and monitoring for biases are crucial steps. Engaging diverse perspectives helps uncover potential pitfalls and ensures responsible deployment. 
Ethical Frameworks for ChatGPT 
Artificial Intelligence (AI) technologies like ChatGPT hold immense potential but also raise ethical concerns. To ensure responsible and ethical use, several frameworks have been proposed. 
Transparency, fairness, and accountability are key principles. AI systems must be transparent in their decision-making processes, ensuring individuals understand their workings. Fairness requires avoiding bias and discrimination, while accountability holds developers and users responsible for AI's actions. 
The human-centered approach prioritizes aligning AI with human values and interests. It aims to maximize benefits while minimizing harm to individuals and society. 
The beneficence and non-maleficence principle emphasizes avoiding harm and promoting well-being in AI systems. 
Implementing these frameworks presents challenges. Ensuring transparency is difficult when algorithms are complex. Bias and discrimination can inadvertently be present in AI due to training data. 
Nevertheless, refining ethical frameworks is crucial. It ensures AI technologies[4] like ChatGPT are developed and used responsibly, maximizing benefits and minimizing negative impacts on individuals and society. 
Responsibility in Developing and Using ChatGPT 
The creators of ChatGPT bear the weight of its development, carrying the responsibility to design and develop the technology ethically, prioritizing humanity's best interests. This entails considering the potential consequences of ChatGPT's actions and ensuring steadfast adherence to ethical principles. 
The guardianship of ChatGPT lies with its users, who bear the responsibility of employing it conscientiously. They must ensure their usage does no harm, respects privacy and autonomy, and remains mindful of the potential consequences, utilizing it with unwavering ethics. 
The ramifications of unethical ChatGPT development and use are grave. It has the potential to disseminate misinformation, harass individuals, and manipulate public opinion, thereby jeopardizing democracy and human rights on a significant scale. 
To ensure ChatGPT's responsible development and use, ethical guidelines are crucial. These guidelines, rooted in transparency, accountability, privacy, and non-discrimination, must be crafted collaboratively with diverse stakeholders spanning ethics, technology, and social justice domains. 
Empowering developers and users with comprehensive ethical training for ChatGPT cultivates the necessary knowledge and skills to wield it responsibly. 
Addressing Bias in ChatGPT 
According to the NIST report, the perception of bias in AI[5] systems as solely a technical issue is challenged, as it recognizes that a significant portion of AI bias originates from human biases and systemic, institutional biases. 
Bias poses a formidable challenge for ChatGPT, manifesting through various channels: training data, processing algorithms, and the biases of developers and users. Its presence in ChatGPT carries profound ethical implications and far-reaching consequences. 
Biased ChatGPT carries weighty ethical implications, fueling harmful stereotypes, reinforcing inequalities, and subjecting individuals to unfair treatment based on race, gender, and other characteristics. 
To combat bias in ChatGPT, we delve into its origins and detection. Unveiling strategies such as scrutinizing training data, evaluating processing algorithms, and analyzing ChatGPT's output enables us to identify and rectify patterns of bias. 
Unearthing bias within ChatGPT necessitates employing diverse data during training, ensuring representation of the population's diversity and mitigating bias risk. Additionally, employing transparent and interpretable algorithms enables the identification and resolution of bias more effectively 
By fostering inclusivity and diverse collaboration in ChatGPT's development and testing, we honor varied perspectives, mitigate bias, and promote a more equitable AI. 
Transparency and Accountability in ChatGPT 
In the world of AI, transparency and accountability are essential for responsible development. ChatGPT, the virtual oracle among us, warrants a closer look at the importance of transparency and accountability. 
A Hidden Tapestry of Algorithms: 
Unraveling the complex algorithms behind ChatGPT allows us to understand its decision-making process and ensure alignment with our values. 
The Shadows of Bias: 
Addressing and rectifying biases within ChatGPT ensure fairness and inclusivity in its responses. 
The Journey Towards Explainability: 
Striving for explainability enables us to evaluate the ethics of ChatGPT's actions and fosters human understanding. 
An Oath of Responsibility: 
Developers and users share the responsibility of ensuring the ethical use of ChatGPT, with developers embedding transparency and accountability from the start. 
The Power of Public Scrutiny: 
Public scrutiny holds developers accountable and promotes transparent practices, ensuring ChatGPT faithfully serves humanity. 
Conclusion 
In navigating the ethical considerations surrounding ChatGPT, we must balance its potential benefits with the risks it poses. Ethical frameworks, transparency, and addressing bias are essential in ensuring responsible AI use. 
Collaboration among stakeholders is key to shaping a future where ChatGPT serves humanity's needs while upholding our values. By fostering dialogue and remaining committed to ethical development, we can harness the transformative power of AI for the betterment of society. 
Let us strive for a future where ChatGPT becomes a trusted ally, enhancing our lives and reflecting our shared humanity. 
The post The Ethics of ChatGPT: Ensuring AI Responsibly Serves Humanity[6] appeared first on ReadWrite[7]. 
 [ 1]: https://readwrite.com/artificial-intelligence-digital-marketing/ [ 2]: https://www.workamajig.com/blog/chatgpt [ 3]: https://readwrite.com/how-a-virtual-assistant-can-help-startup-make-more-sales/ [ 4]: https://readwrite.com/how-ai-technologies-help-banks-and-fintech-startups/ [ 5]: https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights#:~:text=Bias%20in%20AI%20systems%20is,systemic%2C%20institutional%20biases%20as%20well. [ 6]: https://readwrite.com/the-ethics-of-chatgpt-ensuring-ai-responsibly-serves-humanity/ [ 7]: https://readwrite.com 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: RDWR-7023
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); DISINFORMATION & MISINFORMATION (90%); GENERATIVE AI (90%); NEGATIVE SOCIETAL NEWS (87%); DISCRIMINATION (86%); DEEPFAKE TECHNOLOGY (79%); NATURAL LANGUAGE PROCESSING (79%); CUSTOMER SERVICE (74%); PRIVACY RIGHTS (73%); LANGUAGE & LANGUAGES (71%); FAKE NEWS (67%); AI (%); Big Data (%); #aiethics (%); AI Adoption (%); ai algorithms (%); AI an privacy (%); ChatGPT (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); INFORMATION SECURITY & PRIVACY (90%); DEEPFAKE TECHNOLOGY (79%)
Load-Date: June 24, 2023","Jun 24, 2023( ReadWrite: https://readwrite.com/ Delivered by Newstex)  
 https://readwrite.com/the-ethics-of-chatgpt-ensuring-ai-responsibly-serves-humanity/ Artificial intelligence (AI)[1] is a rapidly evolving technology, and ChatGPT is an extraordinary creation that showcases the latest breakthroughs in natural language processing. However, we cannot ignore the ethical implications of its existence. This piece aims to explore the ethical considerations surrounding ChatGPT's role in serving humanity responsibly. 
Potential Benefits and Risks of ChatGPT 
ChatGPT[2] holds immense promise, enhancing customer service, personalizing recommendations, and transforming information accessibility. Its proficiency in processing data and generating coherent responses knows no bounds, enabling language translation, content creation, and virtual assistance[3]. ChatGPT paves the way for limitless human-machine collaboration. 
The Perils Lurking Beneath: 
Yet, we must confront the risks of ChatGPT. Misinformation and manipulation pose significant concerns, as it can unknowingly spread falsehoods and exacerbate fake news. Furthermore, malicious actors may exploit ChatGPT for harmful purposes, such as generating deep fakes or engaging in unethical practices. 
Ethical Implications: 
The ethical considerations surrounding ChatGPT are paramount. Developers and society at large share the responsibility of ensuring responsible use. Transparency, accountability, and fairness must guide its development. Addressing biases and privacy concerns is crucial to prevent discrimination and protect sensitive information. 
Navigating the Path Ahead: 
A collaborative approach is essential to unlocking ChatGPT's benefits while mitigating risks. Establishing guidelines and regulations, integrating ethical frameworks, and monitoring for biases are crucial steps. Engaging diverse perspectives helps uncover potential pitfalls and ensures responsible deployment. 
Ethical Frameworks for ChatGPT 
Artificial Intelligence (AI) technologies like ChatGPT hold immense potential but also raise ethical concerns. To ensure responsible and ethical use, several frameworks have been proposed. 
Transparency, fairness, and accountability are key principles. AI systems must be transparent in their decision-making processes, ensuring individuals understand their workings. Fairness requires avoiding bias and discrimination, while accountability holds developers and users responsible for AI's actions. 
The human-centered approach prioritizes aligning AI with human values and interests. It aims to maximize benefits while minimizing harm to individuals and society. 
The beneficence and non-maleficence principle emphasizes avoiding harm and promoting well-being in AI systems. 
Implementing these frameworks presents challenges. Ensuring transparency is difficult when algorithms are complex. Bias and discrimination can inadvertently be present in AI due to training data. 
Nevertheless, refining ethical frameworks is crucial. It ensures AI technologies[4] like ChatGPT are developed and used responsibly, maximizing benefits and minimizing negative impacts on individuals and society. 
Responsibility in Developing and Using ChatGPT 
The creators of ChatGPT bear the weight of its development, carrying the responsibility to design and develop the technology ethically, prioritizing humanity's best interests. This entails considering the potential consequences of ChatGPT's actions and ensuring steadfast adherence to ethical principles. 
The guardianship of ChatGPT lies with its users, who bear the responsibility of employing it conscientiously. They must ensure their usage does no harm, respects privacy and autonomy, and remains mindful of the potential consequences, utilizing it with unwavering ethics. 
The ramifications of unethical ChatGPT development and use are grave. It has the potential to disseminate misinformation, harass individuals, and manipulate public opinion, thereby jeopardizing democracy and human rights on a significant scale. 
To ensure ChatGPT's responsible development and use, ethical guidelines are crucial. These guidelines, rooted in transparency, accountability, privacy, and non-discrimination, must be crafted collaboratively with diverse stakeholders spanning ethics, technology, and social justice domains. 
Empowering developers and users with comprehensive ethical training for ChatGPT cultivates the necessary knowledge and skills to wield it responsibly. 
Addressing Bias in ChatGPT 
According to the NIST report, the perception of bias in AI[5] systems as solely a technical issue is challenged, as it recognizes that a significant portion of AI bias originates from human biases and systemic, institutional biases. 
Bias poses a formidable challenge for ChatGPT, manifesting through various channels: training data, processing algorithms, and the biases of developers and users. Its presence in ChatGPT carries profound ethical implications and far-reaching consequences. 
Biased ChatGPT carries weighty ethical implications, fueling harmful stereotypes, reinforcing inequalities, and subjecting individuals to unfair treatment based on race, gender, and other characteristics. 
To combat bias in ChatGPT, we delve into its origins and detection. Unveiling strategies such as scrutinizing training data, evaluating processing algorithms, and analyzing ChatGPT's output enables us to identify and rectify patterns of bias. 
Unearthing bias within ChatGPT necessitates employing diverse data during training, ensuring representation of the population's diversity and mitigating bias risk. Additionally, employing transparent and interpretable algorithms enables the identification and resolution of bias more effectively 
By fostering inclusivity and diverse collaboration in ChatGPT's development and testing, we honor varied perspectives, mitigate bias, and promote a more equitable AI. 
Transparency and Accountability in ChatGPT 
In the world of AI, transparency and accountability are essential for responsible development. ChatGPT, the virtual oracle among us, warrants a closer look at the importance of transparency and accountability. 
A Hidden Tapestry of Algorithms: 
Unraveling the complex algorithms behind ChatGPT allows us to understand its decision-making process and ensure alignment with our values. 
The Shadows of Bias: 
Addressing and rectifying biases within ChatGPT ensure fairness and inclusivity in its responses. 
The Journey Towards Explainability: 
Striving for explainability enables us to evaluate the ethics of ChatGPT's actions and fosters human understanding. 
An Oath of Responsibility: 
Developers and users share the responsibility of ensuring the ethical use of ChatGPT, with developers embedding transparency and accountability from the start. 
The Power of Public Scrutiny: 
Public scrutiny holds developers accountable and promotes transparent practices, ensuring ChatGPT faithfully serves humanity. 
Conclusion 
In navigating the ethical considerations surrounding ChatGPT, we must balance its potential benefits with the risks it poses. Ethical frameworks, transparency, and addressing bias are essential in ensuring responsible AI use. 
Collaboration among stakeholders is key to shaping a future where ChatGPT serves humanity's needs while upholding our values. By fostering dialogue and remaining committed to ethical development, we can harness the transformative power of AI for the betterment of society. 
Let us strive for a future where ChatGPT becomes a trusted ally, enhancing our lives and reflecting our shared humanity. 
The post The Ethics of ChatGPT: Ensuring AI Responsibly Serves Humanity[6] appeared first on ReadWrite[7]. 
 [ 1]: https://readwrite.com/artificial-intelligence-digital-marketing/ [ 2]: https://www.workamajig.com/blog/chatgpt [ 3]: https://readwrite.com/how-a-virtual-assistant-can-help-startup-make-more-sales/ [ 4]: https://readwrite.com/how-ai-technologies-help-banks-and-fintech-startups/ [ 5]: https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights#:~:text=Bias%20in%20AI%20systems%20is,systemic%2C%20institutional%20biases%20as%20well. [ 6]: https://readwrite.com/the-ethics-of-chatgpt-ensuring-ai-responsibly-serves-humanity/ [ 7]: https://readwrite.com 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: RDWR-7023
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); DISINFORMATION & MISINFORMATION (90%); GENERATIVE AI (90%); NEGATIVE SOCIETAL NEWS (87%); DISCRIMINATION (86%); DEEPFAKE TECHNOLOGY (79%); NATURAL LANGUAGE PROCESSING (79%); CUSTOMER SERVICE (74%); PRIVACY RIGHTS (73%); LANGUAGE & LANGUAGES (71%); FAKE NEWS (67%); AI (%); Big Data (%); #aiethics (%); AI Adoption (%); ai algorithms (%); AI an privacy (%); ChatGPT (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); GENERATIVE AI (90%); INFORMATION SECURITY & PRIVACY (90%); DEEPFAKE TECHNOLOGY (79%)
Load-Date: June 24, 2023",neutral,0.6335620284080505,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'human rights', 'autonomy', 'manipulation', 'misinformation', 'disinformation', 'inclusivity']","['justice', 'fairness', 'autonomy', 'beneficence', 'non-maleficence', 'justice']","['guidelines', 'should', 'must']","['generative ai', 'chatgpt', 'natural language processing']",14,6,3,3
2023,Unknown Title,"Byline: Targeted News Service
Dateline: BLACKSBURG, Virginia 
Body
(TNSres) -- Virginia Tech issued the following news:
* * *
The two-day event on Virginia Tech's Blacksburg campus highlights research funded by the National Science Foundation.
* * *
What happens when a large university decides to change how it teaches ethics to its science and engineering students? How does that new material get integrated into an already demanding course-load and technical training for STEM majors?
And how do you track the changes in culture as they move through the web of personal and professional relationships in the institution? Or maybe most importantly: What does an education in ethics even mean to faculty and students?
Those questions were the subject of a six-year grant from the National Science Foundation awarded to the Department of Engineering Education in the College of Engineering, which culminated in a two-day workshop in June that drew 90 participants from 10 countries.
""When you realize roughly two-thirds of our students are involved in science or engineering -- and that all of our students will be influenced by changes in technology that will happen in the 21st century -- an education in ethics about how to employ those tools for maximum benefit and minimum detriment becomes incredibly important,"" said Thomas Staley, collegiate associate professor in materials science and engineering and the principal investigator for the grant.
The grant's transdisciplinary team, led with Staley and co-investigators Stephen Biscotte and Diana Bairaktarova, have met twice a month since the grant's start in 2017. As the work progressed, the research branched into three areas of interest: focus groups with faculty and staff, a survey of 1,500 students, and how the shift in culture spread through the university.
""I've been involved with ethics during my whole academic and industry career through teaching, research, and as a design and manufacturing engineer,"" said Bairaktarova, associate professor in engineering education. ""And this has been one of the most exciting projects I've worked on. It's been fascinating.""
The grant largely coincided with the implementation of Pathways General Education, a transdisciplinary curriculum launched in 2018. The program requires all undergraduates to take 45 credits over seven core concepts and two integrative concepts, including ethical reasoning.
""When Virginia Tech rolled out the Pathways program, after years of reimagining its Gen Ed curriculum, it provided the perfect laboratory to study ethics education campuswide,"" said Biscotte, assistant provost for undergraduate education. ""The grant raised several important and challenging questions: What does ethical reasoning mean? How should it be taught? And how do we connect instructors with resources and support to integrate ethical reasoning into their courses?
""Those are the questions our team has worked to answer and ultimately share with colleagues both inside and outside our community,"" he said.
Central to that outreach two-day international workshop held at the end of June on Virginia Tech's Blacksburg campus that explored current topics in STEM ethics and undergraduate ethics education research.
""The workshop was an opportunity to explore all of the dimensions of the work that's been done over the last six years,"" said Staley. ""For an internal audience, people involved in ethics and undergraduate education were able to see the patterns our research found in and around campus.
""Also, about 60 percent of the workshop's content was from external contributors which gave us an opportunity to learn how ethical education is approached on campuses around the world,"" he said.
Forty-five universities, including six European institutions, were represented at the June workshop, exploring such topics as ethical identities, professional ethics, ethical infrastructures, ethics and artificial intelligence, and much more.
""We are working on ethical questions in Switzerland too, but it's very nice to see a project in a very advanced stage,"" said Vladimir Macko, a researcher at the University of Neuchatel. ""It's a nice reference for us to see these issues studied on a large scale at an institution like Virgina Tech. One of the things I will be taking home is how we could apply this to European universities.""
A post-conference survey found the event, called the CCE STEM Summer Workshop, was extremely well received with respondents rating it 4.67 out of a potential five points.
""I've been really inspired and energized because it is so exciting to see people working on a really important issue from such an incredible range of perspectives and topics,"" said Amanda Kellogg, associate professor of English at Radford University. ""There are people here who are in engineering education, but we're also talking about AI and faculty development - it's just great to see a group of people come together.""
The National Science Foundation (NSF) is an independent federal agency with an annual budget of more than $8 billion that provides grants to support all fields of science and engineering. The grants account for about 25 percent of the federal support to America's colleges and universities, funding more than 300,000 researchers at 2,000 universities.
The project's abstract, titled ""Institutional Transformation: Cultivating an Ethical STEM Culture Through an Integrated Undergraduate General Education,"" can be found on the NSF website. Since 2017, the project has received $711,203 in funding.
In addition to Bairaktarova, Biscotte, and Staley, researchers included Kojo Akrong, Talha Bin Asad, Hesam Hosseinpour, Karen Gilbert, Jill Sible, Sam Snyder, and Hao Wang.
The team plans to continue to publish its results next year on student and faculty perceptions of ethics and ethics education as well as the faculty social network that guides programmatic change.
""This work has been extremely valuable also because for our graduating engineering students, their education should be grounded in ethical reasoning as much as in their technical training,"" said Bairaktarova. ""Hopefully, after they leave the university and start their careers, being ethical will become part of their professional identity. ""
* * *
Original text here: https://news.vt.edu/articles/2023/07/PGE-COE-NSF-GRANT.html
Contact: Dave Guerin, 540/231-0871, dwguerin@vt.edu
MSTRUCK-8224497 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: CONFERENCES & CONVENTIONS (90%); ETHICS (90%); GOVERNMENT RESEARCH FUNDING (90%); INVESTIGATIONS (90%); SCIENCE FUNDING (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); CURRICULA (89%); ENGINEERING (89%); TEACHING & TEACHERS (89%); COLLEGES & UNIVERSITIES (78%); EDUCATIONAL INSTITUTION EMPLOYEES (78%); GRANTS & GIFTS (78%); STEM EDUCATION (78%); VOCATIONAL & TECHNICAL TRAINING (78%); CIVIL ENGINEERING (77%); MATERIALS SCIENCE & TECHNOLOGY (73%); SCIENCE & TECHNOLOGY (73%); UNIVERSITY ADMINISTRATION (72%)
Organization: NATIONAL SCIENCE FOUNDATION (91%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); ENGINEERING (89%); COLLEGES & UNIVERSITIES (78%); VOCATIONAL & TECHNICAL TRAINING (78%); CIVIL ENGINEERING (77%); FOCUS GROUPS (73%); MANUFACTURING (73%)
Geographic: VIRGINIA, USA (79%)
Load-Date: July 25, 2023","(TNSres) -- Virginia Tech issued the following news:
* * *
The two-day event on Virginia Tech's Blacksburg campus highlights research funded by the National Science Foundation.
* * *
What happens when a large university decides to change how it teaches ethics to its science and engineering students? How does that new material get integrated into an already demanding course-load and technical training for STEM majors?
And how do you track the changes in culture as they move through the web of personal and professional relationships in the institution? Or maybe most importantly: What does an education in ethics even mean to faculty and students?
Those questions were the subject of a six-year grant from the National Science Foundation awarded to the Department of Engineering Education in the College of Engineering, which culminated in a two-day workshop in June that drew 90 participants from 10 countries.
""When you realize roughly two-thirds of our students are involved in science or engineering -- and that all of our students will be influenced by changes in technology that will happen in the 21st century -- an education in ethics about how to employ those tools for maximum benefit and minimum detriment becomes incredibly important,"" said Thomas Staley, collegiate associate professor in materials science and engineering and the principal investigator for the grant.
The grant's transdisciplinary team, led with Staley and co-investigators Stephen Biscotte and Diana Bairaktarova, have met twice a month since the grant's start in 2017. As the work progressed, the research branched into three areas of interest: focus groups with faculty and staff, a survey of 1,500 students, and how the shift in culture spread through the university.
""I've been involved with ethics during my whole academic and industry career through teaching, research, and as a design and manufacturing engineer,"" said Bairaktarova, associate professor in engineering education. ""And this has been one of the most exciting projects I've worked on. It's been fascinating.""
The grant largely coincided with the implementation of Pathways General Education, a transdisciplinary curriculum launched in 2018. The program requires all undergraduates to take 45 credits over seven core concepts and two integrative concepts, including ethical reasoning.
""When Virginia Tech rolled out the Pathways program, after years of reimagining its Gen Ed curriculum, it provided the perfect laboratory to study ethics education campuswide,"" said Biscotte, assistant provost for undergraduate education. ""The grant raised several important and challenging questions: What does ethical reasoning mean? How should it be taught? And how do we connect instructors with resources and support to integrate ethical reasoning into their courses?
""Those are the questions our team has worked to answer and ultimately share with colleagues both inside and outside our community,"" he said.
Central to that outreach two-day international workshop held at the end of June on Virginia Tech's Blacksburg campus that explored current topics in STEM ethics and undergraduate ethics education research.
""The workshop was an opportunity to explore all of the dimensions of the work that's been done over the last six years,"" said Staley. ""For an internal audience, people involved in ethics and undergraduate education were able to see the patterns our research found in and around campus.
""Also, about 60 percent of the workshop's content was from external contributors which gave us an opportunity to learn how ethical education is approached on campuses around the world,"" he said.
Forty-five universities, including six European institutions, were represented at the June workshop, exploring such topics as ethical identities, professional ethics, ethical infrastructures, ethics and artificial intelligence, and much more.
""We are working on ethical questions in Switzerland too, but it's very nice to see a project in a very advanced stage,"" said Vladimir Macko, a researcher at the University of Neuchatel. ""It's a nice reference for us to see these issues studied on a large scale at an institution like Virgina Tech. One of the things I will be taking home is how we could apply this to European universities.""
A post-conference survey found the event, called the CCE STEM Summer Workshop, was extremely well received with respondents rating it 4.67 out of a potential five points.
""I've been really inspired and energized because it is so exciting to see people working on a really important issue from such an incredible range of perspectives and topics,"" said Amanda Kellogg, associate professor of English at Radford University. ""There are people here who are in engineering education, but we're also talking about AI and faculty development - it's just great to see a group of people come together.""
The National Science Foundation (NSF) is an independent federal agency with an annual budget of more than $8 billion that provides grants to support all fields of science and engineering. The grants account for about 25 percent of the federal support to America's colleges and universities, funding more than 300,000 researchers at 2,000 universities.
The project's abstract, titled ""Institutional Transformation: Cultivating an Ethical STEM Culture Through an Integrated Undergraduate General Education,"" can be found on the NSF website. Since 2017, the project has received $711,203 in funding.
In addition to Bairaktarova, Biscotte, and Staley, researchers included Kojo Akrong, Talha Bin Asad, Hesam Hosseinpour, Karen Gilbert, Jill Sible, Sam Snyder, and Hao Wang.
The team plans to continue to publish its results next year on student and faculty perceptions of ethics and ethics education as well as the faculty social network that guides programmatic change.
""This work has been extremely valuable also because for our graduating engineering students, their education should be grounded in ethical reasoning as much as in their technical training,"" said Bairaktarova. ""Hopefully, after they leave the university and start their careers, being ethical will become part of their professional identity. ""
* * *
Original text here: https://news.vt.edu/articles/2023/07/PGE-COE-NSF-GRANT.html
Contact: Dave Guerin, 540/231-0871, dwguerin@vt.edu
MSTRUCK-8224497 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: CONFERENCES & CONVENTIONS (90%); ETHICS (90%); GOVERNMENT RESEARCH FUNDING (90%); INVESTIGATIONS (90%); SCIENCE FUNDING (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); CURRICULA (89%); ENGINEERING (89%); TEACHING & TEACHERS (89%); COLLEGES & UNIVERSITIES (78%); EDUCATIONAL INSTITUTION EMPLOYEES (78%); GRANTS & GIFTS (78%); STEM EDUCATION (78%); VOCATIONAL & TECHNICAL TRAINING (78%); CIVIL ENGINEERING (77%); MATERIALS SCIENCE & TECHNOLOGY (73%); SCIENCE & TECHNOLOGY (73%); UNIVERSITY ADMINISTRATION (72%)
Organization: NATIONAL SCIENCE FOUNDATION (91%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); ENGINEERING (89%); COLLEGES & UNIVERSITIES (78%); VOCATIONAL & TECHNICAL TRAINING (78%); CIVIL ENGINEERING (77%); FOCUS GROUPS (73%); MANUFACTURING (73%)
Geographic: VIRGINIA, USA (79%)
Load-Date: July 25, 2023",neutral,0.9012523293495178,balanced/neutral,['agency'],[],['should'],[],1,0,1,0
2023,Unknown Title,"Body
Barton: Australian Medical Association has issued the following news release:
This year ’ s Governance Institute of Australia ’ s Ethics Index highlights the AMA ’ s continued strength as one of the most trusted ethical member associations in Australia. Running a very close second to Choice, the AMA ’ s ethics rating continues to rise with a net ethical rating of 56, up 3 from last year. The Ethics Index is an annual nationwide survey measuring perceptions of ethical issues and conduct in Australian society, providing a glimpse of what Australians consider the most and least ethical occupations, organisations and sectors, plus the top ethical challenges of the future.
The survey found the importance of ethics is at an all-time high with a rating of 84 amongst the Australian community with the health sector the only one rated as perceived to be very ethical with a net score of 66 amongst a range of broad sectors (such as education, the public sector and government).
The top ethical challenges for 2024 have implications for healthcare and include the rising cost of living and the impacts of inflation (including housing and healthcare) at 54 per cent, followed by cybersecurity breaches and privacy protection at 37 per cent and, not surprisingly, the increasing use of artificial intelligence at 31 per cent which also tied with embryo experimentation as the most ethically challenging and difficult future development to navigate.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (93%); ASSOCIATIONS & ORGANIZATIONS (92%); BIOETHICS (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (78%); HEALTH CARE SECTOR PERFORMANCE (78%); POLLS & SURVEYS (76%); COST OF LIVING (72%); ARTIFICIAL INTELLIGENCE (51%); DATA BREACHES (51%)
Industry: HEALTH CARE (90%); HEALTH CARE SECTOR PERFORMANCE (78%); CYBERSECURITY (71%); INFORMATION SECURITY & PRIVACY (71%); ARTIFICIAL INTELLIGENCE (51%); DATA BREACHES (51%)
Geographic: AUSTRALIA (93%)
Load-Date: September 25, 2023","Barton: Australian Medical Association has issued the following news release:
This year ’ s Governance Institute of Australia ’ s Ethics Index highlights the AMA ’ s continued strength as one of the most trusted ethical member associations in Australia. Running a very close second to Choice, the AMA ’ s ethics rating continues to rise with a net ethical rating of 56, up 3 from last year. The Ethics Index is an annual nationwide survey measuring perceptions of ethical issues and conduct in Australian society, providing a glimpse of what Australians consider the most and least ethical occupations, organisations and sectors, plus the top ethical challenges of the future.
The survey found the importance of ethics is at an all-time high with a rating of 84 amongst the Australian community with the health sector the only one rated as perceived to be very ethical with a net score of 66 amongst a range of broad sectors (such as education, the public sector and government).
The top ethical challenges for 2024 have implications for healthcare and include the rising cost of living and the impacts of inflation (including housing and healthcare) at 54 per cent, followed by cybersecurity breaches and privacy protection at 37 per cent and, not surprisingly, the increasing use of artificial intelligence at 31 per cent which also tied with embryo experimentation as the most ethically challenging and difficult future development to navigate.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (93%); ASSOCIATIONS & ORGANIZATIONS (92%); BIOETHICS (78%); BUSINESS & PROFESSIONAL ASSOCIATIONS (78%); HEALTH CARE SECTOR PERFORMANCE (78%); POLLS & SURVEYS (76%); COST OF LIVING (72%); ARTIFICIAL INTELLIGENCE (51%); DATA BREACHES (51%)
Industry: HEALTH CARE (90%); HEALTH CARE SECTOR PERFORMANCE (78%); CYBERSECURITY (71%); INFORMATION SECURITY & PRIVACY (71%); ARTIFICIAL INTELLIGENCE (51%); DATA BREACHES (51%)
Geographic: AUSTRALIA (93%)
Load-Date: September 25, 2023",positive,0.5754056572914124,balanced/neutral,"['privacy', 'security']",[],['governance'],[],2,0,1,0
2023,Unknown Title,"Body
In a world increasingly driven by technology and automation, Artificial Intelligence is shaping a number of emerging occupations that raise questions about the skills and knowledge needed to excel in these professions of the future. In this article we will tell you what you should know about this topic.
WHAT ARE THE 6 NEW JOBS THAT HAVE BEEN CREATED BY ARTIFICIAL INTELLIGENCE?
Artificial Intelligence has revolutionized the way we live and work, and is not only changing the way we perform our daily tasks, but is also creating new jobs and roles in the working world.
As AI becomes an integral part of our lives, career opportunities are emerging that were previously unthinkable. Here are six of the new jobs created thanks to AI:
1. Prompts engineer: designing instructions 2.
2. Artificial intelligence researcher
3. Natural language processing expert
4. Robotic process automation expert
5. Algorithm auditor
6. AI ethics and law specialist
WHAT PREPARATION IS NEEDED FOR THE 6 NEW JOBS CREATED BY IA
Here's what it takes to prepare for and excel in these six new AI-generated jobs:
1. prompts engineer: designing prompts 2.
Prompt engineers are essential to ensure the accuracy of the instructions used to train generative AI tools. Their job focuses on designing prompts, requests or premises that enable AI to understand and generate accurate results. The key to success in this role lies in the quality of the instructions developed. Although some see this work as temporary due to the rapid advancement of AI, it is still crucial for optimal results. Training in programming and a thorough understanding of AI are essential.
2. Artificial intelligence researcher
AI researchers are dedicated to achieving peak levels of innovation by applying AI to solve problems and overcome constraints in various organizations. This occupation requires solid technical skills, but also soft skills such as emotional intelligence and critical thinking to generate new ideas and approaches. A background in computer science or related fields is typically required to enter this profession.
3. Natural language processing expert
Natural language processing (NLP) experts are masters in human language processing and support AI-related software development. In addition to a solid understanding of the technology, a specialization in NLP enriches the profile of these professionals. The intersection of humanistic and technological disciplines is essential to build effective applications such as chatbots.
4. Expert in robotic process automation
Robotic Process Automation (RPA) experts manage software systems that automate repetitive tasks in companies. Specializations in programming and RPA are fundamental to this role. RPA adoption is associated with productivity gains and business benefits by automating a variety of tasks, from inventory management to data transfer.
5. Algorithm Auditor
Algorithm auditors review systems and applications to ensure that algorithms are transparent and fair, without discriminatory bias. This occupation requires an understanding of both technical and ethical issues, and works closely with data scientists to ensure integrity and fairness in algorithms. A strong background in AI and technology ethics is essential.
6. AI ethics and law specialist
With the proliferation of AI, the need arises for specialists in ethics and law who can address the legal and ethical challenges associated with this technology. These professionals must understand both the legal and technological worlds to ensure that AI is used ethically and responsibly, avoiding legal and social risks. A background in law and a thorough understanding of ethical principles are crucial to excel in this field.
As these emerging occupations continue to transform the intersection of technology and human labor, it is clear that constant adaptation and a focus on training are essential to maximize the potential of AI for the benefit of society. Proper preparation is the key to opening the doors to these exciting job opportunities in the age of AI.
WHAT IS ARTIFICIAL INTELLIGENCE
Artificial intelligence is a field of computer and data science that focuses on creating systems and programs capable of performing tasks that, when executed by humans, require intelligence and reasoning. These AI systems are designed to learn, adapt and improve as they are exposed to additional data and experiences. In essence, AI seeks to mimic human cognitive ability, enabling machines to make decisions, understand natural language, recognize patterns and solve complex problems autonomously.
AI approaches include machine learning, where machines can learn from data without being explicitly programmed, natural language processing, which enables computers to understand and communicate in human language, and computer vision, which trains machines to interpret and analyze images and videos. AI has a wide range of applications in diverse industries, from healthcare and automotive to customer service and weather prediction, and its continued growth is transforming the way we interact with technology and the world around us.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: EMPLOYMENT GROWTH (93%); JOB CREATION (91%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); NATURAL LANGUAGE PROCESSING (89%); PROFESSIONAL WORKERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CHATBOTS (78%); COMPUTER SCIENCE (78%); DATA SCIENCE (78%); ETHICS (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); EMOTIONAL INTELLIGENCE (73%); PRODUCTIVITY (72%); INTELLIGENCE & COGNITION (62%); EMOTIONS (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); ROBOTIC PROCESS AUTOMATION (89%); COMPUTER SOFTWARE (86%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CHATBOTS (78%); COMPUTER SCIENCE (78%); DATA SCIENCE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); SOFTWARE DEVELOPMENT & ENGINEERING (74%)
Load-Date: September 14, 2023","In a world increasingly driven by technology and automation, Artificial Intelligence is shaping a number of emerging occupations that raise questions about the skills and knowledge needed to excel in these professions of the future. In this article we will tell you what you should know about this topic.
WHAT ARE THE 6 NEW JOBS THAT HAVE BEEN CREATED BY ARTIFICIAL INTELLIGENCE?
Artificial Intelligence has revolutionized the way we live and work, and is not only changing the way we perform our daily tasks, but is also creating new jobs and roles in the working world.
As AI becomes an integral part of our lives, career opportunities are emerging that were previously unthinkable. Here are six of the new jobs created thanks to AI:
1. Prompts engineer: designing instructions 2.
2. Artificial intelligence researcher
3. Natural language processing expert
4. Robotic process automation expert
5. Algorithm auditor
6. AI ethics and law specialist
WHAT PREPARATION IS NEEDED FOR THE 6 NEW JOBS CREATED BY IA
Here's what it takes to prepare for and excel in these six new AI-generated jobs:
1. prompts engineer: designing prompts 2.
Prompt engineers are essential to ensure the accuracy of the instructions used to train generative AI tools. Their job focuses on designing prompts, requests or premises that enable AI to understand and generate accurate results. The key to success in this role lies in the quality of the instructions developed. Although some see this work as temporary due to the rapid advancement of AI, it is still crucial for optimal results. Training in programming and a thorough understanding of AI are essential.
2. Artificial intelligence researcher
AI researchers are dedicated to achieving peak levels of innovation by applying AI to solve problems and overcome constraints in various organizations. This occupation requires solid technical skills, but also soft skills such as emotional intelligence and critical thinking to generate new ideas and approaches. A background in computer science or related fields is typically required to enter this profession.
3. Natural language processing expert
Natural language processing (NLP) experts are masters in human language processing and support AI-related software development. In addition to a solid understanding of the technology, a specialization in NLP enriches the profile of these professionals. The intersection of humanistic and technological disciplines is essential to build effective applications such as chatbots.
4. Expert in robotic process automation
Robotic Process Automation (RPA) experts manage software systems that automate repetitive tasks in companies. Specializations in programming and RPA are fundamental to this role. RPA adoption is associated with productivity gains and business benefits by automating a variety of tasks, from inventory management to data transfer.
5. Algorithm Auditor
Algorithm auditors review systems and applications to ensure that algorithms are transparent and fair, without discriminatory bias. This occupation requires an understanding of both technical and ethical issues, and works closely with data scientists to ensure integrity and fairness in algorithms. A strong background in AI and technology ethics is essential.
6. AI ethics and law specialist
With the proliferation of AI, the need arises for specialists in ethics and law who can address the legal and ethical challenges associated with this technology. These professionals must understand both the legal and technological worlds to ensure that AI is used ethically and responsibly, avoiding legal and social risks. A background in law and a thorough understanding of ethical principles are crucial to excel in this field.
As these emerging occupations continue to transform the intersection of technology and human labor, it is clear that constant adaptation and a focus on training are essential to maximize the potential of AI for the benefit of society. Proper preparation is the key to opening the doors to these exciting job opportunities in the age of AI.
WHAT IS ARTIFICIAL INTELLIGENCE
Artificial intelligence is a field of computer and data science that focuses on creating systems and programs capable of performing tasks that, when executed by humans, require intelligence and reasoning. These AI systems are designed to learn, adapt and improve as they are exposed to additional data and experiences. In essence, AI seeks to mimic human cognitive ability, enabling machines to make decisions, understand natural language, recognize patterns and solve complex problems autonomously.
AI approaches include machine learning, where machines can learn from data without being explicitly programmed, natural language processing, which enables computers to understand and communicate in human language, and computer vision, which trains machines to interpret and analyze images and videos. AI has a wide range of applications in diverse industries, from healthcare and automotive to customer service and weather prediction, and its continued growth is transforming the way we interact with technology and the world around us.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: EMPLOYMENT GROWTH (93%); JOB CREATION (91%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); NATURAL LANGUAGE PROCESSING (89%); PROFESSIONAL WORKERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CHATBOTS (78%); COMPUTER SCIENCE (78%); DATA SCIENCE (78%); ETHICS (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); EMOTIONAL INTELLIGENCE (73%); PRODUCTIVITY (72%); INTELLIGENCE & COGNITION (62%); EMOTIONS (50%)
Industry: ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); ROBOTIC PROCESS AUTOMATION (89%); COMPUTER SOFTWARE (86%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CHATBOTS (78%); COMPUTER SCIENCE (78%); DATA SCIENCE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); SOFTWARE DEVELOPMENT & ENGINEERING (74%)
Load-Date: September 14, 2023",neutral,0.4946027994155884,balanced/neutral,"['bias', 'fairness']",['fairness'],"['regulation', 'policy', 'law', 'should', 'must']","['machine learning', 'generative ai', 'computer vision', 'natural language processing', 'nlp', 'algorithm']",2,1,5,6
2023,Unknown Title,"Dateline: AUSTIN, Texas, Dec. 20, 2023 
Body
PR NewswireNew EAIC members represent Program/MGA/Reinsurance Insurance, Workers' Compensation, Geospatial Risk Analytics, and Connected Car Solutions/Auto InsuranceAUSTIN, Texas, Dec. 20, 2023 /PRNewswire-PRWeb/ -- The Ethical AI in Insurance Consortium (EAIC), which aims to foster responsible and transparent adoption of artificial intelligence (AI) for decision management in the insurance sector, is announcing new members MS Transverse Insurance Group, the Pennsylvania Compensation Rating Bureau (PCRB), Geospatial expert from Verisk Analytics – Todd Barr, Connected Car and Next Generation Auto Insurance expert from Telenav and Novo Insurance - Kumar Maddali, and Ogon Consulting. Additionally, the EAIC has just completed its survey of insurance and reinsurance executives determining attitudes, readiness, and use of AI that it announced during InsureTechConnect, and will be sharing the results in Q1 2024.""We are pleased to join the Ethical AI in Insurance Consortium, a collective force shaping the future of responsible AI adoption in our industry,"" said John Williams, Senior Vice President and Head of Operations at MS Transverse Insurance Group. ""Our company believes that fostering transparency, ethical guidelines, and collaboration is critical in ensuring the responsible integration of AI. 
By uniting with other industry leaders in the EAIC, we will drive a vision of using AI to enhance operational efficiency and effectiveness while upholding the highest standards of integrity, fairness, and accountability.""Bill Taylor, President and CEO of PCRB said, ""As a data collection organization for the workers' compensation industry, we are always interested in how technology is evolving. With the emergence of AI, we all have different levels of interest and concerns. The Consortium's mission is focused on the ethical use of AI tools and components, which is a philosophy that aligns closely with our mission of more than 100 years to be a trusted, essential, and objective industry resource.""""With over two decades of experience in the Geospatial field, including roles in Intelligence and Defense, Emergency Response, and Public Health, I have witnessed the transformative power of geospatial analytics in understanding and mitigating the impact of natural and man-made events,"" said Todd Barr, Director of Geospatial Product and Solutions at Verisk. ""My expertise collaborating with scientists and risk analysts to model the financial impact of extreme insurance events including natural disasters and impacts of climate change will provide another unique angle to the importance of ethical AI in the insurance industry.""Kumar Maddali, Vice President of Product Development at Telenav and Novo Insurance added, ""For nearly 30 years I have sparked innovation for leading insurtech and enterprise technologies companies. While focusing on developing next generation Connected Car solutions and Auto Insurance products, I have seen the responsibility the insured has entrusted the industry with as companies work to responsibly leverage AI. The EAIC is an innovative organization that can foster the trust the insured demands by developing rigorous standards and guidelines, complete with checks and balances, for entities that create AI services.""""Our participation in the Ethical AI in Insurance Consortium collaborative platform enables us to collaborate with industry leaders,"" said Karthick Gopalakrishnan, Director of Technical Consulting for Ogon Consulting. ""Together, we aim to set industry-wide standards and work closely with our customer base to guarantee the equitable and responsible deployment of artificial intelligence technologies within the insurance sector.""The EAIC now has 17 members, and the Consortium remains steadfast in its core objectives, which include the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, and promoting standardization within the sector. The Consortium is dedicated to ensuring fairness, transparency, and accountability in the use of AI across crucial functions in the insurance industry, such as underwriting, claims processing, and pricing.The EAIC looks forward to revealing the research findings and recommendations of its AI research report in Q1 2024. A live webinar coinciding with the launch of the research report will provide an opportunity for industry stakeholders to engage in a meaningful dialogue about the responsible integration of AI in insurance practices.""We are thrilled to welcome these outstanding organizations and technology thought leaders to the EAIC,"" said Michael Schwabrow, EVP of Sales and Marketing for Cloverleaf Analytics. ""Their diverse expertise and commitment to ethical AI practices will undoubtedly strengthen our collective efforts to address the challenges and opportunities associated with AI across the insurance sector. As we continue to expand our membership, we are confident that the EAIC will play a pivotal role in shaping the future of responsible AI adoption in insurance.""To join the EAIC, submit a request on the website –https://ethicalaiininsuranceconsortium.org/.About the Ethical AI in Insurance Consortium (EAIC)The Ethical AI in Insurance Consortium is a collaborative platform dedicated to promoting responsible and ethical adoption of artificial intelligence (AI) in the insurance industry. We bring together insurers, insurtechs, influencers, and other stakeholders to establish industry-wide standards, foster transparency, and ensure fair and accountable use of AI technologies.Media ContactMichael Schwabrow, Cloverleaf Analytics, 1 512-361-7173 2121,mschwabrow@cloverleafanalytics.com, Cloverleaf Analytics   View original content to download multimedia:https://www.prweb.com/releases/ethical-ai-in-insurance-consortium-welcomes-five-new-members-to-further-advance-responsible-ai-in-different-sectors-of-the-insurance-industry-302019929.htmlSOURCE Ethical AI in Insurance Consortium 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); ETHICS (90%); EXECUTIVES (90%); INSURANCE TECHNOLOGY (90%); WORKERS COMPENSATION (89%); PRESS RELEASES (79%); GEOSPATIAL DATA (78%); PRODUCT DEVELOPMENT (78%); RISK MANAGEMENT (78%); ACCIDENTS & DISASTERS (73%); INTELLIGENCE SERVICES (71%); SAFETY, ACCIDENTS & DISASTERS (68%); PUBLIC HEALTH (65%); NATURAL DISASTERS (61%); NEGATIVE NEWS (61%); CLIMATE CHANGE (60%); PRWEB (%)
Company:  VERISK ANALYTICS INC (57%);  TELENAV INC (57%); Ethical AI in Insurance Consortium
Ticker: VRSK (NASDAQ) (57%)
Industry: NAICS518210 COMPUTING INFRASTRUCTURE PROVIDERS, DATA PROCESSING, WEB HOSTING, AND RELATED SERVICES (57%); SIC4899 COMMUNICATIONS SERVICES, NEC (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); INSURANCE (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); INSURANCE TECHNOLOGY (90%); GEOSPATIAL DATA (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); RISK MANAGEMENT (78%); INS Insurance (%); CPR Computer; Electronics Products (%); FIN Banking; Financial Services (%)
Geographic: AUSTIN, TX, USA (79%); TEXAS, USA (93%); Texas
Load-Date: December 20, 2023","PR NewswireNew EAIC members represent Program/MGA/Reinsurance Insurance, Workers' Compensation, Geospatial Risk Analytics, and Connected Car Solutions/Auto InsuranceAUSTIN, Texas, Dec. 20, 2023 /PRNewswire-PRWeb/ -- The Ethical AI in Insurance Consortium (EAIC), which aims to foster responsible and transparent adoption of artificial intelligence (AI) for decision management in the insurance sector, is announcing new members MS Transverse Insurance Group, the Pennsylvania Compensation Rating Bureau (PCRB), Geospatial expert from Verisk Analytics – Todd Barr, Connected Car and Next Generation Auto Insurance expert from Telenav and Novo Insurance - Kumar Maddali, and Ogon Consulting. Additionally, the EAIC has just completed its survey of insurance and reinsurance executives determining attitudes, readiness, and use of AI that it announced during InsureTechConnect, and will be sharing the results in Q1 2024.""We are pleased to join the Ethical AI in Insurance Consortium, a collective force shaping the future of responsible AI adoption in our industry,"" said John Williams, Senior Vice President and Head of Operations at MS Transverse Insurance Group. ""Our company believes that fostering transparency, ethical guidelines, and collaboration is critical in ensuring the responsible integration of AI. 
By uniting with other industry leaders in the EAIC, we will drive a vision of using AI to enhance operational efficiency and effectiveness while upholding the highest standards of integrity, fairness, and accountability.""Bill Taylor, President and CEO of PCRB said, ""As a data collection organization for the workers' compensation industry, we are always interested in how technology is evolving. With the emergence of AI, we all have different levels of interest and concerns. The Consortium's mission is focused on the ethical use of AI tools and components, which is a philosophy that aligns closely with our mission of more than 100 years to be a trusted, essential, and objective industry resource.""""With over two decades of experience in the Geospatial field, including roles in Intelligence and Defense, Emergency Response, and Public Health, I have witnessed the transformative power of geospatial analytics in understanding and mitigating the impact of natural and man-made events,"" said Todd Barr, Director of Geospatial Product and Solutions at Verisk. ""My expertise collaborating with scientists and risk analysts to model the financial impact of extreme insurance events including natural disasters and impacts of climate change will provide another unique angle to the importance of ethical AI in the insurance industry.""Kumar Maddali, Vice President of Product Development at Telenav and Novo Insurance added, ""For nearly 30 years I have sparked innovation for leading insurtech and enterprise technologies companies. While focusing on developing next generation Connected Car solutions and Auto Insurance products, I have seen the responsibility the insured has entrusted the industry with as companies work to responsibly leverage AI. The EAIC is an innovative organization that can foster the trust the insured demands by developing rigorous standards and guidelines, complete with checks and balances, for entities that create AI services.""""Our participation in the Ethical AI in Insurance Consortium collaborative platform enables us to collaborate with industry leaders,"" said Karthick Gopalakrishnan, Director of Technical Consulting for Ogon Consulting. ""Together, we aim to set industry-wide standards and work closely with our customer base to guarantee the equitable and responsible deployment of artificial intelligence technologies within the insurance sector.""The EAIC now has 17 members, and the Consortium remains steadfast in its core objectives, which include the development of ethical technology guidelines, strong advocacy for insurers and the insured, fostering collaboration and knowledge-sharing, and promoting standardization within the sector. The Consortium is dedicated to ensuring fairness, transparency, and accountability in the use of AI across crucial functions in the insurance industry, such as underwriting, claims processing, and pricing.The EAIC looks forward to revealing the research findings and recommendations of its AI research report in Q1 2024. A live webinar coinciding with the launch of the research report will provide an opportunity for industry stakeholders to engage in a meaningful dialogue about the responsible integration of AI in insurance practices.""We are thrilled to welcome these outstanding organizations and technology thought leaders to the EAIC,"" said Michael Schwabrow, EVP of Sales and Marketing for Cloverleaf Analytics. ""Their diverse expertise and commitment to ethical AI practices will undoubtedly strengthen our collective efforts to address the challenges and opportunities associated with AI across the insurance sector. As we continue to expand our membership, we are confident that the EAIC will play a pivotal role in shaping the future of responsible AI adoption in insurance.""To join the EAIC, submit a request on the website –https://ethicalaiininsuranceconsortium.org/.About the Ethical AI in Insurance Consortium (EAIC)The Ethical AI in Insurance Consortium is a collaborative platform dedicated to promoting responsible and ethical adoption of artificial intelligence (AI) in the insurance industry. We bring together insurers, insurtechs, influencers, and other stakeholders to establish industry-wide standards, foster transparency, and ensure fair and accountable use of AI technologies.Media ContactMichael Schwabrow, Cloverleaf Analytics, 1 512-361-7173 2121,mschwabrow@cloverleafanalytics.com, Cloverleaf Analytics   View original content to download multimedia:https://www.prweb.com/releases/ethical-ai-in-insurance-consortium-welcomes-five-new-members-to-further-advance-responsible-ai-in-different-sectors-of-the-insurance-industry-302019929.htmlSOURCE Ethical AI in Insurance Consortium 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); ETHICS (90%); EXECUTIVES (90%); INSURANCE TECHNOLOGY (90%); WORKERS COMPENSATION (89%); PRESS RELEASES (79%); GEOSPATIAL DATA (78%); PRODUCT DEVELOPMENT (78%); RISK MANAGEMENT (78%); ACCIDENTS & DISASTERS (73%); INTELLIGENCE SERVICES (71%); SAFETY, ACCIDENTS & DISASTERS (68%); PUBLIC HEALTH (65%); NATURAL DISASTERS (61%); NEGATIVE NEWS (61%); CLIMATE CHANGE (60%); PRWEB (%)
Company:  VERISK ANALYTICS INC (57%);  TELENAV INC (57%); Ethical AI in Insurance Consortium
Ticker: VRSK (NASDAQ) (57%)
Industry: NAICS518210 COMPUTING INFRASTRUCTURE PROVIDERS, DATA PROCESSING, WEB HOSTING, AND RELATED SERVICES (57%); SIC4899 COMMUNICATIONS SERVICES, NEC (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); INSURANCE (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ANALYTICS (90%); DATA ANALYTICS (90%); INSURANCE TECHNOLOGY (90%); GEOSPATIAL DATA (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); RISK MANAGEMENT (78%); INS Insurance (%); CPR Computer; Electronics Products (%); FIN Banking; Financial Services (%)
Geographic: AUSTIN, TX, USA (79%); TEXAS, USA (93%); Texas
Load-Date: December 20, 2023",neutral,0.7802118062973022,balanced/neutral,"['fairness', 'transparency', 'accountability', 'safety']",['fairness'],"['standards', 'guidelines']",[],4,1,2,0
2023,Unknown Title,"Body
Essential ethical practices for students using artificial intelligence (AI) in their education have been explored by young learners at the 2023 WISE, through a session led by Qatar Foundation (QF)'s Akhlaquna initiative.
The global conference on the future of education, hosted by QF's education think tank WISE at the Qatar National Convention Centre (QNCC), featured a discussion on *Artificial Intelligence and the challenges of Education and Ethics* on the summit's Youth Studio platform, which also aimed to increase awareness of AI advantages in learning, and showcase different applications that help students form basic educational principles.
Six secondary and university students, including the StudyRoad team who took second place in the 2023 Akhlaquna Award along with university students from various tech fields, participated in the session to share their perspectives on AI, education, and ethics.
The Akhlaquna initiative, which falls under QF's Pre-University Education, highlights the relationship between knowledge and ethics, advocates for ethics as a pillar for success in life, and recognises those whose projects and behaviours exemplify strong moral and ethical character.
Farah Emad al-Zubi, a 16-year-old student at Al-Sailiyah Secondary Independent School and a member of the StudyRoad team that won the Akhlaquna Award, told the session: ""As AI intersects with education, it enhances learning experiences by offering personalised educational content for each student, tailored through an analysis of their individual behaviour and educational needs.”
""AI's reliance on big data analysis is key, as it allows monitoring of student interests and needs, leading to the development of suitable educational material,” she said.
Al-Zubi also emphasised how AI can support shared learning experiences by providing platforms that connect students and teachers, and discussed the ethics of AI, covering topics like justice, equality, transparency, and privacy, as well as credibility and quality.
""In educational AI applications, we must ensure fairness and equality for all students, maintain transparency in how AI operates, and protect student privacy and data,” she said. “Additionally, AI-generated information and recommendations should be reliable and scientifically sound.”
Jana Yaman Hasnawi, 17-year-old student at Al-Sailiyah Secondary Independent School and another member of the StudyRoad team, spoke about the future of AI: ""The continuous progress in machine learning and network technologies is expected to greatly enhance system capabilities, leading to improved efficiency in AI's data processing and decision-making functions.""
One of the session's speakers, Fatima Naqadan, a computer science student at Qatar University, heads a startup focused on AI programme development.
She also delivers lectures on AI ethics.
“There is indeed a significant connection between ethics and artificial intelligence, particularly when we consider the role of developers,” Naqadan said.
“Developers bear a crucial responsibility for integrating ethical considerations into the design and development of AI technologies,” she said. “This responsibility encompasses ensuring transparency in the workings of algorithms, fostering fairness in the outcomes produced by AI, actively working to prevent any form of discrimination, and rigorously protecting user privacy.”
 Gulf Times Newspaper 2022  
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 183
Subject: ETHICS (93%); STUDENTS & STUDENT LIFE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COMPUTER SCIENCE (78%); CONFERENCES & CONVENTIONS (78%); DATA ANALYTICS (78%); RESEARCH & DEVELOPMENT (78%); TEACHING MATERIALS & MEDIA (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); RESEARCH INSTITUTES (72%)
Company:  ESSENTIAL UTILITIES INC (59%)
Ticker: WTRG (NYSE) (59%)
Industry: NAICS221310 WATER SUPPLY & IRRIGATION SYSTEMS (59%); SIC4941 WATER SUPPLY (59%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); BIG DATA (64%)
Geographic: QATAR (88%)
Load-Date: November 28, 2023","Essential ethical practices for students using artificial intelligence (AI) in their education have been explored by young learners at the 2023 WISE, through a session led by Qatar Foundation (QF)'s Akhlaquna initiative.
The global conference on the future of education, hosted by QF's education think tank WISE at the Qatar National Convention Centre (QNCC), featured a discussion on *Artificial Intelligence and the challenges of Education and Ethics* on the summit's Youth Studio platform, which also aimed to increase awareness of AI advantages in learning, and showcase different applications that help students form basic educational principles.
Six secondary and university students, including the StudyRoad team who took second place in the 2023 Akhlaquna Award along with university students from various tech fields, participated in the session to share their perspectives on AI, education, and ethics.
The Akhlaquna initiative, which falls under QF's Pre-University Education, highlights the relationship between knowledge and ethics, advocates for ethics as a pillar for success in life, and recognises those whose projects and behaviours exemplify strong moral and ethical character.
Farah Emad al-Zubi, a 16-year-old student at Al-Sailiyah Secondary Independent School and a member of the StudyRoad team that won the Akhlaquna Award, told the session: ""As AI intersects with education, it enhances learning experiences by offering personalised educational content for each student, tailored through an analysis of their individual behaviour and educational needs.”
""AI's reliance on big data analysis is key, as it allows monitoring of student interests and needs, leading to the development of suitable educational material,” she said.
Al-Zubi also emphasised how AI can support shared learning experiences by providing platforms that connect students and teachers, and discussed the ethics of AI, covering topics like justice, equality, transparency, and privacy, as well as credibility and quality.
""In educational AI applications, we must ensure fairness and equality for all students, maintain transparency in how AI operates, and protect student privacy and data,” she said. “Additionally, AI-generated information and recommendations should be reliable and scientifically sound.”
Jana Yaman Hasnawi, 17-year-old student at Al-Sailiyah Secondary Independent School and another member of the StudyRoad team, spoke about the future of AI: ""The continuous progress in machine learning and network technologies is expected to greatly enhance system capabilities, leading to improved efficiency in AI's data processing and decision-making functions.""
One of the session's speakers, Fatima Naqadan, a computer science student at Qatar University, heads a startup focused on AI programme development.
She also delivers lectures on AI ethics.
“There is indeed a significant connection between ethics and artificial intelligence, particularly when we consider the role of developers,” Naqadan said.
“Developers bear a crucial responsibility for integrating ethical considerations into the design and development of AI technologies,” she said. “This responsibility encompasses ensuring transparency in the workings of algorithms, fostering fairness in the outcomes produced by AI, actively working to prevent any form of discrimination, and rigorously protecting user privacy.”
 Gulf Times Newspaper 2022  
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 183
Subject: ETHICS (93%); STUDENTS & STUDENT LIFE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COMPUTER SCIENCE (78%); CONFERENCES & CONVENTIONS (78%); DATA ANALYTICS (78%); RESEARCH & DEVELOPMENT (78%); TEACHING MATERIALS & MEDIA (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); RESEARCH INSTITUTES (72%)
Company:  ESSENTIAL UTILITIES INC (59%)
Ticker: WTRG (NYSE) (59%)
Industry: NAICS221310 WATER SUPPLY & IRRIGATION SYSTEMS (59%); SIC4941 WATER SUPPLY (59%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COMPUTER SCIENCE (78%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); BIG DATA (64%)
Geographic: QATAR (88%)
Load-Date: November 28, 2023",neutral,0.6193068623542786,balanced/neutral,"['privacy', 'discrimination', 'fairness', 'transparency']","['character', 'justice', 'fairness', 'equality', 'justice']","['should', 'must']","['machine learning', 'generative ai']",4,5,2,2
2023,Unknown Title,"Dateline: HOBOKEN, N.J., Nov. 22, 2023 
Body
PR NewswireNYC area expert explains the challenges, key principles, and associated business benefits of data ethics and responsibility practices—in a new article from Messaging ArchitectsHOBOKEN, N.J., Nov. 22, 2023 /PRNewswire-PRWeb/ -- Messaging Architects, an eMazzanti Technologies Company andinformation governance expert, discuses data ethics and responsibility in a new article. The informative article first explains data ethics challenges, including misleading results from poor data quality, complex algorithms, and bias and discrimination.Treating data responsibly involves carefully considering the impact of data on individuals and society. While it brings important business benefits, it also requires strategy.The author then shares some key principles of data ethics and responsibility, including transparency, fairness, accountability, and privacy. 
He follows that by identifying several business benefits of ethical data practices, including increased customer loyalty and trust, compliance with regulations, improved operational efficiency, and increased competitive advantage.""Treating data responsibly involves carefully considering the impact of data on individuals and society,"" stated Greg Smith, Vice President of Services Delivery at Messaging Architects. ""While it brings important business benefits, it also requires strategy.""Below are a few excerpts from the article, ""Data Ethics and Responsibility Build Trust, Efficiency, and Competitive Advantage.""Data Ethics Challenges""Ethical dilemmas regarding data can result from poor data quality. Inaccurate, outdated, and incomplete data can lead to misleading results with negative consequences. The Enron scandal of 2001 provides one such example. In this case, fraudulent financial data caused the loss of billions of dollars in investments and thousands of lost jobs.""Key Principles of Data Ethics and Responsibility""Transparency – Businesses should be transparent about what data they collect, how they use it, and who they share it with. They should also provide clear and simple ways for customers to access or correct their data. Customers should also have the ability to opt out of data collection or processing.""""Fairness – Organizations should use data in a way that does not discriminate, exclude, or harm individuals or groups based on identity or preferences. They should also take care that data does not reinforce stereotypes or prejudices. This will require representative data collection and close attention to data quality.""Business Benefits of Ethical Data Practices""While organizations have a moral duty to handle data ethically, responsible data use also delivers business advantages. In the first place, transparency builds customer loyalty and trust, which enhances brand image. And the practices that provide the oversight necessary for accountability also help businesses comply withdata privacy lawsand regulations.""Information Governance ExpertsTo effectively govern data, organizations must know where that data originates, who owns and accesses it, where it lives, and how it is used. The data experts at Messaging Architects bring decades of experience ininformation governance consultingand solutions. Business leaders should contact them to begin developing comprehensive strategies designed to promote the ethical and responsible use of data.Have you read?Data Lineage Best Practices Enhance Data Quality and UsabilityData-driven Business Cultures Spark Innovation and Power Decision MakingAbout Messaging ArchitectsMessaging Architects specializes in effectively managing and securing an organization's most precious asset, its information. With over 20 years of information management and technology consulting experience, the Messaging Architects team has provided corporations, educational intuitions, health care facilities and nonprofits with methodologies, procedures, and technology to keep their data organized, compliant and secure.About eMazzanti TechnologieseMazzanti's team of trained, certified IT experts rapidly deliver increased revenue growth, data security and productivity for clients ranging from law firms to high-end global retailers, expertly providing advanced business cyber security, retail and payment technology, digital marketing services, AI, cloud and mobile solutions, multi-site implementations, 24×7 outsourced network management, remote monitoring, and support.eMazzanti's consistent growth landed them on the Inc. 5000 list 9X. Recognized as a 4X Microsoft Partner of the Year, the #1 ranked NYC area MSP, NJ Business of the Year, and 5X WatchGuard Partner of the Year, the company excels as a trusted outsourced IT partner! Contact: 1-866-362-9926,info@emazzanti.netorhttp://www.emazzanti.netTwitter: @emazzanti Facebook: Facebook.com/emazzantitechnologies.Media ContactKent Sorensen, Messaging Architects, 14803345403,kents@mstar.net,www.messagingarchitects.com  View original content to download multimedia:https://www.prweb.com/releases/data-ethics-and-responsibility-build-trust-efficiency-and-competitive-advantage-301995475.htmlSOURCE Messaging Architects 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ASSOCIATIONS & ORGANIZATIONS (89%); PRESS RELEASES (79%); BEST PRACTICES (78%); CORPORATE WRONGDOING (78%); DISCRIMINATION (76%); NEGATIVE SOCIETAL NEWS (76%); BRANDING (74%); SCANDALS (73%); NEGATIVE MISC NEWS (71%); BRAND EQUITY (68%); PRWEB (%)
Company:  ENRON CREDITORS RECOVERY CORP (54%); Messaging Architects
Industry: SIC4911 ELECTRIC SERVICES (54%); DATA GOVERNANCE & STEWARDSHIP (89%); BRANDING (74%); BRAND EQUITY (68%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Geographic: NEW JERSEY, USA (89%); New Jersey
Load-Date: November 22, 2023","PR NewswireNYC area expert explains the challenges, key principles, and associated business benefits of data ethics and responsibility practices—in a new article from Messaging ArchitectsHOBOKEN, N.J., Nov. 22, 2023 /PRNewswire-PRWeb/ -- Messaging Architects, an eMazzanti Technologies Company andinformation governance expert, discuses data ethics and responsibility in a new article. The informative article first explains data ethics challenges, including misleading results from poor data quality, complex algorithms, and bias and discrimination.Treating data responsibly involves carefully considering the impact of data on individuals and society. While it brings important business benefits, it also requires strategy.The author then shares some key principles of data ethics and responsibility, including transparency, fairness, accountability, and privacy. 
He follows that by identifying several business benefits of ethical data practices, including increased customer loyalty and trust, compliance with regulations, improved operational efficiency, and increased competitive advantage.""Treating data responsibly involves carefully considering the impact of data on individuals and society,"" stated Greg Smith, Vice President of Services Delivery at Messaging Architects. ""While it brings important business benefits, it also requires strategy.""Below are a few excerpts from the article, ""Data Ethics and Responsibility Build Trust, Efficiency, and Competitive Advantage.""Data Ethics Challenges""Ethical dilemmas regarding data can result from poor data quality. Inaccurate, outdated, and incomplete data can lead to misleading results with negative consequences. The Enron scandal of 2001 provides one such example. In this case, fraudulent financial data caused the loss of billions of dollars in investments and thousands of lost jobs.""Key Principles of Data Ethics and Responsibility""Transparency – Businesses should be transparent about what data they collect, how they use it, and who they share it with. They should also provide clear and simple ways for customers to access or correct their data. Customers should also have the ability to opt out of data collection or processing.""""Fairness – Organizations should use data in a way that does not discriminate, exclude, or harm individuals or groups based on identity or preferences. They should also take care that data does not reinforce stereotypes or prejudices. This will require representative data collection and close attention to data quality.""Business Benefits of Ethical Data Practices""While organizations have a moral duty to handle data ethically, responsible data use also delivers business advantages. In the first place, transparency builds customer loyalty and trust, which enhances brand image. And the practices that provide the oversight necessary for accountability also help businesses comply withdata privacy lawsand regulations.""Information Governance ExpertsTo effectively govern data, organizations must know where that data originates, who owns and accesses it, where it lives, and how it is used. The data experts at Messaging Architects bring decades of experience ininformation governance consultingand solutions. Business leaders should contact them to begin developing comprehensive strategies designed to promote the ethical and responsible use of data.Have you read?Data Lineage Best Practices Enhance Data Quality and UsabilityData-driven Business Cultures Spark Innovation and Power Decision MakingAbout Messaging ArchitectsMessaging Architects specializes in effectively managing and securing an organization's most precious asset, its information. With over 20 years of information management and technology consulting experience, the Messaging Architects team has provided corporations, educational intuitions, health care facilities and nonprofits with methodologies, procedures, and technology to keep their data organized, compliant and secure.About eMazzanti TechnologieseMazzanti's team of trained, certified IT experts rapidly deliver increased revenue growth, data security and productivity for clients ranging from law firms to high-end global retailers, expertly providing advanced business cyber security, retail and payment technology, digital marketing services, AI, cloud and mobile solutions, multi-site implementations, 24×7 outsourced network management, remote monitoring, and support.eMazzanti's consistent growth landed them on the Inc. 5000 list 9X. Recognized as a 4X Microsoft Partner of the Year, the #1 ranked NYC area MSP, NJ Business of the Year, and 5X WatchGuard Partner of the Year, the company excels as a trusted outsourced IT partner! Contact: 1-866-362-9926,info@emazzanti.netorhttp://www.emazzanti.netTwitter: @emazzanti Facebook: Facebook.com/emazzantitechnologies.Media ContactKent Sorensen, Messaging Architects, 14803345403,kents@mstar.net,www.messagingarchitects.com  View original content to download multimedia:https://www.prweb.com/releases/data-ethics-and-responsibility-build-trust-efficiency-and-competitive-advantage-301995475.htmlSOURCE Messaging Architects 
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); ASSOCIATIONS & ORGANIZATIONS (89%); PRESS RELEASES (79%); BEST PRACTICES (78%); CORPORATE WRONGDOING (78%); DISCRIMINATION (76%); NEGATIVE SOCIETAL NEWS (76%); BRANDING (74%); SCANDALS (73%); NEGATIVE MISC NEWS (71%); BRAND EQUITY (68%); PRWEB (%)
Company:  ENRON CREDITORS RECOVERY CORP (54%); Messaging Architects
Industry: SIC4911 ELECTRIC SERVICES (54%); DATA GOVERNANCE & STEWARDSHIP (89%); BRANDING (74%); BRAND EQUITY (68%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Geographic: NEW JERSEY, USA (89%); New Jersey
Load-Date: November 22, 2023",neutral,0.8862435221672058,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'security', 'access']","['fairness', 'equity']","['governance', 'oversight', 'law', 'compliance', 'should', 'must']",[],8,2,6,0
2023,Unknown Title,"Body
The Ministry of Science, Technology and Innovation (Minciencias) announced that by January 2024 it will officially launch the roadmap to ensure the ""ethical and sustainable adoption"" of Artificial Intelligence (AI) in Colombia.
Read: Colombian Armed Forces to use Artificial Intelligence in their operations
As explained by the Ministry, the document will be articulated in the National Development Plan where it establishes the basic guidelines around the design, development and use of AI in relation to aspects such as: ethics, governance, innovation, education, industry, legislation, transparency, citizen participation, among others.
""The Government has taken a leading role in the discussion on the regulation of AI, from an ethical framework of governance and sustainability. Our commitment is for Colombia to have a solid, organized technological development that responds to the social, economic and environmental needs of the country,"" explained the Minister of Science, Technology and Innovation, Yesenia Olaya Requene.
She added that the use of AI in Colombia will have the objective of promoting progress towards an ethical, equitable and responsible knowledge society, through permanent support to technology companies in the creation of software with AI, which offer solutions to the country's social problems.
The science portfolio stressed that this roadmap will go hand in hand with the presentation to the Congress of the Republic of the 'Law of Ethics in Artificial Intelligence', which would determine the ethical guidelines, responsibilities and rights related to the implementation and use of AI in Colombia.
""The work that we will soon present seeks to harmonize the forms of governance, social relationship and AI technology, in favor of promoting welfare and social justice; as this is an aspect that every day is more relevant in the lives of people, companies and the advancement of the Nation,"" added the minister.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); GOVERNMENT ADVISORS & MINISTERS (78%); NATIONAL SECURITY & FOREIGN RELATIONS (78%); SOCIAL JUSTICE (78%); SOCIETAL ISSUES (78%); SUSTAINABLE DEVELOPMENT (77%); LEGISLATION (75%); INTERPERSONAL RELATIONSHIPS (64%); Colombia (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); SUSTAINABLE DEVELOPMENT (77%)
Geographic: COLOMBIA (95%)
Load-Date: December 26, 2023","The Ministry of Science, Technology and Innovation (Minciencias) announced that by January 2024 it will officially launch the roadmap to ensure the ""ethical and sustainable adoption"" of Artificial Intelligence (AI) in Colombia.
Read: Colombian Armed Forces to use Artificial Intelligence in their operations
As explained by the Ministry, the document will be articulated in the National Development Plan where it establishes the basic guidelines around the design, development and use of AI in relation to aspects such as: ethics, governance, innovation, education, industry, legislation, transparency, citizen participation, among others.
""The Government has taken a leading role in the discussion on the regulation of AI, from an ethical framework of governance and sustainability. Our commitment is for Colombia to have a solid, organized technological development that responds to the social, economic and environmental needs of the country,"" explained the Minister of Science, Technology and Innovation, Yesenia Olaya Requene.
She added that the use of AI in Colombia will have the objective of promoting progress towards an ethical, equitable and responsible knowledge society, through permanent support to technology companies in the creation of software with AI, which offer solutions to the country's social problems.
The science portfolio stressed that this roadmap will go hand in hand with the presentation to the Congress of the Republic of the 'Law of Ethics in Artificial Intelligence', which would determine the ethical guidelines, responsibilities and rights related to the implementation and use of AI in Colombia.
""The work that we will soon present seeks to harmonize the forms of governance, social relationship and AI technology, in favor of promoting welfare and social justice; as this is an aspect that every day is more relevant in the lives of people, companies and the advancement of the Nation,"" added the minister.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); GOVERNMENT BODIES & OFFICES (90%); GOVERNMENT DEPARTMENTS & AUTHORITIES (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); GOVERNMENT ADVISORS & MINISTERS (78%); NATIONAL SECURITY & FOREIGN RELATIONS (78%); SOCIAL JUSTICE (78%); SOCIETAL ISSUES (78%); SUSTAINABLE DEVELOPMENT (77%); LEGISLATION (75%); INTERPERSONAL RELATIONSHIPS (64%); Colombia (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); SUSTAINABLE DEVELOPMENT (77%)
Geographic: COLOMBIA (95%)
Load-Date: December 26, 2023",neutral,0.5124068856239319,balanced/neutral,"['transparency', 'security']","['justice', 'justice']","['regulation', 'policy', 'governance', 'guidelines', 'framework', 'legislation', 'law']",[],2,2,7,0
2023,Unknown Title,"Byline: The Arabian Post Network
Body
In a world where technology seamlessly integrates with our daily routines, we often find ourselves interacting with artificial intelligence (AI) without even realizing it. Whether you're asking Siri about the weather or contemplating an andar bahar real cash withdrawal, AI quietly works its magic, making life smoother and occasionally sparking curiosity about the intricacies of this technological marvel. In this article, we'll embark on a journey through the various facets of AI, exploring its applications, addressing concerns, and contemplating the role it plays in our everyday lives.
The Good Stuff: How AI Makes Life Easier
Personal Assistants: Ever talked to Siri or asked Alexa to play your favorite song? That's AI at work. These virtual helpers use natural language processing to understand and respond to your commands, making your life a tad more convenient.
Smart Home Devices: From thermostats that learn your temperature preferences to fridges that remind you to buy milk, smart home devices use AI to adapt to your habits. They're like personal assistants for your living space.
Recommendation Systems: Have you ever wondered how Netflix knows exactly what show you're in the mood for? AI algorithms analyze your watching habits and suggest content tailored just for you. It's like having a movie buff friend who always knows what to watch.
The Not-so-Great: Concerns Surrounding AI
Job Displacement: The rise of automation powered by AI has led to concerns about job loss. Machines are getting better at tasks traditionally done by humans, raising questions about the future of employment.
Privacy Issues: AI often relies on data, and lots of it. This has sparked worries about privacy – who has access to our information, and how is it being used? Striking a balance between technological advancement and personal privacy is an ongoing challenge.
Bias in Algorithms: AI systems are only as good as the data they're trained on. If the data contains biases, the AI can perpetuate them. This raises concerns about fairness, especially in areas like hiring, where biased algorithms could inadvertently favor certain groups over others.
The Questions We Ask: Navigating the Ethical Maze
Ethical AI: As AI becomes more integrated into our lives, ethical questions arise. Should AI be used in certain situations? How do we ensure it's used responsibly? The ethical implications of AI are complex and require ongoing discussion.
Transparency: Understanding how AI makes decisions is crucial. The 'black box' nature of some AI systems – where it's challenging to trace how they reached a particular conclusion – raises concerns. Striving for transparency is key to building trust in AI.
Regulation and Governance: As AI continues to evolve, establishing clear regulations and governance becomes essential. How do we ensure that AI is developed and used ethically, without stifling innovation? Striking the right balance is a delicate task for policymakers.
In Conclusion
AI is no longer a distant dream but a reality that shapes our daily experiences. While the convenience it brings is undeniable, it's equally important to address the concerns and ethical considerations surrounding its use. Striking a balance between embracing the benefits of AI and mitigating its potential drawbacks will be crucial as we navigate this ever-evolving technological landscape.
So, the next time you ask your virtual assistant for information or enjoy the personalized recommendations on your favorite streaming platform, remember that you are an active participant in the ongoing narrative of artificial intelligence. Through thoughtful consideration, ethical awareness, and collaborative efforts, we can continue to shape a future where AI seamlessly integrates into our lives, contributing to a society that values innovation, ethics, and the shared human experience.
via AI in Our Daily Lives: The Good, the Not-so-Great, and the Questions We Ask The Arabian Post  
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 2646
Subject: ARTIFICIAL INTELLIGENCE (90%); SMART TECHNOLOGY (90%); ETHICS (89%); PRIVACY RIGHTS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SMART HOMES (78%); ADMINISTRATIVE & CLERICAL WORKERS (75%); NATURAL LANGUAGE PROCESSING (73%); DISMISSALS (64%); LAYOFFS & DISMISSALS (64%)
Company:  NETFLIX INC (55%)
Ticker: NFLX (NASDAQ) (55%)
Industry: NAICS532282 VIDEO TAPE & DISC RENTAL (55%); SIC7841 VIDEO TAPE RENTAL (55%); ARTIFICIAL INTELLIGENCE (90%); BUILDING AUTOMATION (90%); SMART TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SMART HOMES (78%); THERMAL SENSORS (73%)
Load-Date: December 20, 2023","In a world where technology seamlessly integrates with our daily routines, we often find ourselves interacting with artificial intelligence (AI) without even realizing it. Whether you're asking Siri about the weather or contemplating an andar bahar real cash withdrawal, AI quietly works its magic, making life smoother and occasionally sparking curiosity about the intricacies of this technological marvel. In this article, we'll embark on a journey through the various facets of AI, exploring its applications, addressing concerns, and contemplating the role it plays in our everyday lives.
The Good Stuff: How AI Makes Life Easier
Personal Assistants: Ever talked to Siri or asked Alexa to play your favorite song? That's AI at work. These virtual helpers use natural language processing to understand and respond to your commands, making your life a tad more convenient.
Smart Home Devices: From thermostats that learn your temperature preferences to fridges that remind you to buy milk, smart home devices use AI to adapt to your habits. They're like personal assistants for your living space.
Recommendation Systems: Have you ever wondered how Netflix knows exactly what show you're in the mood for? AI algorithms analyze your watching habits and suggest content tailored just for you. It's like having a movie buff friend who always knows what to watch.
The Not-so-Great: Concerns Surrounding AI
Job Displacement: The rise of automation powered by AI has led to concerns about job loss. Machines are getting better at tasks traditionally done by humans, raising questions about the future of employment.
Privacy Issues: AI often relies on data, and lots of it. This has sparked worries about privacy – who has access to our information, and how is it being used? Striking a balance between technological advancement and personal privacy is an ongoing challenge.
Bias in Algorithms: AI systems are only as good as the data they're trained on. If the data contains biases, the AI can perpetuate them. This raises concerns about fairness, especially in areas like hiring, where biased algorithms could inadvertently favor certain groups over others.
The Questions We Ask: Navigating the Ethical Maze
Ethical AI: As AI becomes more integrated into our lives, ethical questions arise. Should AI be used in certain situations? How do we ensure it's used responsibly? The ethical implications of AI are complex and require ongoing discussion.
Transparency: Understanding how AI makes decisions is crucial. The 'black box' nature of some AI systems – where it's challenging to trace how they reached a particular conclusion – raises concerns. Striving for transparency is key to building trust in AI.
Regulation and Governance: As AI continues to evolve, establishing clear regulations and governance becomes essential. How do we ensure that AI is developed and used ethically, without stifling innovation? Striking the right balance is a delicate task for policymakers.
In Conclusion
AI is no longer a distant dream but a reality that shapes our daily experiences. While the convenience it brings is undeniable, it's equally important to address the concerns and ethical considerations surrounding its use. Striking a balance between embracing the benefits of AI and mitigating its potential drawbacks will be crucial as we navigate this ever-evolving technological landscape.
So, the next time you ask your virtual assistant for information or enjoy the personalized recommendations on your favorite streaming platform, remember that you are an active participant in the ongoing narrative of artificial intelligence. Through thoughtful consideration, ethical awareness, and collaborative efforts, we can continue to shape a future where AI seamlessly integrates into our lives, contributing to a society that values innovation, ethics, and the shared human experience.
via AI in Our Daily Lives: The Good, the Not-so-Great, and the Questions We Ask The Arabian Post  
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 2646
Subject: ARTIFICIAL INTELLIGENCE (90%); SMART TECHNOLOGY (90%); ETHICS (89%); PRIVACY RIGHTS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SMART HOMES (78%); ADMINISTRATIVE & CLERICAL WORKERS (75%); NATURAL LANGUAGE PROCESSING (73%); DISMISSALS (64%); LAYOFFS & DISMISSALS (64%)
Company:  NETFLIX INC (55%)
Ticker: NFLX (NASDAQ) (55%)
Industry: NAICS532282 VIDEO TAPE & DISC RENTAL (55%); SIC7841 VIDEO TAPE RENTAL (55%); ARTIFICIAL INTELLIGENCE (90%); BUILDING AUTOMATION (90%); SMART TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SMART HOMES (78%); THERMAL SENSORS (73%)
Load-Date: December 20, 2023",positive,0.6457076072692871,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'job loss', 'access']",['fairness'],"['regulation', 'governance', 'should', 'suggest']",['natural language processing'],6,1,4,1
2023,Unknown Title,"Body
Link to Story
SAN FRANCISCO, Sept. 21, 2023 (GLOBE NEWSWIRE) -- Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
""AI continues to change the way we work every day, and with rapid innovations and shifts in these technologies it is imperative that those developing AI technologies are dedicated to safety, transparency, and accountability. Our commitment to our customers - to deliver solutions that help them harness the full power of the internet and understand and analyze billions of new conversations happening every day - also means we have a commitment to responsibly develop our technologies in ways that benefit society as a whole and keep safety, privacy, and security at the forefront,"" said Aditya Jami, CTO of Meltwater.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
The Meltwater Ethical AI principles are:
In addition to launching these principles, Meltwater has taken concrete steps to strengthen its commitment to ethical AI practices:
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
To learn more about Meltwater's AI ethical principles, visit meltwater.com/
For more information, please contact:
Kelly Costello
Corporate Communications Director
About Meltwater
Meltwater empowers companies with a suite of solutions that spans media, social, consumer and sales intelligence. By analyzing ~1 billion pieces of content each day and transforming them into vital insights, Meltwater unlocks the competitive edge to drive results. With 27,000 global customers, 50 offices across six continents and 2,300 employees, Meltwater is the industry partner of choice for global brands making an impact. Learn more at meltwater.com.
MENAFN21092023004107003653ID1107115521
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SAFETY (90%); SOCIAL MEDIA (90%); TECHNOLOGY (90%); COMPANY ACTIVITIES & MANAGEMENT (77%); CORPORATE CULTURE (77%); EMERGING TECHNOLOGY (77%); MACHINE LEARNING (77%); RESEARCH & DEVELOPMENT (77%); SAFETY, ACCIDENTS & DISASTERS (77%); ASSOCIATIONS & ORGANIZATIONS (76%); ECONOMIC DEVELOPMENT (76%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); DATA SCIENCE (72%); EXECUTIVES (70%)
Company:  GOOGLE LLC (57%)
Organization: ORGANISATION FOR ECONOMIC CO-OPERATION & DEVELOPMENT (54%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SOCIAL MEDIA (90%); MARKET RESEARCH (89%); INFORMATION SECURITY & PRIVACY (77%); MACHINE LEARNING (77%); DATA SCIENCE (72%); INTERNET & WWW (71%)
Load-Date: May 10, 2024","Link to Story
SAN FRANCISCO, Sept. 21, 2023 (GLOBE NEWSWIRE) -- Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
""AI continues to change the way we work every day, and with rapid innovations and shifts in these technologies it is imperative that those developing AI technologies are dedicated to safety, transparency, and accountability. Our commitment to our customers - to deliver solutions that help them harness the full power of the internet and understand and analyze billions of new conversations happening every day - also means we have a commitment to responsibly develop our technologies in ways that benefit society as a whole and keep safety, privacy, and security at the forefront,"" said Aditya Jami, CTO of Meltwater.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
The Meltwater Ethical AI principles are:
In addition to launching these principles, Meltwater has taken concrete steps to strengthen its commitment to ethical AI practices:
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
To learn more about Meltwater's AI ethical principles, visit meltwater.com/
For more information, please contact:
Kelly Costello
Corporate Communications Director
About Meltwater
Meltwater empowers companies with a suite of solutions that spans media, social, consumer and sales intelligence. By analyzing ~1 billion pieces of content each day and transforming them into vital insights, Meltwater unlocks the competitive edge to drive results. With 27,000 global customers, 50 offices across six continents and 2,300 employees, Meltwater is the industry partner of choice for global brands making an impact. Learn more at meltwater.com.
MENAFN21092023004107003653ID1107115521
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); PRESS RELEASES (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SAFETY (90%); SOCIAL MEDIA (90%); TECHNOLOGY (90%); COMPANY ACTIVITIES & MANAGEMENT (77%); CORPORATE CULTURE (77%); EMERGING TECHNOLOGY (77%); MACHINE LEARNING (77%); RESEARCH & DEVELOPMENT (77%); SAFETY, ACCIDENTS & DISASTERS (77%); ASSOCIATIONS & ORGANIZATIONS (76%); ECONOMIC DEVELOPMENT (76%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); DATA SCIENCE (72%); EXECUTIVES (70%)
Company:  GOOGLE LLC (57%)
Organization: ORGANISATION FOR ECONOMIC CO-OPERATION & DEVELOPMENT (54%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SOCIAL MEDIA (90%); MARKET RESEARCH (89%); INFORMATION SECURITY & PRIVACY (77%); MACHINE LEARNING (77%); DATA SCIENCE (72%); INTERNET & WWW (71%)
Load-Date: May 10, 2024",neutral,0.5114596486091614,balanced/neutral,"['privacy', 'transparency', 'accountability', 'safety', 'security']",[],"['guidelines', 'must']",['machine learning'],5,0,2,1
2023,Unknown Title,"Byline: DQINDIA Online
Body
The Indian Institute of Technology Madras (IIT Madras) has established a Centre for Responsible AI (CeRAI), an interdisciplinary research centre, to ensure ethical and responsible development of AI-based solutions in the real world. The Centre will focus on fundamental and applied research in Responsible AI, with a specific focus on India. It will bring together researchers from across IIT Madras and other academic institutions, as well as industry partners, to work on developing ethical and responsible AI technologies and frameworks.
The Centre will be led by Professor Balaraman Ravindran, who is a professor of computer science at IIT Madras. Professor Ravindran has extensive experience in the field of AI, and he is a leading expert on Responsible AI. The Centre will be funded by a grant from Google, which is the first platinum consortium member of the Centre. Google is a leading technology company that is committed to responsible AI.
The Centre for Responsible AI is a significant development for India. It will help to ensure that AI is developed and deployed in an ethical and responsible manner, and it will help to build a strong foundation for the future of AI in India.
Key Objectives of the Centre
The Centre for Responsible AI has the following key objectives:
* To conduct fundamental and applied research in Responsible AI
* To develop ethical and responsible AI technologies and frameworks
* To promote the adoption of ethical and responsible AI in India
* To build a strong community of researchers and practitioners in Responsible AI
The IIT Madras Centre Responsible AI's Work
The Centre for Responsible AI will work on a wide range of projects related to Responsible AI. These projects will include:
* Developing ethical and responsible AI algorithms
* Developing ethical and responsible AI systems
* Developing ethical and responsible AI policies
* Developing ethical and responsible AI guidelines
* Educating the public about Responsible AI
The IIT Madras Centre Responsible AI's Work
The Centre for Responsible AI has the potential to have a significant impact on India. It will help to ensure that AI is developed and deployed in an ethical and responsible manner, and it will help to build a strong foundation for the future of AI in India.
The Centre will also help to promote the adoption of ethical and responsible AI in India. This will benefit businesses, governments, and individuals in India.
The Centre will also build a strong community of researchers and practitioners in Responsible AI. This will help to ensure that India is at the forefront of Responsible AI research and development.
The Centre for Responsible AI is a significant development for India. It has the potential to have a positive impact on India in a number of ways.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); RESEARCH INSTITUTES (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); COMPUTER SCIENCE (78%); RESEARCH & DEVELOPMENT (78%); GRANTS & GIFTS (77%); ALLIANCES & PARTNERSHIPS (73%); EDUCATION SYSTEMS & INSTITUTIONS (72%)
Company:  GOOGLE LLC (58%);  AI SYSTEMS (53%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); COMPUTER SCIENCE (78%); EDUCATIONAL SERVICES (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); EDUCATION SYSTEMS & INSTITUTIONS (72%)
Geographic: INDIA (95%)
Load-Date: May 17, 2023","The Indian Institute of Technology Madras (IIT Madras) has established a Centre for Responsible AI (CeRAI), an interdisciplinary research centre, to ensure ethical and responsible development of AI-based solutions in the real world. The Centre will focus on fundamental and applied research in Responsible AI, with a specific focus on India. It will bring together researchers from across IIT Madras and other academic institutions, as well as industry partners, to work on developing ethical and responsible AI technologies and frameworks.
The Centre will be led by Professor Balaraman Ravindran, who is a professor of computer science at IIT Madras. Professor Ravindran has extensive experience in the field of AI, and he is a leading expert on Responsible AI. The Centre will be funded by a grant from Google, which is the first platinum consortium member of the Centre. Google is a leading technology company that is committed to responsible AI.
The Centre for Responsible AI is a significant development for India. It will help to ensure that AI is developed and deployed in an ethical and responsible manner, and it will help to build a strong foundation for the future of AI in India.
Key Objectives of the Centre
The Centre for Responsible AI has the following key objectives:
* To conduct fundamental and applied research in Responsible AI
* To develop ethical and responsible AI technologies and frameworks
* To promote the adoption of ethical and responsible AI in India
* To build a strong community of researchers and practitioners in Responsible AI
The IIT Madras Centre Responsible AI's Work
The Centre for Responsible AI will work on a wide range of projects related to Responsible AI. These projects will include:
* Developing ethical and responsible AI algorithms
* Developing ethical and responsible AI systems
* Developing ethical and responsible AI policies
* Developing ethical and responsible AI guidelines
* Educating the public about Responsible AI
The IIT Madras Centre Responsible AI's Work
The Centre for Responsible AI has the potential to have a significant impact on India. It will help to ensure that AI is developed and deployed in an ethical and responsible manner, and it will help to build a strong foundation for the future of AI in India.
The Centre will also help to promote the adoption of ethical and responsible AI in India. This will benefit businesses, governments, and individuals in India.
The Centre will also build a strong community of researchers and practitioners in Responsible AI. This will help to ensure that India is at the forefront of Responsible AI research and development.
The Centre for Responsible AI is a significant development for India. It has the potential to have a positive impact on India in a number of ways.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); RESEARCH INSTITUTES (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); COMPUTER SCIENCE (78%); RESEARCH & DEVELOPMENT (78%); GRANTS & GIFTS (77%); ALLIANCES & PARTNERSHIPS (73%); EDUCATION SYSTEMS & INSTITUTIONS (72%)
Company:  GOOGLE LLC (58%);  AI SYSTEMS (53%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); COMPUTER SCIENCE (78%); EDUCATIONAL SERVICES (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); EDUCATION SYSTEMS & INSTITUTIONS (72%)
Geographic: INDIA (95%)
Load-Date: May 17, 2023",neutral,0.5747545957565308,balanced/neutral,[],[],"['regulation', 'policy', 'guidelines']",[],0,0,3,0
2023,Unknown Title,"Byline: Kaitlyn Mattson
Body
Insurtechs have launched an Ethical AI in Insurance Consortium to collaborate on industry-wide standards related to fairness and transparency in the use of artificial intelligence within the insurance industry.
The founding members include Cloverleaf Analytics, Exavalu and Socotra. The consortium hopes to increase knowledge sharing amongst insurance companies, AI developers and regulators, as well as consumer advocacy groups. The organization is working to develop ethical guidelines for the industry related to AI use in underwriting, claims processing and pricing.
Abby Hosseini, chief digital officer of Exavalu, said in an emailed response that each of the initial founding members are focused on specific areas within the industry.
""We each believe that our unique focus, background and perspectives can add value to carriers and brokers that are racing to leverage the advancements in AI,"" Hosseini said. ""The first objective is to raise awareness of the impact of algorithmic bias on the insurance industry.
Hosseini added that it is important to acknowledge that algorithmic bias is a real problem.
""Perhaps the most important initial impact is to raise awareness of the issue of ethics in algorithmic decision making. Our hope is that by making the issue front and center for the industry, we can help accelerate the use of AI with proper guard rails and best practices rather than try to control AI's increased adoption,"" Hosseini said. ""The second impact we hope for is that the ethical standard brings a higher level of transparency to the industry and hopes to undo decades of mistrust between the insured and the carrier. The success of the consortium can only be measured by its ability to scale the use of AI with sound ethical standards that are followed by the members.""
Robert Clark, CEO and founder of Cloverleaf Analytics, said in an email that the consortium is looking to establish a code of ethics.
""This is to help consumers have confidence that their insurance company is applying a code of ethics to implementations of AI that could impact them and to help insurance companies avoid bias towards gender, race, age, etc. that could lead to regulatory action, penalties, or even worse class action suits,"" Clark said.
The code of ethics will include guidelines on how to avoid bias and guarantee fairness, including addressing transparency in the use of algorithmic models and analytical decision making.
For example, Clark expects to see a focus on auditing. ""We believe the consortium will define how to implement continuous auditing to ensure when the first signs of a potential bias begin to surface in AI that it is quickly addressed.""
Criteria for selecting new members have not been fully determined but insurance companies and insurance solution vendors are the target.
https://www.dig-in.com/news/insurtechs-launch-ethical-ai-in-insurance-consortium
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: INSURANCE TECHNOLOGY (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (89%); AGENCY RULEMAKING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); BEST PRACTICES (78%); CONSUMER PROTECTION (78%); CONSUMER WATCHDOGS (78%); NEGATIVE BUSINESS NEWS (77%); CONSUMER LAW (76%); CONSUMERS (76%); PRICES (76%); REGULATORY ACTIONS (76%); ASSOCIATIONS & ORGANIZATIONS (72%); CLASS ACTIONS (71%); SUITS & CLAIMS (71%); EXECUTIVES (70%); LITIGATION (66%)
Industry: INSURANCE TECHNOLOGY (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); INSURANCE (91%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); INSURANCE CLAIMS (73%)
Person: RICHARD T CLARK (75%)
Load-Date: August 25, 2023","Insurtechs have launched an Ethical AI in Insurance Consortium to collaborate on industry-wide standards related to fairness and transparency in the use of artificial intelligence within the insurance industry.
The founding members include Cloverleaf Analytics, Exavalu and Socotra. The consortium hopes to increase knowledge sharing amongst insurance companies, AI developers and regulators, as well as consumer advocacy groups. The organization is working to develop ethical guidelines for the industry related to AI use in underwriting, claims processing and pricing.
Abby Hosseini, chief digital officer of Exavalu, said in an emailed response that each of the initial founding members are focused on specific areas within the industry.
""We each believe that our unique focus, background and perspectives can add value to carriers and brokers that are racing to leverage the advancements in AI,"" Hosseini said. ""The first objective is to raise awareness of the impact of algorithmic bias on the insurance industry.
Hosseini added that it is important to acknowledge that algorithmic bias is a real problem.
""Perhaps the most important initial impact is to raise awareness of the issue of ethics in algorithmic decision making. Our hope is that by making the issue front and center for the industry, we can help accelerate the use of AI with proper guard rails and best practices rather than try to control AI's increased adoption,"" Hosseini said. ""The second impact we hope for is that the ethical standard brings a higher level of transparency to the industry and hopes to undo decades of mistrust between the insured and the carrier. The success of the consortium can only be measured by its ability to scale the use of AI with sound ethical standards that are followed by the members.""
Robert Clark, CEO and founder of Cloverleaf Analytics, said in an email that the consortium is looking to establish a code of ethics.
""This is to help consumers have confidence that their insurance company is applying a code of ethics to implementations of AI that could impact them and to help insurance companies avoid bias towards gender, race, age, etc. that could lead to regulatory action, penalties, or even worse class action suits,"" Clark said.
The code of ethics will include guidelines on how to avoid bias and guarantee fairness, including addressing transparency in the use of algorithmic models and analytical decision making.
For example, Clark expects to see a focus on auditing. ""We believe the consortium will define how to implement continuous auditing to ensure when the first signs of a potential bias begin to surface in AI that it is quickly addressed.""
Criteria for selecting new members have not been fully determined but insurance companies and insurance solution vendors are the target.
https://www.dig-in.com/news/insurtechs-launch-ethical-ai-in-insurance-consortium
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: INSURANCE TECHNOLOGY (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (89%); AGENCY RULEMAKING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); BEST PRACTICES (78%); CONSUMER PROTECTION (78%); CONSUMER WATCHDOGS (78%); NEGATIVE BUSINESS NEWS (77%); CONSUMER LAW (76%); CONSUMERS (76%); PRICES (76%); REGULATORY ACTIONS (76%); ASSOCIATIONS & ORGANIZATIONS (72%); CLASS ACTIONS (71%); SUITS & CLAIMS (71%); EXECUTIVES (70%); LITIGATION (66%)
Industry: INSURANCE TECHNOLOGY (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); INSURANCE (91%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); INSURANCE CLAIMS (73%)
Person: RICHARD T CLARK (75%)
Load-Date: August 25, 2023",neutral,0.6479493975639343,balanced/neutral,"['bias', 'fairness', 'transparency', 'agency']",['fairness'],"['regulation', 'policy', 'standards', 'guidelines', 'law']",[],4,1,5,0
2023,Unknown Title,"Byline: Ahmed Raza
Body
September 26th, 2023 ( TechBullion  — Delivered by  Newstex )
Rethinking AI: Ethical Considerations in Historical Simulations and Beyond
The rapid evolution of AI technology has ushered in a new era where the lines between reality and simulation are increasingly blurred. Amid this transformation, it becomes crucial to examine the ethical implications of  future of AI  within historical simulations and beyond. In this article, we delve into the convergence of AI, ethics, and laws within the context of historical simulations, advocating for a paradigm shift to safeguard human agency and privacy in this brave new world.
'Invest an ounce of AI ethics today, to save a lifetime of AI dilemmas tomorrow.'
-           Olivia Friedman - Mother of AI Ethics (2001)
Historical Simulations: A Brave New World
Imagine a world where we can recreate historical events with astounding accuracy using artificial intelligence. Such simulations have the potential to transport us back in time, offering unprecedented insights into our history. However, beneath this promising facade lie ethical and legal challenges that demand our attention.
To delve into these issues further, consider my work on the Cuban Missile Crisis as a Historical Simulation Case Study. Here, we explore how historical simulations can provide invaluable perspectives on past events. Yet, we must also confront the ethical implications of potentially altering historical narratives or trivializing serious events.
'An ounce of AI prevention today could save a pound of AI dilemmas tomorrow.'
-           Olivia Friedman, Mother of AI Ethics (2006)
AI and the Ethics of Clinical Research
Within historical simulations, AI plays a pivotal role in various aspects, including clinical research. This intersection of AI and healthcare research raises profound ethical questions. We find ourselves at a crossroads, where the pursuit of innovation must be balanced with ethical considerations.
In my article, 'Skin-Mechanics: AI Ethics in Medicine, Biology and the Singularity and Cyborg Movement', I delve into the complexities of AI in clinical research and healthcare. We must ensure that AI is not only a tool for advancement but also a guardian of ethical standards, prioritizing patient welfare and privacy.
Protecting Human Agency and Privacy
Transparency and comprehensibility in AI systems are paramount. Even within the digital realm of historical simulations, we must protect individual rights. In the year 2000, I envisioned an 'AI Bill of Rights (Pro-Human)' that emphasized the importance of safeguarding human agencies and privacy in the face of advancing AI technologies.
This work serves as a foundation for our discussions on the ethical use of AI within simulations. It reminds us that as we venture into this brave new world, we must carry the principles of fairness, transparency, and respect for individual rights with us.
'A small investment in AI planning and ethics is far better than giant leaps in AI complications.'
-           Futurist Olivia Friedman, Mother of AI Ethics (2009)
The Roadmap to Ethical AI in Simulations
Creating ethical AI within historical simulations requires a roadmap. My article titled 'Futurist Olivia Friedman's Step-by-step Roadmap to Ethical AI in Simulation' lays out a comprehensive guide. It navigates the complexities of ensuring AI aligns with our ethical values.
In this roadmap, we distinguish between 'Green AI' and 'White AI.' 'Green AI' symbolizes the beneficial, ethical use of AI, while 'White AI' represents the unseen dangers and potential pitfalls. By following this roadmap, we can foster responsible AI use within simulations.
AI Beyond 2050: Navigating the Unknown
The  future of AI   extends beyond 2050, into uncharted territory. My journal notes and musings over the years have captured the evolution of AI, the concept of Singularity, and the emergence of self-aware AI.
As we navigate this unknown terrain, it becomes evident that long-term planning for AI ethics is essential. We must prepare for unforeseen challenges and ensure that AI remains aligned with our values and ethics. This is precisely why I began the AI Ethics and AI Consumer Protection Movement well over twenty years ago, where I sounded the alarm early. Sure I was a bit early when referencing my Cindy 4.0 AI, after all, that is how I earned the title of 'Futurist', by close friends and family. But had we taken heed of my early warnings and red flags, AI evolution might have looked quite different today.
In conclusion, 'A drop of AI foresight is worthmore than a pound of AI hindsight.' Futurist Olivia Friedman, Mother of AI Ethics& AI Consumer Protection the ethical considerations surrounding AI in historical simulations and the broader AI landscape are paramount. By drawing insights from my previous works and embracing a proactive approach to AI ethics, we can navigate this transformative era while safeguarding our principles and values.
Author, Olivia Friedman - Mother of AI Ethics
Olivia 'The-World' Influencer, Futurist Olivia X, #Fox, Futurist OliviaX, historical simulation, ethical AI, human agency, privacy, AI legislation, long-term AI planning. Olivia Friedman, Forbes.com Business Articles
Recommended for you
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 10009326
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); HISTORY (90%); MEDICAL RESEARCH (90%); EXPERIMENTATION & RESEARCH (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); CASE STUDIES (71%); HEALTH SERVICES RESEARCH (71%); LAW & LEGAL SYSTEM (71%); TRENDS & EVENTS (68%); Artificial intelligence (%); AI (%); OLIVIA FRIEDMAN (%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); HEALTH SERVICES RESEARCH (71%)
Load-Date: October 26, 2023","September 26th, 2023 ( TechBullion  — Delivered by  Newstex )
Rethinking AI: Ethical Considerations in Historical Simulations and Beyond
The rapid evolution of AI technology has ushered in a new era where the lines between reality and simulation are increasingly blurred. Amid this transformation, it becomes crucial to examine the ethical implications of  future of AI  within historical simulations and beyond. In this article, we delve into the convergence of AI, ethics, and laws within the context of historical simulations, advocating for a paradigm shift to safeguard human agency and privacy in this brave new world.
'Invest an ounce of AI ethics today, to save a lifetime of AI dilemmas tomorrow.'
-           Olivia Friedman - Mother of AI Ethics (2001)
Historical Simulations: A Brave New World
Imagine a world where we can recreate historical events with astounding accuracy using artificial intelligence. Such simulations have the potential to transport us back in time, offering unprecedented insights into our history. However, beneath this promising facade lie ethical and legal challenges that demand our attention.
To delve into these issues further, consider my work on the Cuban Missile Crisis as a Historical Simulation Case Study. Here, we explore how historical simulations can provide invaluable perspectives on past events. Yet, we must also confront the ethical implications of potentially altering historical narratives or trivializing serious events.
'An ounce of AI prevention today could save a pound of AI dilemmas tomorrow.'
-           Olivia Friedman, Mother of AI Ethics (2006)
AI and the Ethics of Clinical Research
Within historical simulations, AI plays a pivotal role in various aspects, including clinical research. This intersection of AI and healthcare research raises profound ethical questions. We find ourselves at a crossroads, where the pursuit of innovation must be balanced with ethical considerations.
In my article, 'Skin-Mechanics: AI Ethics in Medicine, Biology and the Singularity and Cyborg Movement', I delve into the complexities of AI in clinical research and healthcare. We must ensure that AI is not only a tool for advancement but also a guardian of ethical standards, prioritizing patient welfare and privacy.
Protecting Human Agency and Privacy
Transparency and comprehensibility in AI systems are paramount. Even within the digital realm of historical simulations, we must protect individual rights. In the year 2000, I envisioned an 'AI Bill of Rights (Pro-Human)' that emphasized the importance of safeguarding human agencies and privacy in the face of advancing AI technologies.
This work serves as a foundation for our discussions on the ethical use of AI within simulations. It reminds us that as we venture into this brave new world, we must carry the principles of fairness, transparency, and respect for individual rights with us.
'A small investment in AI planning and ethics is far better than giant leaps in AI complications.'
-           Futurist Olivia Friedman, Mother of AI Ethics (2009)
The Roadmap to Ethical AI in Simulations
Creating ethical AI within historical simulations requires a roadmap. My article titled 'Futurist Olivia Friedman's Step-by-step Roadmap to Ethical AI in Simulation' lays out a comprehensive guide. It navigates the complexities of ensuring AI aligns with our ethical values.
In this roadmap, we distinguish between 'Green AI' and 'White AI.' 'Green AI' symbolizes the beneficial, ethical use of AI, while 'White AI' represents the unseen dangers and potential pitfalls. By following this roadmap, we can foster responsible AI use within simulations.
AI Beyond 2050: Navigating the Unknown
The  future of AI   extends beyond 2050, into uncharted territory. My journal notes and musings over the years have captured the evolution of AI, the concept of Singularity, and the emergence of self-aware AI.
As we navigate this unknown terrain, it becomes evident that long-term planning for AI ethics is essential. We must prepare for unforeseen challenges and ensure that AI remains aligned with our values and ethics. This is precisely why I began the AI Ethics and AI Consumer Protection Movement well over twenty years ago, where I sounded the alarm early. Sure I was a bit early when referencing my Cindy 4.0 AI, after all, that is how I earned the title of 'Futurist', by close friends and family. But had we taken heed of my early warnings and red flags, AI evolution might have looked quite different today.
In conclusion, 'A drop of AI foresight is worthmore than a pound of AI hindsight.' Futurist Olivia Friedman, Mother of AI Ethics& AI Consumer Protection the ethical considerations surrounding AI in historical simulations and the broader AI landscape are paramount. By drawing insights from my previous works and embracing a proactive approach to AI ethics, we can navigate this transformative era while safeguarding our principles and values.
Author, Olivia Friedman - Mother of AI Ethics
Olivia 'The-World' Influencer, Futurist Olivia X, #Fox, Futurist OliviaX, historical simulation, ethical AI, human agency, privacy, AI legislation, long-term AI planning. Olivia Friedman, Forbes.com Business Articles
Recommended for you
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: 10009326
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); HISTORY (90%); MEDICAL RESEARCH (90%); EXPERIMENTATION & RESEARCH (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); CASE STUDIES (71%); HEALTH SERVICES RESEARCH (71%); LAW & LEGAL SYSTEM (71%); TRENDS & EVENTS (68%); Artificial intelligence (%); AI (%); OLIVIA FRIEDMAN (%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (79%); HEALTH SERVICES RESEARCH (71%)
Load-Date: October 26, 2023",neutral,0.7961884140968323,balanced/neutral,"['privacy', 'fairness', 'transparency', 'agency']",['fairness'],"['regulation', 'policy', 'standards', 'legislation', 'law', 'should', 'must']",[],4,1,7,0
2023,Unknown Title,"Byline: Periodico El Vigia
Body
Ethics is the philosophical discipline that studies good and evil and their relationship to morality and human behavior. The dictionary refers to the set of customs and norms that direct or value human behavior in a community. 
  Ethics finds its root in the ancient Greek thikós (), meaning ""relating to one's character"", which in turn comes from the root word êthos () meaning ""character, moral nature"". This word was transferred to Latin as ""ethica"" and then to French as ""éthique"", from which it was transferred to Spanish. The word ethics connects to a wide range of disciplines, including anthropology, biology, economics, history, politics, sociology and theology.
  With respect to computer science and very specifically with artificial intelligence (AI) it is said that ethics rests on five pillars which are: 
  1) accountability, because, although it is true that in a company the work cycles must be expeditious and fast, it is necessary that they be reliable and completed in a valid manner.
  2) reliability refers to the quality of being trustworthy, that is, in IA the sources of information, which are constantly changing, when processed must yield results that are congruent with those obtained in the past and also with those that will be obtained in the future. This aspect is even more critical when considering the enormous amount of data that companies manipulate.
  3) Explainability or transparency which must ensure that the artificial models are understood and explained by the different actors throughout the organization, its departments and when challenged by governmental authorities. The value of a computational model can be lost if it lacks explainability by becoming irrelevant because it cannot answer ethical questions as in the case of the medical or banking industry.
  4) Security from a technological point of view is a growing concern, as attacks that threaten organizations and the protection of the population's data are major issues for any corporation or government.
  Protecting data from attacks is essential, and decision makers need to understand the potential risks and how they impact the technologies used in the companies they manage. Many businesses and customers evaluate AI security issues with a critical eye.
  5) Privacy refers to the protection of customer data, especially when AI is used in industries that handle sensitive data, this aspect should be of utmost importance to a CIO (not to be confused with CEO, Chief Executive Officer) who must ensure that technology solutions guarantee the protection of sensitive data and that privacy is provided for both the business and the customer.
  As we can see, ethics refers to the ability of people to differentiate between right and wrong and in the context of AI how this can be ensured in the technology that handles information associated with human beings. 
  In a call by monotheistic religions it is stated that new technologies must ensure that they are truly in the service of the entire human family. Principles in addition to those mentioned here include inclusiveness and fairness. 
  In other words, that with such technologies no one should be excluded in such a way that the algorithms do not discriminate against people on the basis of race, color, sex, religion, political or other opinion, national or social origin, property, birth or other status, as stated in Article 2 of the Universal Declaration of Human Rights. This is summarized by what has come to be known as the principles of algor-ethics. 
Classification
Language: ENGLISH
Publication-Type: Jornal
Journal Code: CENAFTAENG
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BEHAVIOR & COGNITION (90%); DICTIONARIES & THESAURI (90%); ETHICS (90%); HUMANITIES & SOCIAL SCIENCE (90%); EXECUTIVES (89%); ANCIENT HISTORY (78%); ANTHROPOLOGY & ARCHAEOLOGY (78%); CLASSICS (78%); COMPUTER SCIENCE (78%); CUSTOMER RELATIONS (78%); ECONOMICS (78%); SOCIOLOGY (78%); THEOLOGY (78%); ASSOCIATIONS & ORGANIZATIONS (77%); MODELING & SIMULATION (74%); RELIGION (69%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SECURITY (89%); INFORMATION SECURITY & PRIVACY (89%); COMPUTER SCIENCE (78%); MODELING & SIMULATION (74%); BANKING & FINANCE (50%)
Load-Date: October 17, 2023","Ethics is the philosophical discipline that studies good and evil and their relationship to morality and human behavior. The dictionary refers to the set of customs and norms that direct or value human behavior in a community. 
  Ethics finds its root in the ancient Greek thikós (), meaning ""relating to one's character"", which in turn comes from the root word êthos () meaning ""character, moral nature"". This word was transferred to Latin as ""ethica"" and then to French as ""éthique"", from which it was transferred to Spanish. The word ethics connects to a wide range of disciplines, including anthropology, biology, economics, history, politics, sociology and theology.
  With respect to computer science and very specifically with artificial intelligence (AI) it is said that ethics rests on five pillars which are: 
  1) accountability, because, although it is true that in a company the work cycles must be expeditious and fast, it is necessary that they be reliable and completed in a valid manner.
  2) reliability refers to the quality of being trustworthy, that is, in IA the sources of information, which are constantly changing, when processed must yield results that are congruent with those obtained in the past and also with those that will be obtained in the future. This aspect is even more critical when considering the enormous amount of data that companies manipulate.
  3) Explainability or transparency which must ensure that the artificial models are understood and explained by the different actors throughout the organization, its departments and when challenged by governmental authorities. The value of a computational model can be lost if it lacks explainability by becoming irrelevant because it cannot answer ethical questions as in the case of the medical or banking industry.
  4) Security from a technological point of view is a growing concern, as attacks that threaten organizations and the protection of the population's data are major issues for any corporation or government.
  Protecting data from attacks is essential, and decision makers need to understand the potential risks and how they impact the technologies used in the companies they manage. Many businesses and customers evaluate AI security issues with a critical eye.
  5) Privacy refers to the protection of customer data, especially when AI is used in industries that handle sensitive data, this aspect should be of utmost importance to a CIO (not to be confused with CEO, Chief Executive Officer) who must ensure that technology solutions guarantee the protection of sensitive data and that privacy is provided for both the business and the customer.
  As we can see, ethics refers to the ability of people to differentiate between right and wrong and in the context of AI how this can be ensured in the technology that handles information associated with human beings. 
  In a call by monotheistic religions it is stated that new technologies must ensure that they are truly in the service of the entire human family. Principles in addition to those mentioned here include inclusiveness and fairness. 
  In other words, that with such technologies no one should be excluded in such a way that the algorithms do not discriminate against people on the basis of race, color, sex, religion, political or other opinion, national or social origin, property, birth or other status, as stated in Article 2 of the Universal Declaration of Human Rights. This is summarized by what has come to be known as the principles of algor-ethics. 
Classification
Language: ENGLISH
Publication-Type: Jornal
Journal Code: CENAFTAENG
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BEHAVIOR & COGNITION (90%); DICTIONARIES & THESAURI (90%); ETHICS (90%); HUMANITIES & SOCIAL SCIENCE (90%); EXECUTIVES (89%); ANCIENT HISTORY (78%); ANTHROPOLOGY & ARCHAEOLOGY (78%); CLASSICS (78%); COMPUTER SCIENCE (78%); CUSTOMER RELATIONS (78%); ECONOMICS (78%); SOCIOLOGY (78%); THEOLOGY (78%); ASSOCIATIONS & ORGANIZATIONS (77%); MODELING & SIMULATION (74%); RELIGION (69%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA SECURITY (89%); INFORMATION SECURITY & PRIVACY (89%); COMPUTER SCIENCE (78%); MODELING & SIMULATION (74%); BANKING & FINANCE (50%)
Load-Date: October 17, 2023",neutral,0.8602484464645386,balanced/neutral,"['privacy', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'human rights']","['character', 'fairness']","['should', 'must', 'need to']",[],7,2,3,0
2023,Unknown Title,"Dateline: NEW YORK, Oct. 10, 2023 
Body
PR Newswire
Annual executive survey examines the ethical implications of emerging technologies, with an added focus on Generative AI this year
Many companies are beginning to test or use Generative AI, yet more than half (56%) of respondents don't know or are unsure if their organizations have ethical standards guiding its use, according to Deloitte's second annual report on the ""State of Ethics and Trust in Technology.""
Nearly three-quarters (74%) of individuals surveyed say their companies have begun testing Generative AI, 65% are already using it inside their businesses, and 31% have begun using this technology for external consumption.
The study, led by Deloitte'sTechnology Trust Ethicspractice, surveyed more than 1,700 business and technical professionals across industry sectors to assess if and how ethical standards are being applied to emerging technology in their organizations. Emerging technology was defined as cognitive technologies (including AI), digital reality, ambient experiences, autonomous vehicles, quantum computing, distributed ledger technology and robotics, and the survey and report had an added focus on Generative AI this year.
""There is an inherent opportunity to apply emerging technologies for societal good while creating financial value for the enterprise,"" saidKwasi Mitchell, chief purpose and DEI officer at Deloitte. ""However, the adoption of Generative AI is outpacing the development of ethical principles around the use of the technology, intensifying the potential risks to society and corporate trust if these standards continue to lag.""
Key Findings:
Data privacy was reported as the top ethical concern about Generative AI. Respondents ranked data privacy (22%) as their No. 1 concern about Generative AI. Despite this, the percent of respondents who selected data privacy as one of the most important ethical principles for general emerging technologies in their organization fell from 19% in last year's survey to 7% this year.
The perception of cognitive technologies' potential for social good is increasing — and the perception of its potential for harm is rising even faster. In this year's survey, 39% of respondents indicated cognitive technologies — which includes Generative AI — have the most potential for good among all emerging technologies, up from 33% last year. Cognitive technologies were also ranked as most likely to pose a serious ethical risk among 57% of respondents, compared with 41% in 2022.
Organizations opt to retain, retrain and upskill in response to automation. Nearly three-quarters (73%) of respondents said their organizations are shifting some workers' tasks due to the adoption of new technologies. Among these organizations, 85% retain individuals whose roles are affected, and more than two-thirds (67%) additionally retrain or upskill those employees for new positions, countering common perceptions that emerging technology will eliminate jobs. When asked to rank top ethical concerns about Generative AI's use more broadly across business, only 7% of respondents cited job displacement where Generative AI replaces human jobs. 
Collaboration with other businesses on ethical tech standards remains unchanged, while expectations of government increase.Despite the increased attention on emerging technologies in the wake of Generative AI, only 27% of survey respondents reported their companies collaborating with commercial entities (down from 31% last year), and only 23% report partnering with government organizations to review potential ethics concerns (flat relative to 22% last year). The percentage of respondents who believe government should have a bigger role in setting ethical standards rose to 71% this year from 61% last year.
Respondents said their organizations are supportive of government playing a role in technology regulation, specifically in fostering cross-business collaboration to define standards (69%), setting regulations (59%), incentivizing adoption of standards (50%), and imposing financial penalties (37%). 
""The potential benefits of emerging technologies can increase when companies collaborate and share their knowledge,"" saidBeena Ammanath, managing director, Deloitte Consulting LLP and leader of Deloitte's Technology Trust Ethics practice, and the report's author. ""The sooner companies work together to identify the risks and establish governance up front, the better their ability may be to help generate stakeholder value, elevate their brands, create new markets and contribute to building a more equitable world.""
Deloitte'sTechnology Trust Ethics practice is part of theU.S. Purpose and DEI Office and focuses on embedding ethical decision-making into the development and use of emerging technology, to build trust in those technologies and expand the equitable opportunities of a tech-savvy world to all people.
The practice developed a Technology Trust Ethicsframework to help organizations assess the ethical implications of emerging technologies and guide responsible decision-making in the design, operation and governance of those technologies.  
MethodologyDeloitte's research included interviews in June 2023 with 26 executives and surveyed more than 1,700 business and technical professionals involved in developing, consuming or managing emerging technologies. Respondents represented industry sectors including technology, media and telecommunications; financial services; life sciences and health care; consumer; energy; academia; government and public service; and nonprofit. The survey spanned the impact of Generative AI on organizations, the understanding of and value placed on ethical principles for emerging technologies, and mechanisms to implement ethical behavior throughout their organizations.
About Deloitte
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world's most admired brands, including nearly 90% of the Fortune 500® and more than 8,500 U.S.-based private companies. At Deloitte, we strive to live our purpose of making animpact that mattersby creating trust and confidence in a more equitable society. We leverage our unique blend of business acumen, command of technology, and strategic technology alliances to advise our clients across industries as theybuild their future. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Bringing more than 175 years of service, our network of member firms spans more than 150 countries and territories. Learn how Deloitte's approximately 457,000 people worldwide connect for impact athttp://www.deloitte.com.
Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee (""DTTL""), its network of member firms, and their related entities. DTTL and each of its member firms are legally separate and independent entities. DTTL (also referred to as ""Deloitte Global"") does not provide services to clients. In the United States, Deloitte refers to one or more of the US member firms of DTTL, their related entities that operate using the ""Deloitte"" name in the United States and their respective affiliates. Certain services may not be available to attest clients under the rules and regulations of public accounting. Please seehttp://www.deloitte.com/about to learn more about our global network of member firms.
 View original content to download multimedia:https://www.prnewswire.com/news-releases/many-executives-uncertain-if-their-organizations-have-ethical-standards-for-generative-ai-deloitte-state-of-ethics-and-trust-in-technology-report-301951750.html
SOURCE Deloitte
CONTACT: Courtney Flaherty, Public Relations, Deloitte Services LP, +1 203 905 2708, cflaherty@deloitte.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (96%); GENERATIVE AI (94%); EMERGING TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); POLLS & SURVEYS (90%); REPORTS, REVIEWS & SECTIONS (90%); COGNITIVE COMPUTING (89%); RANKINGS (89%); PRESS RELEASES (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); TRUST ARRANGEMENTS (78%); RESKILLING & UPSKILLING (74%); ROBOTICS (73%); PROFESSIONAL WORKERS (72%); DISTRIBUTED LEDGERS (67%); EMPLOYEE RETRAINING (63%); QUANTUM COMPUTING (58%); DELOITTE-Report (%); SVY Surveys, polls & research studies (%)
Company:  DELOITTE LLP (90%); Deloitte
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (90%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (90%); GENERATIVE AI (94%); ARTIFICIAL INTELLIGENCE (90%); COGNITIVE COMPUTING (89%); ROBOTICS (73%); INFORMATION SECURITY & PRIVACY (69%); AUTONOMOUS VEHICLES (67%); DISTRIBUTED LEDGERS (67%); QUANTUM COMPUTING (58%); FIN Banking; Financial Services (%); STW Computer Software (%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: October 10, 2023","PR Newswire
Annual executive survey examines the ethical implications of emerging technologies, with an added focus on Generative AI this year
Many companies are beginning to test or use Generative AI, yet more than half (56%) of respondents don't know or are unsure if their organizations have ethical standards guiding its use, according to Deloitte's second annual report on the ""State of Ethics and Trust in Technology.""
Nearly three-quarters (74%) of individuals surveyed say their companies have begun testing Generative AI, 65% are already using it inside their businesses, and 31% have begun using this technology for external consumption.
The study, led by Deloitte'sTechnology Trust Ethicspractice, surveyed more than 1,700 business and technical professionals across industry sectors to assess if and how ethical standards are being applied to emerging technology in their organizations. Emerging technology was defined as cognitive technologies (including AI), digital reality, ambient experiences, autonomous vehicles, quantum computing, distributed ledger technology and robotics, and the survey and report had an added focus on Generative AI this year.
""There is an inherent opportunity to apply emerging technologies for societal good while creating financial value for the enterprise,"" saidKwasi Mitchell, chief purpose and DEI officer at Deloitte. ""However, the adoption of Generative AI is outpacing the development of ethical principles around the use of the technology, intensifying the potential risks to society and corporate trust if these standards continue to lag.""
Key Findings:
Data privacy was reported as the top ethical concern about Generative AI. Respondents ranked data privacy (22%) as their No. 1 concern about Generative AI. Despite this, the percent of respondents who selected data privacy as one of the most important ethical principles for general emerging technologies in their organization fell from 19% in last year's survey to 7% this year.
The perception of cognitive technologies' potential for social good is increasing — and the perception of its potential for harm is rising even faster. In this year's survey, 39% of respondents indicated cognitive technologies — which includes Generative AI — have the most potential for good among all emerging technologies, up from 33% last year. Cognitive technologies were also ranked as most likely to pose a serious ethical risk among 57% of respondents, compared with 41% in 2022.
Organizations opt to retain, retrain and upskill in response to automation. Nearly three-quarters (73%) of respondents said their organizations are shifting some workers' tasks due to the adoption of new technologies. Among these organizations, 85% retain individuals whose roles are affected, and more than two-thirds (67%) additionally retrain or upskill those employees for new positions, countering common perceptions that emerging technology will eliminate jobs. When asked to rank top ethical concerns about Generative AI's use more broadly across business, only 7% of respondents cited job displacement where Generative AI replaces human jobs. 
Collaboration with other businesses on ethical tech standards remains unchanged, while expectations of government increase.Despite the increased attention on emerging technologies in the wake of Generative AI, only 27% of survey respondents reported their companies collaborating with commercial entities (down from 31% last year), and only 23% report partnering with government organizations to review potential ethics concerns (flat relative to 22% last year). The percentage of respondents who believe government should have a bigger role in setting ethical standards rose to 71% this year from 61% last year.
Respondents said their organizations are supportive of government playing a role in technology regulation, specifically in fostering cross-business collaboration to define standards (69%), setting regulations (59%), incentivizing adoption of standards (50%), and imposing financial penalties (37%). 
""The potential benefits of emerging technologies can increase when companies collaborate and share their knowledge,"" saidBeena Ammanath, managing director, Deloitte Consulting LLP and leader of Deloitte's Technology Trust Ethics practice, and the report's author. ""The sooner companies work together to identify the risks and establish governance up front, the better their ability may be to help generate stakeholder value, elevate their brands, create new markets and contribute to building a more equitable world.""
Deloitte'sTechnology Trust Ethics practice is part of theU.S. Purpose and DEI Office and focuses on embedding ethical decision-making into the development and use of emerging technology, to build trust in those technologies and expand the equitable opportunities of a tech-savvy world to all people.
The practice developed a Technology Trust Ethicsframework to help organizations assess the ethical implications of emerging technologies and guide responsible decision-making in the design, operation and governance of those technologies.  
MethodologyDeloitte's research included interviews in June 2023 with 26 executives and surveyed more than 1,700 business and technical professionals involved in developing, consuming or managing emerging technologies. Respondents represented industry sectors including technology, media and telecommunications; financial services; life sciences and health care; consumer; energy; academia; government and public service; and nonprofit. The survey spanned the impact of Generative AI on organizations, the understanding of and value placed on ethical principles for emerging technologies, and mechanisms to implement ethical behavior throughout their organizations.
About Deloitte
Deloitte provides industry-leading audit, consulting, tax and advisory services to many of the world's most admired brands, including nearly 90% of the Fortune 500® and more than 8,500 U.S.-based private companies. At Deloitte, we strive to live our purpose of making animpact that mattersby creating trust and confidence in a more equitable society. We leverage our unique blend of business acumen, command of technology, and strategic technology alliances to advise our clients across industries as theybuild their future. Deloitte is proud to be part of the largest global professional services network serving our clients in the markets that are most important to them. Bringing more than 175 years of service, our network of member firms spans more than 150 countries and territories. Learn how Deloitte's approximately 457,000 people worldwide connect for impact athttp://www.deloitte.com.
Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee (""DTTL""), its network of member firms, and their related entities. DTTL and each of its member firms are legally separate and independent entities. DTTL (also referred to as ""Deloitte Global"") does not provide services to clients. In the United States, Deloitte refers to one or more of the US member firms of DTTL, their related entities that operate using the ""Deloitte"" name in the United States and their respective affiliates. Certain services may not be available to attest clients under the rules and regulations of public accounting. Please seehttp://www.deloitte.com/about to learn more about our global network of member firms.
 View original content to download multimedia:https://www.prnewswire.com/news-releases/many-executives-uncertain-if-their-organizations-have-ethical-standards-for-generative-ai-deloitte-state-of-ethics-and-trust-in-technology-report-301951750.html
SOURCE Deloitte
CONTACT: Courtney Flaherty, Public Relations, Deloitte Services LP, +1 203 905 2708, cflaherty@deloitte.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (96%); GENERATIVE AI (94%); EMERGING TECHNOLOGY (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); POLLS & SURVEYS (90%); REPORTS, REVIEWS & SECTIONS (90%); COGNITIVE COMPUTING (89%); RANKINGS (89%); PRESS RELEASES (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); TRUST ARRANGEMENTS (78%); RESKILLING & UPSKILLING (74%); ROBOTICS (73%); PROFESSIONAL WORKERS (72%); DISTRIBUTED LEDGERS (67%); EMPLOYEE RETRAINING (63%); QUANTUM COMPUTING (58%); DELOITTE-Report (%); SVY Surveys, polls & research studies (%)
Company:  DELOITTE LLP (90%); Deloitte
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (90%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (90%); GENERATIVE AI (94%); ARTIFICIAL INTELLIGENCE (90%); COGNITIVE COMPUTING (89%); ROBOTICS (73%); INFORMATION SECURITY & PRIVACY (69%); AUTONOMOUS VEHICLES (67%); DISTRIBUTED LEDGERS (67%); QUANTUM COMPUTING (58%); FIN Banking; Financial Services (%); STW Computer Software (%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: October 10, 2023",neutral,0.8821825981140137,balanced/neutral,"['privacy', 'security']",[],"['regulation', 'governance', 'standards', 'audit', 'should']","['generative ai', 'robotics']",2,0,5,2
2023,Unknown Title,"Body
Helsinki: Helsinki Municipality, Finland has issued the following news release:
Helsinki has defined the ethical principles of using data and artificial intelligence to promote sustainable digital development. The principles have been drawn up because our city wants to use data and artificial intelligence responsibly and act as a guide for others. There are enormous opportunities in utilizing data and artificial intelligence, but it must be implemented in an ethically sustainable way.
There are eight ethical principles. They are human orientation, transparency, explainability, justice and equality, responsibility and trust, privacy, security and human control over the operation of artificial intelligence.
Helsinki produces and utilizes data in the services it offers to its residents and in its operations as an employer and public administration organization. Various artificial intelligence applications are also utilized and developed continuously. Artificial intelligence can, for example, create opportunities for more efficient, predictive and personalized services. By applying ethical principles, the aim is to minimize ethical risks related to the utilization of data and artificial intelligence.
In practice, the principles mean that they must be applied in city services that are based on artificial intelligence. Services based on artificial intelligence are based on the fact that with the help of machine learning it is possible to predict things.
Part of the whole of the ethical utilization of artificial intelligence is the artificial intelligence register presenting the artificial intelligence systems in use in Helsinki.
Note: This is an automated translated version of the story which may have translation errors. Please always refer to the original story:https://www.hel.fi/fi/uutiset/helsinki-maaritteli-eettiset-periaatteet-datan-ja-tekoalyn-vastuulliselle-kaytolle
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ND
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); INTELLIGENCE SERVICES (73%); MACHINE LEARNING (73%); SUSTAINABILITY (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); MACHINE LEARNING (73%)
Geographic: HELSINKI, FINLAND (93%)
Load-Date: November 30, 2023","Helsinki: Helsinki Municipality, Finland has issued the following news release:
Helsinki has defined the ethical principles of using data and artificial intelligence to promote sustainable digital development. The principles have been drawn up because our city wants to use data and artificial intelligence responsibly and act as a guide for others. There are enormous opportunities in utilizing data and artificial intelligence, but it must be implemented in an ethically sustainable way.
There are eight ethical principles. They are human orientation, transparency, explainability, justice and equality, responsibility and trust, privacy, security and human control over the operation of artificial intelligence.
Helsinki produces and utilizes data in the services it offers to its residents and in its operations as an employer and public administration organization. Various artificial intelligence applications are also utilized and developed continuously. Artificial intelligence can, for example, create opportunities for more efficient, predictive and personalized services. By applying ethical principles, the aim is to minimize ethical risks related to the utilization of data and artificial intelligence.
In practice, the principles mean that they must be applied in city services that are based on artificial intelligence. Services based on artificial intelligence are based on the fact that with the help of machine learning it is possible to predict things.
Part of the whole of the ethical utilization of artificial intelligence is the artificial intelligence register presenting the artificial intelligence systems in use in Helsinki.
Note: This is an automated translated version of the story which may have translation errors. Please always refer to the original story:https://www.hel.fi/fi/uutiset/helsinki-maaritteli-eettiset-periaatteet-datan-ja-tekoalyn-vastuulliselle-kaytolle
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ND
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); INTELLIGENCE SERVICES (73%); MACHINE LEARNING (73%); SUSTAINABILITY (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); MACHINE LEARNING (73%)
Geographic: HELSINKI, FINLAND (93%)
Load-Date: November 30, 2023",neutral,0.7003144025802612,balanced/neutral,"['privacy', 'transparency', 'explainability', 'security']","['justice', 'equality', 'justice']",['must'],['machine learning'],4,3,1,1
2023,Unknown Title,"Body
Medical ethics is a branch of ethics that focuses on the moral principles and standards guiding the conduct of health professionals, particularly doctors. It aims to establish ethical guidelines for decision-making in medical care and promote trust between doctors and patients. Ethical conflicts arise when there are conflicts between values, principles, or moral norms, making decision-making challenging. These conflicts can occur in situations such as when a doctor wants to administer treatment to save a patient's life, but the patient refuses or disagrees with the treatment. Other ethical dilemmas arise at the end of life when decisions must be made to prioritize the patient's comfort, well-being, and autonomy.
Key Highlights:
* Ethical conflicts can also arise at the end of life, when decisions must be made to prioritize the patient's comfort, well-being, and autonomy.
* The incorporation of technology and artificial intelligence in medicine has generated ethical conflicts related to efficiency, humanization of medical care, privacy and equity in data collection, and responsibility in algorithmic decisions.
* To resolve ethical conflicts in medicine, the medical or clinical aspects, the conflicting values and the possible consequences of each alternative solution must be taken into account.
Original Press Release:
Sept. 28 -- Quirnsalud issued the following news release:
- In the medical field, ethical questions can be especially complex due to the delicate and often crucial nature of the decisions that must be made. Ethics Committees contribute to resolving these conflicts and making more informed decisions.
Ethics deals with the study of the moral principles and values that guide human behavior and determine what is considered right or wrong from a moral point of view.
Medical ethics is a specific branch of ethics that focuses on the moral principles and standards that guide the conduct of health professionals , especially doctors. Its main objective is to establish ethical guidelines and guidance for decision-making in situations related to medical care and patient treatment. In addition, it promotes trust between doctors and patients and contributes to quality medical care.
What is an ethical conflict in healthcare practice?
An ethical doubt is a situation in which a person, in a specific context, is undecided about what is the correct or appropriate action . These doubts arise in the face of ethical conflicts, that is, situations in which there are conflicts between values, principles or moral norms that make decision-making difficult.
In the clinical setting, ethical questions can be especially complex due to the delicate and often crucial nature of the decisions that must be made. ""This occurs, for example, when, on the one hand, the doctor wants to apply treatment to save the patient's life and on the other, the patient refuses, is not sure or does not agree with the treatment. Here, care of health (administering the treatment) and the freedom of the patient (respecting his decision) come into conflict ,"" explains Dr. Benjamn Herreros Ruiz-Valdepeas , a doctor specializing in Internal Medicine and Legal and Forensic Medicine at the Ruber International Hospital, in addition Graduate in Philosophy.
""Other ethical problems occur at the end of life , when the patient has less time left and their quality of life is diminished, and decisions must be made to prioritize the patient's comfort, well-being and autonomy,"" he comments.
The incorporation of technology and artificial intelligence in medicine has provided significant advances, but has also generated crucial ethical conflicts. The balance between efficiency and humanization of healthcare , privacy and equity in data collection, as well as accountability in algorithmic decisions are issues that require constant ethical attention.
Resolving these ethical conflicts appropriately is essential to providing ethical, patient-centered medical care .
Response to Ethical Conflicts in Medicine
According to Dr. Herreros, to address the ethical problems of healthcare practice, all the factors that influence decision-making must be taken into account , such as medical or clinical aspects, values that conflict, as well as the different alternatives. of solutions available taking into account the possible consequences of each alternative. ""In the end, with all these variables we build the best possible decision , the one that best resolves the values that are in conflict, and that results in a decision that is consistent with both professionals and patients,"" he highlights.
In their quest to resolve ethical questions, clinicians often draw on their own ethical judgment, personal values, and professional experience. However, this approach may be insufficient when faced with complex or novel ethical dilemmas. To address these situations, it is common for healthcare professionals to seek advice from colleagues, more experienced professionals and also from Healthcare Ethics Committees .
Ethics Committees and Ethics Consultants
For the ethics expert, when faced with a conflict or ethical doubt, professionals and patients can consult the Ethics Committees for Health Care (CEAS) or Ethics Consultants. ""At the Ruber International Hospital there is an Ethics Committee, and when a professional or a patient has an ethical doubt about what to do, for example, if the patient does not agree with the decision made by the medical team, but his or her family is trying to convince him to make that decision, the patient and the medical team can consult the Ethics Committee of our Hospital to find a way out of the conflict.
Medical ethics committees are made up of a multidisciplinary group made up of doctors from different specialties, nurses, medical ethics experts, lawyers, patients and other members of the hospital and the community. ""From this multidisciplinary group, from this prism of visions , ethical conflicts are addressed to find the best solution ,"" she says.
As Dr. Herreros highlights, the recommendations of the Ethics Committees are not binding. "" The recommendations given by an ethics committee are not mandatory ; they are advice and recommendations that the patient or doctors may or may not take into account. What is reasonable is that it be a well-argued and justified recommendation that helps patients to make the best decisions,"" he concludes.
Recently, Dr. Benjamn Herreros Ruiz-Valdepeas presented an interesting talk on "" How to resolve ethical doubts? Ethical advice and consultation in healthcare practice"" , during the General Session of our hospital. In his presentation, the specialist highlighted the importance of the Ethical Consultation and Advisory Models , since they provide professionals with the necessary tools to make informed ethical decisions and, ultimately, provide quality patient-centered care.
Disclaimer: The Above Content is Auto-Translated
[Category: Health Care Services and Facilities, Health Care, Regulatory and Legal]
Source: Quirnsalud
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (96%); HEALTH CARE PROFESSIONALS (90%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (90%); EXPERIMENTATION & RESEARCH (89%); PROFESSIONAL WORKERS (89%); MEDICAL SCIENCE (79%); BEHAVIOR & COGNITION (78%); PHYSICIANS & SURGEONS (78%); SCIENCE & TECHNOLOGY (78%); DEATH & DYING (77%); ARTIFICIAL INTELLIGENCE (53%)
Industry: HEALTH CARE PROFESSIONALS (90%); PHYSICIANS & SURGEONS (78%); ARTIFICIAL INTELLIGENCE (53%)
Load-Date: September 28, 2023","Medical ethics is a branch of ethics that focuses on the moral principles and standards guiding the conduct of health professionals, particularly doctors. It aims to establish ethical guidelines for decision-making in medical care and promote trust between doctors and patients. Ethical conflicts arise when there are conflicts between values, principles, or moral norms, making decision-making challenging. These conflicts can occur in situations such as when a doctor wants to administer treatment to save a patient's life, but the patient refuses or disagrees with the treatment. Other ethical dilemmas arise at the end of life when decisions must be made to prioritize the patient's comfort, well-being, and autonomy.
Key Highlights:
* Ethical conflicts can also arise at the end of life, when decisions must be made to prioritize the patient's comfort, well-being, and autonomy.
* The incorporation of technology and artificial intelligence in medicine has generated ethical conflicts related to efficiency, humanization of medical care, privacy and equity in data collection, and responsibility in algorithmic decisions.
* To resolve ethical conflicts in medicine, the medical or clinical aspects, the conflicting values and the possible consequences of each alternative solution must be taken into account.
Original Press Release:
Sept. 28 -- Quirnsalud issued the following news release:
- In the medical field, ethical questions can be especially complex due to the delicate and often crucial nature of the decisions that must be made. Ethics Committees contribute to resolving these conflicts and making more informed decisions.
Ethics deals with the study of the moral principles and values that guide human behavior and determine what is considered right or wrong from a moral point of view.
Medical ethics is a specific branch of ethics that focuses on the moral principles and standards that guide the conduct of health professionals , especially doctors. Its main objective is to establish ethical guidelines and guidance for decision-making in situations related to medical care and patient treatment. In addition, it promotes trust between doctors and patients and contributes to quality medical care.
What is an ethical conflict in healthcare practice?
An ethical doubt is a situation in which a person, in a specific context, is undecided about what is the correct or appropriate action . These doubts arise in the face of ethical conflicts, that is, situations in which there are conflicts between values, principles or moral norms that make decision-making difficult.
In the clinical setting, ethical questions can be especially complex due to the delicate and often crucial nature of the decisions that must be made. ""This occurs, for example, when, on the one hand, the doctor wants to apply treatment to save the patient's life and on the other, the patient refuses, is not sure or does not agree with the treatment. Here, care of health (administering the treatment) and the freedom of the patient (respecting his decision) come into conflict ,"" explains Dr. Benjamn Herreros Ruiz-Valdepeas , a doctor specializing in Internal Medicine and Legal and Forensic Medicine at the Ruber International Hospital, in addition Graduate in Philosophy.
""Other ethical problems occur at the end of life , when the patient has less time left and their quality of life is diminished, and decisions must be made to prioritize the patient's comfort, well-being and autonomy,"" he comments.
The incorporation of technology and artificial intelligence in medicine has provided significant advances, but has also generated crucial ethical conflicts. The balance between efficiency and humanization of healthcare , privacy and equity in data collection, as well as accountability in algorithmic decisions are issues that require constant ethical attention.
Resolving these ethical conflicts appropriately is essential to providing ethical, patient-centered medical care .
Response to Ethical Conflicts in Medicine
According to Dr. Herreros, to address the ethical problems of healthcare practice, all the factors that influence decision-making must be taken into account , such as medical or clinical aspects, values that conflict, as well as the different alternatives. of solutions available taking into account the possible consequences of each alternative. ""In the end, with all these variables we build the best possible decision , the one that best resolves the values that are in conflict, and that results in a decision that is consistent with both professionals and patients,"" he highlights.
In their quest to resolve ethical questions, clinicians often draw on their own ethical judgment, personal values, and professional experience. However, this approach may be insufficient when faced with complex or novel ethical dilemmas. To address these situations, it is common for healthcare professionals to seek advice from colleagues, more experienced professionals and also from Healthcare Ethics Committees .
Ethics Committees and Ethics Consultants
For the ethics expert, when faced with a conflict or ethical doubt, professionals and patients can consult the Ethics Committees for Health Care (CEAS) or Ethics Consultants. ""At the Ruber International Hospital there is an Ethics Committee, and when a professional or a patient has an ethical doubt about what to do, for example, if the patient does not agree with the decision made by the medical team, but his or her family is trying to convince him to make that decision, the patient and the medical team can consult the Ethics Committee of our Hospital to find a way out of the conflict.
Medical ethics committees are made up of a multidisciplinary group made up of doctors from different specialties, nurses, medical ethics experts, lawyers, patients and other members of the hospital and the community. ""From this multidisciplinary group, from this prism of visions , ethical conflicts are addressed to find the best solution ,"" she says.
As Dr. Herreros highlights, the recommendations of the Ethics Committees are not binding. "" The recommendations given by an ethics committee are not mandatory ; they are advice and recommendations that the patient or doctors may or may not take into account. What is reasonable is that it be a well-argued and justified recommendation that helps patients to make the best decisions,"" he concludes.
Recently, Dr. Benjamn Herreros Ruiz-Valdepeas presented an interesting talk on "" How to resolve ethical doubts? Ethical advice and consultation in healthcare practice"" , during the General Session of our hospital. In his presentation, the specialist highlighted the importance of the Ethical Consultation and Advisory Models , since they provide professionals with the necessary tools to make informed ethical decisions and, ultimately, provide quality patient-centered care.
Disclaimer: The Above Content is Auto-Translated
[Category: Health Care Services and Facilities, Health Care, Regulatory and Legal]
Source: Quirnsalud
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (96%); HEALTH CARE PROFESSIONALS (90%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (90%); EXPERIMENTATION & RESEARCH (89%); PROFESSIONAL WORKERS (89%); MEDICAL SCIENCE (79%); BEHAVIOR & COGNITION (78%); PHYSICIANS & SURGEONS (78%); SCIENCE & TECHNOLOGY (78%); DEATH & DYING (77%); ARTIFICIAL INTELLIGENCE (53%)
Industry: HEALTH CARE PROFESSIONALS (90%); PHYSICIANS & SURGEONS (78%); ARTIFICIAL INTELLIGENCE (53%)
Load-Date: September 28, 2023",neutral,0.8183521628379822,balanced/neutral,"['privacy', 'accountability', 'autonomy']","['equity', 'autonomy']","['standards', 'guidelines', 'must']",[],3,2,3,0
2023,Unknown Title,"Body
 NEW YORK, NY, May  18, 2023  (GLOBE NEWSWIRE) -- via NewMediaWire – Bubblr Inc. (OTC QB: BBLR), an ethical technology company known for pioneering an Ethical Web Open-Source platform, announces its rebranding to Ethical Web AI. This trade name better encapsulates its mission and focus on improving the future of search and advancing a more ethical Internet.
Tim Burks, the CEO of the company formerly known as Bubblr, Inc., stated: ""From the start, it was evident that the name Bubblr did not accurately reflect our company’s purpose, products, or core philosophy. We have always identified ourselves as an ethical web business. Moreover, our soon-to-be-launched GPT Dynamic app is fundamentally centered around large language models (LLMs) and artificial intelligence. Therefore, Ethical Web AI is a name that truly represents our essence.
""We had previously acquired the domain name Ethicalweb.ai, which we believed was far more descriptive of our business. We have now built the EthicalWeb.ai website, and all traffic from bubblr.com has been redirected to this new site. We are in the process of filing a request to the state of Wyoming to formally reserve the name Ethical Web AI, given its active use.""
Burks also highlighted the unanimous support for the name change from the company's marketing partners—Beyond Media Group, Outside the Box Capital, and Milestone Management Services. ""All three firms expressed concern that our previous name did not reflect our business’s purpose and were fully supportive of the change. In fact, they have deliberately reserved their marketing strategies until this change was implemented, which it now has been.
""Both Professor Paul Morrissey, our Chief Strategy Officer, and I were motivated to join the company largely because of its ethical web credentials. We both fully endorse the company's ethical web manifesto, which includes decentralized profits and data collection, protection of citizens' privacy rights, a level playing field for businesses, combating social and cultural division, and resisting corruption by advertising.
""The board of directors unanimously agreed that it made complete sense for our marketing partners to reserve their strategies until we began operating under the more meaningful and reflective business name of Ethical Web AI,"" Burks concluded.
Contact: Steve Morris Bubblr, Inc. (646) 814 7184
Ethical Web AI.  
Ethical Web AI, Inc. is an ethical technology company that is providing the essential building blocks for the future of search on the Internet. It is building an open-source Ethical Web platform that is the technological manifestation of its very valuable granted patents. This platform will make available open-source app templates for licensees to build their own community apps or integrate our software with any existing apps. 
Important Cautions Regarding Forward-Looking Statements This press release contains forward-looking statements within the definition of Section 27A of the Securities Act of 1933, as amended, and such as in Section 21E of the Securities Act of 1934, as amended. These forward-looking statements should not be used to make an investment decision. The words' estimate,' possible,' and 'seeking' and similar expressions identify forward-looking statements, which speak only as to the date the statement was made. The Company undertakes no obligation to publicly update or revise any forward-looking statements, whether because of new information, future events, or otherwise. Forward-looking statements are inherently subject to risks and uncertainties, some of which cannot be predicted or quantified. Future events and actual results could differ materially from those set forth in, contemplated by, or underlying the forward-looking statements. The risks and uncertainties to which forward-looking statements are subject include but are not limited to, the effect of government regulation, competition, and other material risks.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (91%); REBRANDING (90%); COMPANY STRATEGY (89%); EXECUTIVES (89%); BUSINESS ETHICS (79%); ARTIFICIAL INTELLIGENCE (78%); COMPANY NAME CHANGES (78%); LARGE LANGUAGE MODELS (78%); PATENTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BOARDS OF DIRECTORS (74%); CULTURE DEPARTMENTS (74%); CORRUPTION (73%); BRANDING (72%); SECURITIES LAW (66%); US SECURITIES ACT OF 1933 (66%); ALLIANCES & PARTNERSHIPS (65%); PRIVACY RIGHTS (61%)
Company: BUBBLR INC.
Ticker: BBLR (Other OTC)
Industry: INFORMATION TECHNOLOGY INDUSTRY (90%); REBRANDING (90%); COMPUTER NETWORKS (89%); INTERNET & WWW (89%); OPEN SOURCE SOFTWARE (89%); MEDIA & TELECOMMUNICATIONS (79%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER SOFTWARE (78%); LARGE LANGUAGE MODELS (78%); DOMAIN NAMES (73%); BRANDING (72%); MARKETING STRATEGY (70%); INFORMATION SECURITY & PRIVACY (66%); SECURITIES LAW (66%); US SECURITIES ACT OF 1933 (66%); Internet (%)
Company-Terms: Internet Bubblr Inc. BBLR (Other OTC) ::issuer-state=::issuer-country=:: ::issuer-country=:: ::
Geographic: NEW YORK, NY, USA (79%); NEW YORK, USA (79%); WYOMING, USA (78%)
Load-Date: May 18, 2023","NEW YORK, NY, May  18, 2023  (GLOBE NEWSWIRE) -- via NewMediaWire – Bubblr Inc. (OTC QB: BBLR), an ethical technology company known for pioneering an Ethical Web Open-Source platform, announces its rebranding to Ethical Web AI. This trade name better encapsulates its mission and focus on improving the future of search and advancing a more ethical Internet.
Tim Burks, the CEO of the company formerly known as Bubblr, Inc., stated: ""From the start, it was evident that the name Bubblr did not accurately reflect our company’s purpose, products, or core philosophy. We have always identified ourselves as an ethical web business. Moreover, our soon-to-be-launched GPT Dynamic app is fundamentally centered around large language models (LLMs) and artificial intelligence. Therefore, Ethical Web AI is a name that truly represents our essence.
""We had previously acquired the domain name Ethicalweb.ai, which we believed was far more descriptive of our business. We have now built the EthicalWeb.ai website, and all traffic from bubblr.com has been redirected to this new site. We are in the process of filing a request to the state of Wyoming to formally reserve the name Ethical Web AI, given its active use.""
Burks also highlighted the unanimous support for the name change from the company's marketing partners—Beyond Media Group, Outside the Box Capital, and Milestone Management Services. ""All three firms expressed concern that our previous name did not reflect our business’s purpose and were fully supportive of the change. In fact, they have deliberately reserved their marketing strategies until this change was implemented, which it now has been.
""Both Professor Paul Morrissey, our Chief Strategy Officer, and I were motivated to join the company largely because of its ethical web credentials. We both fully endorse the company's ethical web manifesto, which includes decentralized profits and data collection, protection of citizens' privacy rights, a level playing field for businesses, combating social and cultural division, and resisting corruption by advertising.
""The board of directors unanimously agreed that it made complete sense for our marketing partners to reserve their strategies until we began operating under the more meaningful and reflective business name of Ethical Web AI,"" Burks concluded.
Contact: Steve Morris Bubblr, Inc. (646) 814 7184
Ethical Web AI.  
Ethical Web AI, Inc. is an ethical technology company that is providing the essential building blocks for the future of search on the Internet. It is building an open-source Ethical Web platform that is the technological manifestation of its very valuable granted patents. This platform will make available open-source app templates for licensees to build their own community apps or integrate our software with any existing apps. 
Important Cautions Regarding Forward-Looking Statements This press release contains forward-looking statements within the definition of Section 27A of the Securities Act of 1933, as amended, and such as in Section 21E of the Securities Act of 1934, as amended. These forward-looking statements should not be used to make an investment decision. The words' estimate,' possible,' and 'seeking' and similar expressions identify forward-looking statements, which speak only as to the date the statement was made. The Company undertakes no obligation to publicly update or revise any forward-looking statements, whether because of new information, future events, or otherwise. Forward-looking statements are inherently subject to risks and uncertainties, some of which cannot be predicted or quantified. Future events and actual results could differ materially from those set forth in, contemplated by, or underlying the forward-looking statements. The risks and uncertainties to which forward-looking statements are subject include but are not limited to, the effect of government regulation, competition, and other material risks.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (91%); REBRANDING (90%); COMPANY STRATEGY (89%); EXECUTIVES (89%); BUSINESS ETHICS (79%); ARTIFICIAL INTELLIGENCE (78%); COMPANY NAME CHANGES (78%); LARGE LANGUAGE MODELS (78%); PATENTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BOARDS OF DIRECTORS (74%); CULTURE DEPARTMENTS (74%); CORRUPTION (73%); BRANDING (72%); SECURITIES LAW (66%); US SECURITIES ACT OF 1933 (66%); ALLIANCES & PARTNERSHIPS (65%); PRIVACY RIGHTS (61%)
Company: BUBBLR INC.
Ticker: BBLR (Other OTC)
Industry: INFORMATION TECHNOLOGY INDUSTRY (90%); REBRANDING (90%); COMPUTER NETWORKS (89%); INTERNET & WWW (89%); OPEN SOURCE SOFTWARE (89%); MEDIA & TELECOMMUNICATIONS (79%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER SOFTWARE (78%); LARGE LANGUAGE MODELS (78%); DOMAIN NAMES (73%); BRANDING (72%); MARKETING STRATEGY (70%); INFORMATION SECURITY & PRIVACY (66%); SECURITIES LAW (66%); US SECURITIES ACT OF 1933 (66%); Internet (%)
Company-Terms: Internet Bubblr Inc. BBLR (Other OTC) ::issuer-state=::issuer-country=:: ::issuer-country=:: ::
Geographic: NEW YORK, NY, USA (79%); NEW YORK, USA (79%); WYOMING, USA (78%)
Load-Date: May 18, 2023",neutral,0.7167352437973022,balanced/neutral,"['privacy', 'security']",[],"['regulation', 'law', 'should']",['gpt'],2,0,3,1
2023,Unknown Title,"Body
November 9, 2023 | OPINION | By Clay Arnold
On the cusp of a technological revolution, artificial intelligence is set to revolutionize healthcare, banking, retail and manufacturing. But the shine of artificial intelligence's promise is clouded by a ""black box"" mystery: the opaque decision-making that leaves us guessing about how AI thinks. This calls for an urgent push for clarity and ethics in AI's rollout. We are seeing a wave of fresh solutions and laws emerging to crack open the black box, transforming the conversation around ethical and explainable AI from academic musings to a societal imperative.
The black box problem acts as a barrier to trustworthy and ethical deployment. The opacity and lack of understandability in AI's decision-making processes, which are particularly pronounced in deep learning systems, obscure the underlying logic or decision pathways. This presents challenges in critical domains like healthcare, finance and criminal justice, where trust in AI-driven decisions is paramount.
The narrative grows darker when considering incentive schemes, where the races for innovation and market dominance often overshadow the imperatives for transparency and ethical conduct. A case in point is IBM's Watson for Oncology program, which faced setbacks because it couldn't provide rationales for its diagnoses, eroding trust in its capabilities.
In response to these challenges, xAI emerges as a beacon of hope, aiming to demystify AI's black box by making operations understandable and transparent. This is particularly crucial in sensitive areas where AI-driven decisions bear significant repercussions. By fostering a degree of clarity and context, xAI seeks to mitigate human and data bias in AI implementation, thereby establishing a foundation of trust and ensuring accountability.
The regulatory front presents a mixed global response. The European Union has showcased proactive steps by proposing legislation such as the AI Act to foster responsible AI usage. This approach exemplifies how regulatory frameworks can foster an environment conducive to ethical AI development. Conversely, the U.S. lacks a cohesive regulatory strategy, highlighting the varying pace at which different governments are addressing AI transparency and ethics.
The black box exacerbates the alignment problem of ensuring that AI systems' objectives resonate with human values. The opacity in AI-driven decisions intensifies anxieties among the workforce regarding AI's potential to replace human jobs, particularly when there is no clear, understandable logic behind such automated decisions. This misalignment could potentially worsen discrimination, erode public trust and challenge regulatory frameworks.
In tackling the black box issue, it is essential to consider that the demand for transparency need not come at the expense of performance. Trust, a cornerstone for the widespread adoption of AI, often hinges on the intelligibility of its decisions, particularly in sensitive sectors. Advancements in xAI promise to evolve AI methodologies, potentially offering models that provide transparency without compromising on accuracy. Transparency can be tiered, presenting explanations in various user-centric manners which cater to both laypersons and experts.
Adherence to ethical standards and regulatory compliance is necessary, suggesting that if a model's complexity inherently precludes transparency, its application in high-stakes areas should be reconsidered.
Benchmarking and standardization across the AI industry could enforce a harmonious balance between performance and integrity. Furthermore, transparent AI systems permit accountability and facilitate the iterative process of error correction and system improvement, enhancing long-term reliability. Thus, the integration of AI into societal fabrics must not only champion innovation but also uphold a commitment to ethical transparency, ensuring AI remains a trustworthy ally to human progress.
The issues surrounding the black box problem in AI may point toward a more transparent, accountable, and ethically aligned AI landscape. The emergence of xAI, coupled with proactive regulatory steps and a burgeoning global acknowledgment of the issues at hand, hints at a promising future. Addressing the black box problem now is a top priority. It is essential to ensure that, as we advance towards more powerful AI, we also progress toward a future where these systems are transparent, accountable and aligned with human values and societal good.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DISCRIMINATION (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); NEGATIVE SOCIETAL NEWS (75%); DEEP LEARNING (73%); MACHINE LEARNING (73%); CRIMINAL JUSTICE (72%); ONCOLOGY (66%); LABOR FORCE (64%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%); CRIME, LAW ENFORCEMENT & CORRECTIONS (53%); EUROPEAN UNION (50%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MANUFACTURING (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEP LEARNING (73%); MACHINE LEARNING (73%); ONCOLOGY (66%)
Geographic: COLORADO SPRINGS, CO, USA (59%); COLORADO, USA (92%); UNITED STATES (79%); EUROPEAN UNION MEMBER STATES (53%); Colorado Springs; CO
Load-Date: November 9, 2023","November 9, 2023 | OPINION | By Clay Arnold
On the cusp of a technological revolution, artificial intelligence is set to revolutionize healthcare, banking, retail and manufacturing. But the shine of artificial intelligence's promise is clouded by a ""black box"" mystery: the opaque decision-making that leaves us guessing about how AI thinks. This calls for an urgent push for clarity and ethics in AI's rollout. We are seeing a wave of fresh solutions and laws emerging to crack open the black box, transforming the conversation around ethical and explainable AI from academic musings to a societal imperative.
The black box problem acts as a barrier to trustworthy and ethical deployment. The opacity and lack of understandability in AI's decision-making processes, which are particularly pronounced in deep learning systems, obscure the underlying logic or decision pathways. This presents challenges in critical domains like healthcare, finance and criminal justice, where trust in AI-driven decisions is paramount.
The narrative grows darker when considering incentive schemes, where the races for innovation and market dominance often overshadow the imperatives for transparency and ethical conduct. A case in point is IBM's Watson for Oncology program, which faced setbacks because it couldn't provide rationales for its diagnoses, eroding trust in its capabilities.
In response to these challenges, xAI emerges as a beacon of hope, aiming to demystify AI's black box by making operations understandable and transparent. This is particularly crucial in sensitive areas where AI-driven decisions bear significant repercussions. By fostering a degree of clarity and context, xAI seeks to mitigate human and data bias in AI implementation, thereby establishing a foundation of trust and ensuring accountability.
The regulatory front presents a mixed global response. The European Union has showcased proactive steps by proposing legislation such as the AI Act to foster responsible AI usage. This approach exemplifies how regulatory frameworks can foster an environment conducive to ethical AI development. Conversely, the U.S. lacks a cohesive regulatory strategy, highlighting the varying pace at which different governments are addressing AI transparency and ethics.
The black box exacerbates the alignment problem of ensuring that AI systems' objectives resonate with human values. The opacity in AI-driven decisions intensifies anxieties among the workforce regarding AI's potential to replace human jobs, particularly when there is no clear, understandable logic behind such automated decisions. This misalignment could potentially worsen discrimination, erode public trust and challenge regulatory frameworks.
In tackling the black box issue, it is essential to consider that the demand for transparency need not come at the expense of performance. Trust, a cornerstone for the widespread adoption of AI, often hinges on the intelligibility of its decisions, particularly in sensitive sectors. Advancements in xAI promise to evolve AI methodologies, potentially offering models that provide transparency without compromising on accuracy. Transparency can be tiered, presenting explanations in various user-centric manners which cater to both laypersons and experts.
Adherence to ethical standards and regulatory compliance is necessary, suggesting that if a model's complexity inherently precludes transparency, its application in high-stakes areas should be reconsidered.
Benchmarking and standardization across the AI industry could enforce a harmonious balance between performance and integrity. Furthermore, transparent AI systems permit accountability and facilitate the iterative process of error correction and system improvement, enhancing long-term reliability. Thus, the integration of AI into societal fabrics must not only champion innovation but also uphold a commitment to ethical transparency, ensuring AI remains a trustworthy ally to human progress.
The issues surrounding the black box problem in AI may point toward a more transparent, accountable, and ethically aligned AI landscape. The emergence of xAI, coupled with proactive regulatory steps and a burgeoning global acknowledgment of the issues at hand, hints at a promising future. Addressing the black box problem now is a top priority. It is essential to ensure that, as we advance towards more powerful AI, we also progress toward a future where these systems are transparent, accountable and aligned with human values and societal good.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DISCRIMINATION (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); NEGATIVE SOCIETAL NEWS (75%); DEEP LEARNING (73%); MACHINE LEARNING (73%); CRIMINAL JUSTICE (72%); ONCOLOGY (66%); LABOR FORCE (64%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%); CRIME, LAW ENFORCEMENT & CORRECTIONS (53%); EUROPEAN UNION (50%)
Company:  AI SYSTEMS (52%)
Industry: SIC7372 PREPACKAGED SOFTWARE (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MANUFACTURING (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DEEP LEARNING (73%); MACHINE LEARNING (73%); ONCOLOGY (66%)
Geographic: COLORADO SPRINGS, CO, USA (59%); COLORADO, USA (92%); UNITED STATES (79%); EUROPEAN UNION MEMBER STATES (53%); Colorado Springs; CO
Load-Date: November 9, 2023",neutral,0.7625181078910828,balanced/neutral,"['bias', 'discrimination', 'transparency', 'accountability']","['justice', 'justice']","['regulation', 'policy', 'standards', 'legislation', 'law', 'compliance', 'should', 'must', 'calls for']","['machine learning', 'deep learning']",4,2,9,2
2023,Unknown Title,"Body
Paris: Committee On Data For Science And Technology has issued the following news release:
International Seminar on BioData and AI (ISBA) 2023will be held on September 9th, 2023, in Shenzhen, China, with in-person and online participationoptions available.
This event offers free registration with no associated fees in the spirit of open and inclusive science.For more information, the agenda, and to register, please visit our website athttps://db.cngb.org/isba/.
About the ISBA 2023
The ISBA 2023 brings together international researchers, practitioners, policymakers, and ethicists to discuss the crucial issues that arise at the intersection of data science, the life sciences, artificial intelligence (AI), and society. As these fields continue to advance rapidly, it is essential to address the policy and ethical challenges they pose to ensure responsible and beneficial outcomes for individuals and society as a whole. This workshop will examine the ways in which new data and AI technologies are developed, introduced, and implemented in the life sciences, industry, and society. It will give particular attention to a focus on economics and the advancement of the life sciences and their impact on health, the environment, and society. The sessions will explore how human, animal, and plant (organic) specimens and data are collected, processed, and used by science, industry, and government to address the needs of our societies. The role of various ML and AI models, their implementation, and their impact will be considered within the development of legal structures, policy, and governance models for new technologies, the life sciences, data, and AI. The workshop will examine how we can support the development of genomics, multi-omics, and the life sciences using policy and ethics to empower, not only our economies and healthcare systems, but also citizens by creating healthier and more harmonised societies.
Objectives
The primary objective of the workshop is to foster interdisciplinary dialogue that encourages meaningful discussions and collaborations among experts from diverse disciplines engaged with data science, the life sciences, AI, policy making, and ethics. The following aims support this primary objective:
Within the context of open science and new emerging technologies, the workshop will investigate the policy implications and considerations arising from the use of data science, the life sciences, and AI applications and their impact on society.
The seminar will address the ethical challenges posed by the development and deployment of data science, life sciences, AI technologies and applications, and consider ethical frameworks for responsible innovation.
The seminar will promote responsible practices that foster the adoption of responsible frameworks and conduct in data science, life sciences, and AI to safeguard privacy, equity, fairness, transparency, and accountability.
The seminar will facilitate knowledge exchange by providing a platform for participants to share their research findings, best practices, case studies, and experiences related to policy and ethics in the intersecting fields.
The seminar will examine pathways and methodologies for the development of state-of-the-art platforms for education and expertise development in ethics and governance to meet the needs of academia, industry, government agencies, and NGOs in developing young leadership for our digital societies.
Practical Information
Registrationand participation:The event is free, and no registration fees are associated. The participants are expected to cover the costs of their travel. The organisers expect up to 120 participants.Venue:China National GenBank, Jinsha Road, Dapeng District, Shenzhen, Guangdong Province, China.Dates:September 9th, 2023Convenors:China National GenBank (CNGB), Committee on Data of the International Science Council (CODATA)Sponsors:Guangdong Science & Technology Infrastructure Center (GDSTIC)Contact:cngb_isba@cngb.org
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPANY PRESS RELEASES (90%); ETHICS (90%); DATA SCIENCE (89%); EMERGING TECHNOLOGY (89%); PUBLIC POLICY (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CASE STUDIES (78%); ECONOMICS (78%); EXPERIMENTATION & RESEARCH (78%); SCIENCE POLICY (78%); BEST PRACTICES (75%); BIOTECHNOLOGY & GENETIC SCIENCE (71%); RESEARCH REPORTS (71%); GENOMICS (70%); BIOTECHNOLOGY INDUSTRY (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); BIOTECHNOLOGY INDUSTRY (68%)
Geographic: SHENZHEN, GUANGDONG, CHINA (58%); SOUTH CHINA (73%); CHINA (79%)
Load-Date: August 31, 2023","Paris: Committee On Data For Science And Technology has issued the following news release:
International Seminar on BioData and AI (ISBA) 2023will be held on September 9th, 2023, in Shenzhen, China, with in-person and online participationoptions available.
This event offers free registration with no associated fees in the spirit of open and inclusive science.For more information, the agenda, and to register, please visit our website athttps://db.cngb.org/isba/.
About the ISBA 2023
The ISBA 2023 brings together international researchers, practitioners, policymakers, and ethicists to discuss the crucial issues that arise at the intersection of data science, the life sciences, artificial intelligence (AI), and society. As these fields continue to advance rapidly, it is essential to address the policy and ethical challenges they pose to ensure responsible and beneficial outcomes for individuals and society as a whole. This workshop will examine the ways in which new data and AI technologies are developed, introduced, and implemented in the life sciences, industry, and society. It will give particular attention to a focus on economics and the advancement of the life sciences and their impact on health, the environment, and society. The sessions will explore how human, animal, and plant (organic) specimens and data are collected, processed, and used by science, industry, and government to address the needs of our societies. The role of various ML and AI models, their implementation, and their impact will be considered within the development of legal structures, policy, and governance models for new technologies, the life sciences, data, and AI. The workshop will examine how we can support the development of genomics, multi-omics, and the life sciences using policy and ethics to empower, not only our economies and healthcare systems, but also citizens by creating healthier and more harmonised societies.
Objectives
The primary objective of the workshop is to foster interdisciplinary dialogue that encourages meaningful discussions and collaborations among experts from diverse disciplines engaged with data science, the life sciences, AI, policy making, and ethics. The following aims support this primary objective:
Within the context of open science and new emerging technologies, the workshop will investigate the policy implications and considerations arising from the use of data science, the life sciences, and AI applications and their impact on society.
The seminar will address the ethical challenges posed by the development and deployment of data science, life sciences, AI technologies and applications, and consider ethical frameworks for responsible innovation.
The seminar will promote responsible practices that foster the adoption of responsible frameworks and conduct in data science, life sciences, and AI to safeguard privacy, equity, fairness, transparency, and accountability.
The seminar will facilitate knowledge exchange by providing a platform for participants to share their research findings, best practices, case studies, and experiences related to policy and ethics in the intersecting fields.
The seminar will examine pathways and methodologies for the development of state-of-the-art platforms for education and expertise development in ethics and governance to meet the needs of academia, industry, government agencies, and NGOs in developing young leadership for our digital societies.
Practical Information
Registrationand participation:The event is free, and no registration fees are associated. The participants are expected to cover the costs of their travel. The organisers expect up to 120 participants.Venue:China National GenBank, Jinsha Road, Dapeng District, Shenzhen, Guangdong Province, China.Dates:September 9th, 2023Convenors:China National GenBank (CNGB), Committee on Data of the International Science Council (CODATA)Sponsors:Guangdong Science & Technology Infrastructure Center (GDSTIC)Contact:cngb_isba@cngb.org
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPANY PRESS RELEASES (90%); ETHICS (90%); DATA SCIENCE (89%); EMERGING TECHNOLOGY (89%); PUBLIC POLICY (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); CASE STUDIES (78%); ECONOMICS (78%); EXPERIMENTATION & RESEARCH (78%); SCIENCE POLICY (78%); BEST PRACTICES (75%); BIOTECHNOLOGY & GENETIC SCIENCE (71%); RESEARCH REPORTS (71%); GENOMICS (70%); BIOTECHNOLOGY INDUSTRY (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); BIOTECHNOLOGY INDUSTRY (68%)
Geographic: SHENZHEN, GUANGDONG, CHINA (58%); SOUTH CHINA (73%); CHINA (79%)
Load-Date: August 31, 2023",neutral,0.7486664056777954,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability']","['fairness', 'equity']","['regulation', 'policy', 'governance']",[],4,2,3,0
2023,Unknown Title,"Body
Link to Image
Link to Story
Doha, Qatar, 28 November 2023: Essential ethical practices for students using Artificial Intelligence in their education have been explored by young learners at the 2023 WISE Summit, through a session led by Qatar Foundation's Akhlaquna initiative.
The global conference on the future of education, hosted by Qatar Foundation's (QF) education think tank WISE at Qatar National Convention Centre, featured a discussion on 'Artificial Intelligence and the Challenges of Education and Ethics' on the summit's Youth Studio platform, which also aimed to increase awareness of Artificial IntelIigence's (AI) advantages in learning, and showcase different applications that help students form basic educational principles.
Six secondary and university students, including the StudyRoad team who took second place in the 2023 Akhlaquna Award along with university students from various tech fields, participated in the session to share their perspectives on AI, education, and ethics. The Akhlaquna initiative, which falls under QF's Pre-University Education, highlights the relationship between knowledge and ethics, advocates for ethics as a pillar for success in life, and recognizes those whose projects and behaviors exemplify strong moral and ethical character.
Farah Emad Al Zubi, a 16-year-old student at Al-Sailiyah Secondary Independent School and a member of the StudyRoad team that won the Akhlaquna Award, told the session: ""As AI intersects with education, it enhances learning experiences by offering personalized educational content for each student, tailored through an analysis of their individual behavior and educational needs.
""AI's reliance on big data analysis is key, as it allows monitoring of student interests and needs, leading to the development of suitable educational material.""
She also emphasized how AI can support shared learning experiences by providing platforms that connect students and teachers, and discussed the ethics of AI, covering topics like justice, equality, transparency, and privacy, as well as credibility and quality.
""In educational AI applications, we must ensure fairness and equality for all students, maintain transparency in how AI operates, and protect student privacy and data,"" she said. ""Additionally, AI-generated information and recommendations should be reliable and scientifically sound.""
Jana Yaman Hasnawi, 17-year-old student at Al-Sailiyah Secondary Independent School, and another member of the StudyRoad team, spoke about the future of AI, saying: ""The continuous progress in machine learning and network technologies is expected to greatly enhance system capabilities, leading to improved efficiency in AI's data processing and decision-making functions.""
However, Hasnawi sounded a note of caution about ethical and security issues arising from these technologies, emphasizing the need for a legal and ethical framework for the safe and responsible use of AI: ""These technologies raise ethical and security concerns, requiring a legal and ethical framework for artificial intelligence to be used safely and responsibly.
""While the future of AI presents a thrilling chance to advance technology and enhance human life quality, it's crucial to carefully and thoroughly address its challenges.""
One of the session's speakers, Fatima Naqadan, a computer science student at Qatar University, heads a startup focused on AI program development. She also delivers lectures on AI ethics and explained: ""There is indeed a significant connection between ethics and artificial intelligence, particularly when we consider the role of developers.
""Developers bear a crucial responsibility for integrating ethical considerations into the design and development of AI technologies. This responsibility encompasses ensuring transparency in the workings of algorithms, fostering fairness in the outcomes produced by AI, actively working to prevent any form of discrimination, and rigorously protecting user privacy.
""We must acknowledge that while AI technology offers numerous benefits, it also poses several ethical challenges, so achieving a delicate equilibrium between advancing technological frontiers and maintaining our social and ethical obligations is essential.""
MENAFN29112023004929011400ID1107506975
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); STUDENTS & STUDENT LIFE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); TECHNOLOGY (89%); DATA ANALYTICS (78%); CONFERENCES & CONVENTIONS (77%); GENERATIVE AI (73%); MACHINE LEARNING (73%); TEACHING MATERIALS & MEDIA (73%); RESEARCH INSTITUTES (71%)
Company:  ESSENTIAL UTILITIES INC (58%)
Ticker: WTRG (NYSE) (58%)
Industry: NAICS221310 WATER SUPPLY & IRRIGATION SYSTEMS (58%); SIC4941 WATER SUPPLY (58%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); BIG DATA (63%)
Geographic: DOHA, QATAR (58%); QATAR (90%)
Load-Date: April 4, 2024","Link to Image
Link to Story
Doha, Qatar, 28 November 2023: Essential ethical practices for students using Artificial Intelligence in their education have been explored by young learners at the 2023 WISE Summit, through a session led by Qatar Foundation's Akhlaquna initiative.
The global conference on the future of education, hosted by Qatar Foundation's (QF) education think tank WISE at Qatar National Convention Centre, featured a discussion on 'Artificial Intelligence and the Challenges of Education and Ethics' on the summit's Youth Studio platform, which also aimed to increase awareness of Artificial IntelIigence's (AI) advantages in learning, and showcase different applications that help students form basic educational principles.
Six secondary and university students, including the StudyRoad team who took second place in the 2023 Akhlaquna Award along with university students from various tech fields, participated in the session to share their perspectives on AI, education, and ethics. The Akhlaquna initiative, which falls under QF's Pre-University Education, highlights the relationship between knowledge and ethics, advocates for ethics as a pillar for success in life, and recognizes those whose projects and behaviors exemplify strong moral and ethical character.
Farah Emad Al Zubi, a 16-year-old student at Al-Sailiyah Secondary Independent School and a member of the StudyRoad team that won the Akhlaquna Award, told the session: ""As AI intersects with education, it enhances learning experiences by offering personalized educational content for each student, tailored through an analysis of their individual behavior and educational needs.
""AI's reliance on big data analysis is key, as it allows monitoring of student interests and needs, leading to the development of suitable educational material.""
She also emphasized how AI can support shared learning experiences by providing platforms that connect students and teachers, and discussed the ethics of AI, covering topics like justice, equality, transparency, and privacy, as well as credibility and quality.
""In educational AI applications, we must ensure fairness and equality for all students, maintain transparency in how AI operates, and protect student privacy and data,"" she said. ""Additionally, AI-generated information and recommendations should be reliable and scientifically sound.""
Jana Yaman Hasnawi, 17-year-old student at Al-Sailiyah Secondary Independent School, and another member of the StudyRoad team, spoke about the future of AI, saying: ""The continuous progress in machine learning and network technologies is expected to greatly enhance system capabilities, leading to improved efficiency in AI's data processing and decision-making functions.""
However, Hasnawi sounded a note of caution about ethical and security issues arising from these technologies, emphasizing the need for a legal and ethical framework for the safe and responsible use of AI: ""These technologies raise ethical and security concerns, requiring a legal and ethical framework for artificial intelligence to be used safely and responsibly.
""While the future of AI presents a thrilling chance to advance technology and enhance human life quality, it's crucial to carefully and thoroughly address its challenges.""
One of the session's speakers, Fatima Naqadan, a computer science student at Qatar University, heads a startup focused on AI program development. She also delivers lectures on AI ethics and explained: ""There is indeed a significant connection between ethics and artificial intelligence, particularly when we consider the role of developers.
""Developers bear a crucial responsibility for integrating ethical considerations into the design and development of AI technologies. This responsibility encompasses ensuring transparency in the workings of algorithms, fostering fairness in the outcomes produced by AI, actively working to prevent any form of discrimination, and rigorously protecting user privacy.
""We must acknowledge that while AI technology offers numerous benefits, it also poses several ethical challenges, so achieving a delicate equilibrium between advancing technological frontiers and maintaining our social and ethical obligations is essential.""
MENAFN29112023004929011400ID1107506975
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (93%); STUDENTS & STUDENT LIFE (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); TECHNOLOGY (89%); DATA ANALYTICS (78%); CONFERENCES & CONVENTIONS (77%); GENERATIVE AI (73%); MACHINE LEARNING (73%); TEACHING MATERIALS & MEDIA (73%); RESEARCH INSTITUTES (71%)
Company:  ESSENTIAL UTILITIES INC (58%)
Ticker: WTRG (NYSE) (58%)
Industry: NAICS221310 WATER SUPPLY & IRRIGATION SYSTEMS (58%); SIC4941 WATER SUPPLY (58%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); GENERATIVE AI (73%); MACHINE LEARNING (73%); BIG DATA (63%)
Geographic: DOHA, QATAR (58%); QATAR (90%)
Load-Date: April 4, 2024",neutral,0.5676043629646301,balanced/neutral,"['privacy', 'discrimination', 'fairness', 'transparency', 'security']","['character', 'justice', 'fairness', 'equality', 'justice']","['framework', 'should', 'must']","['machine learning', 'generative ai']",5,5,3,2
2023,Unknown Title,"Body
AI has whet the appetites of organizations across nearly every sector. As AI pilots move toward production, discussions about the need for ethical AI are growing, along with terms like ""fairness,"" ""privacy,"" ""transparency,"" ""accountability,"" and the big one -""bias.""
But ensuring those and other measures are taken into consideration is a weighty task that CIOs will be grappling with as AI becomes integral to how people work and conduct business.
For many CIOs, implementations may be nascent, but mitigating biases in AI models and balancing innovation with ethical considerations are already among their biggest challenges. What they are finding is that the line between advancing technologically and ensuring AI doesn't result in detrimental outcomes is thin.
Christoph Wollersheim, a member of the services and artificial intelligence practices group at global consulting firm Egon Zehnder, pinpoints five critical areas most organizations need to address when implementing AI: accuracy, bias, security, transparency, and societal responsibility.
Unfortunately, achieving 100% accuracy with AI is ""impossible,"" says Wollersheim, who recently co-authored The Board Member's Guide to Overseeing AI. ""The real ethical concern lies in how companies safeguard against misinformation. What's the plan if customers are presented with false data, or if critical decisions are based on inaccurate AI responses? Companies need both a practical plan and a transparent communications strategy in their response.""
Bias can be inadvertently perpetuated when AI is trained on historical data, he notes.
""Both executive management and boards must ensure fairness in the use of AI and guard against discrimination."" Research is under way to correct biases, using synthetic data to address attributes such as gender, race, and ethnicity, he says, ""but there will always be a need for a human-centric lens to be applied.""
The need to secure sensitive information is paramount for ethical AI deployment because AI's heavy dependency on data increases the risk of breaches and unauthorized access, Wollersheim says. ""Companies must fortify against attacks that could mislead AI models and result in ill-informed decisions. Ensuring the security of sensitive information is paramount for ethical AI deployment,"" he says.
As for transparency, it's not just about algorithms, but building trust, he says. ""Stakeholders need to comprehend how AI makes decisions and handles data. A transparent AI framework is the linchpin for ethical use, accountability, and maintaining trust.""
Organizations must also consider what values guide them, and what obligations they have in terms of retraining, upskilling, and job protection. ""Ethical AI is about shaping a responsible future for our workforce,"" Wollersheim says.
To address these issues, establishing an AI review board and implementing an ethical AI framework are critical, Wollersheim says. ""An ethical AI framework provides clear guidance on monitoring and approval for every project, internal or external. An AI review board, comprised of technical and business experts, ensures ethical considerations are at the forefront of decision-making.""
Here is a look at how CIOs are addressing ethical AI in their organizations.
Making ethical AI a team sport
Plexus Worldwide is one organization using AI to identify fraudulent account creation and transactions, says Alan McIntosh, CIO and CTO of the $500 million global health and wellness company. As McIntosh sees it, bias is fundamentally a data problem. ""We attempt to eliminate bias and incorrect results by leveraging and validating against multiple, complete data sources,"" he says.
Plexus IT is also in the analysis phase of using AI within the company's e-commerce platform ""to gain better insights for predicting and optimizing the customer experience and enhancing personalization,"" McIntosh says. ""We also see automation opportunities to eliminate many legacy manual and repetitive tasks.""
Plexus Worldwide
To ensure ethical AI practices are adhered to, Plexus Worldwide has formed a team of IT, legal, and HR representatives responsible for the development and evolution of AI governance and policy, he says. This team establishes the company's risk tolerance, acceptable use cases and restrictions, and applicable disclosures.
Even with a team focused on AI, identifying risks and understanding how the organization intends to use AI both internally and publicly is challenging, McIntosh says. Team members must also understand and address the inherent possibility of AI bias, erroneous claims, and incorrect results, he says. ""Depending on the use cases, the reputation of your company and brand may be at stake, so it's imperative that you plan for effective governance.""
With that in mind, McIntosh says it's critical that CIOs ""don't rush to the finish line."" Organizations must create a thorough plan and focus on developing a governance framework and AI policy before implementing and exposing the technology. Identifying appropriate stakeholders, such as legal, HR, compliance and privacy, and IT, is where Plexus started its ethical AI process, McIntosh says.
""We then created a draft policy to outline the roles and responsibilities, scope, context, acceptable use guidelines, risk tolerance and management, and governance,"" he says.  ""We continue to iterate and evolve our policy, but it is still in development. We intend to implement it in Q1 2024."" 
McIntosh recommends seeking out third-party resources and subject matter expertise. ""It will greatly assist with expediting the development and execution of your plan and framework,"" McIntosh explains. ""And, based on your current program management practices, provide the same level of rigor - or more - for your AI adoption initiatives.""
Treading slowly so AI doesn't 'run amok'
The Laborer's International Union of North America (LIUNA), which represents more than 500,000 construction workers, public employees, and mail handlers, has dipped its toes into using AI, mainly for document accuracy and clarification, and for writing contracts, says CIO Matt Richard. 
As LIUNA expands AI use cases in 2024, ""this gets to the question about how we use AI ethically,"" he says. The organization has started piloting Google Duet to automate the process of writing and negotiating contractor agreements.
LIUNA
Right now, union officials are not using AI to identify members' wants and needs, nor to comb through hiring data that might be sensitive and return biases on people based on how the models are trained, Richard says.
""Those are the areas where I get nervous: when a model tells me about a person. And I don't feel we're ready to dive into that space yet, because frankly, I don't trust publicly trained models to give me insights into the person I want to hire,"" he says.
Still, Richard expects a ""natural evolution"" in which, down the road, LIUNA may want to use AI to derive insights into its members to help the union deliver better benefits to them. For now, ""it's still a gray area on how we want to do that,"" he says.
The union is also trying to grow its membership and part of that means using AI to identify prospective members efficiently, ""without identifying the same homogenous people,"" Richard says. ""Our organization is pushing very hard and does a good job of empowering minorities and women, and we want to grow those groups.""
That's where Richard worries about how AI models are used, because avoiding ""the rabbit hole of finding the same stereotypical demographic"" and introducing biases means humans must be part of the process. ""You don't just let the models do all the work,"" he says. ""You understand where you are today, and then we stop and say, 'OK, humans need to intervene here and look at what the models are telling us.'""
 ""You can't let AI run amok ... with no intervention. Then you're perpetuating the problem,"" he says, adding that organizations shouldn't take the ""easy way out"" with AI and only delve into what the tools can do. ""My fear is people are going to buy and implement an AI tool and let it go and trust it. ... You have to be careful these tools aren't telling us what we want to hear,"" he says.
To that end, Richard believes AI can be used as a kick-starter, but IT leaders must use your team's intuition ""to make sure we're not falling into the trap of just trusting flashy software tools that aren't giving us the data we need,"" he says.
Taking AI ethics personally
Like LIUNA, Czech-based global consumer finance provider Home Credit is early in its AI journey, using GitHub Copilot for coding and documentation processes, says Group CIO Jan Cenkr.  
""It's offered a huge advantage in terms of time-saving, which in turn has a beneficial cost element too,"" says Cenkr, who is also CEO of Home Credit's subsidiary EmbedIT. Ethical AI has been top of mind for Cenkr from the start.
Home Credit
""When we started rolling out our AI tool pilots, we also had deep discussions internally about creating ethical governance structures to go with the use of this technology. That means we have genuine checks in place to ensure that we do not violate our codes of conduct,"" he says.
Those codes are regularly refreshed and tested to ensure they are as robust as possible, Cenkr adds.
Data privacy is the most challenging consideration, he adds. ""Any information and data that we feed into our AI platforms absolutely has to comply with GDPR regulations."" Because Home Credit operates in multiple jurisdictions, IT must also ensure compliance in all those markets, some of which have different laws, adding to the complexity.
Organizations should develop their governance structures ""in a way that reflects your own personal approach to ethics,"" Cenkr says. ""I believe that if you put the same care into developing these ethical structures that you do into the ethics you apply in your personal, everyday life, these structures will be all the safer.""
Further, Cenkr says IT should be prepared to update its governance policies regularly. ""AI technology is advancing daily and it's a real challenge to keep pace with its evolution, however exciting that might be.""
Put in guardrails
AI tools such as chatbots have been in use at UST for several years, but generative AI is a whole new ballgame. This fundamentally changes business models, and has made ethical AI part of the discussion, says Krishna Prasad, chief strategy officer and CIO of the digital transformation company, while admitting that ""it's a little more theoretical today.""
Ethical AI ""doesn't always come up"" in implementation considerations, Prasad says, ""but we do talk about ... the fact that we need to have responsible AI and some ability to get transparency and trace back how a recommendation was made.""
UST
Discussions among UST leaders focus on what the company doesn't want to do with AI ""and where do we want to draw boundaries as we understand them today; how do we remain true to our mission without producing harm,"" Prasad says.
Echoing the others, Prasad says this means humans must be part of the equation as AI is more deeply embedded inside the organization.
One question that has come up at UST is whether it is a compromise of confidentiality if leaders are having a conversation about employee performance as a bot listens in. ""Things [like that] have started bubbling up,"" Prasad says, ""but at this point, we're comfortable moving forward using [Microsoft] Copilot as a way to summarize conversations.""
Another consideration is how to protect intellectual property around a tool the company builds. ""Based on protections that have been provided by software vendors today we still feel data is contained within our own environment, and there's been no evidence of data being lost externally,"" he says. For that reason, Prasad says he and other leaders don't have any qualms about continuing to use certain AI tools, especially because of the productivity gains they see.
Even as he believes humans need to be involved, Prasad also worries about their input. ""At the end of the day, human beings inherently have biases because of the nature of the environments we're exposed to and our experiences and how it formulates our thinking,"" he explains.
He also worries about whether bad actors will gain access to certain AI tools as they use clients' data to develop new models for them.
These are areas leaders will have to worry about as the software becomes more prevalent, Prasad says. In the meantime, CIOs must lead the way and demonstrate how AI can be used for good and how it will impact their business models, and bring leadership together to discuss the best path forward, he says.
""CIOs have to play a role in driving that conversation because they can bust myths and also execute,"" he says, adding that they also have to be prepared for those conversations to at times become very difficult.  
For example, if a tool offers a certain capability, ""do we want it to be used whenever possible, or should we hold back because it's the right thing to do,"" Prasad says. ""It's the most difficult conversation,"" but CIOs must present that a tool ""could be more than you bargained for. To me, that part is still a little fuzzy, so how do I put constraints around the model ... before making the choice to offer new products and services that use AI.""
Artificial Intelligence, Data Governance, Generative AI, IT Governance, IT Leadership, IT Strategy
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); BOARDS OF DIRECTORS (78%); DISCRIMINATION (77%); NEGATIVE SOCIETAL NEWS (77%); RESKILLING & UPSKILLING (76%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (73%); DISINFORMATION & MISINFORMATION (72%); RACE & ETHNICITY (72%); APPROVALS (71%); EMPLOYEE TRAINING (71%); LABOR FORCE (69%); HISTORY (64%); EMPLOYEE RETRAINING (60%)
Company:  EGON ZEHNDER INTERNATIONAL INC (56%)
Industry: NAICS541612 HUMAN RESOURCES CONSULTING SERVICES (56%); SIC8999 SERVICES, NEC (56%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (89%); CONSULTING SERVICES (73%)
Load-Date: December 11, 2023","AI has whet the appetites of organizations across nearly every sector. As AI pilots move toward production, discussions about the need for ethical AI are growing, along with terms like ""fairness,"" ""privacy,"" ""transparency,"" ""accountability,"" and the big one -""bias.""
But ensuring those and other measures are taken into consideration is a weighty task that CIOs will be grappling with as AI becomes integral to how people work and conduct business.
For many CIOs, implementations may be nascent, but mitigating biases in AI models and balancing innovation with ethical considerations are already among their biggest challenges. What they are finding is that the line between advancing technologically and ensuring AI doesn't result in detrimental outcomes is thin.
Christoph Wollersheim, a member of the services and artificial intelligence practices group at global consulting firm Egon Zehnder, pinpoints five critical areas most organizations need to address when implementing AI: accuracy, bias, security, transparency, and societal responsibility.
Unfortunately, achieving 100% accuracy with AI is ""impossible,"" says Wollersheim, who recently co-authored The Board Member's Guide to Overseeing AI. ""The real ethical concern lies in how companies safeguard against misinformation. What's the plan if customers are presented with false data, or if critical decisions are based on inaccurate AI responses? Companies need both a practical plan and a transparent communications strategy in their response.""
Bias can be inadvertently perpetuated when AI is trained on historical data, he notes.
""Both executive management and boards must ensure fairness in the use of AI and guard against discrimination."" Research is under way to correct biases, using synthetic data to address attributes such as gender, race, and ethnicity, he says, ""but there will always be a need for a human-centric lens to be applied.""
The need to secure sensitive information is paramount for ethical AI deployment because AI's heavy dependency on data increases the risk of breaches and unauthorized access, Wollersheim says. ""Companies must fortify against attacks that could mislead AI models and result in ill-informed decisions. Ensuring the security of sensitive information is paramount for ethical AI deployment,"" he says.
As for transparency, it's not just about algorithms, but building trust, he says. ""Stakeholders need to comprehend how AI makes decisions and handles data. A transparent AI framework is the linchpin for ethical use, accountability, and maintaining trust.""
Organizations must also consider what values guide them, and what obligations they have in terms of retraining, upskilling, and job protection. ""Ethical AI is about shaping a responsible future for our workforce,"" Wollersheim says.
To address these issues, establishing an AI review board and implementing an ethical AI framework are critical, Wollersheim says. ""An ethical AI framework provides clear guidance on monitoring and approval for every project, internal or external. An AI review board, comprised of technical and business experts, ensures ethical considerations are at the forefront of decision-making.""
Here is a look at how CIOs are addressing ethical AI in their organizations.
Making ethical AI a team sport
Plexus Worldwide is one organization using AI to identify fraudulent account creation and transactions, says Alan McIntosh, CIO and CTO of the $500 million global health and wellness company. As McIntosh sees it, bias is fundamentally a data problem. ""We attempt to eliminate bias and incorrect results by leveraging and validating against multiple, complete data sources,"" he says.
Plexus IT is also in the analysis phase of using AI within the company's e-commerce platform ""to gain better insights for predicting and optimizing the customer experience and enhancing personalization,"" McIntosh says. ""We also see automation opportunities to eliminate many legacy manual and repetitive tasks.""
Plexus Worldwide
To ensure ethical AI practices are adhered to, Plexus Worldwide has formed a team of IT, legal, and HR representatives responsible for the development and evolution of AI governance and policy, he says. This team establishes the company's risk tolerance, acceptable use cases and restrictions, and applicable disclosures.
Even with a team focused on AI, identifying risks and understanding how the organization intends to use AI both internally and publicly is challenging, McIntosh says. Team members must also understand and address the inherent possibility of AI bias, erroneous claims, and incorrect results, he says. ""Depending on the use cases, the reputation of your company and brand may be at stake, so it's imperative that you plan for effective governance.""
With that in mind, McIntosh says it's critical that CIOs ""don't rush to the finish line."" Organizations must create a thorough plan and focus on developing a governance framework and AI policy before implementing and exposing the technology. Identifying appropriate stakeholders, such as legal, HR, compliance and privacy, and IT, is where Plexus started its ethical AI process, McIntosh says.
""We then created a draft policy to outline the roles and responsibilities, scope, context, acceptable use guidelines, risk tolerance and management, and governance,"" he says.  ""We continue to iterate and evolve our policy, but it is still in development. We intend to implement it in Q1 2024."" 
McIntosh recommends seeking out third-party resources and subject matter expertise. ""It will greatly assist with expediting the development and execution of your plan and framework,"" McIntosh explains. ""And, based on your current program management practices, provide the same level of rigor - or more - for your AI adoption initiatives.""
Treading slowly so AI doesn't 'run amok'
The Laborer's International Union of North America (LIUNA), which represents more than 500,000 construction workers, public employees, and mail handlers, has dipped its toes into using AI, mainly for document accuracy and clarification, and for writing contracts, says CIO Matt Richard. 
As LIUNA expands AI use cases in 2024, ""this gets to the question about how we use AI ethically,"" he says. The organization has started piloting Google Duet to automate the process of writing and negotiating contractor agreements.
LIUNA
Right now, union officials are not using AI to identify members' wants and needs, nor to comb through hiring data that might be sensitive and return biases on people based on how the models are trained, Richard says.
""Those are the areas where I get nervous: when a model tells me about a person. And I don't feel we're ready to dive into that space yet, because frankly, I don't trust publicly trained models to give me insights into the person I want to hire,"" he says.
Still, Richard expects a ""natural evolution"" in which, down the road, LIUNA may want to use AI to derive insights into its members to help the union deliver better benefits to them. For now, ""it's still a gray area on how we want to do that,"" he says.
The union is also trying to grow its membership and part of that means using AI to identify prospective members efficiently, ""without identifying the same homogenous people,"" Richard says. ""Our organization is pushing very hard and does a good job of empowering minorities and women, and we want to grow those groups.""
That's where Richard worries about how AI models are used, because avoiding ""the rabbit hole of finding the same stereotypical demographic"" and introducing biases means humans must be part of the process. ""You don't just let the models do all the work,"" he says. ""You understand where you are today, and then we stop and say, 'OK, humans need to intervene here and look at what the models are telling us.'""
 ""You can't let AI run amok ... with no intervention. Then you're perpetuating the problem,"" he says, adding that organizations shouldn't take the ""easy way out"" with AI and only delve into what the tools can do. ""My fear is people are going to buy and implement an AI tool and let it go and trust it. ... You have to be careful these tools aren't telling us what we want to hear,"" he says.
To that end, Richard believes AI can be used as a kick-starter, but IT leaders must use your team's intuition ""to make sure we're not falling into the trap of just trusting flashy software tools that aren't giving us the data we need,"" he says.
Taking AI ethics personally
Like LIUNA, Czech-based global consumer finance provider Home Credit is early in its AI journey, using GitHub Copilot for coding and documentation processes, says Group CIO Jan Cenkr.  
""It's offered a huge advantage in terms of time-saving, which in turn has a beneficial cost element too,"" says Cenkr, who is also CEO of Home Credit's subsidiary EmbedIT. Ethical AI has been top of mind for Cenkr from the start.
Home Credit
""When we started rolling out our AI tool pilots, we also had deep discussions internally about creating ethical governance structures to go with the use of this technology. That means we have genuine checks in place to ensure that we do not violate our codes of conduct,"" he says.
Those codes are regularly refreshed and tested to ensure they are as robust as possible, Cenkr adds.
Data privacy is the most challenging consideration, he adds. ""Any information and data that we feed into our AI platforms absolutely has to comply with GDPR regulations."" Because Home Credit operates in multiple jurisdictions, IT must also ensure compliance in all those markets, some of which have different laws, adding to the complexity.
Organizations should develop their governance structures ""in a way that reflects your own personal approach to ethics,"" Cenkr says. ""I believe that if you put the same care into developing these ethical structures that you do into the ethics you apply in your personal, everyday life, these structures will be all the safer.""
Further, Cenkr says IT should be prepared to update its governance policies regularly. ""AI technology is advancing daily and it's a real challenge to keep pace with its evolution, however exciting that might be.""
Put in guardrails
AI tools such as chatbots have been in use at UST for several years, but generative AI is a whole new ballgame. This fundamentally changes business models, and has made ethical AI part of the discussion, says Krishna Prasad, chief strategy officer and CIO of the digital transformation company, while admitting that ""it's a little more theoretical today.""
Ethical AI ""doesn't always come up"" in implementation considerations, Prasad says, ""but we do talk about ... the fact that we need to have responsible AI and some ability to get transparency and trace back how a recommendation was made.""
UST
Discussions among UST leaders focus on what the company doesn't want to do with AI ""and where do we want to draw boundaries as we understand them today; how do we remain true to our mission without producing harm,"" Prasad says.
Echoing the others, Prasad says this means humans must be part of the equation as AI is more deeply embedded inside the organization.
One question that has come up at UST is whether it is a compromise of confidentiality if leaders are having a conversation about employee performance as a bot listens in. ""Things [like that] have started bubbling up,"" Prasad says, ""but at this point, we're comfortable moving forward using [Microsoft] Copilot as a way to summarize conversations.""
Another consideration is how to protect intellectual property around a tool the company builds. ""Based on protections that have been provided by software vendors today we still feel data is contained within our own environment, and there's been no evidence of data being lost externally,"" he says. For that reason, Prasad says he and other leaders don't have any qualms about continuing to use certain AI tools, especially because of the productivity gains they see.
Even as he believes humans need to be involved, Prasad also worries about their input. ""At the end of the day, human beings inherently have biases because of the nature of the environments we're exposed to and our experiences and how it formulates our thinking,"" he explains.
He also worries about whether bad actors will gain access to certain AI tools as they use clients' data to develop new models for them.
These are areas leaders will have to worry about as the software becomes more prevalent, Prasad says. In the meantime, CIOs must lead the way and demonstrate how AI can be used for good and how it will impact their business models, and bring leadership together to discuss the best path forward, he says.
""CIOs have to play a role in driving that conversation because they can bust myths and also execute,"" he says, adding that they also have to be prepared for those conversations to at times become very difficult.  
For example, if a tool offers a certain capability, ""do we want it to be used whenever possible, or should we hold back because it's the right thing to do,"" Prasad says. ""It's the most difficult conversation,"" but CIOs must present that a tool ""could be more than you bargained for. To me, that part is still a little fuzzy, so how do I put constraints around the model ... before making the choice to offer new products and services that use AI.""
Artificial Intelligence, Data Governance, Generative AI, IT Governance, IT Leadership, IT Strategy
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); BOARDS OF DIRECTORS (78%); DISCRIMINATION (77%); NEGATIVE SOCIETAL NEWS (77%); RESKILLING & UPSKILLING (76%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (73%); DISINFORMATION & MISINFORMATION (72%); RACE & ETHNICITY (72%); APPROVALS (71%); EMPLOYEE TRAINING (71%); LABOR FORCE (69%); HISTORY (64%); EMPLOYEE RETRAINING (60%)
Company:  EGON ZEHNDER INTERNATIONAL INC (56%)
Industry: NAICS541612 HUMAN RESOURCES CONSULTING SERVICES (56%); SIC8999 SERVICES, NEC (56%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (89%); CONSULTING SERVICES (73%)
Load-Date: December 11, 2023",neutral,0.6456745862960815,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'security', 'misinformation', 'disinformation', 'access']",['fairness'],"['policy', 'governance', 'guidelines', 'framework', 'compliance', 'should', 'must', 'need to']",['generative ai'],10,1,8,1
2023,Unknown Title,"Dateline: New Delhi 
Body
 March 01 -- Microsoft and IBM recently renewed support for the Rome Call for AI Ethics, which outlines six short principles to guide the development and use of AI in the enterprise.
As enterprises increasingly look to artificial intelligence (AI) to support, speed up, or even supplant human decision-making, calls have rung out for AI's use and development to be subject to a higher power: our collective sense of right and wrong.
One such entity weighing in on the need for AI ethics is the Vatican, which exactly three years ago, on Feb. 28, 2020, brought together representatives from Microsoft and IBM to first sign the Rome Call for AI Ethics, a commitment to develop AI that serves humanity as a whole.
This ethical commitment, which brings together high-tech and religious leadership, as well as universities and government entities, was renewed in January 2023, with representatives of the Muslim and Jewish faiths joining alongside the Vatican.
In many ways, the Rome Call is symbolic, enforcing principles that many IT vendors and enterprises are already undertaking around AI's use and development. But it also raises the profile of an emerging issue that has real impact on people around the globe - something CIOs must consider in their approaches to AI.
Laying the groundworkIBM and others in the IT industry had been thinking about the ethics of AI since long before signing the Rome Call, says Christina Montgomery, the company's chief privacy officer and chair of its AI ethics board.
""It's essentially a reiteration of principles that we had adopted internally, that Microsoft had adopted internally, and that a number of companies were adopting or thinking about at the time,"" she says.
It's natural for IBM, a company that traces its origins back over a century, to take a more holisitic view of its technology, she says. ""We're very different culturally from a lot of new technology companies and we think deeply about the technology that we're putting into the world.""
Deep thought about the ethics of AI is something IBM is encouraging in other ways, supporting the development of a network of universities that will incorporate the principles of the Rome Call for AI Ethics in their curriculums, something that will eventually lead to a new generation of graduates better equipped to consider such questions.
The six principlesThe Rome Call itself consists of a preamble and six succinct principles that supporters commit to. In their entirety, they are:
Transparency: AI systems must be understandable to all.
Inclusion: These systems must not discriminate against anyone because every human being has equal dignity.
Responsibility: There must always be someone who takes responsibility for what a machine does.
Impartiality: AI systems must not follow or create biases.
Reliability: AI must be reliable.
Security and privacy: These systems must be secure and respect the privacy of users.
While software vendors Microsoft and IBM were the first two enterprises to support the Rome Call, its ethos is aimed more broadly at any organization using the technology, in enterprises, governments, and civil society.
It will be easier for enterprises to comply with some of these principles than with others. Reliability and security can be taken into account at every level, but CIOs may need to bake inclusion and impartiality into project requirements at an early stage.
The principle of responsibility will require broader buy-in, as it requires a cultural shift to avoid blaming unwelcome decisions on an algorithm, whether AI-based or not.
Transparency, though, is a whole other matter.
Hurdles to answering the callShlomit Yanisky-Ravid, a visiting professor at Fordham University's School of Law, says that unless we understand what an AI is really doing, we won't be able to think about the ethical issues around it. ""That's where I see a lot of gaps and conflicts between the industry and the ethical and legal demands,"" she says.
The EU's General Data Protection Regulation (GDPR) already includes provisions that some academics construe as a right to explainability of software in general. Articles 13-15 give those who are subject to the effects of automated decisions a right to ""meaningful information about the logic involved.""
For IBM's Montgomery, it's clear: ""Using AI models in your operations that aren't explainable, that aren't transparent, could have unintended consequences.""
But there's a problem, says Yanisky-Ravid: ""We can speak about transparency, we can speak about explainability, but we cannot really make it happen - at least for now.""
Her speciality is intellectual property law, where the opacity of AI systems is making for interesting cases involving the moral right of AIs to be recognized as inventors or creators.
Some of those cases involve Stephen Thaler, creator of an AI tool called Dabus that he used to design a novel food container. His initial attempts to credit Dabus as co-inventor in patent filings around the world were rejected, with patent authorities insisting only a human could be responsible for the process of invention. However, Thaler later won one case on appeal: IP Australia, the government agency, has recognized Dabus as an inventor. Other appeals are ongoing.
Some may be put off by the fact the first signatories of the call included a representative of the Pontifical Academy of Life, an ethics think tank run by the Catholic Church, but IBM's Montgomery says it was never intended to be just a religious call. ""The goal is to extend it as much as possible.""
Whatever their beliefs, CIOs should be engaging with the ethical questions around AI right now, she says. ""If you wait, it's too late,"" she says.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (91%); RELIGION (91%); ARTIFICIAL INTELLIGENCE (89%); EXECUTIVES (89%); CURRICULA (78%); CATHOLICS & CATHOLICISM (75%); CLERGY & RELIGIOUS VOCATIONS (68%); JEWS & JUDAISM (68%); MUSLIMS & ISLAM (68%)
Company:  MICROSOFT CORP (90%)
Industry: NAICS513210 SOFTWARE PUBLISHERS (90%); SIC7372 PREPACKAGED SOFTWARE (90%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (89%); INFORMATION TECHNOLOGY INDUSTRY (89%); COMPUTING & INFORMATION TECHNOLOGY (73%)
Geographic: ROME, ITALY (90%); NEW DELHI, INDIA (74%); VATICAN CITY (73%)
Load-Date: March 1, 2023","March 01 -- Microsoft and IBM recently renewed support for the Rome Call for AI Ethics, which outlines six short principles to guide the development and use of AI in the enterprise.
As enterprises increasingly look to artificial intelligence (AI) to support, speed up, or even supplant human decision-making, calls have rung out for AI's use and development to be subject to a higher power: our collective sense of right and wrong.
One such entity weighing in on the need for AI ethics is the Vatican, which exactly three years ago, on Feb. 28, 2020, brought together representatives from Microsoft and IBM to first sign the Rome Call for AI Ethics, a commitment to develop AI that serves humanity as a whole.
This ethical commitment, which brings together high-tech and religious leadership, as well as universities and government entities, was renewed in January 2023, with representatives of the Muslim and Jewish faiths joining alongside the Vatican.
In many ways, the Rome Call is symbolic, enforcing principles that many IT vendors and enterprises are already undertaking around AI's use and development. But it also raises the profile of an emerging issue that has real impact on people around the globe - something CIOs must consider in their approaches to AI.
Laying the groundworkIBM and others in the IT industry had been thinking about the ethics of AI since long before signing the Rome Call, says Christina Montgomery, the company's chief privacy officer and chair of its AI ethics board.
""It's essentially a reiteration of principles that we had adopted internally, that Microsoft had adopted internally, and that a number of companies were adopting or thinking about at the time,"" she says.
It's natural for IBM, a company that traces its origins back over a century, to take a more holisitic view of its technology, she says. ""We're very different culturally from a lot of new technology companies and we think deeply about the technology that we're putting into the world.""
Deep thought about the ethics of AI is something IBM is encouraging in other ways, supporting the development of a network of universities that will incorporate the principles of the Rome Call for AI Ethics in their curriculums, something that will eventually lead to a new generation of graduates better equipped to consider such questions.
The six principlesThe Rome Call itself consists of a preamble and six succinct principles that supporters commit to. In their entirety, they are:
Transparency: AI systems must be understandable to all.
Inclusion: These systems must not discriminate against anyone because every human being has equal dignity.
Responsibility: There must always be someone who takes responsibility for what a machine does.
Impartiality: AI systems must not follow or create biases.
Reliability: AI must be reliable.
Security and privacy: These systems must be secure and respect the privacy of users.
While software vendors Microsoft and IBM were the first two enterprises to support the Rome Call, its ethos is aimed more broadly at any organization using the technology, in enterprises, governments, and civil society.
It will be easier for enterprises to comply with some of these principles than with others. Reliability and security can be taken into account at every level, but CIOs may need to bake inclusion and impartiality into project requirements at an early stage.
The principle of responsibility will require broader buy-in, as it requires a cultural shift to avoid blaming unwelcome decisions on an algorithm, whether AI-based or not.
Transparency, though, is a whole other matter.
Hurdles to answering the callShlomit Yanisky-Ravid, a visiting professor at Fordham University's School of Law, says that unless we understand what an AI is really doing, we won't be able to think about the ethical issues around it. ""That's where I see a lot of gaps and conflicts between the industry and the ethical and legal demands,"" she says.
The EU's General Data Protection Regulation (GDPR) already includes provisions that some academics construe as a right to explainability of software in general. Articles 13-15 give those who are subject to the effects of automated decisions a right to ""meaningful information about the logic involved.""
For IBM's Montgomery, it's clear: ""Using AI models in your operations that aren't explainable, that aren't transparent, could have unintended consequences.""
But there's a problem, says Yanisky-Ravid: ""We can speak about transparency, we can speak about explainability, but we cannot really make it happen - at least for now.""
Her speciality is intellectual property law, where the opacity of AI systems is making for interesting cases involving the moral right of AIs to be recognized as inventors or creators.
Some of those cases involve Stephen Thaler, creator of an AI tool called Dabus that he used to design a novel food container. His initial attempts to credit Dabus as co-inventor in patent filings around the world were rejected, with patent authorities insisting only a human could be responsible for the process of invention. However, Thaler later won one case on appeal: IP Australia, the government agency, has recognized Dabus as an inventor. Other appeals are ongoing.
Some may be put off by the fact the first signatories of the call included a representative of the Pontifical Academy of Life, an ethics think tank run by the Catholic Church, but IBM's Montgomery says it was never intended to be just a religious call. ""The goal is to extend it as much as possible.""
Whatever their beliefs, CIOs should be engaging with the ethical questions around AI right now, she says. ""If you wait, it's too late,"" she says.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (91%); RELIGION (91%); ARTIFICIAL INTELLIGENCE (89%); EXECUTIVES (89%); CURRICULA (78%); CATHOLICS & CATHOLICISM (75%); CLERGY & RELIGIOUS VOCATIONS (68%); JEWS & JUDAISM (68%); MUSLIMS & ISLAM (68%)
Company:  MICROSOFT CORP (90%)
Industry: NAICS513210 SOFTWARE PUBLISHERS (90%); SIC7372 PREPACKAGED SOFTWARE (90%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (89%); INFORMATION TECHNOLOGY INDUSTRY (89%); COMPUTING & INFORMATION TECHNOLOGY (73%)
Geographic: ROME, ITALY (90%); NEW DELHI, INDIA (74%); VATICAN CITY (73%)
Load-Date: March 1, 2023",neutral,0.6434874534606934,balanced/neutral,"['privacy', 'transparency', 'explainability', 'security', 'agency']",['dignity'],"['regulation', 'law', 'should', 'must', 'need to']",['algorithm'],5,1,5,1
2023,Unknown Title,"Byline: Danette BreitenbachDanette Breitenbach is a marketing & media editor at Bizcommunity.com. Previously she freelanced  in the marketing and media sector, including for Bizcommunity. She was editor and publisher of AdVantage, the publication that served the marketing, media and advertising industry in southern Africa. She has worked extensively in print media, mainly B2B. She has a Masters in Financial Journalism from Wits.https://www.bizcommunity.com/Profile.aspx?pro=69010
Body
Poor evaluation and measurement are one of the biggest threats to the African public relations (PR) and communications industry,
This is one of the findings from the Public Relations and Communications Association (PRCA) Africa and African Public Relations Association (APRA) joint research on the state of ethics and PR landscape in Africa.The report, released at annual APRA Conference, which this year takes place from 15-19 May in Zambia, found that while the biggest threat identified is reduced budget (59%) poor measurement and evaluation (53%) was a close second.Why this is concerning is that the result is similar to 2022, showing that no real growth in adopting recognised evaluation methods has taken place over the past year. In addition, 26% of those surveyed did not use any evaluation methods (compared to 25% in 2022).This was one of the key focuses of a panel discussion on the report findings that was recorded earlier and then shown at the conference.The panel was moderated by Danette Breitenbach, co-editor of Marketing and Media at Bizcommunity.com. Panelists include Faisal Hussain from PRCA (UK), Henry Rugamba from APRA (Uganda), Tolulope Olorundero from Nigerian Women in PR (Nigeria) and Dustin Chick from Razor (South Africa).Ethics and TransparencyThe second part of the survey concerned ethics and transparency in PR and communications. 
While ethics is very important in the PRCA Professional Charter and Codes of Conduct, it is concerning that the report shows that 15% - an increase of two percent - of the respondents indicated that they have been asked by someone to act in an unethical way or had decided to do so in the past 12 months.Five percent acted on an incident, and 10% did not. Only 0.5% reported the incident and 17% did not report it.However, it is hearting to see that 79% said no when approached by someone to act in an unethical way while five percent were unsure.When respondents were asked to rate how ethical PR is in their country, the mean average out score is 5.3 (out of 10), a year-on-year decrease of 0.8 compared to last year. Consequently PR s perceived ethical standing has gone backward, and there is clearly much work to do in the region to ensure that ethics is at the forefront of the agenda when it comes to the PR and communications industry,  states the report.The respondents did feel that their organisations were ethical, with 69% responding that their organisation was not compromised. The report also surveyed respondents about their perception of their organisation s ethical business practices compared to similar organisations in other countries across Africa.The vast majority (90%) said that organisation ranks  above average  while the remaining 10% ranked their organisation  below average .However the same cannot be said about their countries with 88% of respondents saying their country was compromised. Asked to compare their respective countries' ethical business conduct against others on the African continent, 67% of respondents said their country was below average, while only 33% said their country was above average.<!--EMBED:https://www.bizcommunity.com/Article/196/18/238292.html:EMBED-->PR standing in the boardroomA concerning finding of the survey is that 47% of PR professionals said they are not appreciated in the boardroom - up from 14% in 2022   and 19% felt they have to prove their existence.Only 28% said senior leaders are relying on PR more than ever - a five percent decrease on 2022. Respondents felt that organisations only remember PR when they are challenged. They also felt  governments are not investing enough in PR and communications or hearing the call of strategy in this area .What PR professionals doWhat PR professionals do has remained steady, with 61% citing communications strategy development (slightly down on the 63% in 2022) as their main activity, while just over half ticked reputation management.Crisis management and Corporate PR made up 50%,  increasing by 10% and 4% respectively. Crisis management and reputation management have become more important over the past two years, at the expense of digital and social media, which have decreased by 10%.Also less important are ethics management, sales promotion and events planning   the latter two an effect of Covid and also demonstrating the shift from physical to digital PR.Future of reputation management in AfricaAsked what this will look like in Africa produced responses ranging from bleak and not promising to fairly optimistic to a positive outlook. What is certain is that there is work that needs to be done to move the needle away from just coverage to reputation management and communications that is trusted and valuable.A new strategy is needed as there is no improvement here.<!--EMBED:https://www.bizcommunity.com/Article/196/18/237762.html:EMBED-->A recession-proof industryOf the respondents, 54% said the perception of PR had improved and would be utilised more if a recession occurred, while 21% said no and 25% were not sure.While there is a mainly positive outlook, the results are a mixed bag.The report expands on this, quoting one respondent who alluded to the idea that the PR industry may be becoming less valued during the current  technological revolution  and that there may be a shift towards the reliance on artificial intelligence tools such as ChatGPT.Again this shows the need for education and training on technology and what it means for the industry going forward.Training needsThe biggest training needs identified by the report include:
- Strategy development (59%)
- Reputation management (51%)
- Crisis management (42%)
- Ethic management (41%)
While only selected by 30%, the metaverse generated the most interest demonstrating the importance of getting ahead of the curve and educating PR professionals on matters such as AI and its impact on the sector.The PRCA s survey of PR and communications practitioners from across Africa received more than 550 responses from a total of 27 countries, This Census is based on a sample of 566 respondents from across the region, with data gathered between 21 January and 27 February 2022.The survey was generated by Reputation Matter using sample sources from the PRCA s own database, a public link on the PRCA website as well as respondents recruited by APRA.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Subject: ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); POLLS & SURVEYS (78%); BUSINESS ETHICS (72%); Public relations (%); Dustin Chick (%); Danette Breitenbach (%); African Public Relations Association (%); APRA (%); PRCA Africa (%); Public Relations and Communications Association Africa (%); African communications industry (%); African public relations (PR) (%); Ethics in African PR (%); evaluation and measurement (%); PR and communcations (%); PR landscape in Africa (%); PRCA Conference 2023 (%); PRCA Conference in Zambia (%); Faisal Hussain (%); Henry Rugamba (%); Tolulope Olorundero (%)
Industry: PUBLIC RELATIONS (95%); MEDIA & TELECOMMUNICATIONS (90%); TELECOMMUNICATIONS (89%); BUDGETS (70%); BUDGET CUTS (55%)
Geographic: AFRICA (96%); NIGERIA (88%); ZAMBIA (88%); UGANDA (73%)
Load-Date: May 17, 2023","Poor evaluation and measurement are one of the biggest threats to the African public relations (PR) and communications industry,
This is one of the findings from the Public Relations and Communications Association (PRCA) Africa and African Public Relations Association (APRA) joint research on the state of ethics and PR landscape in Africa.The report, released at annual APRA Conference, which this year takes place from 15-19 May in Zambia, found that while the biggest threat identified is reduced budget (59%) poor measurement and evaluation (53%) was a close second.Why this is concerning is that the result is similar to 2022, showing that no real growth in adopting recognised evaluation methods has taken place over the past year. In addition, 26% of those surveyed did not use any evaluation methods (compared to 25% in 2022).This was one of the key focuses of a panel discussion on the report findings that was recorded earlier and then shown at the conference.The panel was moderated by Danette Breitenbach, co-editor of Marketing and Media at Bizcommunity.com. Panelists include Faisal Hussain from PRCA (UK), Henry Rugamba from APRA (Uganda), Tolulope Olorundero from Nigerian Women in PR (Nigeria) and Dustin Chick from Razor (South Africa).Ethics and TransparencyThe second part of the survey concerned ethics and transparency in PR and communications. 
While ethics is very important in the PRCA Professional Charter and Codes of Conduct, it is concerning that the report shows that 15% - an increase of two percent - of the respondents indicated that they have been asked by someone to act in an unethical way or had decided to do so in the past 12 months.Five percent acted on an incident, and 10% did not. Only 0.5% reported the incident and 17% did not report it.However, it is hearting to see that 79% said no when approached by someone to act in an unethical way while five percent were unsure.When respondents were asked to rate how ethical PR is in their country, the mean average out score is 5.3 (out of 10), a year-on-year decrease of 0.8 compared to last year. Consequently PR s perceived ethical standing has gone backward, and there is clearly much work to do in the region to ensure that ethics is at the forefront of the agenda when it comes to the PR and communications industry,  states the report.The respondents did feel that their organisations were ethical, with 69% responding that their organisation was not compromised. The report also surveyed respondents about their perception of their organisation s ethical business practices compared to similar organisations in other countries across Africa.The vast majority (90%) said that organisation ranks  above average  while the remaining 10% ranked their organisation  below average .However the same cannot be said about their countries with 88% of respondents saying their country was compromised. Asked to compare their respective countries' ethical business conduct against others on the African continent, 67% of respondents said their country was below average, while only 33% said their country was above average.<!--EMBED:https://www.bizcommunity.com/Article/196/18/238292.html:EMBED-->PR standing in the boardroomA concerning finding of the survey is that 47% of PR professionals said they are not appreciated in the boardroom - up from 14% in 2022   and 19% felt they have to prove their existence.Only 28% said senior leaders are relying on PR more than ever - a five percent decrease on 2022. Respondents felt that organisations only remember PR when they are challenged. They also felt  governments are not investing enough in PR and communications or hearing the call of strategy in this area .What PR professionals doWhat PR professionals do has remained steady, with 61% citing communications strategy development (slightly down on the 63% in 2022) as their main activity, while just over half ticked reputation management.Crisis management and Corporate PR made up 50%,  increasing by 10% and 4% respectively. Crisis management and reputation management have become more important over the past two years, at the expense of digital and social media, which have decreased by 10%.Also less important are ethics management, sales promotion and events planning   the latter two an effect of Covid and also demonstrating the shift from physical to digital PR.Future of reputation management in AfricaAsked what this will look like in Africa produced responses ranging from bleak and not promising to fairly optimistic to a positive outlook. What is certain is that there is work that needs to be done to move the needle away from just coverage to reputation management and communications that is trusted and valuable.A new strategy is needed as there is no improvement here.<!--EMBED:https://www.bizcommunity.com/Article/196/18/237762.html:EMBED-->A recession-proof industryOf the respondents, 54% said the perception of PR had improved and would be utilised more if a recession occurred, while 21% said no and 25% were not sure.While there is a mainly positive outlook, the results are a mixed bag.The report expands on this, quoting one respondent who alluded to the idea that the PR industry may be becoming less valued during the current  technological revolution  and that there may be a shift towards the reliance on artificial intelligence tools such as ChatGPT.Again this shows the need for education and training on technology and what it means for the industry going forward.Training needsThe biggest training needs identified by the report include:
- Strategy development (59%)
- Reputation management (51%)
- Crisis management (42%)
- Ethic management (41%)
While only selected by 30%, the metaverse generated the most interest demonstrating the importance of getting ahead of the curve and educating PR professionals on matters such as AI and its impact on the sector.The PRCA s survey of PR and communications practitioners from across Africa received more than 550 responses from a total of 27 countries, This Census is based on a sample of 566 respondents from across the region, with data gathered between 21 January and 27 February 2022.The survey was generated by Reputation Matter using sample sources from the PRCA s own database, a public link on the PRCA website as well as respondents recruited by APRA.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Subject: ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); POLLS & SURVEYS (78%); BUSINESS ETHICS (72%); Public relations (%); Dustin Chick (%); Danette Breitenbach (%); African Public Relations Association (%); APRA (%); PRCA Africa (%); Public Relations and Communications Association Africa (%); African communications industry (%); African public relations (PR) (%); Ethics in African PR (%); evaluation and measurement (%); PR and communcations (%); PR landscape in Africa (%); PRCA Conference 2023 (%); PRCA Conference in Zambia (%); Faisal Hussain (%); Henry Rugamba (%); Tolulope Olorundero (%)
Industry: PUBLIC RELATIONS (95%); MEDIA & TELECOMMUNICATIONS (90%); TELECOMMUNICATIONS (89%); BUDGETS (70%); BUDGET CUTS (55%)
Geographic: AFRICA (96%); NIGERIA (88%); ZAMBIA (88%); UGANDA (73%)
Load-Date: May 17, 2023",negative,0.7369434237480164,balanced/neutral,['transparency'],[],[],['chatgpt'],1,0,0,1
2023,Unknown Title,"Body
BUBBLR INC (""BBLR-0"") - Ethical Web AI Unveils Enhanced AI Seek App with Exciting New - Features
Ethical Web AI, also known as Bubblr, Inc., a pioneering ethical technology firm dedicated to reshaping the online experience, is thrilled to unveil Version 2.0 of its cutting-edge AI Seek consumer app. This new release brings a more affordable and enriched Chat GPT 4.0 experience to users. AI Seek 2.0 is now available for submission to both the Apple and Google Play Store.
Since its initial launch on July 30th, AI Seek has gained traction among users, though it has not yet been extensively marketed. Based on invaluable feedback from early members, the Ethical Web AI team has been able to craft an improved and more intuitive user experience in this updated version.
AI Seek 2.0 boasts a complete redesign, making it even more accessible for users of all tech backgrounds. Gone are the days of navigating through menus; now, users can enjoy icon-driven functions complete with tooltips. Plus, the updated appearance is clean and streamlined, optimized for effortless navigation and usability. AI Seek's user interface (UI) now aligns with the sleek and minimalist aesthetics of Apple's Cupertino and Google's Material design frameworks.
In line with our previous press release, this revamped version of AI Seek will serve as the foundation for essential explainer videos on the AI Seek website, providing users with a more comprehensive understanding of the app's capabilities. Furthermore, we're excited to announce the development of instructive video tutorials that will showcase a variety of use-case scenarios.
One standout feature of the synchronized desktop microsite is the ability to export results to various file formats, including Microsoft Word, Adobe Acrobat, or even programming language files like DART and Python, without any loss of formatting. This added functionality, not currently available in the native Chat GPT version, is sure to make AI Seek a preferred choice among users.
The Ethical Web AI team is already hard at work on the next iteration of AI Seek, which promises to deliver an even more enhanced user experience. Version 3.0 will introduce a secure desktop microsite for each AI Seek user, granting them full access to the app's functionalities without sacrificing their anonymity or security.
With this suite of exciting updates, Ethical Web AI is solidifying its position as a leader in ethical and innovative technology, bringing consumers a new era of intuitive and secure AI applications.
About Ethical Web AI:
Ethical Web AI (formerly Bubblr Inc.) is an ethical technology company that is championing a new internet that is anonymous, safe and fair. We are producing unique intellectual property and technology that is made defensible by our valuable utility software patents.
Visit the new AI Seek website at https://www.aiseek.ai/
For more information about Ethical Web AI and our products, please visit our website at https:hicalweb.ai/
About Ethical Web AI:
Ethical Web AI, is an ethical technology company focused on mobile-first technology that strives to provide a fair and uncompromised user experience. Ethical Web AIs innovative platform offers solutions to the challenges posed by today's digital ecosystem. The company's dedication to privacy, transparency, and fairness sets it apart in the technology landscape.
Company Contact:
Steve Morris
Ethical Web AI
(646) 814-7184
Join our public shareholder forum on telegram: https://t.me/+fJU
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management and are subject to a number of uncertainties and risks that could significantly affect the company's current plans and expectations, as well as future results of operations and financial condition. The company reserves the right to update or alter its forward-looking statements whether as a result of new information, future events or otherwise.
__________________________________________________
_______________________________________________
____________________________________________________________
(c)2023 Market News Publishing Inc. All rights reserved. Toronto:(416)366-8881 Vancouver:(604)689-1101 Fax:(604)689-1106
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: MNP
Subject: PRODUCT ENHANCEMENTS (90%); CHATBOTS (89%); CUSTOMER EXPERIENCE (89%); USER EXPERIENCE (89%); CONSUMERS (79%); ARTIFICIAL INTELLIGENCE (78%); INTELLECTUAL PROPERTY (78%); PATENTS (77%); PRODUCT INNOVATION (77%); USABILITY (76%); PRESS RELEASES (74%); HUMAN MACHINE INTERACTION (71%)
Company:  GOOGLE LLC (85%);  APPLE INC (84%); BUBBLR INC
Ticker: AAPL (NASDAQ) (84%); BBLR; (Nasdaq Pink Sheets)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); NAICS423430 COMPUTER & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE MERCHANT WHOLESALERS (84%); NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (84%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (84%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (84%); SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (84%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (84%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (84%); SIC3572 COMPUTER STORAGE DEVICES (84%); SIC3571 ELECTRONIC COMPUTERS (84%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (89%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER NETWORKS (78%); COMPUTER SOFTWARE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%); WORD PROCESSING SOFTWARE (67%); PROGRAMMING LANGUAGES & TOOLS (66%)
Load-Date: August 23, 2023","BUBBLR INC (""BBLR-0"") - Ethical Web AI Unveils Enhanced AI Seek App with Exciting New - Features
Ethical Web AI, also known as Bubblr, Inc., a pioneering ethical technology firm dedicated to reshaping the online experience, is thrilled to unveil Version 2.0 of its cutting-edge AI Seek consumer app. This new release brings a more affordable and enriched Chat GPT 4.0 experience to users. AI Seek 2.0 is now available for submission to both the Apple and Google Play Store.
Since its initial launch on July 30th, AI Seek has gained traction among users, though it has not yet been extensively marketed. Based on invaluable feedback from early members, the Ethical Web AI team has been able to craft an improved and more intuitive user experience in this updated version.
AI Seek 2.0 boasts a complete redesign, making it even more accessible for users of all tech backgrounds. Gone are the days of navigating through menus; now, users can enjoy icon-driven functions complete with tooltips. Plus, the updated appearance is clean and streamlined, optimized for effortless navigation and usability. AI Seek's user interface (UI) now aligns with the sleek and minimalist aesthetics of Apple's Cupertino and Google's Material design frameworks.
In line with our previous press release, this revamped version of AI Seek will serve as the foundation for essential explainer videos on the AI Seek website, providing users with a more comprehensive understanding of the app's capabilities. Furthermore, we're excited to announce the development of instructive video tutorials that will showcase a variety of use-case scenarios.
One standout feature of the synchronized desktop microsite is the ability to export results to various file formats, including Microsoft Word, Adobe Acrobat, or even programming language files like DART and Python, without any loss of formatting. This added functionality, not currently available in the native Chat GPT version, is sure to make AI Seek a preferred choice among users.
The Ethical Web AI team is already hard at work on the next iteration of AI Seek, which promises to deliver an even more enhanced user experience. Version 3.0 will introduce a secure desktop microsite for each AI Seek user, granting them full access to the app's functionalities without sacrificing their anonymity or security.
With this suite of exciting updates, Ethical Web AI is solidifying its position as a leader in ethical and innovative technology, bringing consumers a new era of intuitive and secure AI applications.
About Ethical Web AI:
Ethical Web AI (formerly Bubblr Inc.) is an ethical technology company that is championing a new internet that is anonymous, safe and fair. We are producing unique intellectual property and technology that is made defensible by our valuable utility software patents.
Visit the new AI Seek website at https://www.aiseek.ai/
For more information about Ethical Web AI and our products, please visit our website at https:hicalweb.ai/
About Ethical Web AI:
Ethical Web AI, is an ethical technology company focused on mobile-first technology that strives to provide a fair and uncompromised user experience. Ethical Web AIs innovative platform offers solutions to the challenges posed by today's digital ecosystem. The company's dedication to privacy, transparency, and fairness sets it apart in the technology landscape.
Company Contact:
Steve Morris
Ethical Web AI
(646) 814-7184
Join our public shareholder forum on telegram: https://t.me/+fJU
Safe Harbor Statement
This press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management and are subject to a number of uncertainties and risks that could significantly affect the company's current plans and expectations, as well as future results of operations and financial condition. The company reserves the right to update or alter its forward-looking statements whether as a result of new information, future events or otherwise.
__________________________________________________
_______________________________________________
____________________________________________________________
(c)2023 Market News Publishing Inc. All rights reserved. Toronto:(416)366-8881 Vancouver:(604)689-1101 Fax:(604)689-1106
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: MNP
Subject: PRODUCT ENHANCEMENTS (90%); CHATBOTS (89%); CUSTOMER EXPERIENCE (89%); USER EXPERIENCE (89%); CONSUMERS (79%); ARTIFICIAL INTELLIGENCE (78%); INTELLECTUAL PROPERTY (78%); PATENTS (77%); PRODUCT INNOVATION (77%); USABILITY (76%); PRESS RELEASES (74%); HUMAN MACHINE INTERACTION (71%)
Company:  GOOGLE LLC (85%);  APPLE INC (84%); BUBBLR INC
Ticker: AAPL (NASDAQ) (84%); BBLR; (Nasdaq Pink Sheets)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); NAICS423430 COMPUTER & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE MERCHANT WHOLESALERS (84%); NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (84%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (84%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (84%); SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (84%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (84%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (84%); SIC3572 COMPUTER STORAGE DEVICES (84%); SIC3571 ELECTRONIC COMPUTERS (84%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (89%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER NETWORKS (78%); COMPUTER SOFTWARE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%); WORD PROCESSING SOFTWARE (67%); PROGRAMMING LANGUAGES & TOOLS (66%)
Load-Date: August 23, 2023",positive,0.9064332246780396,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security', 'access']",['fairness'],[],['gpt'],5,1,0,1
2023,Unknown Title,"Body
May 04, 2023( Carnegie Council Transcripts and Articles: http://carnegiecouncil.org Delivered by Newstex)  
 To the EIA community: 
The editors of Ethics & International Affairs, the journal of Carnegie Council, are proud to announce the beginning of a new era in our publishing history. Starting with the Spring 2023 issue[1], Ethics & International Affairs (EIA) will be a digital-only quarterly.  
As much as we, the editors, hold a deep reverence for print, we also recognize that for many years now, our community of academics, students, organizers, and policymakers have primarily been interacting with digital versions of our content. On balance, this has meant a wider proliferation of EIA content than would otherwise have been possible, with access becoming truly global. 
The decision to make this jump to a fully digital publication reflects both a recognition of present realities and an acute awareness of significant changes that are necessary to achieve a carbon neutral future. By eliminating print and its associated global distribution, EIA and Carnegie Council are taking an important step toward an environmentally sustainable planet. EIA will still be published by Cambridge University Press and will maintain the same rigorous editorial review process that has been a hallmark of the journal for decades.  
As part of the transition to digital, we're also thrilled to unveil a new website[2] for the journal. In addition to an aesthetic overhaul, the new site will allow us to showcase the excellent work of our authors in a more user-friendly digital environment, providing easier navigation between related content, archived quarterly material, and website exclusives.  
Headlining the new site is the Spring 2023 issue of the journal, featuring a symposium on nuclear ethics from Scott D. Sagan and Joseph Nye, Jr., in addition to articles and essays on ecocide, democratizing fintech, and more. 
The history of the journal has been a history of transformation. When the journal was founded in 1987 it would have been near-impossible to predict many of the seismic changes that have taken place both in global politics and in academic publishing. The first issue[3] of EIA was still firmly planted in the landscape of the Cold War, with a collection on super-power ethics leading off the volume. Over the years, as the audience and reach of the journal has expanded, so too have its areas of intellectual exploration. Articles and essays on topics such as artificial intelligence, feminist foreign policy, and climate engineering, to name but a few, have enriched our collective understanding of what can and should constitute the building blocks for a just and ethical world. 
Today, as we mark both the transition to a fully digital publication and launch of the new website, we do so in a dramatically changed publishing landscape. The last few years have seen an industry-wide push toward open access publishing of academic content, with many long-held principles of the subscription model being turned upside down. The EIA editorial team has worked in partnership with our colleagues at Cambridge University Press to publish more and more of our content fully open access, without paywalls. This means wider access for scholars globally, in particular for those working at under-resourced institutions, often in the Global South. Last year, more than three quarters of all EIA articles and essays were open access. 
As Ethics & International Affairs embarks on this next phase of its journey as a publication, we invite you join us—as a reader, a researcher, a contributor, or as all of the above. After all, it is only thanks to the vibrant community, both in academia and beyond, that the journal is poised to take this important next step. In partnership with the members of the EIA community, we look forward to continuing to provide a platform for some of the most urgent debates of our time, making sure that ethics retains a central place in international affairs. 
Sincerely, https://www.carnegiecouncil.org/people/joel-h-rosenthal 
Joel Rosenthal, Editor-in-Chief Adam Read-Brown, Editor Priya Chokshi, Associate Editor 
Click here to view this letter on the EIA site. [4] 
 [ 1]: https://www.ethicsandinternationalaffairs.org/journal/issue/spring-2023-37-1 [ 2]: https://www.ethicsandinternationalaffairs.org/ [ 3]: https://www.cambridge.org/core/journals/ethics-and-international-affairs/volume/B9E0550B1DAAD0AB13A8E21164300269 [ 4]: https://www.ethicsandinternationalaffairs.org/online-exclusives/from-our-editors-a-new-era-for-ethics-international-affairs 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CCIL-8167
Subject: REPORTS, REVIEWS & SECTIONS (93%); ASSOCIATIONS & ORGANIZATIONS (90%); BLOGS & MESSAGE BOARDS (90%); ETHICS (90%); INTERNATIONAL ASSISTANCE (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); NATIONAL SECURITY & FOREIGN RELATIONS (89%); INTERNATIONAL RELATIONS (78%); FEMINISM & WOMEN'S RIGHTS (73%); WRITERS (73%); ENVIRONMENT & NATURAL RESOURCES (71%); CONFERENCES & CONVENTIONS (70%); FOREIGN POLICY (70%); SUSTAINABILITY (66%); ARTIFICIAL INTELLIGENCE (50%)
Industry: BLOGS & MESSAGE BOARDS (90%); PUBLISHING (89%); WEBSITES (86%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (50%)
Load-Date: May 10, 2023","May 04, 2023( Carnegie Council Transcripts and Articles: http://carnegiecouncil.org Delivered by Newstex)  
 To the EIA community: 
The editors of Ethics & International Affairs, the journal of Carnegie Council, are proud to announce the beginning of a new era in our publishing history. Starting with the Spring 2023 issue[1], Ethics & International Affairs (EIA) will be a digital-only quarterly.  
As much as we, the editors, hold a deep reverence for print, we also recognize that for many years now, our community of academics, students, organizers, and policymakers have primarily been interacting with digital versions of our content. On balance, this has meant a wider proliferation of EIA content than would otherwise have been possible, with access becoming truly global. 
The decision to make this jump to a fully digital publication reflects both a recognition of present realities and an acute awareness of significant changes that are necessary to achieve a carbon neutral future. By eliminating print and its associated global distribution, EIA and Carnegie Council are taking an important step toward an environmentally sustainable planet. EIA will still be published by Cambridge University Press and will maintain the same rigorous editorial review process that has been a hallmark of the journal for decades.  
As part of the transition to digital, we're also thrilled to unveil a new website[2] for the journal. In addition to an aesthetic overhaul, the new site will allow us to showcase the excellent work of our authors in a more user-friendly digital environment, providing easier navigation between related content, archived quarterly material, and website exclusives.  
Headlining the new site is the Spring 2023 issue of the journal, featuring a symposium on nuclear ethics from Scott D. Sagan and Joseph Nye, Jr., in addition to articles and essays on ecocide, democratizing fintech, and more. 
The history of the journal has been a history of transformation. When the journal was founded in 1987 it would have been near-impossible to predict many of the seismic changes that have taken place both in global politics and in academic publishing. The first issue[3] of EIA was still firmly planted in the landscape of the Cold War, with a collection on super-power ethics leading off the volume. Over the years, as the audience and reach of the journal has expanded, so too have its areas of intellectual exploration. Articles and essays on topics such as artificial intelligence, feminist foreign policy, and climate engineering, to name but a few, have enriched our collective understanding of what can and should constitute the building blocks for a just and ethical world. 
Today, as we mark both the transition to a fully digital publication and launch of the new website, we do so in a dramatically changed publishing landscape. The last few years have seen an industry-wide push toward open access publishing of academic content, with many long-held principles of the subscription model being turned upside down. The EIA editorial team has worked in partnership with our colleagues at Cambridge University Press to publish more and more of our content fully open access, without paywalls. This means wider access for scholars globally, in particular for those working at under-resourced institutions, often in the Global South. Last year, more than three quarters of all EIA articles and essays were open access. 
As Ethics & International Affairs embarks on this next phase of its journey as a publication, we invite you join us—as a reader, a researcher, a contributor, or as all of the above. After all, it is only thanks to the vibrant community, both in academia and beyond, that the journal is poised to take this important next step. In partnership with the members of the EIA community, we look forward to continuing to provide a platform for some of the most urgent debates of our time, making sure that ethics retains a central place in international affairs. 
Sincerely, https://www.carnegiecouncil.org/people/joel-h-rosenthal 
Joel Rosenthal, Editor-in-Chief Adam Read-Brown, Editor Priya Chokshi, Associate Editor 
Click here to view this letter on the EIA site. [4] 
 [ 1]: https://www.ethicsandinternationalaffairs.org/journal/issue/spring-2023-37-1 [ 2]: https://www.ethicsandinternationalaffairs.org/ [ 3]: https://www.cambridge.org/core/journals/ethics-and-international-affairs/volume/B9E0550B1DAAD0AB13A8E21164300269 [ 4]: https://www.ethicsandinternationalaffairs.org/online-exclusives/from-our-editors-a-new-era-for-ethics-international-affairs 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CCIL-8167
Subject: REPORTS, REVIEWS & SECTIONS (93%); ASSOCIATIONS & ORGANIZATIONS (90%); BLOGS & MESSAGE BOARDS (90%); ETHICS (90%); INTERNATIONAL ASSISTANCE (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); NATIONAL SECURITY & FOREIGN RELATIONS (89%); INTERNATIONAL RELATIONS (78%); FEMINISM & WOMEN'S RIGHTS (73%); WRITERS (73%); ENVIRONMENT & NATURAL RESOURCES (71%); CONFERENCES & CONVENTIONS (70%); FOREIGN POLICY (70%); SUSTAINABILITY (66%); ARTIFICIAL INTELLIGENCE (50%)
Industry: BLOGS & MESSAGE BOARDS (90%); PUBLISHING (89%); WEBSITES (86%); WRITERS (73%); ARTIFICIAL INTELLIGENCE (50%)
Load-Date: May 10, 2023",positive,0.5371420979499817,balanced/neutral,"['security', 'access']",[],"['policy', 'should']",[],2,0,2,0
2023,Unknown Title,"Body
EAST POINT. Almost a year after Chat GTP burst into the market and caused a stir about artificial intelligence (AI), the legislation on this technology has hardly been implemented.
In 2021, the United Nations Educational, Scientific and Cultural Organization (Unesco) published its Recommendations on the Ethics of AI, and to date only Peru has published a law on the matter, although it lacks regulations, while other nations in the region have barely launched recommendations.
  Theater
""There is no country that has legislation capable of dealing with the problems involved in this technology. All this emerged with the recommendations on ethics launched by Unesco in 2021, from there everyone talks about the subject and countries began to work on projects, recommendations and so on, but in terms of accessible laws we are still quite behind the advance of technology,"" Fabiana Ramirez, ESET's Information Security researcher, told El Sol de Mexico.
Last year, Peru passed Law 31.814, which establishes the principles for the development and use of AI through risk-based standards and Internet governance.
Ramirez highlighted the Andean country's legislative work for the approval of this law, however, he stressed that it lacks a regulation defining its use.
Mexico, Chile and Brazil, meanwhile, have announced projects to regulate this technology.
In the Mexican case, there is a draft Law for the Ethical Regulation of Artificial Intelligence and Robotics, which provides for the creation of a Mexican Ethics Council, the promotion of human rights and data protection, as well as the prohibition of the use of this tool for social manipulation.
The bill, presented in May by PAN deputy Ignacio Loyola Vera, provides for the regulation of the use of this technology for governmental, economic, commercial, administrative, communicational and financial purposes.
It foresees that no public or private entity may misuse AI and robotics for purposes of social manipulation, discrimination or violation of the rule of law, as well as the creation of the Mexican Council of Ethics for Artificial Intelligence and Robotics, whose obligation is to review ethical protocols surrounding this technology.
For Alejandro González, analyst at Digital Policy and Law (DPL), AI legislation has been relegated in Mexico because legislators are at a stage where the issue is not a priority, but rather other political and even electoral issues.
In this regard, the ESET analyst stressed that while Chat GTP already shows updates and large companies such as Google launch their own tools, in most nations people are unprotected from the theft of personal data through these platforms.
In the framework of the eighth Information Security Forum, the specialist stressed that, in general, worldwide, legislation on the proper use of AI is not as advanced due to the fact that the processes of laws are slower than technological development.
She highlighted the case of the United States, which is at the forefront with agreements with companies such as OpenAI, Alphabet, Meta Platforms, Anthropic, Inflection, Amazon and Microsoft to guarantee the security of the systems.
Meanwhile, in the European Union, the regulation on the use of AI to safeguard citizens' rights is still pending.
?? Subscribe to our Newsletter and receive the most relevant news in your inbox.
In Latin America, Argentina and Colombia published between last year and this one a provision and an ethical framework for the use of AI that, among other elements, promote data transparency and privacy. a social perspective and the safeguarding and protection of vulnerable sectors, such as children.""
""Ethics of course is always going to depend on the society where the law is applied, but the idea would be that all laws address an ethical issue in relation to respect for Human Rights and of course the indiscriminate use of data, which is linked. What is always expected is that a law is capable of protecting people's sensitive data"", considered Ramírez Cuenca.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); LEGISLATION (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ROBOTICS (89%); AGREEMENTS (78%); DISCRIMINATION (78%); ELECTIONS & POLITICS (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (78%); LEGISLATIVE BODIES (78%); RULE OF LAW (78%); NEGATIVE SOCIETAL NEWS (77%); AGENCY RULEMAKING (73%); HUMAN RIGHTS (73%); APPROVALS (72%); ASSOCIATIONS & ORGANIZATIONS (72%); DATA THEFT (68%); Finanzas (%)
Company:  GOOGLE LLC (58%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (89%); ROBOTICS (89%); DATA SECURITY (73%); INTERNET & WWW (73%); ONLINE SECURITY & PRIVACY (72%); DATA THEFT (68%)
Geographic: MEXICO (94%); BRAZIL (79%); CHILE (79%); LATIN AMERICA (79%); UNITED STATES (79%)
Load-Date: November 19, 2023","EAST POINT. Almost a year after Chat GTP burst into the market and caused a stir about artificial intelligence (AI), the legislation on this technology has hardly been implemented.
In 2021, the United Nations Educational, Scientific and Cultural Organization (Unesco) published its Recommendations on the Ethics of AI, and to date only Peru has published a law on the matter, although it lacks regulations, while other nations in the region have barely launched recommendations.
  Theater
""There is no country that has legislation capable of dealing with the problems involved in this technology. All this emerged with the recommendations on ethics launched by Unesco in 2021, from there everyone talks about the subject and countries began to work on projects, recommendations and so on, but in terms of accessible laws we are still quite behind the advance of technology,"" Fabiana Ramirez, ESET's Information Security researcher, told El Sol de Mexico.
Last year, Peru passed Law 31.814, which establishes the principles for the development and use of AI through risk-based standards and Internet governance.
Ramirez highlighted the Andean country's legislative work for the approval of this law, however, he stressed that it lacks a regulation defining its use.
Mexico, Chile and Brazil, meanwhile, have announced projects to regulate this technology.
In the Mexican case, there is a draft Law for the Ethical Regulation of Artificial Intelligence and Robotics, which provides for the creation of a Mexican Ethics Council, the promotion of human rights and data protection, as well as the prohibition of the use of this tool for social manipulation.
The bill, presented in May by PAN deputy Ignacio Loyola Vera, provides for the regulation of the use of this technology for governmental, economic, commercial, administrative, communicational and financial purposes.
It foresees that no public or private entity may misuse AI and robotics for purposes of social manipulation, discrimination or violation of the rule of law, as well as the creation of the Mexican Council of Ethics for Artificial Intelligence and Robotics, whose obligation is to review ethical protocols surrounding this technology.
For Alejandro González, analyst at Digital Policy and Law (DPL), AI legislation has been relegated in Mexico because legislators are at a stage where the issue is not a priority, but rather other political and even electoral issues.
In this regard, the ESET analyst stressed that while Chat GTP already shows updates and large companies such as Google launch their own tools, in most nations people are unprotected from the theft of personal data through these platforms.
In the framework of the eighth Information Security Forum, the specialist stressed that, in general, worldwide, legislation on the proper use of AI is not as advanced due to the fact that the processes of laws are slower than technological development.
She highlighted the case of the United States, which is at the forefront with agreements with companies such as OpenAI, Alphabet, Meta Platforms, Anthropic, Inflection, Amazon and Microsoft to guarantee the security of the systems.
Meanwhile, in the European Union, the regulation on the use of AI to safeguard citizens' rights is still pending.
?? Subscribe to our Newsletter and receive the most relevant news in your inbox.
In Latin America, Argentina and Colombia published between last year and this one a provision and an ethical framework for the use of AI that, among other elements, promote data transparency and privacy. a social perspective and the safeguarding and protection of vulnerable sectors, such as children.""
""Ethics of course is always going to depend on the society where the law is applied, but the idea would be that all laws address an ethical issue in relation to respect for Human Rights and of course the indiscriminate use of data, which is linked. What is always expected is that a law is capable of protecting people's sensitive data"", considered Ramírez Cuenca.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); LEGISLATION (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ROBOTICS (89%); AGREEMENTS (78%); DISCRIMINATION (78%); ELECTIONS & POLITICS (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (78%); LEGISLATIVE BODIES (78%); RULE OF LAW (78%); NEGATIVE SOCIETAL NEWS (77%); AGENCY RULEMAKING (73%); HUMAN RIGHTS (73%); APPROVALS (72%); ASSOCIATIONS & ORGANIZATIONS (72%); DATA THEFT (68%); Finanzas (%)
Company:  GOOGLE LLC (58%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (89%); ROBOTICS (89%); DATA SECURITY (73%); INTERNET & WWW (73%); ONLINE SECURITY & PRIVACY (72%); DATA THEFT (68%)
Geographic: MEXICO (94%); BRAZIL (79%); CHILE (79%); LATIN AMERICA (79%); UNITED STATES (79%)
Load-Date: November 19, 2023",neutral,0.5799559950828552,balanced/neutral,"['privacy', 'discrimination', 'transparency', 'security', 'human rights', 'agency', 'manipulation']",[],"['regulation', 'policy', 'governance', 'standards', 'framework', 'legislation', 'law']",['robotics'],7,0,7,1
2023,Unknown Title,"Byline: CRN Team
Body
Technology serves as a yardstick for societal progress, reflecting our ability to enhance the quality of life and elevate the human experience - by applying and democratizing these technological advancements. We are on the brink of the Fifth Industrial Revolution, driven by significant advancements in artificial intelligence (AI). AI has revolutionized our ability to perform tasks with increased speed and efficiency.
While there is immense potential for positive impact, we must also acknowledge the challenges associated with AI. Instances of bias in voice recognition software favoring male voices and discriminatory policing reinforced by crime-prediction tools serve as reminders of the problems AI can present.
Lacking a solid ethical foundation, AI advancements can lead to undesired consequences and perpetuate biases. To establish reliable AI systems, organizations must prioritize accountability, transparency, and fairness. When considering the positive contributions of AI to society, there are three key pillars that form the foundation for building trusted AI within any organization:
Cultivate an Ethics-By-Design Mindset
Within the business context, integrating ethics into AI involves fostering and maintaining a culture of critical thinking among employees. It is unrealistic to expect a single group to identify ethical risks throughout the development process. Instead, a collaborative approach is necessary, engaging various stakeholders to effectively address and mitigate ethical concerns associated with AI. Instead, ethics by design requires a multitude of diverse perspectives from different cultures, ethnicities, genders, and areas of expertise.
A consequence scanning; framework, which involves anticipating unintended outcomes of new features and finding ways to mitigate harm, has dual benefits. It not only enhances the final product but also stimulates creative thinking among teams during the development phase. By considering the potential impact on various stakeholders, as well as anticipating other problems, this framework promotes a holistic approach to product development.
Creating an environment that embraces input from a broader audience can help organizations eliminate blind spots that can be ripe for bias. By offering training programs that help employees put ethics at the core of their respective workflows, organizations can also empower their workforce to critically identify potential risks. An effective approach is to provide comprehensive training to new employees right from the beginning, enabling them to grasp their responsibilities in the development process and cultivate a mindset focused on ethics by design.
Apply Best Practice Through Transparency
Transparency plays a crucial role in capturing diversified perspectives and avoiding unintended consequences. Collaborating with external experts, including academics, industry leaders, and government representatives, can provide valuable feedback and insights. Sharing information about data quality, bias mitigation efforts, and the development process with the relevant audiences fosters trust. Publishing model cards, like nutrition labels, help users understand the AI system's intended use, performance metrics, and ethical considerations. Effective communication of AI explanations is essential to inspire confidence and prevent confusion among user groups.
To establish trust in AI, it is crucial for the intended audience to comprehend the rationale behind AIs recommendations or predictions. Different users engage with AI technologies with varying levels of knowledge and expertise. For instance, data scientists may need access to all the factors utilized in a model. On the other hand, sales representatives lacking a background in data science or statistics may find such detailed information overwhelming. To instill confidence and prevent confusion, it is essential for teams to possess the ability to effectively communicate these concepts and explanations in a manner that suits the understanding and needs of diverse users.
Empower Customers to Make Ethical Choices
Ethics doesn't stop at development. Developers serve as providers of AI platforms, but it is important to recognize that AI users ultimately own and bear responsibility for their data. Although developers can offer training and resources to assist customers in identifying bias and minimizing harm, it is crucial to acknowledge that inadequately trained or unmonitored algorithms have the potential to perpetuate harmful stereotypes. Therefore, organizations must provide customers and users with the right tools to use technologies safely and responsibly, to identify and address problems.
Establishing trusted AI systems requires a comprehensive approach that encompasses an ethics-by- design mindset, transparency throughout the development process, and empowering customers to make ethical choices. By adhering to these three pillars, organizations can foster a culture of accountability, transparency, and fairness in AI development.
Embracing these principles will democratize the benefits of AI and ensure its positive contribution to society. As we navigate the future of AI, prioritizing ethics will pave the way for responsible technological progress and a more inclusive human experience. By providing proper guidance and training, customers can gain a better understanding of the repercussions associated with the decision to include or exclude sensitive fields and ""proxies"" from their AI model.
Embedding values in AI is a complex and multifaceted endeavor. It involves a transformation in culture, the refinement of processes, enhanced engagement with employees, customers, and stakeholders, and empowering users with the necessary tools and understanding to wield technology responsibly. By collectively advancing these three fundamental pillars, we can ensure that AI is developed and implemented with accountability and transparency, thereby democratizing the advantages of AI for the broader society.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ASSOCIATIONS & ORGANIZATIONS (89%); DISCRIMINATION (79%); RACE & ETHNICITY (79%); VOICE RECOGNITION (79%); BEST PRACTICES (78%); NEGATIVE SOCIETAL NEWS (78%); PRODUCT ENHANCEMENTS (78%); EMPLOYEE TRAINING & ASSISTANCE (76%); PRODUCT DEVELOPMENT (76%); NEGATIVE NEWS (75%); LABOR FORCE (71%); BUSINESS METRICS (67%)
Company:  BEST INC (52%)
Ticker: BEST (NYSE) (52%)
Industry: SIC5999 MISCELLANEOUS RETAIL STORES, NEC (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); VOICE RECOGNITION (79%)
Geographic: ASIA (79%); INDIA (79%); SOUTHERN ASIA (57%)
Load-Date: August 25, 2023","Technology serves as a yardstick for societal progress, reflecting our ability to enhance the quality of life and elevate the human experience - by applying and democratizing these technological advancements. We are on the brink of the Fifth Industrial Revolution, driven by significant advancements in artificial intelligence (AI). AI has revolutionized our ability to perform tasks with increased speed and efficiency.
While there is immense potential for positive impact, we must also acknowledge the challenges associated with AI. Instances of bias in voice recognition software favoring male voices and discriminatory policing reinforced by crime-prediction tools serve as reminders of the problems AI can present.
Lacking a solid ethical foundation, AI advancements can lead to undesired consequences and perpetuate biases. To establish reliable AI systems, organizations must prioritize accountability, transparency, and fairness. When considering the positive contributions of AI to society, there are three key pillars that form the foundation for building trusted AI within any organization:
Cultivate an Ethics-By-Design Mindset
Within the business context, integrating ethics into AI involves fostering and maintaining a culture of critical thinking among employees. It is unrealistic to expect a single group to identify ethical risks throughout the development process. Instead, a collaborative approach is necessary, engaging various stakeholders to effectively address and mitigate ethical concerns associated with AI. Instead, ethics by design requires a multitude of diverse perspectives from different cultures, ethnicities, genders, and areas of expertise.
A consequence scanning; framework, which involves anticipating unintended outcomes of new features and finding ways to mitigate harm, has dual benefits. It not only enhances the final product but also stimulates creative thinking among teams during the development phase. By considering the potential impact on various stakeholders, as well as anticipating other problems, this framework promotes a holistic approach to product development.
Creating an environment that embraces input from a broader audience can help organizations eliminate blind spots that can be ripe for bias. By offering training programs that help employees put ethics at the core of their respective workflows, organizations can also empower their workforce to critically identify potential risks. An effective approach is to provide comprehensive training to new employees right from the beginning, enabling them to grasp their responsibilities in the development process and cultivate a mindset focused on ethics by design.
Apply Best Practice Through Transparency
Transparency plays a crucial role in capturing diversified perspectives and avoiding unintended consequences. Collaborating with external experts, including academics, industry leaders, and government representatives, can provide valuable feedback and insights. Sharing information about data quality, bias mitigation efforts, and the development process with the relevant audiences fosters trust. Publishing model cards, like nutrition labels, help users understand the AI system's intended use, performance metrics, and ethical considerations. Effective communication of AI explanations is essential to inspire confidence and prevent confusion among user groups.
To establish trust in AI, it is crucial for the intended audience to comprehend the rationale behind AIs recommendations or predictions. Different users engage with AI technologies with varying levels of knowledge and expertise. For instance, data scientists may need access to all the factors utilized in a model. On the other hand, sales representatives lacking a background in data science or statistics may find such detailed information overwhelming. To instill confidence and prevent confusion, it is essential for teams to possess the ability to effectively communicate these concepts and explanations in a manner that suits the understanding and needs of diverse users.
Empower Customers to Make Ethical Choices
Ethics doesn't stop at development. Developers serve as providers of AI platforms, but it is important to recognize that AI users ultimately own and bear responsibility for their data. Although developers can offer training and resources to assist customers in identifying bias and minimizing harm, it is crucial to acknowledge that inadequately trained or unmonitored algorithms have the potential to perpetuate harmful stereotypes. Therefore, organizations must provide customers and users with the right tools to use technologies safely and responsibly, to identify and address problems.
Establishing trusted AI systems requires a comprehensive approach that encompasses an ethics-by- design mindset, transparency throughout the development process, and empowering customers to make ethical choices. By adhering to these three pillars, organizations can foster a culture of accountability, transparency, and fairness in AI development.
Embracing these principles will democratize the benefits of AI and ensure its positive contribution to society. As we navigate the future of AI, prioritizing ethics will pave the way for responsible technological progress and a more inclusive human experience. By providing proper guidance and training, customers can gain a better understanding of the repercussions associated with the decision to include or exclude sensitive fields and ""proxies"" from their AI model.
Embedding values in AI is a complex and multifaceted endeavor. It involves a transformation in culture, the refinement of processes, enhanced engagement with employees, customers, and stakeholders, and empowering users with the necessary tools and understanding to wield technology responsibly. By collectively advancing these three fundamental pillars, we can ensure that AI is developed and implemented with accountability and transparency, thereby democratizing the advantages of AI for the broader society.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ASSOCIATIONS & ORGANIZATIONS (89%); DISCRIMINATION (79%); RACE & ETHNICITY (79%); VOICE RECOGNITION (79%); BEST PRACTICES (78%); NEGATIVE SOCIETAL NEWS (78%); PRODUCT ENHANCEMENTS (78%); EMPLOYEE TRAINING & ASSISTANCE (76%); PRODUCT DEVELOPMENT (76%); NEGATIVE NEWS (75%); LABOR FORCE (71%); BUSINESS METRICS (67%)
Company:  BEST INC (52%)
Ticker: BEST (NYSE) (52%)
Industry: SIC5999 MISCELLANEOUS RETAIL STORES, NEC (52%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); VOICE RECOGNITION (79%)
Geographic: ASIA (79%); INDIA (79%); SOUTHERN ASIA (57%)
Load-Date: August 25, 2023",positive,0.7607864141464233,balanced/neutral,"['bias', 'discrimination', 'fairness', 'transparency', 'accountability', 'access']",['fairness'],"['framework', 'must']",['ai model'],6,1,2,1
2023,Unknown Title,"Byline: Timothy Sulzer, ZeroEyes
Body
July 1st, 2023 ( VentureBeat  — Delivered by  Newstex )
Join top executives in San Francisco on July 11-12 and learn how business leaders are getting ahead of the generative AI revolution.  Learn More
The power of artificial intelligence (AI) is revolutionizing our lives and work in unprecedented ways. Now, city streets can be illuminated by smart street lights, healthcare systems can use AI to diagnose and treat patients with speed and accuracy, financial institutions are able to employ AI to detect fraudulent activities, and there are even schools protected by AI-powered gun detection systems. AI  is steadily advancing many aspects of our existence, often without us even realizing it.
As AI becomes increasingly sophisticated and ubiquitous, its continuous rise is illuminating challenges and ethical considerations that we must navigate carefully. To ensure that its development and deployment properly align with key values that are beneficial to society, it is crucial to approach AI with a balanced perspective and work to maximize its potential for good while minimizing its possible risks.
Navigating ethics across multiple AI types 
The pace of technological advancement in recent years has been extraordinary, with AI evolving rapidly and the latest developments receiving considerable media attention and mainstream adoption. This is especially true of the viral launches of large language models (LLMs) like ChatGPT, which recently set the record for the fastest-growing consumer app in history. However, success also brings ethical challenges  that must be navigated, and ChatGPT is no exception.
ChatGPT is a valuable tool for content creation that is being used worldwide, but its ability to be used for nefarious purposes like plagiarism has been widely reported. Additionally, because the system is trained on data from the internet, it can be vulnerable to false information and may regurgitate or craft responses based on false information in a discriminatory or harmful fashion.
Event
Transform 2023
Join us in San Francisco on July 11-12, where top executives will share how they have integrated and optimized AI investments for success and avoided common pitfalls.
Register Now
Of course, AI can benefit society in unprecedented ways, especially when used for public safety. However, even engineers who have dedicated their lives to its evolution are aware that its rise carries risks and pitfalls. It is crucial to approach AI with a perspective that balances ethical considerations.
This requires a thoughtful and proactive approach. One strategy is for AI companies to establish a third-party ethics board to oversee the development of new products. Ethics boards are focused on responsible AI , ensuring new products align with the organization's core values and code of ethics. In addition to third-party boards, external AI ethics consortiums are providing valuable oversight and ensuring companies prioritize ethical considerations that benefit society rather than solely focusing on shareholder value. Consortiums enable competitors in the space to collaborate and establish fair and equitable rules and requirements, reducing the concern that any one company may lose out by adhering to a higher standard of AI ethics.
We must remember that AI systems are trained by humans, which makes them vulnerable to corruption for any use case. To address this vulnerability, we as leaders need to invest in thoughtful approaches and rigorous processes for data capture and storage, as well as testing and improving models in-house to maintain AI quality control.
Ethical AI: A balancing act of transparency and competition
When it comes to ethical AI, there is a true balancing act. The industry as a whole has differing views on what is deemed ethical, making it unclear who should make the executive decision on whose ethics are the right ethics. However, perhaps the question to ask is whether companies are being transparent about how they are building these systems. This is the main issue we are facing today.
Ultimately, although supporting regulation and legislation may seem like a good solution, even the best efforts can be thwarted in the face of fast-paced technological advancements. The future is uncertain, and it is very possible that in the next few years, a loophole or an ethical quagmire may surface that we could not foresee. This is why transparency and competition are the ultimate solutions to ethical AI today.
Currently, companies compete to provide a comprehensive and seamless user experience. For example, people may choose Instagram over Facebook, Google over Bing, or Slack over Microsoft Teams based on the quality of experience. However, users often lack a clear understanding of how these features work and the data privacy  they are sacrificing to access them.
If companies were more transparent about processes, programs and data usage and collection , users would have a better understanding of how their personal data is being used. This would lead to companies competing not only on the quality of the user experience, but on providing customers with the privacy they desire. In the future, open-source  technology companies that provide transparency and prioritize both privacy and user experience will be more prominent.
Proactive preparation for future regulations 
Promoting transparency in AI development will also help companies stay ahead of any potential regulatory requirements while building trust within their customer base. To achieve this, companies must remain informed of emerging standards and conduct internal audits to assess and ensure compliance with AI-related regulations before those regulations are even enforced. Taking these steps not only ensures that companies are meeting legal obligations but provides the best possible user experience for customers.
Essentially, the AI industry must be proactive in developing fair and unbiased systems while protecting user privacy, and these regulations are a starting point on the road to transparency.
Conclusion: Keeping ethical AI in focus
As AI becomes increasingly integrated into our world, it is evident that without attention, these systems can be built on datasets that reflect many of the flaws and biases of their human creators.
To proactively address this issue, AI developers should mindfully construct their systems and test them using datasets that reflect the diversity of human experience, ensuring fair and unbiased representation of all users. Developers should establish and maintain clear guidelines for the use of these systems, taking ethical considerations into account while remaining transparent and accountable. 
AI development requires a forward-looking approach that balances the potential benefits and risks. Technology will only continue to evolve and become more sophisticated, so it is essential that we remain vigilant in our efforts to ensure that AI is used ethically. However, determining what constitutes the greater good of society is a complex and subjective matter. The ethics and values of different individuals and groups must be considered, and ultimately, it is up to the users to decide what aligns with their beliefs.
Timothy Sulzer  is CTO of ZeroEyes.
DataDecisionMakers
Welcome to the VentureBeat community!
DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.
If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.
You might even consider  contributing an article  of your own!
Read More From DataDecisionMakers
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 107988
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); NEGATIVE PERSONAL NEWS (90%); CHATBOTS (89%); EXECUTIVES (89%); LARGE LANGUAGE MODELS (79%); BLOGS & MESSAGE BOARDS (78%); SHAREHOLDERS (78%); NEGATIVE SOCIETAL NEWS (75%); SAFETY (75%); SCHOOL CHEATING (75%); PRODUCT DEVELOPMENT (73%); NEGATIVE NEWS (70%); NEW PRODUCTS (70%); PLAGIARISM (70%); ASSOCIATIONS & ORGANIZATIONS (60%); SAFETY, ACCIDENTS & DISASTERS (50%); AI (%); Business (%); DataDecisionMakers (%); AI, ML and Deep Learning (%); category-/News (%); ethical AI (%); responsible AI (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); CHATBOTS (89%); LARGE LANGUAGE MODELS (79%); BLOGS & MESSAGE BOARDS (78%); BANKING & FINANCE (71%); NEW PRODUCTS (70%)
Geographic: CALIFORNIA, USA (90%)
Load-Date: July 1, 2023","July 1st, 2023 ( VentureBeat  — Delivered by  Newstex )
Join top executives in San Francisco on July 11-12 and learn how business leaders are getting ahead of the generative AI revolution.  Learn More
The power of artificial intelligence (AI) is revolutionizing our lives and work in unprecedented ways. Now, city streets can be illuminated by smart street lights, healthcare systems can use AI to diagnose and treat patients with speed and accuracy, financial institutions are able to employ AI to detect fraudulent activities, and there are even schools protected by AI-powered gun detection systems. AI  is steadily advancing many aspects of our existence, often without us even realizing it.
As AI becomes increasingly sophisticated and ubiquitous, its continuous rise is illuminating challenges and ethical considerations that we must navigate carefully. To ensure that its development and deployment properly align with key values that are beneficial to society, it is crucial to approach AI with a balanced perspective and work to maximize its potential for good while minimizing its possible risks.
Navigating ethics across multiple AI types 
The pace of technological advancement in recent years has been extraordinary, with AI evolving rapidly and the latest developments receiving considerable media attention and mainstream adoption. This is especially true of the viral launches of large language models (LLMs) like ChatGPT, which recently set the record for the fastest-growing consumer app in history. However, success also brings ethical challenges  that must be navigated, and ChatGPT is no exception.
ChatGPT is a valuable tool for content creation that is being used worldwide, but its ability to be used for nefarious purposes like plagiarism has been widely reported. Additionally, because the system is trained on data from the internet, it can be vulnerable to false information and may regurgitate or craft responses based on false information in a discriminatory or harmful fashion.
Event
Transform 2023
Join us in San Francisco on July 11-12, where top executives will share how they have integrated and optimized AI investments for success and avoided common pitfalls.
Register Now
Of course, AI can benefit society in unprecedented ways, especially when used for public safety. However, even engineers who have dedicated their lives to its evolution are aware that its rise carries risks and pitfalls. It is crucial to approach AI with a perspective that balances ethical considerations.
This requires a thoughtful and proactive approach. One strategy is for AI companies to establish a third-party ethics board to oversee the development of new products. Ethics boards are focused on responsible AI , ensuring new products align with the organization's core values and code of ethics. In addition to third-party boards, external AI ethics consortiums are providing valuable oversight and ensuring companies prioritize ethical considerations that benefit society rather than solely focusing on shareholder value. Consortiums enable competitors in the space to collaborate and establish fair and equitable rules and requirements, reducing the concern that any one company may lose out by adhering to a higher standard of AI ethics.
We must remember that AI systems are trained by humans, which makes them vulnerable to corruption for any use case. To address this vulnerability, we as leaders need to invest in thoughtful approaches and rigorous processes for data capture and storage, as well as testing and improving models in-house to maintain AI quality control.
Ethical AI: A balancing act of transparency and competition
When it comes to ethical AI, there is a true balancing act. The industry as a whole has differing views on what is deemed ethical, making it unclear who should make the executive decision on whose ethics are the right ethics. However, perhaps the question to ask is whether companies are being transparent about how they are building these systems. This is the main issue we are facing today.
Ultimately, although supporting regulation and legislation may seem like a good solution, even the best efforts can be thwarted in the face of fast-paced technological advancements. The future is uncertain, and it is very possible that in the next few years, a loophole or an ethical quagmire may surface that we could not foresee. This is why transparency and competition are the ultimate solutions to ethical AI today.
Currently, companies compete to provide a comprehensive and seamless user experience. For example, people may choose Instagram over Facebook, Google over Bing, or Slack over Microsoft Teams based on the quality of experience. However, users often lack a clear understanding of how these features work and the data privacy  they are sacrificing to access them.
If companies were more transparent about processes, programs and data usage and collection , users would have a better understanding of how their personal data is being used. This would lead to companies competing not only on the quality of the user experience, but on providing customers with the privacy they desire. In the future, open-source  technology companies that provide transparency and prioritize both privacy and user experience will be more prominent.
Proactive preparation for future regulations 
Promoting transparency in AI development will also help companies stay ahead of any potential regulatory requirements while building trust within their customer base. To achieve this, companies must remain informed of emerging standards and conduct internal audits to assess and ensure compliance with AI-related regulations before those regulations are even enforced. Taking these steps not only ensures that companies are meeting legal obligations but provides the best possible user experience for customers.
Essentially, the AI industry must be proactive in developing fair and unbiased systems while protecting user privacy, and these regulations are a starting point on the road to transparency.
Conclusion: Keeping ethical AI in focus
As AI becomes increasingly integrated into our world, it is evident that without attention, these systems can be built on datasets that reflect many of the flaws and biases of their human creators.
To proactively address this issue, AI developers should mindfully construct their systems and test them using datasets that reflect the diversity of human experience, ensuring fair and unbiased representation of all users. Developers should establish and maintain clear guidelines for the use of these systems, taking ethical considerations into account while remaining transparent and accountable. 
AI development requires a forward-looking approach that balances the potential benefits and risks. Technology will only continue to evolve and become more sophisticated, so it is essential that we remain vigilant in our efforts to ensure that AI is used ethically. However, determining what constitutes the greater good of society is a complex and subjective matter. The ethics and values of different individuals and groups must be considered, and ultimately, it is up to the users to decide what aligns with their beliefs.
Timothy Sulzer  is CTO of ZeroEyes.
DataDecisionMakers
Welcome to the VentureBeat community!
DataDecisionMakers is where experts, including the technical people doing data work, can share data-related insights and innovation.
If you want to read about cutting-edge ideas and up-to-date information, best practices, and the future of data and data tech, join us at DataDecisionMakers.
You might even consider  contributing an article  of your own!
Read More From DataDecisionMakers
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 107988
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); NEGATIVE PERSONAL NEWS (90%); CHATBOTS (89%); EXECUTIVES (89%); LARGE LANGUAGE MODELS (79%); BLOGS & MESSAGE BOARDS (78%); SHAREHOLDERS (78%); NEGATIVE SOCIETAL NEWS (75%); SAFETY (75%); SCHOOL CHEATING (75%); PRODUCT DEVELOPMENT (73%); NEGATIVE NEWS (70%); NEW PRODUCTS (70%); PLAGIARISM (70%); ASSOCIATIONS & ORGANIZATIONS (60%); SAFETY, ACCIDENTS & DISASTERS (50%); AI (%); Business (%); DataDecisionMakers (%); AI, ML and Deep Learning (%); category-/News (%); ethical AI (%); responsible AI (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); CHATBOTS (89%); LARGE LANGUAGE MODELS (79%); BLOGS & MESSAGE BOARDS (78%); BANKING & FINANCE (71%); NEW PRODUCTS (70%)
Geographic: CALIFORNIA, USA (90%)
Load-Date: July 1, 2023",positive,0.5985416769981384,balanced/neutral,"['privacy', 'transparency', 'safety', 'access']",[],"['regulation', 'oversight', 'standards', 'guidelines', 'legislation', 'compliance', 'should', 'must', 'need to']","['deep learning', 'generative ai', 'chatgpt']",4,0,9,3
2023,Unknown Title,"Body
2023 JUL 25 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting originating from Pensacola, Florida, by NewsRx correspondents, research stated, ""The rise in artificial intelligence (AI) and machine learning (ML) in cryptocurrency trading has precipitated complex ethical considerations, demanding a thorough exploration of responsible regulatory approaches."" 
 The news correspondents obtained a quote from the research from University of West Florida: ""This research expands upon this need by employing a consequentialist theoretical framework, emphasizing the outcomes of AI and ML's deployment within the sector and its effects on stakeholders. Drawing on critical case studies, such as SBF and FTX, and conducting an extensive review of relevant literature, this study explores the ethical implications of AI and ML in the context of cryptocurrency trading. It investigates the necessity for novel regulatory methods that address the unique characteristics of digital assets alongside existing legalities, such as those about fraud and insider trading."" 
 According to the news reporters, the research concluded: ""The author proposes a typology framework for AI and ML trading by comparing consequentialism to other ethical theories applicable to AI and ML use in cryptocurrency trading. By applying a consequentialist lens, this study underscores the significance of balancing AI and ML's transformative potential with ethical considerations to ensure market integrity, investor protection, and overall well-being in cryptocurrency trading."" 
 For more information on this research see: Developing an Ethical Framework for Responsible Artificial Intelligence (AI) and Machine Learning (ML) Applications in Cryptocurrency Trading: A Consequentialism Ethics Analysis. FinTech, 2023,2(3). The publisher for FinTech is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/fintech2030024. 
 Our news editors report that more information may be obtained by contacting Haris Alibašic, Public Administration Program, University of West Florida, 11000 University Pkwy, Pensacola, FL 32514, United States.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Haris Alibašic (orcid.org/0000-0001-8721-0411). 
 Keywords for this news article include: University of West Florida, Pensacola, Florida, United States, North and Central America, Artificial Intelligence, Cyborgs, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: MACHINE LEARNING (95%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DIGITAL CURRENCY (90%); INVESTIGATIONS (90%); JOURNALISM (90%); REGULATORY COMPLIANCE (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); CRYPTOCURRENCY (89%); FINANCIAL TECHNOLOGY (89%); RESEARCH REPORTS (89%); WRITERS (89%); NEWS REPORTING (78%); CASE STUDIES (77%); NOVELS & SHORT STORIES (77%); EMERGING TECHNOLOGY (74%); EXPERIMENTATION & RESEARCH (72%); NEGATIVE BUSINESS NEWS (72%); INSIDER TRADING (71%); Artificial Intelligence;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CRYPTO ASSETS (90%); DIGITAL CURRENCY (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); CRYPTOCURRENCY (89%); FINANCIAL TECHNOLOGY (89%); WRITERS (89%); NEWS REPORTING (78%); PUBLISHING (78%); DIGITAL ASSETS (76%); INSIDER TRADING (71%)
Geographic: PENSACOLA, FL, USA (88%); FLORIDA, USA (94%); CENTRAL AMERICA (79%)
Load-Date: July 25, 2023","2023 JUL 25 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news reporting originating from Pensacola, Florida, by NewsRx correspondents, research stated, ""The rise in artificial intelligence (AI) and machine learning (ML) in cryptocurrency trading has precipitated complex ethical considerations, demanding a thorough exploration of responsible regulatory approaches."" 
 The news correspondents obtained a quote from the research from University of West Florida: ""This research expands upon this need by employing a consequentialist theoretical framework, emphasizing the outcomes of AI and ML's deployment within the sector and its effects on stakeholders. Drawing on critical case studies, such as SBF and FTX, and conducting an extensive review of relevant literature, this study explores the ethical implications of AI and ML in the context of cryptocurrency trading. It investigates the necessity for novel regulatory methods that address the unique characteristics of digital assets alongside existing legalities, such as those about fraud and insider trading."" 
 According to the news reporters, the research concluded: ""The author proposes a typology framework for AI and ML trading by comparing consequentialism to other ethical theories applicable to AI and ML use in cryptocurrency trading. By applying a consequentialist lens, this study underscores the significance of balancing AI and ML's transformative potential with ethical considerations to ensure market integrity, investor protection, and overall well-being in cryptocurrency trading."" 
 For more information on this research see: Developing an Ethical Framework for Responsible Artificial Intelligence (AI) and Machine Learning (ML) Applications in Cryptocurrency Trading: A Consequentialism Ethics Analysis. FinTech, 2023,2(3). The publisher for FinTech is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/fintech2030024. 
 Our news editors report that more information may be obtained by contacting Haris Alibašic, Public Administration Program, University of West Florida, 11000 University Pkwy, Pensacola, FL 32514, United States.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Haris Alibašic (orcid.org/0000-0001-8721-0411). 
 Keywords for this news article include: University of West Florida, Pensacola, Florida, United States, North and Central America, Artificial Intelligence, Cyborgs, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: MACHINE LEARNING (95%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DIGITAL CURRENCY (90%); INVESTIGATIONS (90%); JOURNALISM (90%); REGULATORY COMPLIANCE (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); CRYPTOCURRENCY (89%); FINANCIAL TECHNOLOGY (89%); RESEARCH REPORTS (89%); WRITERS (89%); NEWS REPORTING (78%); CASE STUDIES (77%); NOVELS & SHORT STORIES (77%); EMERGING TECHNOLOGY (74%); EXPERIMENTATION & RESEARCH (72%); NEGATIVE BUSINESS NEWS (72%); INSIDER TRADING (71%); Artificial Intelligence;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (95%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); CRYPTO ASSETS (90%); DIGITAL CURRENCY (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); CRYPTOCURRENCY (89%); FINANCIAL TECHNOLOGY (89%); WRITERS (89%); NEWS REPORTING (78%); PUBLISHING (78%); DIGITAL ASSETS (76%); INSIDER TRADING (71%)
Geographic: PENSACOLA, FL, USA (88%); FLORIDA, USA (94%); CENTRAL AMERICA (79%)
Load-Date: July 25, 2023",neutral,0.9343457818031311,balanced/neutral,[],"['consequentialism', 'consequentialist']","['framework', 'compliance']","['machine learning', 'robotics']",0,2,2,2
2023,Unknown Title,"Body
(GlobeNewswire) - Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
AI continues to change the way we work every day, and with rapid innovations and shifts in these technologies it is imperative that those developing AI technologies are dedicated to safety, transparency, and accountability. Our commitment to our customers to deliver solutions that help them harness the full power of the internet and understand and analyze billions of new conversations happening every day also means we have a commitment to responsibly develop our technologies in ways that benefit society as a whole and keep safety, privacy, and security at the forefront, said Aditya Jami, CTO of Meltwater.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
The Meltwater Ethical AI principles are: Benefit society whenever opportunities arise in inclusive and sustainable ways.
Bias and drifts are defects. They fail the business and our customers.
Safety, privacy, and security as first-class citizens.
Trace everything and be accountable. Transparency is key.
We are scientists and engineers; everything must be proven and tested.
Use open source whenever possible; vet everything else and assume it is unsafe.
In addition to launching these principles, Meltwater has taken concrete steps to strengthen its commitment to ethical AI practices: Establishing a Scientific Advisory Board (SAB), with industry leaders in AI and machine learning who support the company in setting its AI strategy
Adhering to the PR Councils guidance for Generative AI that was introduced in April 2023
Adhering to the WFA GARM's Brand Safety Floor & Suitability Framework by providing multiple AI models to detect harmful, abusive, and unsafe content in text, audio, images, and videos, including misinformation use cases through Meltwaters partnership with Newsguard
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
To learn more about Meltwater's AI ethical principles, visit meltwater.com/
For more information, please contact:
Kelly Costello
Corporate Communications Director
kelly.costello@meltwater.com 
About Meltwater
Meltwater empowers companies with a suite of solutions that spans media, social, consumer and sales intelligence. By analyzing ~1 billion pieces of content each day and transforming them into vital insights, Meltwater unlocks the competitive edge to drive results. With 27,000 global customers, 50 offices across six continents and 2,300 employees, Meltwater is the industry partner of choice for global brands making an impact. Learn more at meltwater.com.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1847
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SAFETY (90%); SOCIAL MEDIA (90%); MACHINE LEARNING (89%); SAFETY, ACCIDENTS & DISASTERS (89%); ABUSE & NEGLECT (78%); DATA SCIENCE (78%); EMERGING TECHNOLOGY (78%); NEGATIVE NEWS (78%); RESEARCH & DEVELOPMENT (78%); ASSOCIATIONS & ORGANIZATIONS (77%); ECONOMIC DEVELOPMENT (77%); GENERATIVE AI (73%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); DISINFORMATION & MISINFORMATION (62%); SUSTAINABILITY (62%)
Company:  GOOGLE LLC (58%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MARKET RESEARCH (90%); NEW PRODUCTS (90%); SOCIAL MEDIA (90%); INFORMATION SECURITY & PRIVACY (89%); MACHINE LEARNING (89%); PUBLIC RELATIONS (89%); DATA SCIENCE (78%); MARKETING & ADVERTISING (74%); GENERATIVE AI (73%); INTERNET & WWW (72%)
Load-Date: September 22, 2023","(GlobeNewswire) - Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
AI continues to change the way we work every day, and with rapid innovations and shifts in these technologies it is imperative that those developing AI technologies are dedicated to safety, transparency, and accountability. Our commitment to our customers to deliver solutions that help them harness the full power of the internet and understand and analyze billions of new conversations happening every day also means we have a commitment to responsibly develop our technologies in ways that benefit society as a whole and keep safety, privacy, and security at the forefront, said Aditya Jami, CTO of Meltwater.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
The Meltwater Ethical AI principles are: Benefit society whenever opportunities arise in inclusive and sustainable ways.
Bias and drifts are defects. They fail the business and our customers.
Safety, privacy, and security as first-class citizens.
Trace everything and be accountable. Transparency is key.
We are scientists and engineers; everything must be proven and tested.
Use open source whenever possible; vet everything else and assume it is unsafe.
In addition to launching these principles, Meltwater has taken concrete steps to strengthen its commitment to ethical AI practices: Establishing a Scientific Advisory Board (SAB), with industry leaders in AI and machine learning who support the company in setting its AI strategy
Adhering to the PR Councils guidance for Generative AI that was introduced in April 2023
Adhering to the WFA GARM's Brand Safety Floor & Suitability Framework by providing multiple AI models to detect harmful, abusive, and unsafe content in text, audio, images, and videos, including misinformation use cases through Meltwaters partnership with Newsguard
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
To learn more about Meltwater's AI ethical principles, visit meltwater.com/
For more information, please contact:
Kelly Costello
Corporate Communications Director
kelly.costello@meltwater.com 
About Meltwater
Meltwater empowers companies with a suite of solutions that spans media, social, consumer and sales intelligence. By analyzing ~1 billion pieces of content each day and transforming them into vital insights, Meltwater unlocks the competitive edge to drive results. With 27,000 global customers, 50 offices across six continents and 2,300 employees, Meltwater is the industry partner of choice for global brands making an impact. Learn more at meltwater.com.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1847
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); SAFETY (90%); SOCIAL MEDIA (90%); MACHINE LEARNING (89%); SAFETY, ACCIDENTS & DISASTERS (89%); ABUSE & NEGLECT (78%); DATA SCIENCE (78%); EMERGING TECHNOLOGY (78%); NEGATIVE NEWS (78%); RESEARCH & DEVELOPMENT (78%); ASSOCIATIONS & ORGANIZATIONS (77%); ECONOMIC DEVELOPMENT (77%); GENERATIVE AI (73%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); DISINFORMATION & MISINFORMATION (62%); SUSTAINABILITY (62%)
Company:  GOOGLE LLC (58%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (58%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MARKET RESEARCH (90%); NEW PRODUCTS (90%); SOCIAL MEDIA (90%); INFORMATION SECURITY & PRIVACY (89%); MACHINE LEARNING (89%); PUBLIC RELATIONS (89%); DATA SCIENCE (78%); MARKETING & ADVERTISING (74%); GENERATIVE AI (73%); INTERNET & WWW (72%)
Load-Date: September 22, 2023",positive,0.5501378774642944,balanced/neutral,"['privacy', 'bias', 'transparency', 'accountability', 'safety', 'security', 'misinformation', 'disinformation']",[],"['guidelines', 'framework', 'must']","['machine learning', 'generative ai']",8,0,3,2
2023,Unknown Title,"Byline: Hillary
Body
November 13th, 2023 ( TechBullion  — Delivered by  Newstex )
In an age dominated by technological advancements, the intertwining issues of tech, privacy, and ethics have become increasingly prominent. As our lives become more interconnected with digital tools and platforms, the need to navigate this changing landscape with a keen eye on privacy and ethical considerations becomes paramount.
Introduction
The Digital Evolution
Over the past few decades, technology has evolved at an unprecedented pace, reshaping the way we live, work, and interact. With the rise of smartphones, smart homes, and the Internet of Things (IoT),  our daily activities have become intricately connected to the digital realm. However, this digital evolution has brought forth concerns about privacy invasion and ethical implications.
Privacy in the Digital Age
As we embrace the convenience and efficiency offered by technology, the question of personal privacy looms large. Smart devices, from voice-activated assistants to fitness trackers, gather vast amounts of personal data. This data, often used to enhance user experience, raises concerns about how it is stored, shared, and, most importantly, protected.
Shortening the gap between individuals and technology necessitates a critical examination of the data collection practices employed by tech companies. Striking a balance between personalization and privacy becomes a central challenge, prompting users to question the ethical implications of their digital interactions.
Ethical Considerations in Tech
The rapid pace of technological innovation often outstrips the development of ethical frameworks to govern its use. This gap leads to ethical dilemmas in areas such as artificial intelligence (AI),  biotechnology, and data management.
In the realm of AI, questions surrounding bias and fairness arise as algorithms make decisions that impact individuals' lives. Transparent and ethical AI development is crucial to ensure that these systems do not perpetuate societal biases.
Biotechnology, with breakthroughs like gene editing, presents ethical challenges related to the manipulation of life itself. Striking a balance between scientific progress and ethical boundaries is imperative to prevent unintended consequences.
The ethical responsibility extends to how companies handle user data. Instances of data breaches and misuse underscore the importance of robust data protection measures and ethical data practices.
Navigating the Crossroads: Tech, Privacy, and Ethics
The intersection of technology, privacy, and ethics requires a thoughtful approach to navigate the challenges posed by this dynamic landscape.
User Empowerment
Empowering users with control over their data is a fundamental step in addressing privacy concerns. Tech companies must prioritize transparency, providing users with clear information on how their data is collected, used, and shared.
Ethical Tech Development
Innovation must be coupled with a commitment to ethical tech development. This involves incorporating ethical considerations from the early stages of product design and ensuring that technology aligns with societal values.
Regulatory Frameworks
The development and enforcement of robust regulatory frameworks are pivotal in safeguarding privacy and upholding ethical standards. Governments and international bodies play a crucial role in setting guidelines that tech companies must adhere to, fostering accountability and responsibility.
Public Awareness and Education
Raising public awareness about digital privacy and ethical tech use is paramount. Education initiatives can empower individuals to make informed decisions about the technology they use and encourage a collective demand for ethical practices.
The Future Landscape
As we navigate the intricate web of tech, privacy, and ethics, it becomes evident that the future digital landscape hinges on responsible innovation and user-centric approaches.
Responsible Innovation
The tech industry must embrace responsible innovation that prioritizes ethical considerations. This involves anticipating the societal impact of new technologies and proactively addressing potential challenges before they arise.
User-Centric Design
Designing technology  with the user in mind fosters a sense of trust and ensures that privacy considerations are at the forefront. User-centric design puts control back into the hands of individuals, allowing them to navigate the digital landscape with confidence.
Continuous Dialogue
A continuous dialogue between tech developers, policymakers, ethicists, and the public is essential. This open conversation allows for the identification of emerging issues, the development of ethical standards, and the establishment of a collaborative approach to addressing challenges.
Conclusion
In conclusion, as we stand at the crossroads of tech, privacy, and ethics, the path forward requires a delicate balance. Navigating the changing digital landscape demands a collective effort to prioritize privacy, uphold ethical standards, and ensure that technology serves as a force for positive transformation in our lives. By fostering responsible innovation, user empowerment, and ongoing dialogue, we can shape a digital future that aligns with our values and respects the ethical principles that underpin a connected world.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (95%); PRIVACY RIGHTS (90%); ARTIFICIAL INTELLIGENCE (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); EMERGING TECHNOLOGY (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); CREDIT REGULATION (78%); INTELLIGENT PERSONAL ASSISTANTS (78%); INVASION OF PRIVACY (78%); NEGATIVE BUSINESS NEWS (78%); USER EXPERIENCE (75%); NEGATIVE TECHNOLOGY NEWS (74%); VOICE RECOGNITION (74%); ACTIVITY & HEALTH TRACKING (73%); GENE EDITING (73%); GENETIC ENGINEERING (73%); PRODUCT INNOVATION (70%); VOICE COMMAND DEVICES (70%); CUSTOMER EXPERIENCE (67%); DATA BREACHES (67%); Technology (%); artificial intelligence (AI) (%); Biotechnology (%); internet of things (iot) (%)
Industry: ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); INFORMATION TECHNOLOGY INDUSTRY (89%); PHARMACEUTICALS & BIOTECHNOLOGY (89%); DATA SECURITY (88%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); INTERNET OF THINGS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); CREDIT REGULATION (78%); INTELLIGENT PERSONAL ASSISTANTS (78%); ONLINE SECURITY & PRIVACY (78%); SMART HOMES (74%); VOICE RECOGNITION (74%); VOICE COMMAND DEVICES (70%); DATA BREACHES (67%); MOBILE & CELLULAR TELEPHONES (55%)
Load-Date: November 13, 2023","November 13th, 2023 ( TechBullion  — Delivered by  Newstex )
In an age dominated by technological advancements, the intertwining issues of tech, privacy, and ethics have become increasingly prominent. As our lives become more interconnected with digital tools and platforms, the need to navigate this changing landscape with a keen eye on privacy and ethical considerations becomes paramount.
Introduction
The Digital Evolution
Over the past few decades, technology has evolved at an unprecedented pace, reshaping the way we live, work, and interact. With the rise of smartphones, smart homes, and the Internet of Things (IoT),  our daily activities have become intricately connected to the digital realm. However, this digital evolution has brought forth concerns about privacy invasion and ethical implications.
Privacy in the Digital Age
As we embrace the convenience and efficiency offered by technology, the question of personal privacy looms large. Smart devices, from voice-activated assistants to fitness trackers, gather vast amounts of personal data. This data, often used to enhance user experience, raises concerns about how it is stored, shared, and, most importantly, protected.
Shortening the gap between individuals and technology necessitates a critical examination of the data collection practices employed by tech companies. Striking a balance between personalization and privacy becomes a central challenge, prompting users to question the ethical implications of their digital interactions.
Ethical Considerations in Tech
The rapid pace of technological innovation often outstrips the development of ethical frameworks to govern its use. This gap leads to ethical dilemmas in areas such as artificial intelligence (AI),  biotechnology, and data management.
In the realm of AI, questions surrounding bias and fairness arise as algorithms make decisions that impact individuals' lives. Transparent and ethical AI development is crucial to ensure that these systems do not perpetuate societal biases.
Biotechnology, with breakthroughs like gene editing, presents ethical challenges related to the manipulation of life itself. Striking a balance between scientific progress and ethical boundaries is imperative to prevent unintended consequences.
The ethical responsibility extends to how companies handle user data. Instances of data breaches and misuse underscore the importance of robust data protection measures and ethical data practices.
Navigating the Crossroads: Tech, Privacy, and Ethics
The intersection of technology, privacy, and ethics requires a thoughtful approach to navigate the challenges posed by this dynamic landscape.
User Empowerment
Empowering users with control over their data is a fundamental step in addressing privacy concerns. Tech companies must prioritize transparency, providing users with clear information on how their data is collected, used, and shared.
Ethical Tech Development
Innovation must be coupled with a commitment to ethical tech development. This involves incorporating ethical considerations from the early stages of product design and ensuring that technology aligns with societal values.
Regulatory Frameworks
The development and enforcement of robust regulatory frameworks are pivotal in safeguarding privacy and upholding ethical standards. Governments and international bodies play a crucial role in setting guidelines that tech companies must adhere to, fostering accountability and responsibility.
Public Awareness and Education
Raising public awareness about digital privacy and ethical tech use is paramount. Education initiatives can empower individuals to make informed decisions about the technology they use and encourage a collective demand for ethical practices.
The Future Landscape
As we navigate the intricate web of tech, privacy, and ethics, it becomes evident that the future digital landscape hinges on responsible innovation and user-centric approaches.
Responsible Innovation
The tech industry must embrace responsible innovation that prioritizes ethical considerations. This involves anticipating the societal impact of new technologies and proactively addressing potential challenges before they arise.
User-Centric Design
Designing technology  with the user in mind fosters a sense of trust and ensures that privacy considerations are at the forefront. User-centric design puts control back into the hands of individuals, allowing them to navigate the digital landscape with confidence.
Continuous Dialogue
A continuous dialogue between tech developers, policymakers, ethicists, and the public is essential. This open conversation allows for the identification of emerging issues, the development of ethical standards, and the establishment of a collaborative approach to addressing challenges.
Conclusion
In conclusion, as we stand at the crossroads of tech, privacy, and ethics, the path forward requires a delicate balance. Navigating the changing digital landscape demands a collective effort to prioritize privacy, uphold ethical standards, and ensure that technology serves as a force for positive transformation in our lives. By fostering responsible innovation, user empowerment, and ongoing dialogue, we can shape a digital future that aligns with our values and respects the ethical principles that underpin a connected world.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (95%); PRIVACY RIGHTS (90%); ARTIFICIAL INTELLIGENCE (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); EMERGING TECHNOLOGY (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); CREDIT REGULATION (78%); INTELLIGENT PERSONAL ASSISTANTS (78%); INVASION OF PRIVACY (78%); NEGATIVE BUSINESS NEWS (78%); USER EXPERIENCE (75%); NEGATIVE TECHNOLOGY NEWS (74%); VOICE RECOGNITION (74%); ACTIVITY & HEALTH TRACKING (73%); GENE EDITING (73%); GENETIC ENGINEERING (73%); PRODUCT INNOVATION (70%); VOICE COMMAND DEVICES (70%); CUSTOMER EXPERIENCE (67%); DATA BREACHES (67%); Technology (%); artificial intelligence (AI) (%); Biotechnology (%); internet of things (iot) (%)
Industry: ARTIFICIAL INTELLIGENCE (89%); INFORMATION SECURITY & PRIVACY (89%); INFORMATION TECHNOLOGY INDUSTRY (89%); PHARMACEUTICALS & BIOTECHNOLOGY (89%); DATA SECURITY (88%); INFORMATION MANAGEMENT & TECHNOLOGY (79%); INTERNET OF THINGS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); CREDIT REGULATION (78%); INTELLIGENT PERSONAL ASSISTANTS (78%); ONLINE SECURITY & PRIVACY (78%); SMART HOMES (74%); VOICE RECOGNITION (74%); VOICE COMMAND DEVICES (70%); DATA BREACHES (67%); MOBILE & CELLULAR TELEPHONES (55%)
Load-Date: November 13, 2023",neutral,0.7180442810058594,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'security', 'manipulation']",['fairness'],"['regulation', 'standards', 'guidelines', 'should', 'must', 'need to']",[],7,1,6,0
2023,Unknown Title,"Dateline: New Delhi, 2023-10-04 16:35:55 
Body
 October 04 -- Chief Information Officers (CIOs) serve as the masterminds behind an organization's technological roadmap. In an era where technology significantly influences the direction of businesses and industries, the role of the CIO has never been more pivotal. As technology visionaries, CIOs bear the weighty responsibility of guiding the integration of AI within their organizations. The world has observed the incredible journey of AI, from its early stages to its current state of advanced capabilities. Let's delve deeply into the concept of human-centered AI and emphasize the critical significance of embedding ethics and accountability at the heart of AI systems.
AI has revolutionised industries, driven innovation, and streamlined operations. However, with great power comes great responsibility. The rapid advancements in AI have raised ethical questions and concerns that cannot be ignored.
Why Does Human-Centred AI Matter?
In the relentless pursuit of technological excellence, technology leaders must never lose sight of their shared responsibility to ensure that AI remains a force for good. Human-centred AI is the guiding principle that places people at the centre of AI development and deployment. It emphasises transparency, fairness, accountability, and privacy. The four core blocks of ethics for human-centred AI are as follows:
Transparency
Transparency in AI means opening the black box and making AI algorithms understandable and interpretable. It is essential to be able to explain how AI systems arrive at their decisions, especially when those decisions impact individuals' lives. Transparent AI fosters trust, a cornerstone of successful AI integration.
Fairness
AI must be designed to be unbiased and equitable. Unintentional bias in AI systems can lead to unfair treatment of certain groups, reinforcing existing disparities. Leaders must proactively address and rectify biases in AI models to ensure fairness and inclusivity.
Accountability
Accountability in AI systems is a must. It involves setting up clear lines of responsibility, understanding the consequences of AI decisions, and being ready to rectify any harm caused by AI errors or oversights.
Privacy
Respecting individuals' privacy is non-negotiable. AI systems must be developed with robust data protection mechanisms, and data usage should always adhere to the highest ethical standards and legal requirements.
The Way Forward
To ensure that organisations harness the power of AI while upholding ethical principles, technology leaders must take deliberate actions such as:
Leadership Commitment: Foster a culture of ethical AI from the top down. Ensure that AI ethics are a fundamental part of the organisation's strategy.
Ethical AI Frameworks: Develop and implement ethical AI frameworks that guide AI development, deployment, and monitoring.
Diverse Teams: Build diverse and multi-disciplinary teams to assess, mitigate bias, and consider ethical implications in AI projects.
Continuous Monitoring: Regularly monitor AI systems for unintended consequences and iterate on them to improve fairness, transparency, and accountability.
The Future of Human-Centred AI
The future of AI lies in our hands. Embracing human-centred AI isn't just a matter of compliance; it is a testament to our commitment to society, our customers, and our employees. As we move forward, we can expect more stringent regulations and standards governing AI ethics globally.
In Conclusion
CIOs are the architects of an organisation's technological future. They must herald these initiatives, ensuring that AI remains a powerful tool for good. They must put ethics and responsibility at the core of AI systems, setting the standard for the technology-driven world we shape. It is time to embrace human-centred AI and ensure that it benefits all of humanity. Together, we can create a brighter, more responsible future where AI enhances lives without compromise.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (92%); EXECUTIVES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ASSOCIATIONS & ORGANIZATIONS (89%); UNCONSCIOUS BIAS (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (78%); DATA SECURITY (73%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: October 12, 2023","October 04 -- Chief Information Officers (CIOs) serve as the masterminds behind an organization's technological roadmap. In an era where technology significantly influences the direction of businesses and industries, the role of the CIO has never been more pivotal. As technology visionaries, CIOs bear the weighty responsibility of guiding the integration of AI within their organizations. The world has observed the incredible journey of AI, from its early stages to its current state of advanced capabilities. Let's delve deeply into the concept of human-centered AI and emphasize the critical significance of embedding ethics and accountability at the heart of AI systems.
AI has revolutionised industries, driven innovation, and streamlined operations. However, with great power comes great responsibility. The rapid advancements in AI have raised ethical questions and concerns that cannot be ignored.
Why Does Human-Centred AI Matter?
In the relentless pursuit of technological excellence, technology leaders must never lose sight of their shared responsibility to ensure that AI remains a force for good. Human-centred AI is the guiding principle that places people at the centre of AI development and deployment. It emphasises transparency, fairness, accountability, and privacy. The four core blocks of ethics for human-centred AI are as follows:
Transparency
Transparency in AI means opening the black box and making AI algorithms understandable and interpretable. It is essential to be able to explain how AI systems arrive at their decisions, especially when those decisions impact individuals' lives. Transparent AI fosters trust, a cornerstone of successful AI integration.
Fairness
AI must be designed to be unbiased and equitable. Unintentional bias in AI systems can lead to unfair treatment of certain groups, reinforcing existing disparities. Leaders must proactively address and rectify biases in AI models to ensure fairness and inclusivity.
Accountability
Accountability in AI systems is a must. It involves setting up clear lines of responsibility, understanding the consequences of AI decisions, and being ready to rectify any harm caused by AI errors or oversights.
Privacy
Respecting individuals' privacy is non-negotiable. AI systems must be developed with robust data protection mechanisms, and data usage should always adhere to the highest ethical standards and legal requirements.
The Way Forward
To ensure that organisations harness the power of AI while upholding ethical principles, technology leaders must take deliberate actions such as:
Leadership Commitment: Foster a culture of ethical AI from the top down. Ensure that AI ethics are a fundamental part of the organisation's strategy.
Ethical AI Frameworks: Develop and implement ethical AI frameworks that guide AI development, deployment, and monitoring.
Diverse Teams: Build diverse and multi-disciplinary teams to assess, mitigate bias, and consider ethical implications in AI projects.
Continuous Monitoring: Regularly monitor AI systems for unintended consequences and iterate on them to improve fairness, transparency, and accountability.
The Future of Human-Centred AI
The future of AI lies in our hands. Embracing human-centred AI isn't just a matter of compliance; it is a testament to our commitment to society, our customers, and our employees. As we move forward, we can expect more stringent regulations and standards governing AI ethics globally.
In Conclusion
CIOs are the architects of an organisation's technological future. They must herald these initiatives, ensuring that AI remains a powerful tool for good. They must put ethics and responsibility at the core of AI systems, setting the standard for the technology-driven world we shape. It is time to embrace human-centred AI and ensure that it benefits all of humanity. Together, we can create a brighter, more responsible future where AI enhances lives without compromise.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (92%); EXECUTIVES (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ASSOCIATIONS & ORGANIZATIONS (89%); UNCONSCIOUS BIAS (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); INFORMATION SECURITY & PRIVACY (78%); DATA SECURITY (73%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: October 12, 2023",positive,0.5014169812202454,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'accountability', 'security', 'inclusivity']",['fairness'],"['standards', 'compliance', 'should', 'must']",[],7,1,4,0
2023,Unknown Title,"Byline: JIANG CHENGLONG
Body
China has released a trial guideline on the review of science and technology ethics to ensure both high-quality development and high-level security in sci-tech innovation.
The guideline was jointly released by the ministries of science and technology, industry and information technology, and education, the National Health Commission and other departments with the aim of tackling problems such as unclear responsibilities, nonstandard procedures and imperfect mechanisms for ethical reviews in the sci-tech sector.
Activities involving human research participants, human biological samples and personal information data, as well as those related to experimental animals, must face ethical reviews, according to the guideline.
It delineated a major range of reviews with focusing on activities that may pose ethical risks and challenges in areas such as life and health, ecological environment, public order and sustainable development.
The guideline also stipulated entities responsible for managing sci-tech ethics review in higher education, research, medical and health institutions and enterprises.
A review committee is required to be established in institutions engaging in life sciences, medicine and artificial intelligence activities if the research subjects are ""ethically sensitive"".
The committee must conduct follow-up ethical reviews of the approved sci-tech activities and make decisions to suspend or terminate such activities if necessary, the guideline said, adding that the interval between follow-up reviews must not exceed 12 months.
The guideline specified a range of activities that need to undergo a ""second ethics review"", targeting those activities that may pose ""relatively high"" ethical risks.
The list, which will be dynamically adjusted, has been released by the Ministry of Science and Technology. It covers basic research that alter the genetic material or genetic laws of human reproductive cells and fertilized eggs, and the development of algorithm models, applications and systems with the ability to ""mobilize public opinion and guide social consciousness"".
Zhai Xiaomei, a member of the National Science and Technology Ethics Committee, said the guideline provides a comprehensive and universally applicable bench mark for ethical review in different sci-tech activities.
It will help overcome problems previously encountered in ethical review work such as coordination difficulties and the lack of unified evaluation criteria, she said.
Zhai said that many emerging technological research and development projects currently have significant social value and are in line with the public interest, but they also pose certain risks.
""For example, in research involving the use of data and biological samples, there are risks related to protecting the privacy of sample providers and ensuring biosecurity,"" she added.
Zhai also said that people are increasingly concerned about the misuse of scientific achievements.
Public awareness of ethical risks increased after Chinese researcher He Jiankui claimed in 2018 that he had created the world's first gene-edited baby immune to HIV.
In 2019, He was sentenced to three years in prison and fined 3 million yuan ($412,000) for illegal practices including forging ethical approval documents and practicing medicine without a license.
jiangchenglong@chinadaily.com.cn
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (95%); GENETIC ENGINEERING (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); EDUCATION RESEARCH (78%); EMERGING TECHNOLOGY (78%); EXPERIMENTATION & RESEARCH (78%); LITIGATION (78%); PRISONS (78%); RESEARCH & DEVELOPMENT (78%); SENTENCING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); SUSTAINABLE DEVELOPMENT (78%); GOVERNMENT RESEARCH FUNDING (77%); HEALTH DEPARTMENTS (77%); MEDICINE & HEALTH (77%); TEACHING MATERIALS & MEDIA (77%); INTELLIGENCE SERVICES (73%); GOVERNMENT BODIES & OFFICES (72%); FINES & PENALTIES (71%); ANIMAL EXPERIMENTS (70%); PRIVACY RIGHTS (70%); GENE EDITING (68%); SUSTAINABILITY (68%); ARTIFICIAL INTELLIGENCE (67%); CRIMINAL FINES (60%); COLLEGES & UNIVERSITIES (53%); TOP NEWS (%)
Industry: INFORMATION TECHNOLOGY INDUSTRY (90%); SUSTAINABLE DEVELOPMENT (78%); HEALTH DEPARTMENTS (77%); ARTIFICIAL INTELLIGENCE (67%); COLLEGES & UNIVERSITIES (53%)
Geographic: CHINA (94%)
Load-Date: October 9, 2023","China has released a trial guideline on the review of science and technology ethics to ensure both high-quality development and high-level security in sci-tech innovation.
The guideline was jointly released by the ministries of science and technology, industry and information technology, and education, the National Health Commission and other departments with the aim of tackling problems such as unclear responsibilities, nonstandard procedures and imperfect mechanisms for ethical reviews in the sci-tech sector.
Activities involving human research participants, human biological samples and personal information data, as well as those related to experimental animals, must face ethical reviews, according to the guideline.
It delineated a major range of reviews with focusing on activities that may pose ethical risks and challenges in areas such as life and health, ecological environment, public order and sustainable development.
The guideline also stipulated entities responsible for managing sci-tech ethics review in higher education, research, medical and health institutions and enterprises.
A review committee is required to be established in institutions engaging in life sciences, medicine and artificial intelligence activities if the research subjects are ""ethically sensitive"".
The committee must conduct follow-up ethical reviews of the approved sci-tech activities and make decisions to suspend or terminate such activities if necessary, the guideline said, adding that the interval between follow-up reviews must not exceed 12 months.
The guideline specified a range of activities that need to undergo a ""second ethics review"", targeting those activities that may pose ""relatively high"" ethical risks.
The list, which will be dynamically adjusted, has been released by the Ministry of Science and Technology. It covers basic research that alter the genetic material or genetic laws of human reproductive cells and fertilized eggs, and the development of algorithm models, applications and systems with the ability to ""mobilize public opinion and guide social consciousness"".
Zhai Xiaomei, a member of the National Science and Technology Ethics Committee, said the guideline provides a comprehensive and universally applicable bench mark for ethical review in different sci-tech activities.
It will help overcome problems previously encountered in ethical review work such as coordination difficulties and the lack of unified evaluation criteria, she said.
Zhai said that many emerging technological research and development projects currently have significant social value and are in line with the public interest, but they also pose certain risks.
""For example, in research involving the use of data and biological samples, there are risks related to protecting the privacy of sample providers and ensuring biosecurity,"" she added.
Zhai also said that people are increasingly concerned about the misuse of scientific achievements.
Public awareness of ethical risks increased after Chinese researcher He Jiankui claimed in 2018 that he had created the world's first gene-edited baby immune to HIV.
In 2019, He was sentenced to three years in prison and fined 3 million yuan ($412,000) for illegal practices including forging ethical approval documents and practicing medicine without a license.
jiangchenglong@chinadaily.com.cn
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (95%); GENETIC ENGINEERING (89%); GOVERNMENT DEPARTMENTS & AUTHORITIES (89%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); EDUCATION RESEARCH (78%); EMERGING TECHNOLOGY (78%); EXPERIMENTATION & RESEARCH (78%); LITIGATION (78%); PRISONS (78%); RESEARCH & DEVELOPMENT (78%); SENTENCING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); SUSTAINABLE DEVELOPMENT (78%); GOVERNMENT RESEARCH FUNDING (77%); HEALTH DEPARTMENTS (77%); MEDICINE & HEALTH (77%); TEACHING MATERIALS & MEDIA (77%); INTELLIGENCE SERVICES (73%); GOVERNMENT BODIES & OFFICES (72%); FINES & PENALTIES (71%); ANIMAL EXPERIMENTS (70%); PRIVACY RIGHTS (70%); GENE EDITING (68%); SUSTAINABILITY (68%); ARTIFICIAL INTELLIGENCE (67%); CRIMINAL FINES (60%); COLLEGES & UNIVERSITIES (53%); TOP NEWS (%)
Industry: INFORMATION TECHNOLOGY INDUSTRY (90%); SUSTAINABLE DEVELOPMENT (78%); HEALTH DEPARTMENTS (77%); ARTIFICIAL INTELLIGENCE (67%); COLLEGES & UNIVERSITIES (53%)
Geographic: CHINA (94%)
Load-Date: October 9, 2023",neutral,0.8037382364273071,balanced/neutral,"['privacy', 'security']",[],"['must', 'need to']",['algorithm'],2,0,2,1
2023,Unknown Title,"Body
 Link to Image 
The rush to implement powerful new generative Artificial Intelligence (AI) technologies has raised alarms about potential harm and misuse, and companies are expected to develop technologies in an ethical manner.
But what exactly does that mean? The straightforward answer would be to align a company's operations with one or more of the dozens of sets of ethical AI principles that governments, multi-stakeholder groups and academics have produced. But that's easier said than done.
You may be interested in: Generative AI will make us rethink the idea of authenticity
We and our colleagues spent two years interviewing and surveying AI ethics practitioners in a variety of sectors to try to understand how they sought to achieve ethical AI, and what they might be missing.
We learned that pursuing AI ethics in the field is less about mapping ethical principles onto corporate actions than it is about implementing management structures and processes that enable an organization to detect and mitigate threats.
This is likely to be disappointing news for organizations looking for unambiguous guidance that avoids gray areas and for consumers who expect clear and protective standards. But it points to a better understanding of how companies can pursue ethical AI.
  World  
Dealing with uncertainties
Our study, which is the basis for a forthcoming book, focused on those responsible for managing AI ethics issues at major companies that use AI. From late 2017 to early 2019, we interviewed 23 of these managers. Their titles ranged from privacy officer and privacy advisor to one that was new at the time, but increasingly common today: data ethics officer. Our conversations with these AI ethics managers yielded four main conclusions.
First, in addition to its many benefits, the commercial use of AI presents substantial risks, and companies know it. AI ethics managers expressed concerns about privacy, manipulation, bias, opacity, inequality, and labor displacement. In one well-known example, Amazon developed an AI tool to sort resumes and trained it to find candidates similar to those it had hired in the past.
Commercial use of AI presents substantial risks, and companies know it
Male dominance in the tech industry meant that most of Amazon's employees were men. As a result, the tool learned to reject female candidates. Unable to fix the problem, Amazon eventually had to scrap the project.
Second, companies that pursue ethical AI do so largely for strategic reasons. They want to maintain trust among customers, business partners and employees. And they want to stay ahead of or prepare for emerging regulations.
Companies pursuing ethical AI do so largely for strategic reasons.
The Facebook-Cambridge Analytica scandal, in which Cambridge Analytica used Facebook user data, shared without consent, to infer users' psychological types and target them with manipulative political ads, showed that unethical use of advanced analytics can destroy a company's reputation or even, as in the case of Cambridge Analytica itself, bring it down.
The challenge facing AI ethics managers was to figure out how best to achieve ""ethical AI."" They first examined the ethical principles of AI, particularly those rooted in bioethics or human rights principles, but found them wanting.
 Justice, fairness, beneficence, autonomy, and other such principles are contested and subject to interpretation and may conflict with each other
It was not simply that there were many competing sets of principles. It was that justice, fairness, beneficence, autonomy, and similar principles are contested and subject to interpretation and may conflict with each other.
This led to our third conclusion: managers needed more than high-level AI principles to decide what to do in specific situations.
 Managers needed more than high-level AI principles to decide what to do in specific situations.
Fourth, practitioners faced with ethical uncertainties relied on organizational structures and procedures to arrive at judgments about what to do. Some of these were clearly inadequate. But others, although still largely in development, were more useful, such as:
?? Subscribe to our newsletter and receive the most relevant notes on the latest developments.
Hiring an AI ethics officer to build and oversee the program; establishing an internal AI ethics committee to weigh and decide difficult issues; developing data ethics checklists and requiring front-line data scientists to complete them; and reaching out to academics, former regulators and advocates of alternative perspectives.
For the time being, and in the absence of explicit legal requirements, companies, like individuals, can only do their best to be aware of how AI affects people and the environment and keep abreast of public concerns and the latest research and ideas from experts.
* Professor of Computer Science and Philosophy, Ohio State University.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); MANAGERS & SUPERVISORS (90%); COMPANY ACTIVITIES & MANAGEMENT (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); DATA ANALYTICS (78%); NEGATIVE BUSINESS NEWS (78%); ASSOCIATIONS & ORGANIZATIONS (76%); PSYCHOLOGY (73%); CORPORATE ACTIONS (71%); POLITICAL ADVERTISING (67%); CONSUMERS (66%); NEGATIVE MISC NEWS (62%); Tecnología (%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); DATA ANALYTICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); PSYCHOLOGY (73%); POLITICAL ADVERTISING (67%)
Load-Date: May 30, 2023","Link to Image 
The rush to implement powerful new generative Artificial Intelligence (AI) technologies has raised alarms about potential harm and misuse, and companies are expected to develop technologies in an ethical manner.
But what exactly does that mean? The straightforward answer would be to align a company's operations with one or more of the dozens of sets of ethical AI principles that governments, multi-stakeholder groups and academics have produced. But that's easier said than done.
You may be interested in: Generative AI will make us rethink the idea of authenticity
We and our colleagues spent two years interviewing and surveying AI ethics practitioners in a variety of sectors to try to understand how they sought to achieve ethical AI, and what they might be missing.
We learned that pursuing AI ethics in the field is less about mapping ethical principles onto corporate actions than it is about implementing management structures and processes that enable an organization to detect and mitigate threats.
This is likely to be disappointing news for organizations looking for unambiguous guidance that avoids gray areas and for consumers who expect clear and protective standards. But it points to a better understanding of how companies can pursue ethical AI.
  World  
Dealing with uncertainties
Our study, which is the basis for a forthcoming book, focused on those responsible for managing AI ethics issues at major companies that use AI. From late 2017 to early 2019, we interviewed 23 of these managers. Their titles ranged from privacy officer and privacy advisor to one that was new at the time, but increasingly common today: data ethics officer. Our conversations with these AI ethics managers yielded four main conclusions.
First, in addition to its many benefits, the commercial use of AI presents substantial risks, and companies know it. AI ethics managers expressed concerns about privacy, manipulation, bias, opacity, inequality, and labor displacement. In one well-known example, Amazon developed an AI tool to sort resumes and trained it to find candidates similar to those it had hired in the past.
Commercial use of AI presents substantial risks, and companies know it
Male dominance in the tech industry meant that most of Amazon's employees were men. As a result, the tool learned to reject female candidates. Unable to fix the problem, Amazon eventually had to scrap the project.
Second, companies that pursue ethical AI do so largely for strategic reasons. They want to maintain trust among customers, business partners and employees. And they want to stay ahead of or prepare for emerging regulations.
Companies pursuing ethical AI do so largely for strategic reasons.
The Facebook-Cambridge Analytica scandal, in which Cambridge Analytica used Facebook user data, shared without consent, to infer users' psychological types and target them with manipulative political ads, showed that unethical use of advanced analytics can destroy a company's reputation or even, as in the case of Cambridge Analytica itself, bring it down.
The challenge facing AI ethics managers was to figure out how best to achieve ""ethical AI."" They first examined the ethical principles of AI, particularly those rooted in bioethics or human rights principles, but found them wanting.
 Justice, fairness, beneficence, autonomy, and other such principles are contested and subject to interpretation and may conflict with each other
It was not simply that there were many competing sets of principles. It was that justice, fairness, beneficence, autonomy, and similar principles are contested and subject to interpretation and may conflict with each other.
This led to our third conclusion: managers needed more than high-level AI principles to decide what to do in specific situations.
 Managers needed more than high-level AI principles to decide what to do in specific situations.
Fourth, practitioners faced with ethical uncertainties relied on organizational structures and procedures to arrive at judgments about what to do. Some of these were clearly inadequate. But others, although still largely in development, were more useful, such as:
?? Subscribe to our newsletter and receive the most relevant notes on the latest developments.
Hiring an AI ethics officer to build and oversee the program; establishing an internal AI ethics committee to weigh and decide difficult issues; developing data ethics checklists and requiring front-line data scientists to complete them; and reaching out to academics, former regulators and advocates of alternative perspectives.
For the time being, and in the absence of explicit legal requirements, companies, like individuals, can only do their best to be aware of how AI affects people and the environment and keep abreast of public concerns and the latest research and ideas from experts.
* Professor of Computer Science and Philosophy, Ohio State University.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); MANAGERS & SUPERVISORS (90%); COMPANY ACTIVITIES & MANAGEMENT (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); DATA ANALYTICS (78%); NEGATIVE BUSINESS NEWS (78%); ASSOCIATIONS & ORGANIZATIONS (76%); PSYCHOLOGY (73%); CORPORATE ACTIONS (71%); POLITICAL ADVERTISING (67%); CONSUMERS (66%); NEGATIVE MISC NEWS (62%); Tecnología (%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); DATA ANALYTICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); PSYCHOLOGY (73%); POLITICAL ADVERTISING (67%)
Load-Date: May 30, 2023",neutral,0.698937714099884,balanced/neutral,"['privacy', 'bias', 'fairness', 'human rights', 'autonomy', 'consent', 'manipulation', 'inequality']","['justice', 'fairness', 'autonomy', 'beneficence', 'justice']",['standards'],['generative ai'],8,5,1,1
2023,Unknown Title,"Byline: Targeted News Service
Dateline: LONDON, England 
Body
The Journal of Medical Ethics, a peer-reviewed journal, published research articles on the following topics, in its December 2023 edition (Vol. 49, Issue 12):
Editorial:
* Equity needs to be (even) more central under the WHO Pandemic Agreement
Current controversy:
* Revisiting the comparison between healthcare strikes and just war
Clinical ethics:
* Teenager and the transplant: how the case of William Verden highlights action is needed to optimise equitable access to organs for patients with impaired decision-making
Feature article and commentaries:
* Is there a duty to routinely reinterpret genomic variant classifications?
* Downgrades: a potential source of moral tension
* Primary duty is to communicate moment-in-time nature of genetic variant interpretation
* Moral obligation to actively reinterpret VUS and the constraint of NGS technologies
* Promoting diagnostic equity: specifying genetic similarity rather than race or ethnicity
* Professionalism or prejudice? Modelling roles, risking microaggressions
* Reconsidering reinterpretation: response to commentaries
Original research:
* With great power comes great vulnerability: an ethical analysis of psychedelics' therapeutic mechanisms proposed by the REBUS hypothesis
* Harnessing legal structures of virtue for planetary health
* Machine learning models, trusted research environments and UK health data: ensuring a safe and beneficial future for AI development in healthcare
* Mapping out the arguments for and against patient non-attendance fees in healthcare: an analysis of public consultation documents
Response:
* Whose models? Which representations? A response to Wagner
* Abortion policies at the bedside: a response
The Vol. 49, Issue 12 edition of Journal of Medical Ethics can be viewed at https://jme.bmj.com/content/49/12. The journal is published by BMJ Publishing Group.
[Category: Medical]
MSTRUCK-8381214 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: EDITORIALS & OPINIONS (99%); ETHICS (93%); MEDICAL ETHICS (91%); HUMAN SUBJECTS (90%); PUBLIC HEALTH (90%); RESEARCH REPORTS (90%); AGREEMENTS (78%); BIOTECHNOLOGY & GENETIC SCIENCE (78%); GENES & CHROMOSOMES (78%); GENOMICS (78%); DISCRIMINATION (77%); HEALTH CARE INFORMATION (73%); RACE & ETHNICITY (72%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); ABORTION (50%); ABORTION REGULATION & POLICY (50%)
Industry: PERIODICAL PUBLISHING (89%); PUBLISHING (89%); HEALTH CARE INFORMATION (73%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); ABORTION REGULATION & POLICY (50%)
Geographic: LONDON, ENGLAND (59%); ENGLAND (59%); UNITED KINGDOM (59%)
Load-Date: November 24, 2023","The Journal of Medical Ethics, a peer-reviewed journal, published research articles on the following topics, in its December 2023 edition (Vol. 49, Issue 12):
Editorial:
* Equity needs to be (even) more central under the WHO Pandemic Agreement
Current controversy:
* Revisiting the comparison between healthcare strikes and just war
Clinical ethics:
* Teenager and the transplant: how the case of William Verden highlights action is needed to optimise equitable access to organs for patients with impaired decision-making
Feature article and commentaries:
* Is there a duty to routinely reinterpret genomic variant classifications?
* Downgrades: a potential source of moral tension
* Primary duty is to communicate moment-in-time nature of genetic variant interpretation
* Moral obligation to actively reinterpret VUS and the constraint of NGS technologies
* Promoting diagnostic equity: specifying genetic similarity rather than race or ethnicity
* Professionalism or prejudice? Modelling roles, risking microaggressions
* Reconsidering reinterpretation: response to commentaries
Original research:
* With great power comes great vulnerability: an ethical analysis of psychedelics' therapeutic mechanisms proposed by the REBUS hypothesis
* Harnessing legal structures of virtue for planetary health
* Machine learning models, trusted research environments and UK health data: ensuring a safe and beneficial future for AI development in healthcare
* Mapping out the arguments for and against patient non-attendance fees in healthcare: an analysis of public consultation documents
Response:
* Whose models? Which representations? A response to Wagner
* Abortion policies at the bedside: a response
The Vol. 49, Issue 12 edition of Journal of Medical Ethics can be viewed at https://jme.bmj.com/content/49/12. The journal is published by BMJ Publishing Group.
[Category: Medical]
MSTRUCK-8381214 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: EDITORIALS & OPINIONS (99%); ETHICS (93%); MEDICAL ETHICS (91%); HUMAN SUBJECTS (90%); PUBLIC HEALTH (90%); RESEARCH REPORTS (90%); AGREEMENTS (78%); BIOTECHNOLOGY & GENETIC SCIENCE (78%); GENES & CHROMOSOMES (78%); GENOMICS (78%); DISCRIMINATION (77%); HEALTH CARE INFORMATION (73%); RACE & ETHNICITY (72%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); ABORTION (50%); ABORTION REGULATION & POLICY (50%)
Industry: PERIODICAL PUBLISHING (89%); PUBLISHING (89%); HEALTH CARE INFORMATION (73%); ARTIFICIAL INTELLIGENCE (66%); MACHINE LEARNING (66%); ABORTION REGULATION & POLICY (50%)
Geographic: LONDON, ENGLAND (59%); ENGLAND (59%); UNITED KINGDOM (59%)
Load-Date: November 24, 2023",neutral,0.90813809633255,balanced/neutral,"['discrimination', 'access']",['equity'],"['regulation', 'policy']",['machine learning'],2,1,2,1
2023,Unknown Title,"Body
Link to Image
Link to Story
The rush to deploy powerful new generative AI technologies, such as ChatGPT, has raised alarms about potential harm and misuse . The law's glacial response to such threats has prompted demands that the companies developing these technologies implement AI""ethically."" But what, exactly, does that mean?
The straightforward answer would be to align a business's operations with one or more of the dozens of sets of ai ethics principles that governments, multistakeholder groups and academics have produced. But that is easier said than done.
We and our colleagues spent two years interviewing and surveying ai ethics professionals across a range of sectors to try to understand how they sought to achieve ethical AI - and what they might be missing. We learned that pursuing AI ethics on the ground is less about mapping ethical principles onto corporate actions than it is about implementing management structures and processes that enable an organization to spot and mitigate threats.
This is likely to be disappointing news for organizations looking for unambiguous guidance that avoids gray areas, and for consumers hoping for clear and protective standards. But it points to a better understanding of how companies can pursue ethical AI.
Grappling with ethical uncertaintiesour study , which is the basis for a forthcoming book , centered on those responsible for managing AI ethics issues at major companies that use AI. From late 2017 to early 2019, we interviewed 23 such managers. Their titles ranged from privacy officer and privacy counsel to one that was new at the time but increasingly common today: data ethics officer. Our conversations with these AI ethics managers produced four main takeaways.
First, along with its many benefits, business use of AI poses substantial risks, and the companies know it. AI ethics managers expressed concerns about privacy , manipulation , bias, opacity, inequality and labor displacement. In one well-known example, amazon developed an ai tool to sort résumés and trained it to find candidates similar to those it had hired in the past. Male dominance in the tech industry meant that most of Amazon's employees were men. The tool accordingly learned to reject female candidates. Unable to fix the problem, Amazon ultimately had to scrap the project.
Generative AI raises additional worries about misinformation and hate speech at large scale and misappropriation of intellectual property .
Second, companies that pursue ethical AI do so largely for strategic reasons. They want to sustain trust among customers, business partners and employees. And they want to preempt, or prepare for, emerging regulations. The facebook-cambridge analytica scandal , in which Cambridge Analytica used Facebook user data, shared without consent, to infer the users' psychological types and target them with manipulative political ads, showed that the unethical use of advanced analytics can eviscerate a company's reputation or even, as in the case of Cambridge Analytica itself, bring it down. The companies we spoke to wanted instead to be viewed as responsible stewards of people's data.
The challenge that AI ethics managers faced was figuring out how best to achieve""ethical AI."" They looked first to AI ethics principles, particularly those rooted in bioethics or human rights principles, but found them insufficient. It was not just that there are many competing sets of principles. It was that justice, fairness, beneficence, autonomy and other such principles are contested and subject to interpretation and can conflict with one another.
This led to our third takeaway: Managers needed more than high-level AI principles to decide what to do in specific situations. One AI ethics manager described trying to translate human rights principles into a set of questions that developers could ask themselves to produce more ethical AI software systems.""We stopped after 34 pages of questions,"" the manager said.
Fourth, professionals grappling with ethical uncertainties turned to organizational structures and procedures to arrive at judgments about what to do. Some of these were clearly inadequate. But others, while still largely in development, were more helpful, such as:
Hiring an AI ethics officer to build and oversee the program. Establishing an internal AI ethics committee to weigh and decide hard issues. Crafting data ethics checklists and requiring front-line data scientists to fill them out. Reaching out to academics, former regulators and advocates for alternative perspectives. Conducting algorithmic impact assessments of the type already in use in environmental and privacy governance.
Ethics as responsible decision-makingThe key idea that emerged from our study is this: Companies seeking to use AI ethically should not expect to discover a simple set of principles that delivers correct answers from an all-knowing, God's-eye perspective. Instead, they should focus on the very human task of trying to make responsible decisions in a world of finite understanding and changing circumstances, even if some decisions end up being imperfect.
In the absence of explicit legal requirements, companies, like individuals, can only do their best to make themselves aware of how AI affects people and the environment and to stay abreast of public concerns and the latest research and expert ideas. They can also seek input from a large and diverse set of stakeholders and seriously engage with high-level ethical principles.
This simple idea changes the conversation in important ways. It encourages AI ethics professionals to focus their energies less on identifying and applying AI principles - though they remain part of the story - and more on adopting decision-making structures and processes to ensure that they consider the impacts, viewpoints and public expectations that should inform their business decisions.
In testimony to a Senate committee in May 2023, OpenAI CEO Sam Altman called for stricter oversight, including licensing requirements, for companies that develop AI software. ap photo/patrick semansky Ultimately, we believe laws and regulations will need to provide substantive benchmarks for organizations to aim for. But the structures and processes of responsible decision-making are a place to start and should, over time, help to build the knowledge needed to craft protective and workable substantive legal standards.
Indeed, the emerging law and policy of AI focuses on process. new york city passed a law requiring companies to audit their AI systems for harmful bias before using these systems to make hiring decisions. Members of congress have introduced bills that would require businesses to conduct algorithmic impact assessments before using AI for lending, employment, insurance and other such consequential decisions. These laws emphasize processes that address in advance AI's many threats.
Some of the developers of generative AI have taken a very different approach. Sam Altman, the CEO of OpenAI, initially explained that, in releasing ChatGPT to the public, the company sought to give the chatbot""enough exposure to the real world that you find some of the misuse cases you wouldn't have thought of so that you can build better tools."" To us, that is not responsible AI. It is treating human beings as guinea pigs in a risky experiment.
Altman's call at a may 2023 senate hearing for government regulation of AI shows greater awareness of the problem. But we believe he goes too far in shifting to government the responsibilities that the developers of generative AI must also bear. Maintaining public trust, and avoiding harm to society, will require companies more fully to face up to their responsibilities.
MENAFN25052023000199003603ID1106315109
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); GENERATIVE AI (90%); MANAGERS & SUPERVISORS (90%); ARTIFICIAL INTELLIGENCE (89%); CHATBOTS (89%); CONVERSATIONAL AI (89%); NEGATIVE BUSINESS NEWS (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); INTELLECTUAL PROPERTY (78%); MISAPPROPRIATION (78%); NEGATIVE NEWS (78%); GOVERNMENT ETHICS (77%); ASSOCIATIONS & ORGANIZATIONS (75%); DATA ANALYTICS (73%); HATE SPEECH (73%); INTELLECTUAL PROPERTY CRIME (73%); CONSUMERS (72%); POLITICAL ADVERTISING (72%); DISINFORMATION & MISINFORMATION (67%); NEGATIVE MISC NEWS (62%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); CHATBOTS (89%); CONVERSATIONAL AI (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); DATA ANALYTICS (73%); POLITICAL ADVERTISING (72%)
Load-Date: August 5, 2023","Link to Image
Link to Story
The rush to deploy powerful new generative AI technologies, such as ChatGPT, has raised alarms about potential harm and misuse . The law's glacial response to such threats has prompted demands that the companies developing these technologies implement AI""ethically."" But what, exactly, does that mean?
The straightforward answer would be to align a business's operations with one or more of the dozens of sets of ai ethics principles that governments, multistakeholder groups and academics have produced. But that is easier said than done.
We and our colleagues spent two years interviewing and surveying ai ethics professionals across a range of sectors to try to understand how they sought to achieve ethical AI - and what they might be missing. We learned that pursuing AI ethics on the ground is less about mapping ethical principles onto corporate actions than it is about implementing management structures and processes that enable an organization to spot and mitigate threats.
This is likely to be disappointing news for organizations looking for unambiguous guidance that avoids gray areas, and for consumers hoping for clear and protective standards. But it points to a better understanding of how companies can pursue ethical AI.
Grappling with ethical uncertaintiesour study , which is the basis for a forthcoming book , centered on those responsible for managing AI ethics issues at major companies that use AI. From late 2017 to early 2019, we interviewed 23 such managers. Their titles ranged from privacy officer and privacy counsel to one that was new at the time but increasingly common today: data ethics officer. Our conversations with these AI ethics managers produced four main takeaways.
First, along with its many benefits, business use of AI poses substantial risks, and the companies know it. AI ethics managers expressed concerns about privacy , manipulation , bias, opacity, inequality and labor displacement. In one well-known example, amazon developed an ai tool to sort résumés and trained it to find candidates similar to those it had hired in the past. Male dominance in the tech industry meant that most of Amazon's employees were men. The tool accordingly learned to reject female candidates. Unable to fix the problem, Amazon ultimately had to scrap the project.
Generative AI raises additional worries about misinformation and hate speech at large scale and misappropriation of intellectual property .
Second, companies that pursue ethical AI do so largely for strategic reasons. They want to sustain trust among customers, business partners and employees. And they want to preempt, or prepare for, emerging regulations. The facebook-cambridge analytica scandal , in which Cambridge Analytica used Facebook user data, shared without consent, to infer the users' psychological types and target them with manipulative political ads, showed that the unethical use of advanced analytics can eviscerate a company's reputation or even, as in the case of Cambridge Analytica itself, bring it down. The companies we spoke to wanted instead to be viewed as responsible stewards of people's data.
The challenge that AI ethics managers faced was figuring out how best to achieve""ethical AI."" They looked first to AI ethics principles, particularly those rooted in bioethics or human rights principles, but found them insufficient. It was not just that there are many competing sets of principles. It was that justice, fairness, beneficence, autonomy and other such principles are contested and subject to interpretation and can conflict with one another.
This led to our third takeaway: Managers needed more than high-level AI principles to decide what to do in specific situations. One AI ethics manager described trying to translate human rights principles into a set of questions that developers could ask themselves to produce more ethical AI software systems.""We stopped after 34 pages of questions,"" the manager said.
Fourth, professionals grappling with ethical uncertainties turned to organizational structures and procedures to arrive at judgments about what to do. Some of these were clearly inadequate. But others, while still largely in development, were more helpful, such as:
Hiring an AI ethics officer to build and oversee the program. Establishing an internal AI ethics committee to weigh and decide hard issues. Crafting data ethics checklists and requiring front-line data scientists to fill them out. Reaching out to academics, former regulators and advocates for alternative perspectives. Conducting algorithmic impact assessments of the type already in use in environmental and privacy governance.
Ethics as responsible decision-makingThe key idea that emerged from our study is this: Companies seeking to use AI ethically should not expect to discover a simple set of principles that delivers correct answers from an all-knowing, God's-eye perspective. Instead, they should focus on the very human task of trying to make responsible decisions in a world of finite understanding and changing circumstances, even if some decisions end up being imperfect.
In the absence of explicit legal requirements, companies, like individuals, can only do their best to make themselves aware of how AI affects people and the environment and to stay abreast of public concerns and the latest research and expert ideas. They can also seek input from a large and diverse set of stakeholders and seriously engage with high-level ethical principles.
This simple idea changes the conversation in important ways. It encourages AI ethics professionals to focus their energies less on identifying and applying AI principles - though they remain part of the story - and more on adopting decision-making structures and processes to ensure that they consider the impacts, viewpoints and public expectations that should inform their business decisions.
In testimony to a Senate committee in May 2023, OpenAI CEO Sam Altman called for stricter oversight, including licensing requirements, for companies that develop AI software. ap photo/patrick semansky Ultimately, we believe laws and regulations will need to provide substantive benchmarks for organizations to aim for. But the structures and processes of responsible decision-making are a place to start and should, over time, help to build the knowledge needed to craft protective and workable substantive legal standards.
Indeed, the emerging law and policy of AI focuses on process. new york city passed a law requiring companies to audit their AI systems for harmful bias before using these systems to make hiring decisions. Members of congress have introduced bills that would require businesses to conduct algorithmic impact assessments before using AI for lending, employment, insurance and other such consequential decisions. These laws emphasize processes that address in advance AI's many threats.
Some of the developers of generative AI have taken a very different approach. Sam Altman, the CEO of OpenAI, initially explained that, in releasing ChatGPT to the public, the company sought to give the chatbot""enough exposure to the real world that you find some of the misuse cases you wouldn't have thought of so that you can build better tools."" To us, that is not responsible AI. It is treating human beings as guinea pigs in a risky experiment.
Altman's call at a may 2023 senate hearing for government regulation of AI shows greater awareness of the problem. But we believe he goes too far in shifting to government the responsibilities that the developers of generative AI must also bear. Maintaining public trust, and avoiding harm to society, will require companies more fully to face up to their responsibilities.
MENAFN25052023000199003603ID1106315109
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (93%); GENERATIVE AI (90%); MANAGERS & SUPERVISORS (90%); ARTIFICIAL INTELLIGENCE (89%); CHATBOTS (89%); CONVERSATIONAL AI (89%); NEGATIVE BUSINESS NEWS (89%); BUSINESS ETHICS (78%); BUSINESS OPERATIONS (78%); COMPANY ACTIVITIES & MANAGEMENT (78%); INTELLECTUAL PROPERTY (78%); MISAPPROPRIATION (78%); NEGATIVE NEWS (78%); GOVERNMENT ETHICS (77%); ASSOCIATIONS & ORGANIZATIONS (75%); DATA ANALYTICS (73%); HATE SPEECH (73%); INTELLECTUAL PROPERTY CRIME (73%); CONSUMERS (72%); POLITICAL ADVERTISING (72%); DISINFORMATION & MISINFORMATION (67%); NEGATIVE MISC NEWS (62%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); GENERATIVE AI (90%); ARTIFICIAL INTELLIGENCE (89%); CHATBOTS (89%); CONVERSATIONAL AI (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); DATA ANALYTICS (73%); POLITICAL ADVERTISING (72%)
Load-Date: August 5, 2023",neutral,0.5161516666412354,balanced/neutral,"['privacy', 'bias', 'fairness', 'human rights', 'autonomy', 'consent', 'manipulation', 'misinformation', 'disinformation', 'inequality']","['justice', 'fairness', 'autonomy', 'beneficence', 'justice']","['regulation', 'policy', 'governance', 'oversight', 'standards', 'law', 'audit', 'should', 'must', 'need to']","['generative ai', 'chatgpt']",10,5,10,2
2023,Unknown Title,"Byline: Hillary
Body
December 21st, 2023 ( TechBullion  — Delivered by  Newstex )
In the fast-evolving landscape of technology, Virtual Reality (VR) stands at the forefront, offering immersive experiences  that transcend the boundaries of reality. While the potential applications of VR are vast and transformative, it is crucial to delve into the ethical considerations that accompany this groundbreaking technology. This article explores the ethical dimensions of virtual reality, addressing the implications and responsibilities associated with its development, implementation, and use.
Understanding Virtual Reality Ethics:
As virtual reality becomes more integrated into our daily lives, questions surrounding its ethical implications become increasingly relevant. Ethical considerations in the context of VR extend beyond the mere development of the technology; they encompass its societal impact, potential consequences, and the responsibilities of those involved in its creation.
Informed Consent and User Privacy:
One of the primary ethical considerations in virtual reality revolves around informed consent and user privacy. VR applications often collect and process vast amounts of personal data, ranging from user behavior to physiological responses. Ensuring that users are fully informed about the data being collected and how it will be used is paramount. Transparent privacy policies and explicit consent mechanisms are essential to uphold the rights and autonomy of VR users.
Addressing the Potential for Addiction:
The immersive nature of virtual reality raises concerns about the potential for addiction. As users delve into captivating virtual worlds, there is a risk of excessive use, leading to negative consequences on physical and mental well-being. Developers and content creators must consider the ethical responsibility of creating experiences that are engaging without crossing the line into addictive territory. Implementing features that encourage responsible use and providing adequate warnings about potential risks is essential.
Virtual Reality and Psychological Impact:
The psychological impact of virtual reality on users is a significant ethical consideration. VR has the power to evoke strong emotional responses and can simulate intense experiences. This raises questions about the potential for triggering trauma or exacerbating existing mental health conditions. Ethical development practices involve conducting thorough research on the psychological effects of VR experiences and implementing safeguards to minimize harm.
Diversity and Inclusivity:
Another ethical consideration in the realm of virtual reality is the promotion of diversity and inclusivity . VR experiences should cater to a broad and diverse audience, ensuring that content is not biased or discriminatory. Developers must be mindful of creating inclusive virtual environments that respect cultural, gender, and societal differences. Fostering diversity in both the development teams and the content produced is a step towards ethical VR practices.
Virtual Reality in Education:
Ethical Implications:
As virtual reality finds its way into educational settings, ethical considerations become paramount. The immersive nature of VR can significantly impact the learning experience, but issues such as data security, age-appropriate content, and equal access to educational VR resources must be addressed. Striking a balance between the benefits of VR in education and ensuring ethical practices is essential for creating a positive and equitable learning environment.
Ensuring Accessibility for All:
Virtual reality has the potential to exclude individuals with certain disabilities if not developed with accessibility in mind. Ethical VR practices involve designing experiences that consider the needs of users with disabilities, providing alternative modes of interaction, and ensuring compatibility with assistive technologies. Prioritizing accessibility is not only an ethical imperative but also aligns with principles of inclusivity and equal access.
The Ethical Use of VR in Healthcare:
In healthcare, virtual reality holds promise for therapeutic interventions, training simulations, and pain management. However, ethical considerations arise concerning patient consent, data security, and the potential for misdiagnosis based on VR-generated information. Healthcare practitioners using VR must adhere to strict ethical guidelines, ensuring that patient well-being is prioritized, and the technology is employed responsibly.
Artificial Intelligence Integration:
The intersection of virtual reality and artificial intelligence introduces ethical considerations related to autonomy, accountability, and bias. AI algorithms powering VR experiences should be transparent, accountable, and devoid of discriminatory biases. Striking a balance between the potential benefits of AI in enhancing VR interactions and the ethical concerns associated with algorithmic decision-making is a complex but crucial task.
Child Safety and Content:
Given the immersive nature of virtual reality, child safety is a paramount ethical consideration. Developers must ensure that VR content is age-appropriate, avoiding potentially harmful or distressing experiences for young users. Implementing robust age verification mechanisms and parental controls is essential to protect children from content that may not be suitable for their age and maturity level.
Balancing Commercial Interests and Ethical Practices:
The commercialization of virtual reality introduces ethical dilemmas concerning profit motives and responsible practices. Moreover, developers and companies must prioritize ethical considerations over short-term gains, ensuring that user well-being, privacy, and safety are not compromised for the sake of commercial interests. Additionally, transparent business practices and ethical decision-making frameworks are imperative in navigating this delicate balance.
The Need for Ethical Guidelines and Standards:
In light of the myriad ethical considerations associated with virtual reality , the development and use of this technology call for comprehensive ethical guidelines and standards. Industry stakeholders, including developers, policymakers, and ethicists, should collaborate to establish clear ethical frameworks that guide the responsible creation, deployment, and use of virtual reality across various sectors.
Conclusion:
As virtual reality technology continues to advance, so too must our awareness and commitment to ethical considerations. From user privacy and psychological impact to inclusivity and responsible business practices, the ethical dimensions of virtual reality are multifaceted and evolving. It is incumbent upon developers, industry leaders, and policymakers to prioritize ethical practices, fostering a virtual reality landscape that is not only innovative but also responsible and respectful of the rights and well-being of users. In navigating the exciting future of virtual reality, a commitment to ethical considerations will be the compass that ensures this groundbreaking technology benefits society as a whole.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (95%); PRIVACY RIGHTS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); MENTAL HEALTH (87%); PSYCHOLOGY (87%); DIVERSITY & INCLUSION (84%); NEGATIVE SOCIETAL NEWS (74%); EMOTIONS (72%); ACCESS TO EDUCATION (71%); EMOTIONAL TRIGGERS (71%); MEDICINE & HEALTH (67%); Virtual Reality (%); software (%); technology (%); virtual reality (%)
Industry: VIRTUAL REALITY (94%); INFORMATION SECURITY & PRIVACY (88%); PSYCHOLOGY (87%); DATA SECURITY (72%)
Load-Date: December 21, 2023","December 21st, 2023 ( TechBullion  — Delivered by  Newstex )
In the fast-evolving landscape of technology, Virtual Reality (VR) stands at the forefront, offering immersive experiences  that transcend the boundaries of reality. While the potential applications of VR are vast and transformative, it is crucial to delve into the ethical considerations that accompany this groundbreaking technology. This article explores the ethical dimensions of virtual reality, addressing the implications and responsibilities associated with its development, implementation, and use.
Understanding Virtual Reality Ethics:
As virtual reality becomes more integrated into our daily lives, questions surrounding its ethical implications become increasingly relevant. Ethical considerations in the context of VR extend beyond the mere development of the technology; they encompass its societal impact, potential consequences, and the responsibilities of those involved in its creation.
Informed Consent and User Privacy:
One of the primary ethical considerations in virtual reality revolves around informed consent and user privacy. VR applications often collect and process vast amounts of personal data, ranging from user behavior to physiological responses. Ensuring that users are fully informed about the data being collected and how it will be used is paramount. Transparent privacy policies and explicit consent mechanisms are essential to uphold the rights and autonomy of VR users.
Addressing the Potential for Addiction:
The immersive nature of virtual reality raises concerns about the potential for addiction. As users delve into captivating virtual worlds, there is a risk of excessive use, leading to negative consequences on physical and mental well-being. Developers and content creators must consider the ethical responsibility of creating experiences that are engaging without crossing the line into addictive territory. Implementing features that encourage responsible use and providing adequate warnings about potential risks is essential.
Virtual Reality and Psychological Impact:
The psychological impact of virtual reality on users is a significant ethical consideration. VR has the power to evoke strong emotional responses and can simulate intense experiences. This raises questions about the potential for triggering trauma or exacerbating existing mental health conditions. Ethical development practices involve conducting thorough research on the psychological effects of VR experiences and implementing safeguards to minimize harm.
Diversity and Inclusivity:
Another ethical consideration in the realm of virtual reality is the promotion of diversity and inclusivity . VR experiences should cater to a broad and diverse audience, ensuring that content is not biased or discriminatory. Developers must be mindful of creating inclusive virtual environments that respect cultural, gender, and societal differences. Fostering diversity in both the development teams and the content produced is a step towards ethical VR practices.
Virtual Reality in Education:
Ethical Implications:
As virtual reality finds its way into educational settings, ethical considerations become paramount. The immersive nature of VR can significantly impact the learning experience, but issues such as data security, age-appropriate content, and equal access to educational VR resources must be addressed. Striking a balance between the benefits of VR in education and ensuring ethical practices is essential for creating a positive and equitable learning environment.
Ensuring Accessibility for All:
Virtual reality has the potential to exclude individuals with certain disabilities if not developed with accessibility in mind. Ethical VR practices involve designing experiences that consider the needs of users with disabilities, providing alternative modes of interaction, and ensuring compatibility with assistive technologies. Prioritizing accessibility is not only an ethical imperative but also aligns with principles of inclusivity and equal access.
The Ethical Use of VR in Healthcare:
In healthcare, virtual reality holds promise for therapeutic interventions, training simulations, and pain management. However, ethical considerations arise concerning patient consent, data security, and the potential for misdiagnosis based on VR-generated information. Healthcare practitioners using VR must adhere to strict ethical guidelines, ensuring that patient well-being is prioritized, and the technology is employed responsibly.
Artificial Intelligence Integration:
The intersection of virtual reality and artificial intelligence introduces ethical considerations related to autonomy, accountability, and bias. AI algorithms powering VR experiences should be transparent, accountable, and devoid of discriminatory biases. Striking a balance between the potential benefits of AI in enhancing VR interactions and the ethical concerns associated with algorithmic decision-making is a complex but crucial task.
Child Safety and Content:
Given the immersive nature of virtual reality, child safety is a paramount ethical consideration. Developers must ensure that VR content is age-appropriate, avoiding potentially harmful or distressing experiences for young users. Implementing robust age verification mechanisms and parental controls is essential to protect children from content that may not be suitable for their age and maturity level.
Balancing Commercial Interests and Ethical Practices:
The commercialization of virtual reality introduces ethical dilemmas concerning profit motives and responsible practices. Moreover, developers and companies must prioritize ethical considerations over short-term gains, ensuring that user well-being, privacy, and safety are not compromised for the sake of commercial interests. Additionally, transparent business practices and ethical decision-making frameworks are imperative in navigating this delicate balance.
The Need for Ethical Guidelines and Standards:
In light of the myriad ethical considerations associated with virtual reality , the development and use of this technology call for comprehensive ethical guidelines and standards. Industry stakeholders, including developers, policymakers, and ethicists, should collaborate to establish clear ethical frameworks that guide the responsible creation, deployment, and use of virtual reality across various sectors.
Conclusion:
As virtual reality technology continues to advance, so too must our awareness and commitment to ethical considerations. From user privacy and psychological impact to inclusivity and responsible business practices, the ethical dimensions of virtual reality are multifaceted and evolving. It is incumbent upon developers, industry leaders, and policymakers to prioritize ethical practices, fostering a virtual reality landscape that is not only innovative but also responsible and respectful of the rights and well-being of users. In navigating the exciting future of virtual reality, a commitment to ethical considerations will be the compass that ensures this groundbreaking technology benefits society as a whole.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (95%); PRIVACY RIGHTS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); MENTAL HEALTH (87%); PSYCHOLOGY (87%); DIVERSITY & INCLUSION (84%); NEGATIVE SOCIETAL NEWS (74%); EMOTIONS (72%); ACCESS TO EDUCATION (71%); EMOTIONAL TRIGGERS (71%); MEDICINE & HEALTH (67%); Virtual Reality (%); software (%); technology (%); virtual reality (%)
Industry: VIRTUAL REALITY (94%); INFORMATION SECURITY & PRIVACY (88%); PSYCHOLOGY (87%); DATA SECURITY (72%)
Load-Date: December 21, 2023",positive,0.6182844042778015,balanced/neutral,"['privacy', 'bias', 'accountability', 'safety', 'security', 'autonomy', 'consent', 'inclusivity', 'access']",['autonomy'],"['standards', 'guidelines', 'should', 'must']",[],9,1,4,0
2023,Unknown Title,"Body
2023 APR 07 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Research findings on artificial intelligence are discussed in a new report. According to news reporting from Eindhoven, Netherlands, by NewsRx journalists, research stated, ""In modern life, the application of artificial intelligence (AI) has promoted the implementation of data-driven algorithms in high-stakes domains, such as healthcare."" 
 Financial supporters for this research include Eindhoven University of Technology; China Scholarship Council. 
 The news editors obtained a quote from the research from Eindhoven University of Technology: ""However, it is becoming increasingly challenging for humans to understand the working and reasoning of these complex and opaque algorithms. For AI to support essential decisions in these domains, specific ethical issues need to be addressed to prevent the misinterpretation of AI, which may have severe consequences for humans. However, little research has been published on guidelines that systematically addresses ethical issues when AI techniques are applied in healthcare. In this systematic literature review, we aimed to provide an overview of ethical concerns and related strategies that are currently identified when applying AI in healthcare. The review, which followed the PRISMA guidelines, revealed 12 main ethical issues: justice and fairness, freedom and autonomy, privacy, transparency, patient safety and cyber security, trust, beneficence, responsibility, solidarity, sustainability, dignity, and conflicts."" 
 According to the news editors, the research concluded: ""In addition to these 12 main ethical issues, we derived 19 ethical sub-issues and associated strategies from the literature."" 
 For more information on this research see: Ethics & AI: A Systematic Review on Ethical Concerns and Related Strategies for Designing with AI in Healthcare. AI, 2022,4(3):28-53. The publisher for AI is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/ai4010003. 
 Our news journalists report that additional information may be obtained by contacting Fan Li, Industrial Design Department, Eindhoven University of Technology, 5600 MB Eindhoven, Netherlands. Additional authors for this research include Nick Ruijs, Yuan Lu. 
 Keywords for this news article include: Eindhoven University of Technology, Eindhoven, Netherlands, Europe, Artificial Intelligence, Cybersecurity. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); RESEARCH REPORTS (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); STUDENT EXPENSES & FINANCING (76%); SAFETY (73%); SAFETY, ACCIDENTS & DISASTERS (65%); Artificial Intelligence;Cybersecurity (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); INDUSTRIAL AUTOMATION (89%); INFORMATION SECURITY & PRIVACY (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); PUBLISHING (78%)
Geographic: NETHERLANDS (93%); CHINA (79%); EUROPE (58%)
Load-Date: April 7, 2023","2023 APR 07 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Research findings on artificial intelligence are discussed in a new report. According to news reporting from Eindhoven, Netherlands, by NewsRx journalists, research stated, ""In modern life, the application of artificial intelligence (AI) has promoted the implementation of data-driven algorithms in high-stakes domains, such as healthcare."" 
 Financial supporters for this research include Eindhoven University of Technology; China Scholarship Council. 
 The news editors obtained a quote from the research from Eindhoven University of Technology: ""However, it is becoming increasingly challenging for humans to understand the working and reasoning of these complex and opaque algorithms. For AI to support essential decisions in these domains, specific ethical issues need to be addressed to prevent the misinterpretation of AI, which may have severe consequences for humans. However, little research has been published on guidelines that systematically addresses ethical issues when AI techniques are applied in healthcare. In this systematic literature review, we aimed to provide an overview of ethical concerns and related strategies that are currently identified when applying AI in healthcare. The review, which followed the PRISMA guidelines, revealed 12 main ethical issues: justice and fairness, freedom and autonomy, privacy, transparency, patient safety and cyber security, trust, beneficence, responsibility, solidarity, sustainability, dignity, and conflicts."" 
 According to the news editors, the research concluded: ""In addition to these 12 main ethical issues, we derived 19 ethical sub-issues and associated strategies from the literature."" 
 For more information on this research see: Ethics & AI: A Systematic Review on Ethical Concerns and Related Strategies for Designing with AI in Healthcare. AI, 2022,4(3):28-53. The publisher for AI is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/ai4010003. 
 Our news journalists report that additional information may be obtained by contacting Fan Li, Industrial Design Department, Eindhoven University of Technology, 5600 MB Eindhoven, Netherlands. Additional authors for this research include Nick Ruijs, Yuan Lu. 
 Keywords for this news article include: Eindhoven University of Technology, Eindhoven, Netherlands, Europe, Artificial Intelligence, Cybersecurity. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); RESEARCH REPORTS (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); STUDENT EXPENSES & FINANCING (76%); SAFETY (73%); SAFETY, ACCIDENTS & DISASTERS (65%); Artificial Intelligence;Cybersecurity (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COLLEGES & UNIVERSITIES (90%); MACHINE LEARNING (90%); ROBOTICS (90%); INDUSTRIAL AUTOMATION (89%); INFORMATION SECURITY & PRIVACY (89%); WRITERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); PUBLISHING (78%)
Geographic: NETHERLANDS (93%); CHINA (79%); EUROPE (58%)
Load-Date: April 7, 2023",neutral,0.8916181921958923,balanced/neutral,"['privacy', 'fairness', 'transparency', 'safety', 'security', 'autonomy']","['justice', 'fairness', 'autonomy', 'dignity', 'beneficence', 'justice']","['guidelines', 'need to']","['machine learning', 'robotics']",6,6,2,2
2023,Unknown Title,"Byline: Targeted News Service
Dateline: LONDON, England 
Body
(TNSres) -- The Institute of Business Ethics issued the following news release on Oct. 25, 2023:
* * *
* New recommendations from the UK's leading business ethics experts urge companies to appoint an AI lead to ensure ethical use of technology.
* Companies urged to provide staff training on ethical use of AI.
* Businesses told to ensure ethical AI use across supply chains.
* * *
Chief executives should appoint a dedicated AI leader or committee to ensure companies' ethical use of new technologies, according to new recommendations from the UK's leading business ethics experts.
Guidance published today by the Institute of Business Ethics (IBE) has also urged companies to ensure ongoing reviews of the use of artificial intelligence, training of staff on ethical practice, and ensuring ethical use of AI is embedded across supply chain companies.
The guidance has been issued ahead of the government's international summit on the future of artificial intelligence at Bletchley Park.
The IBE has warned that companies failing to put provisions in place to ensure the ethical use of AI across the workforce could be at risk of breaching privacy rules or damaging their reputations.
The guidance also includes recommendations for companies to ensure ethical practice when using AI is embedded across the workforce, and the creation of toolkits to support ongoing staff training.
Dr Ian Peters MBE, Director of the Institute of Business Ethics, said:
""AI can be a powerful tool for business, supporting planning, enabling greater productivity and profitability. But it comes with risks, and companies that fail to put steps in place to ensure they use artificial intelligence ethically will face difficulties in the longer term.
""How AI is and should be used must be a shared responsibility, and companies should be embedding best practice across the workforce. But CEOs should also designate an individual or committee specifically to ensure ethical practice - and those that don't do so put themselves at risk when it comes to issues like data protection. We would urge every business using AI or thinking about how it can be incorporated into their work to ensure they've created the practices necessary to protect privacy and ensure the highest standards of ethical behaviour.""
* * *
Original text here: https://www.ibe.org.uk/resource/businesses-must-have-ai-ethics-lead-uk-business-ethics-experts.html
[Category: Business]
MSTRUCK-8336432 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (98%); BUSINESS ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); EMPLOYEE TRAINING (90%); EMPLOYEE TRAINING & ASSISTANCE (90%); LABOR FORCE (90%); EXECUTIVES (89%); BEST PRACTICES (77%); PRODUCTIVITY (75%); PRIVACY RIGHTS (71%); INVASION OF PRIVACY (66%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA SECURITY (66%); INFORMATION SECURITY & PRIVACY (66%)
Geographic: LONDON, ENGLAND (74%); UNITED KINGDOM (91%); ENGLAND (74%)
Load-Date: October 26, 2023","(TNSres) -- The Institute of Business Ethics issued the following news release on Oct. 25, 2023:
* * *
* New recommendations from the UK's leading business ethics experts urge companies to appoint an AI lead to ensure ethical use of technology.
* Companies urged to provide staff training on ethical use of AI.
* Businesses told to ensure ethical AI use across supply chains.
* * *
Chief executives should appoint a dedicated AI leader or committee to ensure companies' ethical use of new technologies, according to new recommendations from the UK's leading business ethics experts.
Guidance published today by the Institute of Business Ethics (IBE) has also urged companies to ensure ongoing reviews of the use of artificial intelligence, training of staff on ethical practice, and ensuring ethical use of AI is embedded across supply chain companies.
The guidance has been issued ahead of the government's international summit on the future of artificial intelligence at Bletchley Park.
The IBE has warned that companies failing to put provisions in place to ensure the ethical use of AI across the workforce could be at risk of breaching privacy rules or damaging their reputations.
The guidance also includes recommendations for companies to ensure ethical practice when using AI is embedded across the workforce, and the creation of toolkits to support ongoing staff training.
Dr Ian Peters MBE, Director of the Institute of Business Ethics, said:
""AI can be a powerful tool for business, supporting planning, enabling greater productivity and profitability. But it comes with risks, and companies that fail to put steps in place to ensure they use artificial intelligence ethically will face difficulties in the longer term.
""How AI is and should be used must be a shared responsibility, and companies should be embedding best practice across the workforce. But CEOs should also designate an individual or committee specifically to ensure ethical practice - and those that don't do so put themselves at risk when it comes to issues like data protection. We would urge every business using AI or thinking about how it can be incorporated into their work to ensure they've created the practices necessary to protect privacy and ensure the highest standards of ethical behaviour.""
* * *
Original text here: https://www.ibe.org.uk/resource/businesses-must-have-ai-ethics-lead-uk-business-ethics-experts.html
[Category: Business]
MSTRUCK-8336432 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (98%); BUSINESS ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); EMPLOYEE TRAINING (90%); EMPLOYEE TRAINING & ASSISTANCE (90%); LABOR FORCE (90%); EXECUTIVES (89%); BEST PRACTICES (77%); PRODUCTIVITY (75%); PRIVACY RIGHTS (71%); INVASION OF PRIVACY (66%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA SECURITY (66%); INFORMATION SECURITY & PRIVACY (66%)
Geographic: LONDON, ENGLAND (74%); UNITED KINGDOM (91%); ENGLAND (74%)
Load-Date: October 26, 2023",neutral,0.9059475064277649,balanced/neutral,"['privacy', 'security']",[],"['standards', 'should', 'must']",[],2,0,3,0
2023,Unknown Title,"Body
Videotaping surgeries is important for training and quality improvement, but there are multiple ethical concerns. ""The legality area has been well-covered. But issues such as doctor-patient relationship and ethical frameworks need deep consideration at the patient, practitioner, institutional, and societal level,"" according to Ronan Cahill, MB, BAO, BCh, professor of surgery at University College Dublin.
Cahill and colleagues conducted a systematic review of the literature, analyzing 25 publications on the ethics of OR recording.1 ""Given the increasing capability and value in surgical recordings now in this age of AI, we wanted to understand what ethical considerations have been evaluated to date,"" Cahill explains.
Beneficence, nonmaleficence, justice, and autonomy were key areas of focus in the publications. ""We found that there has been only limited work recently, with a predominantly Western perspective, and with a focus on individual patient level and beneficial aspects,"" Cahill notes.
Video training can be an ethical approach to improving health outcomes, says Julie M. Aultman, PhD, dean of the College of Graduate Studies and director of the medical ethics and humanities program at Northeast Ohio Medical University in Rootstown. ""Videos complement the review and reflection of surgical practice that is traditionally done at morbidity and mortality conferences,"" Aultman says.
Ideally, the surgical team uses the recordings in conjunction with quality improvement and risk management to assess efficiency, professionalism, communication, and leadership. 
""Video training can help prevent medical errors and poor surgical outcomes through a review of safety protocols and checklists captured prior to and during a surgery,"" Aultman says.
For interns and residents, video training is an important tool that can improve skills and confidence. ""It can also improve their ability to receive constructive feedback from mentors and educators, and take ownership of mistakes or gaps of knowledge,"" Aultman adds. For example, a second-year resident may learn an incorrect surgical procedure from a senior or chief resident or faculty member, but is uncomfortable calling out their poor training and any resultant errors. ""Training videos can help improve surgical practices and outcomes, regardless of learners' positions or statuses,"" Aultman says.
For patients, video recordings can foster health literacy. Watching a video of a surgical procedure can be more informative than a verbal explanation of what is entailed. ""This level of transparency could potentially alleviate fears, trepidations, and distrust,"" Aultman offers.
IRBs provide oversight if video recordings are used in research. ""But when it comes to educational training, or non-human subjects studies such as quality improvement projects, ethical oversight can vary depending on the clinical setting,"" Aultman says. 
According to Aultman, hospitals and graduate medical education departments should establish oversight committees to ensure videos are used appropriately, inform patients that video training is essential to improve patient safety and health outcomes, and develop safeguards to protect patient privacy (e.g., policies that require de-identification practices). Patients and their families (if patients lack capacity or awareness) should be aware that surgeries will be recorded, and that faces and other identifiable details are blurred, covered, or simply not captured or disseminated unless consent is granted by the patient or their proxy. 
""The ethics of video recording should be integrated in graduate and continuous education modules so surgeons have self-governance when recording or utilizing videos,"" Aultman adds.
    REFERENCE    
1. Walsh R, Kearns EC, Moynihan A, et al. Ethical perspectives on surgical video recording for patients, surgeons and society: Systematic review. BJS Open 2023;7:zrad063.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (96%); PHYSICIANS & SURGEONS (92%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (90%); PROFESSIONAL WORKERS (90%); EDUCATION & TRAINING (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); MEDICAL TREATMENTS & PROCEDURES (89%); SAFETY (89%); SURGERY & TRANSPLANTATION (89%); MEDICAL RESEARCH (79%); MORBIDITY RATES (79%); PUBLIC HEALTH (79%); RESIDENCY PROGRAMS (79%); APPRENTICESHIPS & INTERNSHIPS (78%); MENTORS & ROLE MODELS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ARTS & HUMANITIES EDUCATION (76%); COLLEGE & UNIVERSITY PROFESSORS (76%); COLLEGES & UNIVERSITIES (76%); HUMANITIES & SOCIAL SCIENCE (76%); PATIENT PRIVACY (74%); RISK MANAGEMENT (71%); UNIVERSITY ADMINISTRATION (71%); SAFETY REGULATION & POLICY (70%); SAFETY, ACCIDENTS & DISASTERS (64%); PRIVACY RIGHTS (60%)
Industry: PHYSICIANS & SURGEONS (92%); GRADUATE & PROFESSIONAL SCHOOLS (89%); MORBIDITY RATES (79%); COLLEGE & UNIVERSITY PROFESSORS (76%); COLLEGES & UNIVERSITIES (76%); PATIENT PRIVACY (74%); MEDIA & TELECOMMUNICATIONS (73%); RISK MANAGEMENT (71%)
Geographic: OHIO, USA (79%)
Load-Date: August 30, 2023","Videotaping surgeries is important for training and quality improvement, but there are multiple ethical concerns. ""The legality area has been well-covered. But issues such as doctor-patient relationship and ethical frameworks need deep consideration at the patient, practitioner, institutional, and societal level,"" according to Ronan Cahill, MB, BAO, BCh, professor of surgery at University College Dublin.
Cahill and colleagues conducted a systematic review of the literature, analyzing 25 publications on the ethics of OR recording.1 ""Given the increasing capability and value in surgical recordings now in this age of AI, we wanted to understand what ethical considerations have been evaluated to date,"" Cahill explains.
Beneficence, nonmaleficence, justice, and autonomy were key areas of focus in the publications. ""We found that there has been only limited work recently, with a predominantly Western perspective, and with a focus on individual patient level and beneficial aspects,"" Cahill notes.
Video training can be an ethical approach to improving health outcomes, says Julie M. Aultman, PhD, dean of the College of Graduate Studies and director of the medical ethics and humanities program at Northeast Ohio Medical University in Rootstown. ""Videos complement the review and reflection of surgical practice that is traditionally done at morbidity and mortality conferences,"" Aultman says.
Ideally, the surgical team uses the recordings in conjunction with quality improvement and risk management to assess efficiency, professionalism, communication, and leadership. 
""Video training can help prevent medical errors and poor surgical outcomes through a review of safety protocols and checklists captured prior to and during a surgery,"" Aultman says.
For interns and residents, video training is an important tool that can improve skills and confidence. ""It can also improve their ability to receive constructive feedback from mentors and educators, and take ownership of mistakes or gaps of knowledge,"" Aultman adds. For example, a second-year resident may learn an incorrect surgical procedure from a senior or chief resident or faculty member, but is uncomfortable calling out their poor training and any resultant errors. ""Training videos can help improve surgical practices and outcomes, regardless of learners' positions or statuses,"" Aultman says.
For patients, video recordings can foster health literacy. Watching a video of a surgical procedure can be more informative than a verbal explanation of what is entailed. ""This level of transparency could potentially alleviate fears, trepidations, and distrust,"" Aultman offers.
IRBs provide oversight if video recordings are used in research. ""But when it comes to educational training, or non-human subjects studies such as quality improvement projects, ethical oversight can vary depending on the clinical setting,"" Aultman says. 
According to Aultman, hospitals and graduate medical education departments should establish oversight committees to ensure videos are used appropriately, inform patients that video training is essential to improve patient safety and health outcomes, and develop safeguards to protect patient privacy (e.g., policies that require de-identification practices). Patients and their families (if patients lack capacity or awareness) should be aware that surgeries will be recorded, and that faces and other identifiable details are blurred, covered, or simply not captured or disseminated unless consent is granted by the patient or their proxy. 
""The ethics of video recording should be integrated in graduate and continuous education modules so surgeons have self-governance when recording or utilizing videos,"" Aultman adds.
    REFERENCE    
1. Walsh R, Kearns EC, Moynihan A, et al. Ethical perspectives on surgical video recording for patients, surgeons and society: Systematic review. BJS Open 2023;7:zrad063.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (96%); PHYSICIANS & SURGEONS (92%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (90%); PROFESSIONAL WORKERS (90%); EDUCATION & TRAINING (89%); GRADUATE & PROFESSIONAL SCHOOLS (89%); MEDICAL TREATMENTS & PROCEDURES (89%); SAFETY (89%); SURGERY & TRANSPLANTATION (89%); MEDICAL RESEARCH (79%); MORBIDITY RATES (79%); PUBLIC HEALTH (79%); RESIDENCY PROGRAMS (79%); APPRENTICESHIPS & INTERNSHIPS (78%); MENTORS & ROLE MODELS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ARTS & HUMANITIES EDUCATION (76%); COLLEGE & UNIVERSITY PROFESSORS (76%); COLLEGES & UNIVERSITIES (76%); HUMANITIES & SOCIAL SCIENCE (76%); PATIENT PRIVACY (74%); RISK MANAGEMENT (71%); UNIVERSITY ADMINISTRATION (71%); SAFETY REGULATION & POLICY (70%); SAFETY, ACCIDENTS & DISASTERS (64%); PRIVACY RIGHTS (60%)
Industry: PHYSICIANS & SURGEONS (92%); GRADUATE & PROFESSIONAL SCHOOLS (89%); MORBIDITY RATES (79%); COLLEGE & UNIVERSITY PROFESSORS (76%); COLLEGES & UNIVERSITIES (76%); PATIENT PRIVACY (74%); MEDIA & TELECOMMUNICATIONS (73%); RISK MANAGEMENT (71%)
Geographic: OHIO, USA (79%)
Load-Date: August 30, 2023",neutral,0.8218532204627991,balanced/neutral,"['privacy', 'transparency', 'safety', 'autonomy', 'consent']","['justice', 'autonomy', 'beneficence', 'justice']","['regulation', 'policy', 'governance', 'oversight', 'should']",[],5,4,5,0
2023,Unknown Title,"Body
New York: Carnegie Council for Ethics in International Affairs has opened registration for its 2023 Global Ethics Day keynote event, “Unlocking Cooperation,” taking place on October 18 at 12:00pm ET. Featuring a panel discussion led by Carnegie Council President Joel Rosenthal, the free-to-attend virtual event will examine the psychology of cooperation and its potential to address global-scale challenges. Together, the panelists will explore how we might motivate individuals to act more cooperatively and discuss how multilateral cooperation can help tackle shared challenges from climate change to AI to political violence.
In addition to attending the keynote event, individuals and organizations from around the world are encouraged to plan their own Global Ethics Day activations. For guidance and tools on how to participate, please visit the Global Ethics Day 2023 site to access key messages, a social media toolkit, and other resources. Activities may include debates, panels, social media campaigns, articles/blogs, pop-up events, and so much more. See examples of past activations here.
Remember to share your activations online using #GlobalEthicsDay. Participants are also encouraged to share their Global Ethics Day plans with Carnegie Council via an online contact form for a chance to be featured on the Council ’ s social media platforms and Global Ethics Day materials. Stay up to date on the latest Global Ethics Day news by subscribing to the Carnegie Ethics Newsletter and following Carnegie Council on LinkedIn, Instagram, Threads, X, and Facebook.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); INTERNET SOCIAL NETWORKING (90%); SOCIAL MEDIA (90%); TRENDS & EVENTS (90%); INTERNATIONAL ASSISTANCE (78%); ASSOCIATIONS & ORGANIZATIONS (73%); BLOGS & MESSAGE BOARDS (68%); NEGATIVE POLITICAL NEWS (55%); POLITICAL VIOLENCE (55%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); INTERNET SOCIAL NETWORKING (90%); SOCIAL MEDIA (90%); BLOGS & MESSAGE BOARDS (68%)
Load-Date: September 20, 2023","New York: Carnegie Council for Ethics in International Affairs has opened registration for its 2023 Global Ethics Day keynote event, “Unlocking Cooperation,” taking place on October 18 at 12:00pm ET. Featuring a panel discussion led by Carnegie Council President Joel Rosenthal, the free-to-attend virtual event will examine the psychology of cooperation and its potential to address global-scale challenges. Together, the panelists will explore how we might motivate individuals to act more cooperatively and discuss how multilateral cooperation can help tackle shared challenges from climate change to AI to political violence.
In addition to attending the keynote event, individuals and organizations from around the world are encouraged to plan their own Global Ethics Day activations. For guidance and tools on how to participate, please visit the Global Ethics Day 2023 site to access key messages, a social media toolkit, and other resources. Activities may include debates, panels, social media campaigns, articles/blogs, pop-up events, and so much more. See examples of past activations here.
Remember to share your activations online using #GlobalEthicsDay. Participants are also encouraged to share their Global Ethics Day plans with Carnegie Council via an online contact form for a chance to be featured on the Council ’ s social media platforms and Global Ethics Day materials. Stay up to date on the latest Global Ethics Day news by subscribing to the Carnegie Ethics Newsletter and following Carnegie Council on LinkedIn, Instagram, Threads, X, and Facebook.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); INTERNET SOCIAL NETWORKING (90%); SOCIAL MEDIA (90%); TRENDS & EVENTS (90%); INTERNATIONAL ASSISTANCE (78%); ASSOCIATIONS & ORGANIZATIONS (73%); BLOGS & MESSAGE BOARDS (68%); NEGATIVE POLITICAL NEWS (55%); POLITICAL VIOLENCE (55%)
Company:  META PLATFORMS INC (50%)
Ticker: META (NASDAQ) (50%)
Industry: NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (50%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (50%); INTERNET SOCIAL NETWORKING (90%); SOCIAL MEDIA (90%); BLOGS & MESSAGE BOARDS (68%)
Load-Date: September 20, 2023",neutral,0.7277981638908386,balanced/neutral,"['security', 'access']",[],[],[],2,0,0,0
2023,Unknown Title,"Byline: Brenda Kanana
Body
Nov 16, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In a move that has resonated across the artificial intelligence industry, Ed Newton-Rex, the former Vice President of Audio at Stability AI, resigned last week, citing legal concerns over the use of copyrighted material in AI development. His resignation, announced at the Cerebral Valley AI Summit [1]in San Francisco, throws into sharp relief the ongoing debate about AI technology's ethical and legal boundaries, particularly in the burgeoning field of generative AI.[2] 
Newton-Rex's departure from Stability AI is not just a personal decision but a significant marker in the ongoing discourse around the legalities of AI-driven content creation. Generative AI operates by processing vast amounts of data to produce new content, raising questions about the origins of this data and the rights associated with it. 
The legal and ethical dilemma 
The crux of the issue lies in the method by which generative AI learns and creates. These AI systems can generate new, original works by ingesting and analyzing large datasets, including copyrighted material. However, this process has ignited a debate about whether such usage constitutes fair use or infringement. 
This debate is not confined to the corridors of AI startups but extends to the broader legal and academic communities. As AI continues to advance, the line between inspiration and infringement becomes increasingly blurred, challenging existing copyright laws and principles. 
Industry reaction and future outlook 
The resignation has sparked varied reactions within the AI community. Some view it as a necessary stance on ethical practices, while others see it as an overreaction to a complex issue that is yet to be clearly defined by law. 
Looking forward, this development could signal a shift in how AI companies approach the creation and use of their datasets. The industry might see a rise in efforts to create AI models trained on openly licensed or original content, a move that could reshape the landscape of AI development. 
Ed Newton-Rex's resignation from Stability AI is more than an individual action; it represents a pivotal moment in the ongoing conversation about the ethical and legal frameworks governing AI. As generative AI continues to grow, the industry must navigate these complex issues, balancing innovation with respect for intellectual property rights. The outcome of this debate will likely shape the future of AI development and its role in society. 
 [ 1]: https://cerebralvalleysummit.com/ [ 2]: https://www.cryptopolitan.com/impact-of-generative-ai-on-journalism/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COPYRIGHT (90%); GENERATIVE AI (90%); RESIGNATIONS (90%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); Innovators (%); AI (%)
Company:  AI SYSTEMS (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); BIG DATA (68%)
Geographic: CALIFORNIA, USA (72%)
Load-Date: November 16, 2023","Nov 16, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In a move that has resonated across the artificial intelligence industry, Ed Newton-Rex, the former Vice President of Audio at Stability AI, resigned last week, citing legal concerns over the use of copyrighted material in AI development. His resignation, announced at the Cerebral Valley AI Summit [1]in San Francisco, throws into sharp relief the ongoing debate about AI technology's ethical and legal boundaries, particularly in the burgeoning field of generative AI.[2] 
Newton-Rex's departure from Stability AI is not just a personal decision but a significant marker in the ongoing discourse around the legalities of AI-driven content creation. Generative AI operates by processing vast amounts of data to produce new content, raising questions about the origins of this data and the rights associated with it. 
The legal and ethical dilemma 
The crux of the issue lies in the method by which generative AI learns and creates. These AI systems can generate new, original works by ingesting and analyzing large datasets, including copyrighted material. However, this process has ignited a debate about whether such usage constitutes fair use or infringement. 
This debate is not confined to the corridors of AI startups but extends to the broader legal and academic communities. As AI continues to advance, the line between inspiration and infringement becomes increasingly blurred, challenging existing copyright laws and principles. 
Industry reaction and future outlook 
The resignation has sparked varied reactions within the AI community. Some view it as a necessary stance on ethical practices, while others see it as an overreaction to a complex issue that is yet to be clearly defined by law. 
Looking forward, this development could signal a shift in how AI companies approach the creation and use of their datasets. The industry might see a rise in efforts to create AI models trained on openly licensed or original content, a move that could reshape the landscape of AI development. 
Ed Newton-Rex's resignation from Stability AI is more than an individual action; it represents a pivotal moment in the ongoing conversation about the ethical and legal frameworks governing AI. As generative AI continues to grow, the industry must navigate these complex issues, balancing innovation with respect for intellectual property rights. The outcome of this debate will likely shape the future of AI development and its role in society. 
 [ 1]: https://cerebralvalleysummit.com/ [ 2]: https://www.cryptopolitan.com/impact-of-generative-ai-on-journalism/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); COPYRIGHT (90%); GENERATIVE AI (90%); RESIGNATIONS (90%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); Innovators (%); AI (%)
Company:  AI SYSTEMS (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GENERATIVE AI (90%); BIG DATA (68%)
Geographic: CALIFORNIA, USA (72%)
Load-Date: November 16, 2023",neutral,0.8952481746673584,balanced/neutral,[],[],"['law', 'should', 'must']",['generative ai'],0,0,3,1
2023,Unknown Title,"Byline: Our Bureau
Highlight: Invites proposals to build ‘tools, frameworks’ that promote ethical development of AI tech
Body
New Delhi: The government has invited proposals from academic institutions and research and development organisations to build indigenously developed “tools and frameworks” that promote the just and ethical development of artificial intelligence across themes such as machine unlearning, synthetic data generation, fairness tools, bias mitigating strategies and others. One of the tools, for example, would be around machine unlearning to rectify “inaccuracies, biases, and outdated information that can inadvertently become ingrained in machine learning models”.  “By facilitating the removal of undesirable learned behaviours, machine unlearning algorithms contribute to the development of more accurate, reliable, and fair AI systems across diverse domains,” the proposal document read. 
 Similarly, tools and frameworks for synthetic data generation, algorithm fairness, bias mitigation, ethical AI, and governance testing, the proposal calls for data gaps, mitigating privacy concerns, and promoting equitable representation.  Government-run institutions such as the Indian Institute of Technology (IIT), the National Institute of Technology (NIT) Indian Institutes of Information Technology (IIIT), R&D and private academic organisations that have pre-existing lab infrastructure with workstations, servers and other dedicated staff will be eligible to apply.  Such institutes must, however, justify completion of the project within the next two years, and ensure it is within the overarching goal of promoting fair and ethical AI utilisation. The proposals must be submitted to the ministry of electronics and information technology by January 12.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ETHICS (90%); RESEARCH & DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (78%); MACHINE LEARNING (73%)
Company:  AI SYSTEMS (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); EDUCATIONAL SERVICES (90%); INFORMATION SECURITY & PRIVACY (77%); MACHINE LEARNING (73%)
Geographic: NEW DELHI, INDIA (79%)
Load-Date: December 26, 2023","New Delhi: The government has invited proposals from academic institutions and research and development organisations to build indigenously developed “tools and frameworks” that promote the just and ethical development of artificial intelligence across themes such as machine unlearning, synthetic data generation, fairness tools, bias mitigating strategies and others. One of the tools, for example, would be around machine unlearning to rectify “inaccuracies, biases, and outdated information that can inadvertently become ingrained in machine learning models”.  “By facilitating the removal of undesirable learned behaviours, machine unlearning algorithms contribute to the development of more accurate, reliable, and fair AI systems across diverse domains,” the proposal document read. 
 Similarly, tools and frameworks for synthetic data generation, algorithm fairness, bias mitigation, ethical AI, and governance testing, the proposal calls for data gaps, mitigating privacy concerns, and promoting equitable representation.  Government-run institutions such as the Indian Institute of Technology (IIT), the National Institute of Technology (NIT) Indian Institutes of Information Technology (IIIT), R&D and private academic organisations that have pre-existing lab infrastructure with workstations, servers and other dedicated staff will be eligible to apply.  Such institutes must, however, justify completion of the project within the next two years, and ensure it is within the overarching goal of promoting fair and ethical AI utilisation. The proposals must be submitted to the ministry of electronics and information technology by January 12.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); ETHICS (90%); RESEARCH & DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (78%); MACHINE LEARNING (73%)
Company:  AI SYSTEMS (55%)
Industry: SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (90%); EDUCATIONAL SERVICES (90%); INFORMATION SECURITY & PRIVACY (77%); MACHINE LEARNING (73%)
Geographic: NEW DELHI, INDIA (79%)
Load-Date: December 26, 2023",neutral,0.6943525075912476,balanced/neutral,"['privacy', 'bias', 'fairness', 'security']",['fairness'],"['governance', 'must', 'calls for']","['machine learning', 'algorithm']",4,1,3,2
2023,Unknown Title,"Byline: Tariq Al Fahaam
Body
SHARJAH, 31st August, 2023 (WAM) - Keeping in mind the critical role of artificial intelligence (AI) and other transformative technologies of our era in our lives and economy, the 12th edition of the International Government Communication Forum (IGCF) will turn the spotlight on one of the most interesting questions of our time: what is national wealth in the era of AI?
Global technology, innovation and telecommunications experts, cybersecurity leaders and senior government communication professionals from around the world will come together at the two-day forum on 13th and 14th September, in Expo Centre Sharjah, to discuss the emerging perspectives and fresh interpretations of what really should be considered, sustainably invested in, utilised and preserved as ""national wealth"".
Several panel sessions, inspiring speeches, seven targeted workshops and a first-of-its-kind AI Camp have been designed to boost attendees' understanding, offer insight and promote the exchange of fresh ideas, particularly in the context of the role of government communications. This part of the forum, organised by the Sharjah Government Media Bureau (SGMB) will enable attendees to deliberate on the challenges and opportunities facing advanced sectors and ways to effectively and sustainably invest in them.
Robot Ethics: Asimov's Predictions
A distinguished panel featuring Jean Koh, Chairman of the Presidential Committee on Digital Platform Government, South Korea; Phaedra Buenodris, Author of AI for the Rest of Us and co-founder of the Future World Alliance; Dr. Mohamed Hamad Al-Kuwaiti, Head of Cyber Security of the UAE Government will lead a discussion titled ""Robot Ethics... Asimov's Predictions"".
The session will discuss how governments can play a more critical role in helping design the ethics systems programmed for robots and create innovations and platforms within their mechanisms to better connect with and serve citizens in the era of AI. Whether or not national laws should regulate AI ethics, the ethical considerations we must bear in mind when discussing AI, and the role government communicators will play in defining these for the people and creating acceptance are some of the interesting questions that the discussion will tackle and demand answers from experts.
Power of AI in Digital Era
Abdulla Alsharhan, Director of Creativity and Corporate Identity, at the Sharjah Media City (Shams) will deliver an inspiring speech titled ""The power of artificial intelligence and the enhancement of communication in the digital era"" at the Gov. Talks platform.
Abdulla's expert insights will inform audiences on AI's growing role and impact on various industries, ways to improve government communications, intellectual property rights challenges in light of AI, and the future direction for all these sectors.
First-of-its-Kind Camp in UAE
The Artificial Intelligence Skills Camp (AISC) will offer the first creative environment of its kind in the UAE to impart practical AI skills to school students. Members of Sharjah's Rubu' Qarn Foundation for Creating Leaders and Innovators and members of the Ithmar programme by Sharjah Press Club, aged 12 to 17 years, will attend the camp organised in partnership with the Artificial Intelligence Journalism for Research and Forecasting (AIJRF). Students will design projects at four competitions during the camp and pitch them to the jury of the Sharjah Government Communication Award (SGCA), who will select the winning project.
AI: Ethics, Communication and Technology
The organisers have announced a robust pre-forum agenda, which will host seven hands-on and interactive workshops starting 4th September. In this agenda is the COMMS programme, which will upskill media and communication students and aspiring and established government communicators through training sessions based on the pillars of Ethics and Professionalism, Communications and Technical.
Running until 7th September, the pre-forum COMMS programme will cover key topics such as ""Artificial Intelligence For Good: How AI is Helping Governments Manage Resources in Knowledge and Education"", ""Ethical and Legal Aspects of the Use of Artificial Intelligence Applications"", ""Generative AI and its Application in Media Industry"", ""Using Artificial Intelligence to Create Government Communication Content"", ""Media Coverage for Sustainability and Climate Change Issues"", ""Uses of Artificial Intelligence Tools in Journalism and Media"" and ""Effectiveness of using social media in Government Communication"".
Themed ""Today's Resources. Tomorrow's Wealth"", IGCF 2023 will shine a light on the role of government communication in raising awareness and instilling a culture regarding resources and emphasising their value and importance for societies and future generations. The specialised sessions on technology and AI have been designed to inspire fresh perspectives, innovative new ideas, and adaptability to change about owning and investing in the resources of the current era, including data and advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 55
Subject: ARTIFICIAL INTELLIGENCE (90%); EMERGING TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ETHICS (89%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); GLOBALIZATION (77%); TALKS & MEETINGS (77%); TRADE SHOWS (75%); PRODUCT INNOVATION (71%); PROFESSIONAL WORKERS (56%)
Company:  AL MUDON INTERNATIONAL REAL ESTATE CO KSCC (54%)
Ticker: ALMUDON (KUW) (54%)
Industry: NAICS531110 LESSORS OF RESIDENTIAL BUILDINGS & DWELLINGS (54%); SIC6513 OPERATORS OF APARTMENT BUILDINGS (54%); ARTIFICIAL INTELLIGENCE (90%); PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); CYBERSECURITY (76%); TELECOMMUNICATIONS (72%)
Geographic: UNITED ARAB EMIRATES (96%)
Load-Date: August 31, 2023","SHARJAH, 31st August, 2023 (WAM) - Keeping in mind the critical role of artificial intelligence (AI) and other transformative technologies of our era in our lives and economy, the 12th edition of the International Government Communication Forum (IGCF) will turn the spotlight on one of the most interesting questions of our time: what is national wealth in the era of AI?
Global technology, innovation and telecommunications experts, cybersecurity leaders and senior government communication professionals from around the world will come together at the two-day forum on 13th and 14th September, in Expo Centre Sharjah, to discuss the emerging perspectives and fresh interpretations of what really should be considered, sustainably invested in, utilised and preserved as ""national wealth"".
Several panel sessions, inspiring speeches, seven targeted workshops and a first-of-its-kind AI Camp have been designed to boost attendees' understanding, offer insight and promote the exchange of fresh ideas, particularly in the context of the role of government communications. This part of the forum, organised by the Sharjah Government Media Bureau (SGMB) will enable attendees to deliberate on the challenges and opportunities facing advanced sectors and ways to effectively and sustainably invest in them.
Robot Ethics: Asimov's Predictions
A distinguished panel featuring Jean Koh, Chairman of the Presidential Committee on Digital Platform Government, South Korea; Phaedra Buenodris, Author of AI for the Rest of Us and co-founder of the Future World Alliance; Dr. Mohamed Hamad Al-Kuwaiti, Head of Cyber Security of the UAE Government will lead a discussion titled ""Robot Ethics... Asimov's Predictions"".
The session will discuss how governments can play a more critical role in helping design the ethics systems programmed for robots and create innovations and platforms within their mechanisms to better connect with and serve citizens in the era of AI. Whether or not national laws should regulate AI ethics, the ethical considerations we must bear in mind when discussing AI, and the role government communicators will play in defining these for the people and creating acceptance are some of the interesting questions that the discussion will tackle and demand answers from experts.
Power of AI in Digital Era
Abdulla Alsharhan, Director of Creativity and Corporate Identity, at the Sharjah Media City (Shams) will deliver an inspiring speech titled ""The power of artificial intelligence and the enhancement of communication in the digital era"" at the Gov. Talks platform.
Abdulla's expert insights will inform audiences on AI's growing role and impact on various industries, ways to improve government communications, intellectual property rights challenges in light of AI, and the future direction for all these sectors.
First-of-its-Kind Camp in UAE
The Artificial Intelligence Skills Camp (AISC) will offer the first creative environment of its kind in the UAE to impart practical AI skills to school students. Members of Sharjah's Rubu' Qarn Foundation for Creating Leaders and Innovators and members of the Ithmar programme by Sharjah Press Club, aged 12 to 17 years, will attend the camp organised in partnership with the Artificial Intelligence Journalism for Research and Forecasting (AIJRF). Students will design projects at four competitions during the camp and pitch them to the jury of the Sharjah Government Communication Award (SGCA), who will select the winning project.
AI: Ethics, Communication and Technology
The organisers have announced a robust pre-forum agenda, which will host seven hands-on and interactive workshops starting 4th September. In this agenda is the COMMS programme, which will upskill media and communication students and aspiring and established government communicators through training sessions based on the pillars of Ethics and Professionalism, Communications and Technical.
Running until 7th September, the pre-forum COMMS programme will cover key topics such as ""Artificial Intelligence For Good: How AI is Helping Governments Manage Resources in Knowledge and Education"", ""Ethical and Legal Aspects of the Use of Artificial Intelligence Applications"", ""Generative AI and its Application in Media Industry"", ""Using Artificial Intelligence to Create Government Communication Content"", ""Media Coverage for Sustainability and Climate Change Issues"", ""Uses of Artificial Intelligence Tools in Journalism and Media"" and ""Effectiveness of using social media in Government Communication"".
Themed ""Today's Resources. Tomorrow's Wealth"", IGCF 2023 will shine a light on the role of government communication in raising awareness and instilling a culture regarding resources and emphasising their value and importance for societies and future generations. The specialised sessions on technology and AI have been designed to inspire fresh perspectives, innovative new ideas, and adaptability to change about owning and investing in the resources of the current era, including data and advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 55
Subject: ARTIFICIAL INTELLIGENCE (90%); EMERGING TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ETHICS (89%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); GLOBALIZATION (77%); TALKS & MEETINGS (77%); TRADE SHOWS (75%); PRODUCT INNOVATION (71%); PROFESSIONAL WORKERS (56%)
Company:  AL MUDON INTERNATIONAL REAL ESTATE CO KSCC (54%)
Ticker: ALMUDON (KUW) (54%)
Industry: NAICS531110 LESSORS OF RESIDENTIAL BUILDINGS & DWELLINGS (54%); SIC6513 OPERATORS OF APARTMENT BUILDINGS (54%); ARTIFICIAL INTELLIGENCE (90%); PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); CYBERSECURITY (76%); TELECOMMUNICATIONS (72%)
Geographic: UNITED ARAB EMIRATES (96%)
Load-Date: August 31, 2023",positive,0.5226101875305176,balanced/neutral,"['security', 'agency']",[],"['law', 'should', 'must']","['generative ai', 'robot']",2,0,3,2
2023,Unknown Title,"Byline: Business Matters
Body
Nov 15, 2023( Business Matters: http://www.bmmagazine.co.uk/ Delivered by Newstex)  
 The global banking industry, a cornerstone of economic stability, has always rested on a foundation of trust and ethical conduct. 
Recent revelations surrounding AfrAsia Bank, however, have cast a shadow on this trust, triggering a wave of concerns about ethical integrity in the banking sector. As the spotlight intensifies on AfrAsia's conduct, it becomes clear that the time has come for comprehensive regulatory safeguards to uphold ethical standards in the industry. 
AfrAsia Bank's Ethical Quandary: 
AfrAsia Bank[1], once considered a stalwart in the financial sector, has faced mounting scrutiny for its questionable ethical practices. Reports of dubious lending practices, lack of transparency, and conflicts of interest have raised alarm bells among regulators, customers, and the public alike. Such revelations not only erode public trust in AfrAsia but also have broader implications for the reputation of the entire banking industry. 
The Call for Regulatory Safeguards: 
In the wake of AfrAsia's ethical crisis, there is a growing chorus of voices demanding increased regulatory oversight and safeguards. The existing regulatory frameworks, it seems, are not robust enough to prevent or swiftly address such ethical breaches. There is an urgent need for regulators to revisit and reinforce the rules governing the banking industry to ensure that ethical standards are not just encouraged but enforced. 
Ethics Training and Oversight: 
Regulatory safeguards should also include stringent requirements for ethics training within banks. Employees at all levels must be well-versed in ethical standards and the consequences of breaching them. Furthermore, an independent oversight mechanism should be established to monitor and report on the ethical conduct of banks. This oversight would act as a proactive measure, preventing ethical lapses before they escalate. 
Collaboration Among Regulators: 
Given the global nature of banking, there is a need for enhanced collaboration among regulators across borders. A standardized set of ethical guidelines and regulations could be developed and adopted internationally, ensuring that banks operate under consistent ethical standards regardless of their geographic location. Such collaboration would not only strengthen the industry's ethical fabric but also enhance global financial stability. 
The Relevance of Ethical Fortification: 
AfrAsia's ethical missteps underscore the need for a proactive approach to ethical fortification within the banking sector. As financial institutions serve as custodians of public trust, their ethical conduct directly influences the stability and credibility of the entire economic ecosystem. Regulatory safeguards must evolve to address the complexities of the modern banking landscape, safeguarding against ethical breaches that could compromise the industry's foundational principles. 
Learning from AfrAsia: 
A detailed examination of AfrAsia Bank's conduct serves as a valuable case study for regulators, industry experts, and aspiring ethical banking advocates. By dissecting the root causes and consequences of ethical lapses, the industry can distill essential lessons and identify best practices. These insights can inform the development of targeted regulatory measures that address specific vulnerabilities and reinforce ethical standards across the sector. 
Proactive Ethical Governance: 
Regulatory safeguards should pivot towards proactive ethical governance rather than reactive measures. Establishing robust ethical risk management frameworks, conducting regular ethical audits, and fostering a culture of accountability within banking institutions can mitigate the likelihood of ethical lapses. By placing a premium on prevention, regulators can catalyze a shift towards a more ethically resilient banking sector. 
The Role of Technology in Ethical Compliance: 
In an era of rapid technological advancement, regulators must harness the power of innovation to enhance ethical compliance. Smart contracts, blockchain technology, and artificial intelligence can be leveraged to create transparent and tamper-proof systems that facilitate ethical conduct. This integration of technology not only streamlines regulatory oversight but also serves as a powerful deterrent against unethical practices. 
Conclusion: 
In the aftermath ofAfrAsia Bank's ethical lapses[2], the imperative for regulatory safeguards becomes clear: to fortify the ethical foundations of the banking industry. By learning from past mistakes, embracing technological advancements, fostering global collaboration, and empowering stakeholders, regulators can usher in a new era of ethical governance. Through these measures, the banking industry can regain the public's trust, ensuring that it remains a stalwart guardian of financial stability and ethical integrity. 
Read more:  
Ethical Integrity in Banking: AfrAsia's Conduct Triggers a Demand for Regulatory Safeguards[3] 
 [ 1]: https://mosniccky.medium.com/allegations-of-improper-and-potentially-illegal-misconduct-at-afrasia-bank-27ce9fa1131c [ 2]: https://usawire.com/ethical-concerns-regarding-afrasia-banks-conduct-necessitate-increased-regulation-in-the-banking-industry/ [ 3]: https://bmmagazine.co.uk/business/ethical-integrity-in-banking-afrasias-conduct-triggers-a-demand-for-regulatory-safeguards/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: BMTR-127533
Subject: ETHICS (94%); BUSINESS ETHICS (89%); ECONOMY & ECONOMIC INDICATORS (89%); NEGATIVE BUSINESS NEWS (79%); BEST PRACTICES (78%); REGULATORY ACTIONS (77%); NEGATIVE NEWS (74%); CASE STUDIES (73%); CONFLICTS OF INTEREST (72%); GEOGRAPHY (65%); Business (%)
Industry: BANKING & FINANCE (95%); BANKING & FINANCE REGULATION & POLICY (90%); BANKING INSTITUTIONS & SYSTEMS (90%)
Load-Date: November 16, 2023","Nov 15, 2023( Business Matters: http://www.bmmagazine.co.uk/ Delivered by Newstex)  
 The global banking industry, a cornerstone of economic stability, has always rested on a foundation of trust and ethical conduct. 
Recent revelations surrounding AfrAsia Bank, however, have cast a shadow on this trust, triggering a wave of concerns about ethical integrity in the banking sector. As the spotlight intensifies on AfrAsia's conduct, it becomes clear that the time has come for comprehensive regulatory safeguards to uphold ethical standards in the industry. 
AfrAsia Bank's Ethical Quandary: 
AfrAsia Bank[1], once considered a stalwart in the financial sector, has faced mounting scrutiny for its questionable ethical practices. Reports of dubious lending practices, lack of transparency, and conflicts of interest have raised alarm bells among regulators, customers, and the public alike. Such revelations not only erode public trust in AfrAsia but also have broader implications for the reputation of the entire banking industry. 
The Call for Regulatory Safeguards: 
In the wake of AfrAsia's ethical crisis, there is a growing chorus of voices demanding increased regulatory oversight and safeguards. The existing regulatory frameworks, it seems, are not robust enough to prevent or swiftly address such ethical breaches. There is an urgent need for regulators to revisit and reinforce the rules governing the banking industry to ensure that ethical standards are not just encouraged but enforced. 
Ethics Training and Oversight: 
Regulatory safeguards should also include stringent requirements for ethics training within banks. Employees at all levels must be well-versed in ethical standards and the consequences of breaching them. Furthermore, an independent oversight mechanism should be established to monitor and report on the ethical conduct of banks. This oversight would act as a proactive measure, preventing ethical lapses before they escalate. 
Collaboration Among Regulators: 
Given the global nature of banking, there is a need for enhanced collaboration among regulators across borders. A standardized set of ethical guidelines and regulations could be developed and adopted internationally, ensuring that banks operate under consistent ethical standards regardless of their geographic location. Such collaboration would not only strengthen the industry's ethical fabric but also enhance global financial stability. 
The Relevance of Ethical Fortification: 
AfrAsia's ethical missteps underscore the need for a proactive approach to ethical fortification within the banking sector. As financial institutions serve as custodians of public trust, their ethical conduct directly influences the stability and credibility of the entire economic ecosystem. Regulatory safeguards must evolve to address the complexities of the modern banking landscape, safeguarding against ethical breaches that could compromise the industry's foundational principles. 
Learning from AfrAsia: 
A detailed examination of AfrAsia Bank's conduct serves as a valuable case study for regulators, industry experts, and aspiring ethical banking advocates. By dissecting the root causes and consequences of ethical lapses, the industry can distill essential lessons and identify best practices. These insights can inform the development of targeted regulatory measures that address specific vulnerabilities and reinforce ethical standards across the sector. 
Proactive Ethical Governance: 
Regulatory safeguards should pivot towards proactive ethical governance rather than reactive measures. Establishing robust ethical risk management frameworks, conducting regular ethical audits, and fostering a culture of accountability within banking institutions can mitigate the likelihood of ethical lapses. By placing a premium on prevention, regulators can catalyze a shift towards a more ethically resilient banking sector. 
The Role of Technology in Ethical Compliance: 
In an era of rapid technological advancement, regulators must harness the power of innovation to enhance ethical compliance. Smart contracts, blockchain technology, and artificial intelligence can be leveraged to create transparent and tamper-proof systems that facilitate ethical conduct. This integration of technology not only streamlines regulatory oversight but also serves as a powerful deterrent against unethical practices. 
Conclusion: 
In the aftermath ofAfrAsia Bank's ethical lapses[2], the imperative for regulatory safeguards becomes clear: to fortify the ethical foundations of the banking industry. By learning from past mistakes, embracing technological advancements, fostering global collaboration, and empowering stakeholders, regulators can usher in a new era of ethical governance. Through these measures, the banking industry can regain the public's trust, ensuring that it remains a stalwart guardian of financial stability and ethical integrity. 
Read more:  
Ethical Integrity in Banking: AfrAsia's Conduct Triggers a Demand for Regulatory Safeguards[3] 
 [ 1]: https://mosniccky.medium.com/allegations-of-improper-and-potentially-illegal-misconduct-at-afrasia-bank-27ce9fa1131c [ 2]: https://usawire.com/ethical-concerns-regarding-afrasia-banks-conduct-necessitate-increased-regulation-in-the-banking-industry/ [ 3]: https://bmmagazine.co.uk/business/ethical-integrity-in-banking-afrasias-conduct-triggers-a-demand-for-regulatory-safeguards/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: BMTR-127533
Subject: ETHICS (94%); BUSINESS ETHICS (89%); ECONOMY & ECONOMIC INDICATORS (89%); NEGATIVE BUSINESS NEWS (79%); BEST PRACTICES (78%); REGULATORY ACTIONS (77%); NEGATIVE NEWS (74%); CASE STUDIES (73%); CONFLICTS OF INTEREST (72%); GEOGRAPHY (65%); Business (%)
Industry: BANKING & FINANCE (95%); BANKING & FINANCE REGULATION & POLICY (90%); BANKING INSTITUTIONS & SYSTEMS (90%)
Load-Date: November 16, 2023",neutral,0.8649967908859253,balanced/neutral,"['transparency', 'accountability']",[],"['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'compliance', 'should', 'must']",[],2,0,9,0
2023,Unknown Title,"Body
To provide a framework for ethical decision-making in medical AI
The Indian Council of Medical Research (ICMR) has released""Ethical Guidelines for Application of Artificial Intelligence in Biomedical Research and Healthcare, 2023"" to ensure ethical conduct and address emerging ethical challenges in the field of Artificial Intelligence (AI) in biomedical research and healthcare.
These guidelines are also meant to provide a framework for ethical decision-making in medical AI during the development, deployment, and adoption of AI-based solutions. The guidelines are intended for all stakeholders involved in research on AI in biomedical research and healthcare, including creators, developers, researchers, clinicians, ethics committees, institutions, sponsors, and funding organisations.
The guidelines include sections on ethical principles, guiding principles for stakeholders, an ethics review process, governance of AI use, and informed consent. They have been developed through extensive discussions with experts and ethicists. The guidelines are a living document and will be updated as ethics in AI evolve.
""The adoption of AI technology in healthcare is growing in India. However, AI as data-driven technology has many potential ethical challenges which include algorithmic transparency and explainability, clarity on liability, accountability and oversight, bias and discrimination"", said Dr Rajiv Bahl, Director General, ICMR.
ICMR has formulated ethical guidance documents from time to time for promoting ethical and high quality research in India. The most recent version of ICMR's National Ethical Guidelines for Biomedical and Health Research involving human participants, was released in 2017.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (99%); ARTIFICIAL INTELLIGENCE (90%); BIOETHICS (90%); BIOMEDICINE (90%); MEDICAL RESEARCH (90%); MEDICINE & HEALTH (90%); SCIENCE & TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DISCRIMINATION (78%); PATIENT CONSENT (78%); ASSOCIATIONS & ORGANIZATIONS (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); BIOMEDICINE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); PATIENT CONSENT (78%)
Geographic: INDIA (91%)
Load-Date: March 27, 2023","To provide a framework for ethical decision-making in medical AI
The Indian Council of Medical Research (ICMR) has released""Ethical Guidelines for Application of Artificial Intelligence in Biomedical Research and Healthcare, 2023"" to ensure ethical conduct and address emerging ethical challenges in the field of Artificial Intelligence (AI) in biomedical research and healthcare.
These guidelines are also meant to provide a framework for ethical decision-making in medical AI during the development, deployment, and adoption of AI-based solutions. The guidelines are intended for all stakeholders involved in research on AI in biomedical research and healthcare, including creators, developers, researchers, clinicians, ethics committees, institutions, sponsors, and funding organisations.
The guidelines include sections on ethical principles, guiding principles for stakeholders, an ethics review process, governance of AI use, and informed consent. They have been developed through extensive discussions with experts and ethicists. The guidelines are a living document and will be updated as ethics in AI evolve.
""The adoption of AI technology in healthcare is growing in India. However, AI as data-driven technology has many potential ethical challenges which include algorithmic transparency and explainability, clarity on liability, accountability and oversight, bias and discrimination"", said Dr Rajiv Bahl, Director General, ICMR.
ICMR has formulated ethical guidance documents from time to time for promoting ethical and high quality research in India. The most recent version of ICMR's National Ethical Guidelines for Biomedical and Health Research involving human participants, was released in 2017.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (99%); ARTIFICIAL INTELLIGENCE (90%); BIOETHICS (90%); BIOMEDICINE (90%); MEDICAL RESEARCH (90%); MEDICINE & HEALTH (90%); SCIENCE & TECHNOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DISCRIMINATION (78%); PATIENT CONSENT (78%); ASSOCIATIONS & ORGANIZATIONS (73%)
Industry: ARTIFICIAL INTELLIGENCE (90%); BIOMEDICINE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); PATIENT CONSENT (78%)
Geographic: INDIA (91%)
Load-Date: March 27, 2023",neutral,0.6894014477729797,balanced/neutral,"['bias', 'discrimination', 'transparency', 'explainability', 'accountability', 'consent']",[],"['governance', 'oversight', 'guidelines', 'framework']",[],6,0,4,0
2023,Unknown Title,"Body
This year's spotlight on generative AI has been one of several factors increasingly placing corporate ethics in the crosshairs.
Important today, ethics will soon become foundational and existential for business. Five years from now an organization's ability to recruit and retain top talent and design and sell profitable goods and services will depend on how it is perceived ethically.
Headlines are full of claims (and counter claims) regarding ethical lapses in the judicial, legislative, and executive branches of government. This scrutiny of the intersection of moral principles and action is spreading to nearly every facet of society, begging the question: What should we be doing to make sure IT's ethical house is in order?
Ethics are - note the use of the plural here - among those disciplines that are much discussed but poorly understood. Juan Enríquez, author of Homo Evolutis: Please Meet the Next Human Species, began his remarks, ""Ethics in the Age of Technology"" lamenting that on the first day of work, many knowledge workers are presented with a giant book - The Ethics Manual -which declaims in excruciatingly boring prose, ""What is right and what is wrong."" The net effect of this practice is to send the erroneous signal to new employees that ethical responsibility starts and ends with compliance with pre-existing, created-by-others rule sets. Nothing could be further from the truth.
The what and why of ethics in IT
The ritualistic delivery of The Ethics Manual to employees,ludicrous as it might seem, raises a couple of interesting questions. First, who writes the manual and whom is responsible for monitoring ethics in the enterprise? Second, is there an expanded version of The Ethics Manual for IT professionals?
The scholarship of Dennis F. Thompson, founding director of the University Center for Ethics and the Professions at the John F. Kennedy School of Government at Harvard University, reveals that we need to be aware of at least three distinctly different forms of ethics.
There are personal ethics, frequently referred to by ethics professors as ""sandbox values"" or ""Sunday school ethics""; professional ethics, the codes of conduct specified by various disciplines (e.g., lawyers, accountants, doctors, financial advisors, engineers); and institutional ethics, which constitute normative behaviors of an organization or department. Of increasing importance are something known as ""cohort ethics"" - the assumption that your ethics are the sum of the value sets of your five closest friends.
Special Professor of Law Janis Meyer, who teaches ""Legal Ethics"" at The Maurice A. Deane School of Law at Hofstra University and ""Professional Responsibility"" at Columbia University School of Law, recently spoke at the virtual ""Responsibility of Information Management"" Digital Solutions Gallery at The Ohio State University. (Her remarks start at the 30:15 mark.) There, Meyer explained that there can be a difference between ""professional ethics,"" as specified for lawyers in state and federal law, and morals, aka personal beliefs and values.
Meyer asked, ""Does IT have unambiguously articulated professional ethics?"" This is something our profession needs to work on. In the soon-to-be-published The Day Before IT Transformation: Unlocking Digital Transformation for Business Leaders, Cheryl Smith, former CIO at McKesson, West Jet, and Keyspan, argues that without industry- and discipline-accepted ""Technology Leadership Practices"" it is essentially impossible to articulate professional ethics for IT.
Ethics are much bigger than a set of simple rules - for example, ""Don't lie,"" ""Don't cheat,"" or ""Don't steal other children's toys."" Ethics are more than ""checking the box"" on environmental, social, and governance (ESG) and diversity, equity, and inclusion (DEI) audits.
Ethics drive how we frame and make decisions. How do we protect people's privacy when AI needs so much data? Imagine you are programming a driverless car. When confronted with a crash scenario, should the car save its single occupant or seven pedestrians? Should the car prioritize saving older people or younger people? When using analytics, on what basis should hospitals allocate scarce beds in the intensive care unit? When screening job applicants, which resumes are rejected and which are reviewed? When deploying police, where should resources be focused? IT is not neutral or above the tough ethical questions organizations are confronting.
Currently the spotlight in tech ethics is split between how organizations treat their IT employees and how to prevent algorithmic misbehavior - for example, how to eliminate bias in training data. There is a movement under way to create a new human right against being subject to automated decision-making.
In the ethical IT organization of the future, we should be mindful of the decisions we make and their downstream ramifications. CIOs need to set the tone for their organization, establishing what is important, and what truly merits the time and attention of the professionals working with them. Great organizations might try to forecast future ethical dilemmas, for example, when there is a clash between personal and institutional values. Philosophy professors believe that one way to prepare to face real-world ethical dilemmas is to strengthen your moral muscle by practicing on hypothetical scenarios/case studies.
How will you help your IT organization rise to the evolving ethical moment?
Business IT Alignment, IT Governance, IT Governance Frameworks, IT Leadership
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (96%); BUSINESS ETHICS (90%); EXECUTIVES (90%); TEACHING & TEACHERS (89%); TECHNICIANS & TECHNOLOGICAL WORKERS (89%); PROFESSIONAL WORKERS (88%); LAW SCHOOLS (87%); COLLEGE & UNIVERSITY PROFESSORS (85%); GENERATIVE AI (78%); LEGAL ETHICS (78%); ASSOCIATIONS & ORGANIZATIONS (77%); SCHOLARSHIPS & GRANTS (77%); GOVERNMENT & PUBLIC ADMINISTRATION (76%); LAW & LEGAL SYSTEM (76%); WRITERS (73%); COLLEGES & UNIVERSITIES (67%); STUDENT EXPENSES & FINANCING (67%)
Industry: LAW SCHOOLS (87%); COLLEGE & UNIVERSITY PROFESSORS (85%); GENERATIVE AI (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION MANAGEMENT (73%); WRITERS (73%); COLLEGES & UNIVERSITIES (67%)
Geographic: OHIO, USA (79%)
Load-Date: October 31, 2023","This year's spotlight on generative AI has been one of several factors increasingly placing corporate ethics in the crosshairs.
Important today, ethics will soon become foundational and existential for business. Five years from now an organization's ability to recruit and retain top talent and design and sell profitable goods and services will depend on how it is perceived ethically.
Headlines are full of claims (and counter claims) regarding ethical lapses in the judicial, legislative, and executive branches of government. This scrutiny of the intersection of moral principles and action is spreading to nearly every facet of society, begging the question: What should we be doing to make sure IT's ethical house is in order?
Ethics are - note the use of the plural here - among those disciplines that are much discussed but poorly understood. Juan Enríquez, author of Homo Evolutis: Please Meet the Next Human Species, began his remarks, ""Ethics in the Age of Technology"" lamenting that on the first day of work, many knowledge workers are presented with a giant book - The Ethics Manual -which declaims in excruciatingly boring prose, ""What is right and what is wrong."" The net effect of this practice is to send the erroneous signal to new employees that ethical responsibility starts and ends with compliance with pre-existing, created-by-others rule sets. Nothing could be further from the truth.
The what and why of ethics in IT
The ritualistic delivery of The Ethics Manual to employees,ludicrous as it might seem, raises a couple of interesting questions. First, who writes the manual and whom is responsible for monitoring ethics in the enterprise? Second, is there an expanded version of The Ethics Manual for IT professionals?
The scholarship of Dennis F. Thompson, founding director of the University Center for Ethics and the Professions at the John F. Kennedy School of Government at Harvard University, reveals that we need to be aware of at least three distinctly different forms of ethics.
There are personal ethics, frequently referred to by ethics professors as ""sandbox values"" or ""Sunday school ethics""; professional ethics, the codes of conduct specified by various disciplines (e.g., lawyers, accountants, doctors, financial advisors, engineers); and institutional ethics, which constitute normative behaviors of an organization or department. Of increasing importance are something known as ""cohort ethics"" - the assumption that your ethics are the sum of the value sets of your five closest friends.
Special Professor of Law Janis Meyer, who teaches ""Legal Ethics"" at The Maurice A. Deane School of Law at Hofstra University and ""Professional Responsibility"" at Columbia University School of Law, recently spoke at the virtual ""Responsibility of Information Management"" Digital Solutions Gallery at The Ohio State University. (Her remarks start at the 30:15 mark.) There, Meyer explained that there can be a difference between ""professional ethics,"" as specified for lawyers in state and federal law, and morals, aka personal beliefs and values.
Meyer asked, ""Does IT have unambiguously articulated professional ethics?"" This is something our profession needs to work on. In the soon-to-be-published The Day Before IT Transformation: Unlocking Digital Transformation for Business Leaders, Cheryl Smith, former CIO at McKesson, West Jet, and Keyspan, argues that without industry- and discipline-accepted ""Technology Leadership Practices"" it is essentially impossible to articulate professional ethics for IT.
Ethics are much bigger than a set of simple rules - for example, ""Don't lie,"" ""Don't cheat,"" or ""Don't steal other children's toys."" Ethics are more than ""checking the box"" on environmental, social, and governance (ESG) and diversity, equity, and inclusion (DEI) audits.
Ethics drive how we frame and make decisions. How do we protect people's privacy when AI needs so much data? Imagine you are programming a driverless car. When confronted with a crash scenario, should the car save its single occupant or seven pedestrians? Should the car prioritize saving older people or younger people? When using analytics, on what basis should hospitals allocate scarce beds in the intensive care unit? When screening job applicants, which resumes are rejected and which are reviewed? When deploying police, where should resources be focused? IT is not neutral or above the tough ethical questions organizations are confronting.
Currently the spotlight in tech ethics is split between how organizations treat their IT employees and how to prevent algorithmic misbehavior - for example, how to eliminate bias in training data. There is a movement under way to create a new human right against being subject to automated decision-making.
In the ethical IT organization of the future, we should be mindful of the decisions we make and their downstream ramifications. CIOs need to set the tone for their organization, establishing what is important, and what truly merits the time and attention of the professionals working with them. Great organizations might try to forecast future ethical dilemmas, for example, when there is a clash between personal and institutional values. Philosophy professors believe that one way to prepare to face real-world ethical dilemmas is to strengthen your moral muscle by practicing on hypothetical scenarios/case studies.
How will you help your IT organization rise to the evolving ethical moment?
Business IT Alignment, IT Governance, IT Governance Frameworks, IT Leadership
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (96%); BUSINESS ETHICS (90%); EXECUTIVES (90%); TEACHING & TEACHERS (89%); TECHNICIANS & TECHNOLOGICAL WORKERS (89%); PROFESSIONAL WORKERS (88%); LAW SCHOOLS (87%); COLLEGE & UNIVERSITY PROFESSORS (85%); GENERATIVE AI (78%); LEGAL ETHICS (78%); ASSOCIATIONS & ORGANIZATIONS (77%); SCHOLARSHIPS & GRANTS (77%); GOVERNMENT & PUBLIC ADMINISTRATION (76%); LAW & LEGAL SYSTEM (76%); WRITERS (73%); COLLEGES & UNIVERSITIES (67%); STUDENT EXPENSES & FINANCING (67%)
Industry: LAW SCHOOLS (87%); COLLEGE & UNIVERSITY PROFESSORS (85%); GENERATIVE AI (78%); INFORMATION MANAGEMENT & TECHNOLOGY (78%); INFORMATION MANAGEMENT (73%); WRITERS (73%); COLLEGES & UNIVERSITIES (67%)
Geographic: OHIO, USA (79%)
Load-Date: October 31, 2023",neutral,0.683932363986969,balanced/neutral,"['privacy', 'bias']",['equity'],"['governance', 'law', 'compliance', 'should', 'need to']",['generative ai'],2,1,5,1
2023,Unknown Title,"Body
Minister dr. Today, Emilija Stojmenova Duh participated in the international conference on the ethics of neurotechnology in Paris, organized by the United Nations Educational, Scientific and Cultural Organization (UNESCO) on the theme ""On the way to an ethical framework for protection and promotion of human rights and fundamental freedoms"".
Politicians, scientists, representatives of civil society organizations, academics, media, experts and companies from the private sector gathered at the conference with the aim of discussing the development of international standards in the field of science ethics and preparing a solid foundation for the ethical framework of neurotechnology management, which will enabled progress in this area while simultaneously protecting and promoting human rights and fundamental freedoms. More and more experts warn that, despite the enormous potential of neurotechnology, legal regulation of the ethical and social aspects of technologies such as neurotechnology and artificial intelligence is necessary.
Minister dr. Stojmenova Duh, in addition to the Deputy Director General of UNESCO for Social Sciences and Humanities Gabriele Ramos, the Spanish Secretary of State for Digitization and Artificial Intelligence Carma Artigas, the Undersecretary of Chile for Science, Technology, Knowledge and Innovation Carolina Gainza and the Executive Director of the Center for the Fourth Industrial Revolution in Saudi Basma Al-Buhairan of Arabia participated in a high-level meeting as part of the conference, where they focused mainly on political measures and international cooperation.
At the session, the participants discussed the opportunities and challenges of neurotechnology, its use at the national level, and the role of UNESCO in solving challenges related to neurotechnology and its management. Minister dr. At the conference, Stojmenova Duh defended the position that neurotechnology offers extraordinary opportunities for understanding the functioning of the brain, improving people's health, their cognitive abilities and the quality of life, but it also presents challenges, so it is crucial that its development is based on ethics, justice, responsibility and inclusion. ""Ethical principles and respect for human rights must be incorporated at the very beginning of the development of new technologies. This is why we need close cooperation between governments, businesses, researchers, academics and civil society globally. The dialogue we have at the global level, must be developed among all stakeholders of the digital ecosystem also at the national level,"" said the minister, adding that international organizations such as UNESCO play an important role in the preparation of common ethical guidelines and regulations at the global level, as well as capacity building and knowledge exchange. She also pointed out that Slovenia strongly supports the work of the International Committee for Bioethics at UNESCO on the ethical issues of neurotechnology and advocates for the establishment of a common ethical.
""We believe that all international organizations dealing with artificial intelligence should work closely together. Therefore, at the beginning of next year, together with UNESCO, we will organize a world forum on ethics in artificial intelligence, to which we will invite representatives of international organizations in order to find joint solutions to the challenges of ethics and reliability of artificial intelligence,"" she added.
""Neurotechnology has enormous potential to reduce the consequences of serious neurological disorders such as epilepsy, Alzheimer's, Parkinson's disease and stroke. The fear of new technologies such as artificial intelligence should not stop us from using them, as they are tools that increase efficiency and innovation and can greatly improve the quality of our lives. However, they must be designed transparently and responsibly. Slovenia therefore advocates for the establishment of solid ethical and legal frameworks to prevent the malicious use of artificial intelligence in the field of neurotechnology,"" said Minister Dr. Stojmenova Duh summarized Slovenia's position at the end of the session.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 193
Subject: ETHICS (95%); ASSOCIATIONS & ORGANIZATIONS (90%); CONFERENCES & CONVENTIONS (90%); HUMAN RIGHTS (90%); INTERNATIONAL RELATIONS (90%); NEUROSCIENCE (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TALKS & MEETINGS (89%); ELECTIONS & POLITICS (79%); GOVERNMENT ADVISORS & MINISTERS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BIOETHICS (78%); HUMANITIES & SOCIAL SCIENCE (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); POLITICS (76%); EXECUTIVES (75%); EMERGING TECHNOLOGY (73%); INTELLIGENCE & COGNITION (73%); STANDARDS & MEASUREMENTS (70%)
Industry: PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%)
Geographic: SLOVENIA (92%); SAUDI ARABIA (79%)
Load-Date: July 25, 2023","Minister dr. Today, Emilija Stojmenova Duh participated in the international conference on the ethics of neurotechnology in Paris, organized by the United Nations Educational, Scientific and Cultural Organization (UNESCO) on the theme ""On the way to an ethical framework for protection and promotion of human rights and fundamental freedoms"".
Politicians, scientists, representatives of civil society organizations, academics, media, experts and companies from the private sector gathered at the conference with the aim of discussing the development of international standards in the field of science ethics and preparing a solid foundation for the ethical framework of neurotechnology management, which will enabled progress in this area while simultaneously protecting and promoting human rights and fundamental freedoms. More and more experts warn that, despite the enormous potential of neurotechnology, legal regulation of the ethical and social aspects of technologies such as neurotechnology and artificial intelligence is necessary.
Minister dr. Stojmenova Duh, in addition to the Deputy Director General of UNESCO for Social Sciences and Humanities Gabriele Ramos, the Spanish Secretary of State for Digitization and Artificial Intelligence Carma Artigas, the Undersecretary of Chile for Science, Technology, Knowledge and Innovation Carolina Gainza and the Executive Director of the Center for the Fourth Industrial Revolution in Saudi Basma Al-Buhairan of Arabia participated in a high-level meeting as part of the conference, where they focused mainly on political measures and international cooperation.
At the session, the participants discussed the opportunities and challenges of neurotechnology, its use at the national level, and the role of UNESCO in solving challenges related to neurotechnology and its management. Minister dr. At the conference, Stojmenova Duh defended the position that neurotechnology offers extraordinary opportunities for understanding the functioning of the brain, improving people's health, their cognitive abilities and the quality of life, but it also presents challenges, so it is crucial that its development is based on ethics, justice, responsibility and inclusion. ""Ethical principles and respect for human rights must be incorporated at the very beginning of the development of new technologies. This is why we need close cooperation between governments, businesses, researchers, academics and civil society globally. The dialogue we have at the global level, must be developed among all stakeholders of the digital ecosystem also at the national level,"" said the minister, adding that international organizations such as UNESCO play an important role in the preparation of common ethical guidelines and regulations at the global level, as well as capacity building and knowledge exchange. She also pointed out that Slovenia strongly supports the work of the International Committee for Bioethics at UNESCO on the ethical issues of neurotechnology and advocates for the establishment of a common ethical.
""We believe that all international organizations dealing with artificial intelligence should work closely together. Therefore, at the beginning of next year, together with UNESCO, we will organize a world forum on ethics in artificial intelligence, to which we will invite representatives of international organizations in order to find joint solutions to the challenges of ethics and reliability of artificial intelligence,"" she added.
""Neurotechnology has enormous potential to reduce the consequences of serious neurological disorders such as epilepsy, Alzheimer's, Parkinson's disease and stroke. The fear of new technologies such as artificial intelligence should not stop us from using them, as they are tools that increase efficiency and innovation and can greatly improve the quality of our lives. However, they must be designed transparently and responsibly. Slovenia therefore advocates for the establishment of solid ethical and legal frameworks to prevent the malicious use of artificial intelligence in the field of neurotechnology,"" said Minister Dr. Stojmenova Duh summarized Slovenia's position at the end of the session.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 193
Subject: ETHICS (95%); ASSOCIATIONS & ORGANIZATIONS (90%); CONFERENCES & CONVENTIONS (90%); HUMAN RIGHTS (90%); INTERNATIONAL RELATIONS (90%); NEUROSCIENCE (90%); UNITED NATIONS (90%); UNITED NATIONS INSTITUTIONS (90%); ARTIFICIAL INTELLIGENCE (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); TALKS & MEETINGS (89%); ELECTIONS & POLITICS (79%); GOVERNMENT ADVISORS & MINISTERS (79%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BIOETHICS (78%); HUMANITIES & SOCIAL SCIENCE (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); POLITICS (76%); EXECUTIVES (75%); EMERGING TECHNOLOGY (73%); INTELLIGENCE & COGNITION (73%); STANDARDS & MEASUREMENTS (70%)
Industry: PRESS AGENCY RELEASES (90%); ARTIFICIAL INTELLIGENCE (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%)
Geographic: SLOVENIA (92%); SAUDI ARABIA (79%)
Load-Date: July 25, 2023",neutral,0.6641746759414673,balanced/neutral,"['security', 'human rights', 'agency']","['justice', 'justice']","['regulation', 'standards', 'guidelines', 'framework', 'should', 'must']",[],3,2,6,0
2023,Unknown Title,"Byline: Hillary
Body
November 27th, 2023 ( TechBullion  — Delivered by  Newstex )
In a world driven by innovation and constant technological advancements, we find ourselves facing an increasingly complex question: should technology be subject to regulations? As our reliance on tech has grown exponentially, so too have the ethical dilemmas surrounding its usage. From data privacy concerns to the rise of AI-powered automation, striking the right balance between progress and accountability is no easy feat. Join us on a thought-provoking journey as we navigate these treacherous waters and explore whether or not it's time to rein in technology through regulations.
The Rapid Advancement of Technology: Benefits and Consequences
The rapid advancement of technology has drastically transformed the world we live in, revolutionizing industries and changing the way we interact with each other. From artificial intelligence to virtual reality, these technological advancements have brought numerous benefits to our society. However, with great power comes great responsibility, as there are also consequences that come along with this rapid growth.
Benefits:
One of the biggest advantages of technology is its ability to improve efficiency and productivity in various fields. Through automation and AI, tasks can be completed much faster and with greater accuracy than ever before. This has not only made our lives easier but has also led to significant economic growth for businesses around the world.
In addition, technology has greatly improved communication and connectivity across the globe. With just a click of a button, people can now connect with others from different parts of the world in real-time. This has opened up opportunities for collaboration and innovation on a global scale.
Furthermore, modern technology has also greatly enhanced education by providing students and educators access to vast amounts of information at their fingertips. Online learning platforms, virtual classrooms, and educational apps have made learning more accessible and engaging for students of all ages.
Consequences:
While there are undoubtedly many benefits to technological advancements, there are also concerns about their potential negative consequences. One major consequence is the rising issue of job displacement due to automation. As more jobs become automated or outsourced to machines, it raises questions about job security for workers in various industries.
Moreover, excessive use of technology has been linked to various physical and mental health issues. Constant exposure to screens can lead to eye strain, headaches, and even sleep disorders. Additionally, people's addiction to technology has been shown to cause social isolation and a decline in face-to-face interactions.
Another concern is the potential for technological advancements to increase the wealth gap between different socioeconomic classes. While technology has created new job opportunities and ways to generate income for some, it has also widened the gap between those who have access to these advancements and those who do not.
Growing Concerns: Ethical Dilemmas in the Tech Industry
The growth and innovation in the tech industry have undoubtedly brought immense benefits to our daily lives. From convenience and efficiency to connectivity and accessibility, technology has revolutionized the way we live, work, and communicate.
However, with this rapid development also comes a growing concern for ethical dilemmas within the tech industry. As technologies continue to advance at an unprecedented pace, it has become increasingly challenging to address and regulate potential ethical issues that may arise.
One of the key concerns surrounding ethical dilemmas in the tech industry is privacy and data protection. With the constant collection and utilization of personal data by companies, there are legitimate fears about how this information is being used, who has access to it, and whether it is being adequately safeguarded. This issue was recently highlighted in Facebook's Cambridge Analytica scandal where millions of users' personal data were harvested without their consent for political purposes.
Moreover, as artificial intelligence (AI) becomes more prevalent in various industries, questions are being raised about its potential impact on society. Will AI replace human jobs? Can AI systems exhibit biased or discriminatory behavior? How do we ensure transparency and accountability when decisions are made by machines?
Another pressing concern is the lack of diversity within the tech industry. Despite efforts to promote inclusivity and diversity in hiring practices, reports show that major tech companies still have a predominantly white male workforce. This homogenization can lead to discriminatory algorithms or products that do not cater to diverse populations.
Case Studies: Examples of Technology That Have Caused Controversy
Technology is advancing at an unprecedented rate, with new innovations constantly emerging. While these advancements bring numerous benefits and conveniences to our lives, they also raise ethical concerns and controversies. In this section, we will explore some case studies of technology that have caused controversy and examine the ethical dilemmas surrounding them.
1. Facial Recognition Technology
Facial recognition technology has become increasingly prevalent in recent years, with its use ranging from security and surveillance to marketing and convenience features on mobile devices. However, its deployment has sparked debates about privacy, discrimination, and government overreach.
In China, facial recognition technology is widely used by the government for mass surveillance purposes. This has raised concerns about privacy violations as well as the potential for this data to be used for controlling citizens' behavior or targeting certain groups unfairly.
Similarly, the use of facial recognition in law enforcement in other countries has been met with criticism due to concerns about racial bias in identifying suspects. For instance, studies have shown that these systems are less accurate at recognizing people of color compared to white individuals.
2. Autonomous Vehicles
Autonomous vehicles have been hailed as a major technological breakthrough with the potential to revolutionize transportation and reduce human error-related accidents on the road. However, their development raises ethical questions around safety regulations, responsibility for accidents involving autonomous vehicles, and job displacement.
One prominent example is Uber's self-driving car experiment which resulted in a fatal accident involving a pedestrian in 2018. This raised questions about the readiness and safety of autonomous technology, as well as ethical concerns around liability and responsibility in case of accidents.
Additionally, the rise of self-driving trucks has sparked debates about the potential impact on jobs in the trucking industry. While proponents argue that it could increase efficiency and reduce costs, critics fear that it will lead to job loss for millions of truck drivers.
3. Social Media Algorithms
Social media algorithms use complex data analysis to determine what content is shown to users based on their interests and behaviors. While this may seem harmless, it has led to numerous ethical issues such as polarization, misinformation, and addiction.
The 2016 U.S. presidential election brought attention to the manipulation of social media algorithms by political campaigns to target specific voters with tailored messages. This has led to concerns about the impact on democratic processes as well as privacy violations.
Moreover, social media platforms have been criticized for contributing to political polarization by promoting highly partisan or sensational content in order to keep users engaged. This can lead to echo chambers where individuals only see information that aligns with their beliefs, further exacerbating societal divisions.
The Role of Regulations in Society
Regulations are a set of rules and laws that govern the actions and behaviors of individuals or organizations within a society. In essence, regulations act as a guideline for how people should interact with each other and conduct themselves in various situations. While regulations apply to various areas of society, such as business, medicine, and education, they also play a critical role when it comes to technology.
In today's fast-paced world where technology is constantly evolving, there has been an ongoing debate on whether or not this sector should be subject to regulations. Some argue that strict regulations hinder innovation and progress while others believe that without appropriate regulations in place, technology can cause harm to individuals and society as a whole. To understand the role of regulations in society, we must examine their purpose and the benefits they provide.
Promotion of Ethical Behavior
One of the primary roles of regulations is to promote ethical behavior among individuals and organizations. Technology can have immense power when it comes to data collection , storage, manipulation, and distribution. Without proper guidelines in place, there is potential for misuse by both companies and individuals. As seen in recent cases like Cambridge Analytica's involvement in political campaigns or the Equifax data breach that exposed personal information of millions; lack of regulations can lead to ethical dilemmas causing harm to innocent parties.
Ensuring Consumer Protection
Another crucial role played by regulations is ensuring consumer protection. With advancements in technology come new products and services that may have loopholes or defects which can harm consumers. In such cases, regulations are essential to safeguard the interests of customers and hold companies accountable for their products and services. For instance, laws like the General Data Protection Regulation (GDPR) in the European Union protect individuals' personal data and give them control over how it is collected and used.
Fostering Fair Competition
Regulations also promote fair competition among businesses by setting standards that all must adhere to. Without regulations, larger companies may have an unfair advantage over smaller ones, creating monopolies that limit consumer choice and raise prices. By enforcing regulations on areas such as competition, employment practices, and consumer rights, a level playing field can be maintained for all businesses.
Protection of Public Interest
In addition to promoting ethical behavior, consumer protection, and fair competition, regulations also play a vital role in protecting the public interest. This can include ensuring safety standards are met for products or services that could potentially harm individuals or society at large. For example, regulations enforced by government agencies like the Food and Drug Administration (FDA) ensure that medications and food products are safe for consumption.
Arguments for Regulating Technology
There are many arguments in favor of regulating technology to ensure ethical practices and promote responsible use. In this section, we will discuss some of the key reasons why regulations are necessary for technology.
1. Protecting Privacy:
One of the most pressing concerns related to technology is privacy. With the increasing use of personal data by companies and governments, there is a growing need for regulations that protect individuals' privacy rights. This can include laws governing how companies collect, use, and share personal information, as well as measures to prevent unauthorized access or misuse of this data. Regulating technology can also help address issues such as cyberbullying and online harassment, which can have severe consequences on individuals' mental health and well-being.
2. Ensuring Safety:
Another critical argument for regulating technology is to ensure safety standards are upheld in various industries such as healthcare, transportation, and energy. For example, self-driving cars require strict regulations to prevent accidents and protect passengers' lives. Similarly, medical devices must meet regulatory requirements to guarantee their effectiveness and minimize potential risks to patients.
3. Managing Disruptive Technology:
Technology has the power to disrupt industries by automating processes and replacing traditional jobs with machines or software programs. While technological advancements bring numerous benefits, they also raise ethical dilemmas related to job displacement and income inequality. By enacting appropriate regulations, policymakers can mitigate these disruptions by promoting re-skilling programs or ensuring fair distribution of wealth generated through technological innovations.
Arguments Against Regulating Technology
While there are certainly valid arguments for regulating technology in order to mitigate potential risks and ethical concerns, there are also strong arguments against implementing strict regulations on technological advancements. These arguments often stem from the belief that government intervention in the rapidly evolving world of technology could stifle innovation, hinder economic growth, and limit individual freedoms.
One major argument against regulating technology is that it would impede progress and innovation. The rapid pace of technological development has led to significant improvements in various industries such as healthcare, transportation, communication, and agriculture. Proponents argue that regulation may slow down this progress by limiting experimentation and hindering exploration of new ideas. They also point out that innovation often occurs through trial and error, which could be constrained by stringent regulations.
Moreover, strict regulations can strain the financial resources of companies trying to comply with them. This could especially burden smaller businesses or startups who may not have the funds to hire compliance officers or invest in expensive technologies necessary to meet regulatory standards. As a result, these regulations could create barriers to entry for new companies wanting to enter the market and compete with established players.
Another argument against regulating technology is that it could negatively impact economic growth. In today's global economy where technology plays a vital role in driving growth and creating jobs, overly restrictive regulations could have detrimental effects on businesses' ability to innovate and compete internationally. This could lead to job losses, reduced investments in research and development, decreased productivity, and an overall slowdown in economic growth.
Finding a Balance: Potential Solutions and Compromises
In this rapidly advancing technological age, there is a growing concern over the lack of regulations surrounding technology and its impact on society. On one hand, unrestricted technological innovation has brought about countless benefits and advancements in various industries. But on the other hand, it has also raised ethical dilemmas that pose potential harm to individuals and society as a whole.
To address these concerns, finding a balance between regulating technology and allowing for its continued development is crucial. In this section, we will explore some potential solutions and compromises that can help navigate the ethical dilemmas surrounding technological advancements.
1. Cooperation between stakeholders:
In order to find an effective balance, it is essential for all stakeholders - governments, corporations, developers, consumers, and experts - to collaborate and work together towards creating responsible regulations. This cooperation ensures that different perspectives are taken into consideration and helps prevent any biased or self-serving decisions.
2. Ethical standards for developers:
Developers play a significant role in shaping technology and its impact on society. Therefore, implementing ethical standards for developers can serve as a guideline for responsible tech innovation. These standards could include considerations such as privacy protection, data security measures, transparency in algorithms used by AI systems etc.
3. Government regulations:
Governments have a responsibility to safeguard their citizens from potentially harmful effects of technology while still promoting its growth. Regulations can be put in place to ensure companies abide by ethical practices in terms of user privacy protections, data collection policies or adherence to certain ethical codes of conduct.
Conclusion
As technology continues to advance at a rapid pace, ethical dilemmas regarding its regulation are becoming increasingly prevalent. While some argue that technology should be free from regulations in order to allow for innovation and growth, others believe that there need to be strict guidelines in place to protect individuals and society as a whole. Both sides have valid points, but ultimately it is important for us all to consider both the benefits and potential consequences of unregulated technology. Finding a balance between promoting progress while also addressing ethical concerns is crucial as we move forward into an even more technologically advanced future.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); DISTANCE LEARNING (88%); DIGITAL ADDICTION (79%); BLOGS & MESSAGE BOARDS (78%); JOB CREATION (78%); OUTSOURCING (78%); INTERPERSONAL COMMUNICATION (73%); PRIVACY RIGHTS (73%); ECONOMIC GROWTH (71%); TEACHING & TEACHERS (69%); SOCIAL ISOLATION (68%); MEDICINE & HEALTH (60%); MENTAL HEALTH (50%); SLEEP DISORDERS (50%); Technology (%); cars (%); Companies (%); data (%); Ethics (%); innovation (%); Job (%); privacy (%); technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (89%); BLOGS & MESSAGE BOARDS (78%); INFORMATION SECURITY & PRIVACY (78%); VIRTUAL REALITY (68%)
Load-Date: November 27, 2023","November 27th, 2023 ( TechBullion  — Delivered by  Newstex )
In a world driven by innovation and constant technological advancements, we find ourselves facing an increasingly complex question: should technology be subject to regulations? As our reliance on tech has grown exponentially, so too have the ethical dilemmas surrounding its usage. From data privacy concerns to the rise of AI-powered automation, striking the right balance between progress and accountability is no easy feat. Join us on a thought-provoking journey as we navigate these treacherous waters and explore whether or not it's time to rein in technology through regulations.
The Rapid Advancement of Technology: Benefits and Consequences
The rapid advancement of technology has drastically transformed the world we live in, revolutionizing industries and changing the way we interact with each other. From artificial intelligence to virtual reality, these technological advancements have brought numerous benefits to our society. However, with great power comes great responsibility, as there are also consequences that come along with this rapid growth.
Benefits:
One of the biggest advantages of technology is its ability to improve efficiency and productivity in various fields. Through automation and AI, tasks can be completed much faster and with greater accuracy than ever before. This has not only made our lives easier but has also led to significant economic growth for businesses around the world.
In addition, technology has greatly improved communication and connectivity across the globe. With just a click of a button, people can now connect with others from different parts of the world in real-time. This has opened up opportunities for collaboration and innovation on a global scale.
Furthermore, modern technology has also greatly enhanced education by providing students and educators access to vast amounts of information at their fingertips. Online learning platforms, virtual classrooms, and educational apps have made learning more accessible and engaging for students of all ages.
Consequences:
While there are undoubtedly many benefits to technological advancements, there are also concerns about their potential negative consequences. One major consequence is the rising issue of job displacement due to automation. As more jobs become automated or outsourced to machines, it raises questions about job security for workers in various industries.
Moreover, excessive use of technology has been linked to various physical and mental health issues. Constant exposure to screens can lead to eye strain, headaches, and even sleep disorders. Additionally, people's addiction to technology has been shown to cause social isolation and a decline in face-to-face interactions.
Another concern is the potential for technological advancements to increase the wealth gap between different socioeconomic classes. While technology has created new job opportunities and ways to generate income for some, it has also widened the gap between those who have access to these advancements and those who do not.
Growing Concerns: Ethical Dilemmas in the Tech Industry
The growth and innovation in the tech industry have undoubtedly brought immense benefits to our daily lives. From convenience and efficiency to connectivity and accessibility, technology has revolutionized the way we live, work, and communicate.
However, with this rapid development also comes a growing concern for ethical dilemmas within the tech industry. As technologies continue to advance at an unprecedented pace, it has become increasingly challenging to address and regulate potential ethical issues that may arise.
One of the key concerns surrounding ethical dilemmas in the tech industry is privacy and data protection. With the constant collection and utilization of personal data by companies, there are legitimate fears about how this information is being used, who has access to it, and whether it is being adequately safeguarded. This issue was recently highlighted in Facebook's Cambridge Analytica scandal where millions of users' personal data were harvested without their consent for political purposes.
Moreover, as artificial intelligence (AI) becomes more prevalent in various industries, questions are being raised about its potential impact on society. Will AI replace human jobs? Can AI systems exhibit biased or discriminatory behavior? How do we ensure transparency and accountability when decisions are made by machines?
Another pressing concern is the lack of diversity within the tech industry. Despite efforts to promote inclusivity and diversity in hiring practices, reports show that major tech companies still have a predominantly white male workforce. This homogenization can lead to discriminatory algorithms or products that do not cater to diverse populations.
Case Studies: Examples of Technology That Have Caused Controversy
Technology is advancing at an unprecedented rate, with new innovations constantly emerging. While these advancements bring numerous benefits and conveniences to our lives, they also raise ethical concerns and controversies. In this section, we will explore some case studies of technology that have caused controversy and examine the ethical dilemmas surrounding them.
1. Facial Recognition Technology
Facial recognition technology has become increasingly prevalent in recent years, with its use ranging from security and surveillance to marketing and convenience features on mobile devices. However, its deployment has sparked debates about privacy, discrimination, and government overreach.
In China, facial recognition technology is widely used by the government for mass surveillance purposes. This has raised concerns about privacy violations as well as the potential for this data to be used for controlling citizens' behavior or targeting certain groups unfairly.
Similarly, the use of facial recognition in law enforcement in other countries has been met with criticism due to concerns about racial bias in identifying suspects. For instance, studies have shown that these systems are less accurate at recognizing people of color compared to white individuals.
2. Autonomous Vehicles
Autonomous vehicles have been hailed as a major technological breakthrough with the potential to revolutionize transportation and reduce human error-related accidents on the road. However, their development raises ethical questions around safety regulations, responsibility for accidents involving autonomous vehicles, and job displacement.
One prominent example is Uber's self-driving car experiment which resulted in a fatal accident involving a pedestrian in 2018. This raised questions about the readiness and safety of autonomous technology, as well as ethical concerns around liability and responsibility in case of accidents.
Additionally, the rise of self-driving trucks has sparked debates about the potential impact on jobs in the trucking industry. While proponents argue that it could increase efficiency and reduce costs, critics fear that it will lead to job loss for millions of truck drivers.
3. Social Media Algorithms
Social media algorithms use complex data analysis to determine what content is shown to users based on their interests and behaviors. While this may seem harmless, it has led to numerous ethical issues such as polarization, misinformation, and addiction.
The 2016 U.S. presidential election brought attention to the manipulation of social media algorithms by political campaigns to target specific voters with tailored messages. This has led to concerns about the impact on democratic processes as well as privacy violations.
Moreover, social media platforms have been criticized for contributing to political polarization by promoting highly partisan or sensational content in order to keep users engaged. This can lead to echo chambers where individuals only see information that aligns with their beliefs, further exacerbating societal divisions.
The Role of Regulations in Society
Regulations are a set of rules and laws that govern the actions and behaviors of individuals or organizations within a society. In essence, regulations act as a guideline for how people should interact with each other and conduct themselves in various situations. While regulations apply to various areas of society, such as business, medicine, and education, they also play a critical role when it comes to technology.
In today's fast-paced world where technology is constantly evolving, there has been an ongoing debate on whether or not this sector should be subject to regulations. Some argue that strict regulations hinder innovation and progress while others believe that without appropriate regulations in place, technology can cause harm to individuals and society as a whole. To understand the role of regulations in society, we must examine their purpose and the benefits they provide.
Promotion of Ethical Behavior
One of the primary roles of regulations is to promote ethical behavior among individuals and organizations. Technology can have immense power when it comes to data collection , storage, manipulation, and distribution. Without proper guidelines in place, there is potential for misuse by both companies and individuals. As seen in recent cases like Cambridge Analytica's involvement in political campaigns or the Equifax data breach that exposed personal information of millions; lack of regulations can lead to ethical dilemmas causing harm to innocent parties.
Ensuring Consumer Protection
Another crucial role played by regulations is ensuring consumer protection. With advancements in technology come new products and services that may have loopholes or defects which can harm consumers. In such cases, regulations are essential to safeguard the interests of customers and hold companies accountable for their products and services. For instance, laws like the General Data Protection Regulation (GDPR) in the European Union protect individuals' personal data and give them control over how it is collected and used.
Fostering Fair Competition
Regulations also promote fair competition among businesses by setting standards that all must adhere to. Without regulations, larger companies may have an unfair advantage over smaller ones, creating monopolies that limit consumer choice and raise prices. By enforcing regulations on areas such as competition, employment practices, and consumer rights, a level playing field can be maintained for all businesses.
Protection of Public Interest
In addition to promoting ethical behavior, consumer protection, and fair competition, regulations also play a vital role in protecting the public interest. This can include ensuring safety standards are met for products or services that could potentially harm individuals or society at large. For example, regulations enforced by government agencies like the Food and Drug Administration (FDA) ensure that medications and food products are safe for consumption.
Arguments for Regulating Technology
There are many arguments in favor of regulating technology to ensure ethical practices and promote responsible use. In this section, we will discuss some of the key reasons why regulations are necessary for technology.
1. Protecting Privacy:
One of the most pressing concerns related to technology is privacy. With the increasing use of personal data by companies and governments, there is a growing need for regulations that protect individuals' privacy rights. This can include laws governing how companies collect, use, and share personal information, as well as measures to prevent unauthorized access or misuse of this data. Regulating technology can also help address issues such as cyberbullying and online harassment, which can have severe consequences on individuals' mental health and well-being.
2. Ensuring Safety:
Another critical argument for regulating technology is to ensure safety standards are upheld in various industries such as healthcare, transportation, and energy. For example, self-driving cars require strict regulations to prevent accidents and protect passengers' lives. Similarly, medical devices must meet regulatory requirements to guarantee their effectiveness and minimize potential risks to patients.
3. Managing Disruptive Technology:
Technology has the power to disrupt industries by automating processes and replacing traditional jobs with machines or software programs. While technological advancements bring numerous benefits, they also raise ethical dilemmas related to job displacement and income inequality. By enacting appropriate regulations, policymakers can mitigate these disruptions by promoting re-skilling programs or ensuring fair distribution of wealth generated through technological innovations.
Arguments Against Regulating Technology
While there are certainly valid arguments for regulating technology in order to mitigate potential risks and ethical concerns, there are also strong arguments against implementing strict regulations on technological advancements. These arguments often stem from the belief that government intervention in the rapidly evolving world of technology could stifle innovation, hinder economic growth, and limit individual freedoms.
One major argument against regulating technology is that it would impede progress and innovation. The rapid pace of technological development has led to significant improvements in various industries such as healthcare, transportation, communication, and agriculture. Proponents argue that regulation may slow down this progress by limiting experimentation and hindering exploration of new ideas. They also point out that innovation often occurs through trial and error, which could be constrained by stringent regulations.
Moreover, strict regulations can strain the financial resources of companies trying to comply with them. This could especially burden smaller businesses or startups who may not have the funds to hire compliance officers or invest in expensive technologies necessary to meet regulatory standards. As a result, these regulations could create barriers to entry for new companies wanting to enter the market and compete with established players.
Another argument against regulating technology is that it could negatively impact economic growth. In today's global economy where technology plays a vital role in driving growth and creating jobs, overly restrictive regulations could have detrimental effects on businesses' ability to innovate and compete internationally. This could lead to job losses, reduced investments in research and development, decreased productivity, and an overall slowdown in economic growth.
Finding a Balance: Potential Solutions and Compromises
In this rapidly advancing technological age, there is a growing concern over the lack of regulations surrounding technology and its impact on society. On one hand, unrestricted technological innovation has brought about countless benefits and advancements in various industries. But on the other hand, it has also raised ethical dilemmas that pose potential harm to individuals and society as a whole.
To address these concerns, finding a balance between regulating technology and allowing for its continued development is crucial. In this section, we will explore some potential solutions and compromises that can help navigate the ethical dilemmas surrounding technological advancements.
1. Cooperation between stakeholders:
In order to find an effective balance, it is essential for all stakeholders - governments, corporations, developers, consumers, and experts - to collaborate and work together towards creating responsible regulations. This cooperation ensures that different perspectives are taken into consideration and helps prevent any biased or self-serving decisions.
2. Ethical standards for developers:
Developers play a significant role in shaping technology and its impact on society. Therefore, implementing ethical standards for developers can serve as a guideline for responsible tech innovation. These standards could include considerations such as privacy protection, data security measures, transparency in algorithms used by AI systems etc.
3. Government regulations:
Governments have a responsibility to safeguard their citizens from potentially harmful effects of technology while still promoting its growth. Regulations can be put in place to ensure companies abide by ethical practices in terms of user privacy protections, data collection policies or adherence to certain ethical codes of conduct.
Conclusion
As technology continues to advance at a rapid pace, ethical dilemmas regarding its regulation are becoming increasingly prevalent. While some argue that technology should be free from regulations in order to allow for innovation and growth, others believe that there need to be strict guidelines in place to protect individuals and society as a whole. Both sides have valid points, but ultimately it is important for us all to consider both the benefits and potential consequences of unregulated technology. Finding a balance between promoting progress while also addressing ethical concerns is crucial as we move forward into an even more technologically advanced future.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); DISTANCE LEARNING (88%); DIGITAL ADDICTION (79%); BLOGS & MESSAGE BOARDS (78%); JOB CREATION (78%); OUTSOURCING (78%); INTERPERSONAL COMMUNICATION (73%); PRIVACY RIGHTS (73%); ECONOMIC GROWTH (71%); TEACHING & TEACHERS (69%); SOCIAL ISOLATION (68%); MEDICINE & HEALTH (60%); MENTAL HEALTH (50%); SLEEP DISORDERS (50%); Technology (%); cars (%); Companies (%); data (%); Ethics (%); innovation (%); Job (%); privacy (%); technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (89%); BLOGS & MESSAGE BOARDS (78%); INFORMATION SECURITY & PRIVACY (78%); VIRTUAL REALITY (68%)
Load-Date: November 27, 2023",neutral,0.7603834271430969,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'transparency', 'accountability', 'job loss', 'safety', 'security', 'consent', 'manipulation', 'misinformation', 'inclusivity', 'access', 'inequality']",[],"['regulation', 'standards', 'guidelines', 'law', 'compliance', 'should', 'must', 'need to']","['facial recognition', 'self-driving car']",15,0,8,2
2023,Unknown Title,"Byline: Hemant Sood
Body
Algorithmic trading has taken the Indian financial markets by storm, providing swift decision-making and efficient market execution. According to a report on algo trading by the National Institute of Financial Management (NIFM), 80% of the algorithmic orders are generated from the co-location of NSE and BSE. This showcases how well algo trading has gained ground in India in such a short amount of time. Today, along with institutional investors, retail traders are also using this method to attain lucrative returns. 
However, along with these technological advancements lie a few ethical dilemmas and biases that are poised to sway market dynamics and influence investor confidence.Ethical dilemmas in algo tradingLet us delve into some of the ethical dilemmas that could impact the results of algo trading.Biases: If the algorithms are fed with incomplete data, then the results will not be accurate. The historical data used may reflect past inequalities that may divert the results to a certain industry or sector.Complete reliance on systems: Relying entirely on algo trading gives rise to the absence of human conscience in decision-making. For instance, fake news might let the market tumble down, and the algo might follow its course and sell profusely, leading to subsequent losses.Front-running: There is a probability that the algorithms can exploit the speed to execute a trade ahead of others, which can give them an unfair advantage.Based on these dilemmas, it has become crucial to safeguard ethical trading. For this, the traders must have some ethical considerations while conducting algo trading.Ethical considerationsFairness:It is crucial to ensure that one algo strategy is not giving an unfair advantage to an individual or a group in the market. For instance, the algorithms used trade faster than manual traders who do not have access to this technology. Therefore, the issue of fairness is a critical ethical consideration.Transparency:It is critical to make sure algorithms are not being used fraudulently or to manipulate the market. This necessitates openness in the development and application of algorithms as well as the sharing of details regarding the inputs and data utilised to produce trading decisions. In this regard, SEBI has already proposed regulatory checks for algorithmic trading in 2021.Data Privacy:Algo trading requires a myriad of data collection and processing, which also includes sensitive data. Therefore, it is essential that this data be used in an ethical and responsible manner to safeguard the terms of data privacy.Systematic Risks:Trading using algorithms carries the risk of systemic instability that might affect the whole financial system. For instance, if several algorithms are set up to react to market developments in the same way, this may result in a feedback loop that can intensify volatility and eventually can cause a downtrend.Human involvement:Regardless of the fact that algo trading enhances the proficiency of trading, it is significant to ensure that human oversight is maintained in the sessions. Moreover, the traders must also make sure that the algorithm is not engaging in unethical behaviour, which will help them to negate any unintended consequences.Striking the BalanceSimilar to any powerful strategy, algorithmic trading is neutral in itself. Depending on its usage, it can either be a force for good or a source of chaos. In this context, ethical dilemmas such as biases, a lack of human conscience, and front-running are some of the issues that need to be addressed. In a bid to negate these obstacles, there are some ethical considerations that traders need to pay attention to. These factors can include fairness, transparency, data privacy, systematic risks, and human involvement, which can help the participants strike a balance between responsibility and profitability.Financial institutions and retail investors must adopt the best ethical practices and ensure intelligent systems are built and deployed responsibly. It must also include regular monitoring of the trading systems and addressing the issues promptly. Using AI in a responsible manner, considering its impact on the financial markets, will only foster a healthy trading environment for each participant. Therefore, ethics today have become a crucial factor for every trader engaging in algo trading. (The author is Founder Findoc)(Disclaimer: Recommendations, suggestions, views, and opinions given by experts are their own. These do not represent the views of the Economic Times) For Reprint Rights: timescontent.com
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); FINANCIAL MARKETS & INVESTING (90%); BANKING & FINANCE ASSOCIATIONS (89%); MARKET MANIPULATION (79%); FAKE NEWS (78%); TRENDS (78%); HISTORY (68%); FINANCIAL MARKET UPDATES (59%); STOCK MARKET UPDATES (59%)
Industry: FINANCIAL MARKETS & INVESTING (90%); BANKING & FINANCE ASSOCIATIONS (89%); BANKING & FINANCE REGULATION & POLICY (89%); BANKING & FINANCE (79%); MARKET MANIPULATION (79%); RETAIL & WHOLESALE TRADE (74%); INFORMATION SECURITY & PRIVACY (73%); FINANCIAL MARKET UPDATES (59%); STOCK MARKET UPDATES (59%)
Geographic: INDIA (79%)
Load-Date: December 1, 2023","Algorithmic trading has taken the Indian financial markets by storm, providing swift decision-making and efficient market execution. According to a report on algo trading by the National Institute of Financial Management (NIFM), 80% of the algorithmic orders are generated from the co-location of NSE and BSE. This showcases how well algo trading has gained ground in India in such a short amount of time. Today, along with institutional investors, retail traders are also using this method to attain lucrative returns. 
However, along with these technological advancements lie a few ethical dilemmas and biases that are poised to sway market dynamics and influence investor confidence.Ethical dilemmas in algo tradingLet us delve into some of the ethical dilemmas that could impact the results of algo trading.Biases: If the algorithms are fed with incomplete data, then the results will not be accurate. The historical data used may reflect past inequalities that may divert the results to a certain industry or sector.Complete reliance on systems: Relying entirely on algo trading gives rise to the absence of human conscience in decision-making. For instance, fake news might let the market tumble down, and the algo might follow its course and sell profusely, leading to subsequent losses.Front-running: There is a probability that the algorithms can exploit the speed to execute a trade ahead of others, which can give them an unfair advantage.Based on these dilemmas, it has become crucial to safeguard ethical trading. For this, the traders must have some ethical considerations while conducting algo trading.Ethical considerationsFairness:It is crucial to ensure that one algo strategy is not giving an unfair advantage to an individual or a group in the market. For instance, the algorithms used trade faster than manual traders who do not have access to this technology. Therefore, the issue of fairness is a critical ethical consideration.Transparency:It is critical to make sure algorithms are not being used fraudulently or to manipulate the market. This necessitates openness in the development and application of algorithms as well as the sharing of details regarding the inputs and data utilised to produce trading decisions. In this regard, SEBI has already proposed regulatory checks for algorithmic trading in 2021.Data Privacy:Algo trading requires a myriad of data collection and processing, which also includes sensitive data. Therefore, it is essential that this data be used in an ethical and responsible manner to safeguard the terms of data privacy.Systematic Risks:Trading using algorithms carries the risk of systemic instability that might affect the whole financial system. For instance, if several algorithms are set up to react to market developments in the same way, this may result in a feedback loop that can intensify volatility and eventually can cause a downtrend.Human involvement:Regardless of the fact that algo trading enhances the proficiency of trading, it is significant to ensure that human oversight is maintained in the sessions. Moreover, the traders must also make sure that the algorithm is not engaging in unethical behaviour, which will help them to negate any unintended consequences.Striking the BalanceSimilar to any powerful strategy, algorithmic trading is neutral in itself. Depending on its usage, it can either be a force for good or a source of chaos. In this context, ethical dilemmas such as biases, a lack of human conscience, and front-running are some of the issues that need to be addressed. In a bid to negate these obstacles, there are some ethical considerations that traders need to pay attention to. These factors can include fairness, transparency, data privacy, systematic risks, and human involvement, which can help the participants strike a balance between responsibility and profitability.Financial institutions and retail investors must adopt the best ethical practices and ensure intelligent systems are built and deployed responsibly. It must also include regular monitoring of the trading systems and addressing the issues promptly. Using AI in a responsible manner, considering its impact on the financial markets, will only foster a healthy trading environment for each participant. Therefore, ethics today have become a crucial factor for every trader engaging in algo trading. (The author is Founder Findoc)(Disclaimer: Recommendations, suggestions, views, and opinions given by experts are their own. These do not represent the views of the Economic Times) For Reprint Rights: timescontent.com
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); FINANCIAL MARKETS & INVESTING (90%); BANKING & FINANCE ASSOCIATIONS (89%); MARKET MANIPULATION (79%); FAKE NEWS (78%); TRENDS (78%); HISTORY (68%); FINANCIAL MARKET UPDATES (59%); STOCK MARKET UPDATES (59%)
Industry: FINANCIAL MARKETS & INVESTING (90%); BANKING & FINANCE ASSOCIATIONS (89%); BANKING & FINANCE REGULATION & POLICY (89%); BANKING & FINANCE (79%); MARKET MANIPULATION (79%); RETAIL & WHOLESALE TRADE (74%); INFORMATION SECURITY & PRIVACY (73%); FINANCIAL MARKET UPDATES (59%); STOCK MARKET UPDATES (59%)
Geographic: INDIA (79%)
Load-Date: December 1, 2023",positive,0.5297790169715881,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security', 'manipulation', 'access']",['fairness'],"['regulation', 'policy', 'oversight', 'must', 'need to']",['algorithm'],6,1,5,1
2023,Unknown Title,"Body
NEW YORK, NY, Aug.  23, 2023  (GLOBE NEWSWIRE) -- via NewMediaWire - Ethical Web AI, also known as Bubblr, Inc. (OTC: BBLR), a pioneering ethical technology firm dedicated to reshaping the online experience, is thrilled to unveil Version 2.0 of its cutting-edge AI Seek consumer app. This new release brings a more affordable and enriched Chat GPT 4.0 experience to users. AI Seek 2.0 is now available for submission to both the Apple and Google Play Store.
Since its initial launch on July 30th, AI Seek has gained traction among users, though it has not yet been extensively marketed. Based on invaluable feedback from early members, the Ethical Web AI team has been able to craft an improved and more intuitive user experience in this updated version.
AI Seek 2.0 boasts a complete redesign, making it even more accessible for users of all tech backgrounds. Gone are the days of navigating through menus; now, users can enjoy icon-driven functions complete with tooltips. Plus, the updated appearance is clean and streamlined, optimized for effortless navigation and usability. AI Seek's user interface (UI) now aligns with the sleek and minimalist aesthetics of Apple's Cupertino and Google's Material design frameworks.
In line with our previous press release, this revamped version of AI Seek will serve as the foundation for essential explainer videos on the AI Seek website, providing users with a more comprehensive understanding of the app's capabilities. Furthermore, we're excited to announce the development of instructive video tutorials that will showcase a variety of use-case scenarios.
One standout feature of the synchronized desktop microsite is the ability to export results to various file formats, including Microsoft Word, Adobe Acrobat, or even programming language files like DART and Python, without any loss of formatting. This added functionality, not currently available in the native Chat GPT version, is sure to make AI Seek a preferred choice among users.
The Ethical Web AI team is already hard at work on the next iteration of AI Seek, which promises to deliver an even more enhanced user experience. Version 3.0 will introduce a secure desktop microsite for each AI Seek user, granting them full access to the app's functionalities without sacrificing their anonymity or security.
With this suite of exciting updates, Ethical Web AI is solidifying its position as a leader in ethical and innovative technology, bringing consumers a new era of intuitive and secure AI applications.
About Ethical Web AI:
Ethical Web AI (formerly Bubblr Inc.) is an ethical technology company that is championing a new internet that is anonymous, safe and fair. We are producing unique intellectual property and technology that is made defensible by our valuable utility software patents.
Visit the new AI Seek website at https://www.aiseek.ai/
For more information about Ethical Web AI and our products, please visit our website at https://ethicalweb.ai/
About Ethical Web AI:
Ethical Web AI (OTCQB: BBLR), is an ethical technology company focused on mobile-first technology that strives to provide a fair and uncompromised user experience. Ethical Web AI’s innovative platform offers solutions to the challenges posed by today's digital ecosystem. The company's dedication to privacy, transparency, and fairness sets it apart in the technology landscape.
Company Contact:
Steve MorrisEthical Web AI(646) 814-7184Join our public shareholder forum on telegram: https://t.me/+fJU7QHfSSfc0MmQx
Safe Harbor StatementThis press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management and are subject to a number of uncertainties and risks that could significantly affect the company's current plans and expectations, as well as future results of operations and financial condition. The company reserves the right to update or alter its forward-looking statements whether as a result of new information, future events or otherwise.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (91%); PRODUCT ENHANCEMENTS (90%); CHATBOTS (89%); CUSTOMER EXPERIENCE (89%); USER EXPERIENCE (89%); ARTIFICIAL INTELLIGENCE (78%); INTELLECTUAL PROPERTY (78%); PATENTS (77%); PRODUCT INNOVATION (77%); CONSUMERS (76%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%)
Company:  GOOGLE LLC (85%);  APPLE INC (84%); BUBBLR INC.
Ticker: AAPL (NASDAQ) (84%); BBLR (Other OTC)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); NAICS423430 COMPUTER & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE MERCHANT WHOLESALERS (84%); NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (84%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (84%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (84%); SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (84%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (84%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (84%); SIC3572 COMPUTER STORAGE DEVICES (84%); SIC3571 ELECTRONIC COMPUTERS (84%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (89%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER NETWORKS (78%); COMPUTER SOFTWARE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%); WORD PROCESSING SOFTWARE (67%); PROGRAMMING LANGUAGES & TOOLS (66%); Internet (%)
Company-Terms: Internet Bubblr Inc. BBLR (Other OTC) ::issuer-state=::issuer-country=:: ::issuer-country=:: ::
Geographic: NEW YORK, NY, USA (74%); NEW YORK, USA (74%)
Load-Date: August 23, 2023","NEW YORK, NY, Aug.  23, 2023  (GLOBE NEWSWIRE) -- via NewMediaWire - Ethical Web AI, also known as Bubblr, Inc. (OTC: BBLR), a pioneering ethical technology firm dedicated to reshaping the online experience, is thrilled to unveil Version 2.0 of its cutting-edge AI Seek consumer app. This new release brings a more affordable and enriched Chat GPT 4.0 experience to users. AI Seek 2.0 is now available for submission to both the Apple and Google Play Store.
Since its initial launch on July 30th, AI Seek has gained traction among users, though it has not yet been extensively marketed. Based on invaluable feedback from early members, the Ethical Web AI team has been able to craft an improved and more intuitive user experience in this updated version.
AI Seek 2.0 boasts a complete redesign, making it even more accessible for users of all tech backgrounds. Gone are the days of navigating through menus; now, users can enjoy icon-driven functions complete with tooltips. Plus, the updated appearance is clean and streamlined, optimized for effortless navigation and usability. AI Seek's user interface (UI) now aligns with the sleek and minimalist aesthetics of Apple's Cupertino and Google's Material design frameworks.
In line with our previous press release, this revamped version of AI Seek will serve as the foundation for essential explainer videos on the AI Seek website, providing users with a more comprehensive understanding of the app's capabilities. Furthermore, we're excited to announce the development of instructive video tutorials that will showcase a variety of use-case scenarios.
One standout feature of the synchronized desktop microsite is the ability to export results to various file formats, including Microsoft Word, Adobe Acrobat, or even programming language files like DART and Python, without any loss of formatting. This added functionality, not currently available in the native Chat GPT version, is sure to make AI Seek a preferred choice among users.
The Ethical Web AI team is already hard at work on the next iteration of AI Seek, which promises to deliver an even more enhanced user experience. Version 3.0 will introduce a secure desktop microsite for each AI Seek user, granting them full access to the app's functionalities without sacrificing their anonymity or security.
With this suite of exciting updates, Ethical Web AI is solidifying its position as a leader in ethical and innovative technology, bringing consumers a new era of intuitive and secure AI applications.
About Ethical Web AI:
Ethical Web AI (formerly Bubblr Inc.) is an ethical technology company that is championing a new internet that is anonymous, safe and fair. We are producing unique intellectual property and technology that is made defensible by our valuable utility software patents.
Visit the new AI Seek website at https://www.aiseek.ai/
For more information about Ethical Web AI and our products, please visit our website at https://ethicalweb.ai/
About Ethical Web AI:
Ethical Web AI (OTCQB: BBLR), is an ethical technology company focused on mobile-first technology that strives to provide a fair and uncompromised user experience. Ethical Web AI’s innovative platform offers solutions to the challenges posed by today's digital ecosystem. The company's dedication to privacy, transparency, and fairness sets it apart in the technology landscape.
Company Contact:
Steve MorrisEthical Web AI(646) 814-7184Join our public shareholder forum on telegram: https://t.me/+fJU7QHfSSfc0MmQx
Safe Harbor StatementThis press release contains forward-looking statements within the meaning of Section 27A of the Securities Act of 1933 and Section 21E of the Securities Exchange Act of 1934. These forward-looking statements are based on the current plans and expectations of management and are subject to a number of uncertainties and risks that could significantly affect the company's current plans and expectations, as well as future results of operations and financial condition. The company reserves the right to update or alter its forward-looking statements whether as a result of new information, future events or otherwise.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (91%); PRODUCT ENHANCEMENTS (90%); CHATBOTS (89%); CUSTOMER EXPERIENCE (89%); USER EXPERIENCE (89%); ARTIFICIAL INTELLIGENCE (78%); INTELLECTUAL PROPERTY (78%); PATENTS (77%); PRODUCT INNOVATION (77%); CONSUMERS (76%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%)
Company:  GOOGLE LLC (85%);  APPLE INC (84%); BUBBLR INC.
Ticker: AAPL (NASDAQ) (84%); BBLR (Other OTC)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (85%); NAICS423430 COMPUTER & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE MERCHANT WHOLESALERS (84%); NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (84%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (84%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (84%); SIC5045 COMPUTERS & COMPUTER PERIPHERAL EQUIPMENT & SOFTWARE (84%); SIC3674 SEMICONDUCTORS & RELATED DEVICES (84%); SIC3577 COMPUTER PERIPHERAL EQUIPMENT, NEC (84%); SIC3572 COMPUTER STORAGE DEVICES (84%); SIC3571 ELECTRONIC COMPUTERS (84%); INFORMATION TECHNOLOGY INDUSTRY (90%); CHATBOTS (89%); ARTIFICIAL INTELLIGENCE (78%); COMPUTER NETWORKS (78%); COMPUTER SOFTWARE (78%); SOFTWARE SERVICES & APPLICATIONS (78%); USABILITY (76%); HUMAN MACHINE INTERACTION (71%); WORD PROCESSING SOFTWARE (67%); PROGRAMMING LANGUAGES & TOOLS (66%); Internet (%)
Company-Terms: Internet Bubblr Inc. BBLR (Other OTC) ::issuer-state=::issuer-country=:: ::issuer-country=:: ::
Geographic: NEW YORK, NY, USA (74%); NEW YORK, USA (74%)
Load-Date: August 23, 2023",positive,0.8421885967254639,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security', 'access']",['fairness'],[],['gpt'],5,1,0,1
2023,Unknown Title,"Byline: Ashley Thompson
Body
November 22nd, 2023 ( TechBullion  — Delivered by  Newstex )
The influence of technology on goodness and ethical decision-making has become a topic of significant importance. As the world becomes increasingly interconnected through various technological advancements, it is essential to understand the impact of these developments on ethical considerations and moral values.  Marc Maggisano  delves into the intricate relationship between technology and ethical decision-making, exploring the role of technology in shaping moral values, ethical considerations in technology development, the intersection of technology and social responsibility, as well as strategies for cultivating ethical awareness in the digital age and nurturing a culture of ethical technology use.
Understanding The Impact Of Technology On Ethical Decision-Making
The pervasive nature of technology in modern society has undeniably influenced how individuals make ethical decisions. With the advent of social media, artificial intelligence, and other technological advancements, people are constantly exposed to many ethical dilemmas and moral challenges. The digital age has rapidly disseminated information, blurring the lines between right and wrong in various contexts. Individuals are often confronted with complex ethical decisions, such as determining the authenticity of online information, navigating privacy concerns in the age of big data, and addressing the ethical implications of automation and algorithmic decision-making.
The  digital realm has given rise to new ethical considerations , such as online harassment, cyberbullying, and the ethical use of emerging technologies. The availability of digital platforms has amplified the impact of individuals' actions, leading to ethical implications that extend beyond traditional physical boundaries. Understanding the multifaceted impact of technology on ethical decision-making requires a comprehensive analysis of how technology influences individual behavior, societal norms, and moral reasoning.
Technology can enhance ethical decision-making by providing access to diverse perspectives, facilitating communication across cultures, and promoting transparency. The interconnectedness enabled by technology allows for greater awareness of global issues and ethical dilemmas, fostering a more informed approach to decision-making. However, navigating the ethical implications of rapidly evolving technologies is challenging, requiring individuals and organizations to adapt their ethical frameworks to address contemporary moral issues effectively.
The Role Of Technology In Shaping Moral Values
Marc Maggisano says technology shapes moral values by influencing how individuals perceive, interpret, and respond to ethical dilemmas. The digital environment serves as a platform for disseminating diverse viewpoints, ethical frameworks, and value systems, contributing to forming individuals' moral compass. Exposure to a wide array of information and perspectives through digital channels can lead to the evolution of moral values as individuals engage with contrasting viewpoints and ethical narratives.
In addition, technological advancements have the potential to redefine traditional ethical norms and standards, challenging existing moral paradigms and necessitating a reevaluation of ethical principles. As individuals interact with technology in various facets of their lives, from social interactions to professional endeavors, their moral values may be influenced by the ethical implications of technological innovations. For instance, integrating artificial intelligence in decision-making processes raises questions about accountability, fairness, and the ethical use of algorithmic systems, thereby shaping individuals' perceptions of ethical responsibility in the digital age.
In addition, the  accessibility of information through digital platforms  can broaden individuals' moral horizons, fostering empathy, cultural understanding, and ethical awareness. Technology enables individuals to engage with diverse perspectives and ethical narratives, contributing to the cultivation of a more inclusive and globally aware moral framework. However, it also challenges the credibility and ethical integrity of the information encountered in the digital sphere, highlighting the need for critical thinking and ethical discernment in navigating the complexities of the digital world.
Ethical Considerations In Technology Development
Technology development and implementation inherently involve ethical considerations encompassing a wide range of societal, environmental, and human rights implications. As technological innovations continue to reshape how individuals interact with the world, it is imperative to prioritize ethical considerations in technology design, deployment, and utilization. Ethical frameworks in technology development encompass a spectrum of considerations, including privacy protection, data security, diversity and inclusion, environmental sustainability, and the ethical use of emerging technologies.
Furthermore, the ethical implications of technology development extend to digital equity, accessibility, and societal impact. As technological advancements shape the socio-economic landscape, ethical considerations arise in addressing disparities in digital access, ensuring equal opportunities for technological literacy, and mitigating the potential adverse effects of technology on marginalized communities. The ethical dimensions of technology development also encompass the responsible management of data, the ethical use of automation and artificial intelligence, and the integration of ethical design principles in technological systems.
Ethical considerations in technology development extend to corporate responsibility, requiring organizations to uphold ethical standards in their technological endeavors. The ethical implications of corporate technological initiatives include considerations of transparency, accountability, and the ethical impact of technology on employees, customers, and society. Companies are increasingly called upon to prioritize ethical considerations in their technological practices, fostering a culture of ethical responsibility and integrity in developing and deploying technological innovations.
The Intersection Of Technology And Social Responsibility
The intersection of technology and social responsibility encompasses a complex web of ethical considerations, societal impact, and the ethical obligations of technological stakeholders. As technology becomes deeply intertwined with various aspects of human life, addressing the ethical implications of technological advancements within the broader context of social responsibility is essential. The ethical dimensions of technology and social responsibility extend to issues of digital rights, ethical governance of technological systems, and the ethical use of technology to promote social good.
Furthermore, the ethical obligations of technological stakeholders, including individuals, organizations, and policymakers, play a crucial role in shaping the impact of technology on social responsibility. Technological stakeholders must uphold ethical principles in their decision-making processes, promoting transparency, accountability, and ethical integrity in their technological endeavors. The ethical use of technology to address societal challenges, promote inclusivity, and foster positive social change underscores the intersection of technology and social responsibility, highlighting the potential for technology to catalyze ethical advancement.
Moreover, the ethical implications of technology and social responsibility extend to the global landscape, encompassing considerations of digital human rights, ethical development aid, and the ethical use of technology in international relations. The interconnected nature of technology necessitates a global perspective on ethical considerations, emphasizing the importance of collaborative efforts to address ethical challenges and promote ethical decision-making in the digital age. By prioritizing the intersection of technology and social responsibility, stakeholders can work towards harnessing the potential of technology to contribute to ethical advancements and positive societal impact.
Conclusion
The influence of technology on goodness and ethical decision-making is a multifaceted and increasingly pertinent issue in the modern era. The intricate relationship between technology and ethics necessitates a comprehensive understanding of the impact of technology on ethical decision-making, the role of technology in shaping moral values, ethical considerations in technology development, and the intersection of technology and social responsibility, as well as strategies for cultivating ethical awareness and nurturing a culture of ethical technology use. By prioritizing ethical considerations in the development, deployment, and utilization of technology, stakeholders can harness technology's potential to contribute to ethical advancements, positive societal impact, and the cultivation of a digital landscape that upholds ethical integrity and responsibility.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (96%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); EMERGING TECHNOLOGY (79%); BLOGS & MESSAGE BOARDS (78%); SOCIAL MEDIA (78%); BULLYING (75%); ARTIFICIAL INTELLIGENCE (73%); CYBERBULLYING (73%); CYBERHARASSMENT (70%); PRIVACY RIGHTS (66%); Technology (%); Article (%); technology (%)
Industry: BLOGS & MESSAGE BOARDS (78%); SOCIAL MEDIA (78%); ARTIFICIAL INTELLIGENCE (73%); INFORMATION SECURITY & PRIVACY (72%)
Load-Date: November 22, 2023","November 22nd, 2023 ( TechBullion  — Delivered by  Newstex )
The influence of technology on goodness and ethical decision-making has become a topic of significant importance. As the world becomes increasingly interconnected through various technological advancements, it is essential to understand the impact of these developments on ethical considerations and moral values.  Marc Maggisano  delves into the intricate relationship between technology and ethical decision-making, exploring the role of technology in shaping moral values, ethical considerations in technology development, the intersection of technology and social responsibility, as well as strategies for cultivating ethical awareness in the digital age and nurturing a culture of ethical technology use.
Understanding The Impact Of Technology On Ethical Decision-Making
The pervasive nature of technology in modern society has undeniably influenced how individuals make ethical decisions. With the advent of social media, artificial intelligence, and other technological advancements, people are constantly exposed to many ethical dilemmas and moral challenges. The digital age has rapidly disseminated information, blurring the lines between right and wrong in various contexts. Individuals are often confronted with complex ethical decisions, such as determining the authenticity of online information, navigating privacy concerns in the age of big data, and addressing the ethical implications of automation and algorithmic decision-making.
The  digital realm has given rise to new ethical considerations , such as online harassment, cyberbullying, and the ethical use of emerging technologies. The availability of digital platforms has amplified the impact of individuals' actions, leading to ethical implications that extend beyond traditional physical boundaries. Understanding the multifaceted impact of technology on ethical decision-making requires a comprehensive analysis of how technology influences individual behavior, societal norms, and moral reasoning.
Technology can enhance ethical decision-making by providing access to diverse perspectives, facilitating communication across cultures, and promoting transparency. The interconnectedness enabled by technology allows for greater awareness of global issues and ethical dilemmas, fostering a more informed approach to decision-making. However, navigating the ethical implications of rapidly evolving technologies is challenging, requiring individuals and organizations to adapt their ethical frameworks to address contemporary moral issues effectively.
The Role Of Technology In Shaping Moral Values
Marc Maggisano says technology shapes moral values by influencing how individuals perceive, interpret, and respond to ethical dilemmas. The digital environment serves as a platform for disseminating diverse viewpoints, ethical frameworks, and value systems, contributing to forming individuals' moral compass. Exposure to a wide array of information and perspectives through digital channels can lead to the evolution of moral values as individuals engage with contrasting viewpoints and ethical narratives.
In addition, technological advancements have the potential to redefine traditional ethical norms and standards, challenging existing moral paradigms and necessitating a reevaluation of ethical principles. As individuals interact with technology in various facets of their lives, from social interactions to professional endeavors, their moral values may be influenced by the ethical implications of technological innovations. For instance, integrating artificial intelligence in decision-making processes raises questions about accountability, fairness, and the ethical use of algorithmic systems, thereby shaping individuals' perceptions of ethical responsibility in the digital age.
In addition, the  accessibility of information through digital platforms  can broaden individuals' moral horizons, fostering empathy, cultural understanding, and ethical awareness. Technology enables individuals to engage with diverse perspectives and ethical narratives, contributing to the cultivation of a more inclusive and globally aware moral framework. However, it also challenges the credibility and ethical integrity of the information encountered in the digital sphere, highlighting the need for critical thinking and ethical discernment in navigating the complexities of the digital world.
Ethical Considerations In Technology Development
Technology development and implementation inherently involve ethical considerations encompassing a wide range of societal, environmental, and human rights implications. As technological innovations continue to reshape how individuals interact with the world, it is imperative to prioritize ethical considerations in technology design, deployment, and utilization. Ethical frameworks in technology development encompass a spectrum of considerations, including privacy protection, data security, diversity and inclusion, environmental sustainability, and the ethical use of emerging technologies.
Furthermore, the ethical implications of technology development extend to digital equity, accessibility, and societal impact. As technological advancements shape the socio-economic landscape, ethical considerations arise in addressing disparities in digital access, ensuring equal opportunities for technological literacy, and mitigating the potential adverse effects of technology on marginalized communities. The ethical dimensions of technology development also encompass the responsible management of data, the ethical use of automation and artificial intelligence, and the integration of ethical design principles in technological systems.
Ethical considerations in technology development extend to corporate responsibility, requiring organizations to uphold ethical standards in their technological endeavors. The ethical implications of corporate technological initiatives include considerations of transparency, accountability, and the ethical impact of technology on employees, customers, and society. Companies are increasingly called upon to prioritize ethical considerations in their technological practices, fostering a culture of ethical responsibility and integrity in developing and deploying technological innovations.
The Intersection Of Technology And Social Responsibility
The intersection of technology and social responsibility encompasses a complex web of ethical considerations, societal impact, and the ethical obligations of technological stakeholders. As technology becomes deeply intertwined with various aspects of human life, addressing the ethical implications of technological advancements within the broader context of social responsibility is essential. The ethical dimensions of technology and social responsibility extend to issues of digital rights, ethical governance of technological systems, and the ethical use of technology to promote social good.
Furthermore, the ethical obligations of technological stakeholders, including individuals, organizations, and policymakers, play a crucial role in shaping the impact of technology on social responsibility. Technological stakeholders must uphold ethical principles in their decision-making processes, promoting transparency, accountability, and ethical integrity in their technological endeavors. The ethical use of technology to address societal challenges, promote inclusivity, and foster positive social change underscores the intersection of technology and social responsibility, highlighting the potential for technology to catalyze ethical advancement.
Moreover, the ethical implications of technology and social responsibility extend to the global landscape, encompassing considerations of digital human rights, ethical development aid, and the ethical use of technology in international relations. The interconnected nature of technology necessitates a global perspective on ethical considerations, emphasizing the importance of collaborative efforts to address ethical challenges and promote ethical decision-making in the digital age. By prioritizing the intersection of technology and social responsibility, stakeholders can work towards harnessing the potential of technology to contribute to ethical advancements and positive societal impact.
Conclusion
The influence of technology on goodness and ethical decision-making is a multifaceted and increasingly pertinent issue in the modern era. The intricate relationship between technology and ethics necessitates a comprehensive understanding of the impact of technology on ethical decision-making, the role of technology in shaping moral values, ethical considerations in technology development, and the intersection of technology and social responsibility, as well as strategies for cultivating ethical awareness and nurturing a culture of ethical technology use. By prioritizing ethical considerations in the development, deployment, and utilization of technology, stakeholders can harness technology's potential to contribute to ethical advancements, positive societal impact, and the cultivation of a digital landscape that upholds ethical integrity and responsibility.
Recommended for you
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Publication
Journal Code: 10009326
Subject: ETHICS (96%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); EMERGING TECHNOLOGY (79%); BLOGS & MESSAGE BOARDS (78%); SOCIAL MEDIA (78%); BULLYING (75%); ARTIFICIAL INTELLIGENCE (73%); CYBERBULLYING (73%); CYBERHARASSMENT (70%); PRIVACY RIGHTS (66%); Technology (%); Article (%); technology (%)
Industry: BLOGS & MESSAGE BOARDS (78%); SOCIAL MEDIA (78%); ARTIFICIAL INTELLIGENCE (73%); INFORMATION SECURITY & PRIVACY (72%)
Load-Date: November 22, 2023",neutral,0.622736394405365,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'security', 'human rights', 'inclusivity', 'access']","['fairness', 'equity']","['governance', 'standards', 'framework', 'should', 'must']",[],8,2,5,0
2023,Unknown Title,"Dateline: Hyderabad 
Body
Hyderabad, Aug. 20 -- The Government of Telangana and UNESCO have joined forces to implement the UNESCO Recommendation on the Ethics of AI, signing a Letter of Intent to drive efforts and action on Sunday, August 20.
The collaboration focuses on promoting the ethical development and use of AI awareness raising, capacity building, and contributions to UNESCO's Global Observatory on AI Ethics. The partnership signifies a shared commitment to an AI-powered future that prioritizes societal good and equitable development.
A significant collaboration between the Information Technology, Electronics and Communications (ITE&C) Department of the Government of Telangana and the United Nations Educational, Scientific and Cultural Organization (UNESCO), is set to shape the landscape of the ethical development of and use of Artificial Intelligence (AI).
Vakati Karuna, secretary of education department of government of Telangana, Dr Mariagrazia Squicciarini, director a.i. and chief of executive office of Social and Human Sciences at UNESCO, Rama Devi Lanka, director of emerging technologies, government of Telangana participated in the event to mark the signing of the Letter of Intent.
The collaboration gains further significance with the ITE&C department's role in shaping the technological landscape of Telangana, ensuring that advancements are aligned with ethical values.
With a shared commitment to fostering beneficial development and application of AI technologies and successful mitigation of the inherent risks, the Government of Telangana and UNESCO are embarking on a transformative collaboration that aims to harness the power of AI technologies for societal good.
Published by HT Digital Content Services with permission from Siasat Daily. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); UNITED NATIONS INSTITUTIONS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); SOCIAL JUSTICE (78%); UNITED NATIONS (78%); EDUCATION & TRAINING (77%); EMERGING TECHNOLOGY (73%); GOVERNMENT ADVISORS & MINISTERS (73%); ASSOCIATIONS & ORGANIZATIONS (69%); EDUCATION DEPARTMENTS (69%); HUMANITIES & SOCIAL SCIENCE (69%); EXECUTIVES (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MEDIA CONTENT (64%)
Geographic: HYDERABAD, ANDHRA PRADESH, INDIA (89%); TELANGANA, INDIA (92%); INDIA (92%)
Load-Date: August 21, 2023","Hyderabad, Aug. 20 -- The Government of Telangana and UNESCO have joined forces to implement the UNESCO Recommendation on the Ethics of AI, signing a Letter of Intent to drive efforts and action on Sunday, August 20.
The collaboration focuses on promoting the ethical development and use of AI awareness raising, capacity building, and contributions to UNESCO's Global Observatory on AI Ethics. The partnership signifies a shared commitment to an AI-powered future that prioritizes societal good and equitable development.
A significant collaboration between the Information Technology, Electronics and Communications (ITE&C) Department of the Government of Telangana and the United Nations Educational, Scientific and Cultural Organization (UNESCO), is set to shape the landscape of the ethical development of and use of Artificial Intelligence (AI).
Vakati Karuna, secretary of education department of government of Telangana, Dr Mariagrazia Squicciarini, director a.i. and chief of executive office of Social and Human Sciences at UNESCO, Rama Devi Lanka, director of emerging technologies, government of Telangana participated in the event to mark the signing of the Letter of Intent.
The collaboration gains further significance with the ITE&C department's role in shaping the technological landscape of Telangana, ensuring that advancements are aligned with ethical values.
With a shared commitment to fostering beneficial development and application of AI technologies and successful mitigation of the inherent risks, the Government of Telangana and UNESCO are embarking on a transformative collaboration that aims to harness the power of AI technologies for societal good.
Published by HT Digital Content Services with permission from Siasat Daily. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); UNITED NATIONS INSTITUTIONS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); SOCIAL JUSTICE (78%); UNITED NATIONS (78%); EDUCATION & TRAINING (77%); EMERGING TECHNOLOGY (73%); GOVERNMENT ADVISORS & MINISTERS (73%); ASSOCIATIONS & ORGANIZATIONS (69%); EDUCATION DEPARTMENTS (69%); HUMANITIES & SOCIAL SCIENCE (69%); EXECUTIVES (68%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MEDIA CONTENT (64%)
Geographic: HYDERABAD, ANDHRA PRADESH, INDIA (89%); TELANGANA, INDIA (92%); INDIA (92%)
Load-Date: August 21, 2023",neutral,0.6107206344604492,balanced/neutral,[],"['justice', 'justice']",[],[],0,2,0,0
2023,Unknown Title,"Body
SAN FRANCISCO: Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); NEW PRODUCTS (90%); ECONOMIC DEVELOPMENT (78%); EMERGING TECHNOLOGY (78%); MACHINE LEARNING (78%); SAFETY (78%); SOCIAL MEDIA (78%); RESEARCH & DEVELOPMENT (77%); DATA SCIENCE (73%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); SAFETY, ACCIDENTS & DISASTERS (73%)
Company:  GOOGLE LLC (57%)
Organization: ORGANISATION FOR ECONOMIC CO-OPERATION & DEVELOPMENT (54%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); MACHINE LEARNING (78%); SOCIAL MEDIA (78%); DATA SCIENCE (73%)
Load-Date: September 23, 2023","SAN FRANCISCO: Meltwater, a leading global provider of social, media and consumer intelligence, today announces the launch of its new AI Ethical Principles which guide the company's AI innovation and ensure a commitment to AI safety, transparency, and accountability within the organization and the broader industry.
While AI technology brings unprecedented opportunities, it also poses significant safety concerns that must be addressed to ensure its reliable and equitable use. As Meltwater continues to make significant investments into its cutting-edge AI and machine learning engine, the company also recognizes its pivotal responsibility in shaping the future of AI and tackling AI safety challenges in order to contribute to the responsible advancement of this transformative technology.
The new Meltwater Ethical AI Principles are inspired by the ethical guidelines from industry leaders such as Google and the OECD and serve as a foundation for how Meltwater conducts research and development in the fields of Artificial Intelligence, Machine Learning, and Data Science. They underscore the company's commitment to ethical AI practices, in order to ensure these systems are reliable, ethical and beneficial to all, and aligned with Meltwater's deeply held corporate values.
Meltwater is dedicated to fostering a responsible AI ecosystem and invites industry peers, stakeholders, and partners to join in the journey towards ethical AI practices. By setting these principles and collaborating with leading organizations, Meltwater aims to drive positive change and create a safer, more inclusive AI future. The company will continue to invest in its technology and people to continue providing breakthrough AI innovations and provide more value than ever to its customers.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); NEW PRODUCTS (90%); ECONOMIC DEVELOPMENT (78%); EMERGING TECHNOLOGY (78%); MACHINE LEARNING (78%); SAFETY (78%); SOCIAL MEDIA (78%); RESEARCH & DEVELOPMENT (77%); DATA SCIENCE (73%); INTERNATIONAL ECONOMIC ORGANIZATIONS (73%); SAFETY, ACCIDENTS & DISASTERS (73%)
Company:  GOOGLE LLC (57%)
Organization: ORGANISATION FOR ECONOMIC CO-OPERATION & DEVELOPMENT (54%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); NEW PRODUCTS (90%); MACHINE LEARNING (78%); SOCIAL MEDIA (78%); DATA SCIENCE (73%)
Load-Date: September 23, 2023",positive,0.5785731077194214,balanced/neutral,"['transparency', 'accountability', 'safety']",[],"['guidelines', 'must']",['machine learning'],3,0,2,1
2023,Unknown Title,"Body
2023 JUN 29 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Drugs and Therapies - Personalized Medicine is the subject of a report. According to news reporting originating in Oxford, United Kingdom, by NewsRx journalists, research stated, ""Despite the recognition that developing artificial intelligence (AI) that is trustworthy is necessary for public acceptability and the successful implementation of AI in healthcare contexts, perspectives from key stakeholders are often absent from discourse on the ethical design, development, and deployment of AI. This study explores the perspectives of birth parents and mothers on the introduction of AI-based cardiotocography (CTG) in the context of intrapartum care, focusing on issues pertaining to trust and trustworthiness."" 
 Financial support for this research came from UK National Institute of Health and Care Research. 
 The news reporters obtained a quote from the research from the University of Oxford, ""Seventeen semi-structured interviews were conducted with birth parents and mothers based on a speculative case study. Interviewees were based in England and were pregnant and/or had given birth in the last two years. Thematic analysis was used to analyze transcribed interviews with the use of NVivo. Major recurring themes acted as the basis for identifying the values most important to this population group for evaluating the trustworthiness of AI. Three themes pertaining to the perceived trustworthiness of AI emerged from interviews: (1) trustworthy AI-developing institutions, (2) trustworthy data from which AI is built, and (3) trustworthy decisions made with the assistance of AI. We found that birth parents and mothers trusted public institutions over private companies to develop AI, that they evaluated the trustworthiness of data by how representative it is of all population groups, and that they perceived trustworthy decisions as being mediated by humans even when supported by AI. The ethical values that underscore birth parents and mothers' perceptions of trustworthy AI include fairness and reliability, as well as practices like patient-centered care, the promotion of publicly funded healthcare, holistic care, and personalized medicine. Ultimately, these are also the ethical values that people want to protect in the healthcare system. Therefore, trustworthy AI is best understood not as a list of design features but in relation to how it undermines or promotes the ethical values that matter most to its end users."" 
 According to the news reporters, the research concluded: ""An ethical commitment to these values when creating AI in healthcare contexts opens up new challenges and possibilities for the design and deployment of AI."" 
 For more information on this research see: Trustworthy artificial intelligence and ethical design: public perceptions of trustworthiness of an AI-based decision-support tool in the context of intrapartum care. BMC Medical Ethics, 2023;24(1):42. BMC Medical Ethics can be contacted at: Bmc, Campus, 4 Crinan St, London N1 9XW, England. (BioMed Central - www.biomedcentral.com/; BMC Medical Ethics - www.biomedcentral.com/bmcmedethics/) 
 Our news correspondents report that additional information may be obtained by contacting Antoniya Georgieva, Nuffield Dept. of Women's and Reproductive Health, University of Oxford, Level 3, Women's Centre, John Radcliffe Hospital, Oxford, OX3 9DU, UK. Additional authors for this research include Rachel Dlugatch and Angeliki Kerasidou. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1186/s12910-023-00917-w. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal BMC Medical Ethics can be contacted at: Bmc, Campus, 4 Crinan St, London N1 9XW, England. 
 Keywords for this news article include: Oxford, United Kingdom, Europe, Artificial Intelligence, Drugs and Therapies, Emerging Technologies, Machine Learning, Personalized Medicine, Personalized Therapy. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: PRECISION MEDICINE (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MACHINE LEARNING (90%); PARENTS (90%); ROBOTICS (90%); DECISION SUPPORT SYSTEMS (89%); INTERVIEWS (89%); CASE STUDIES (77%); RESEARCH INSTITUTES (77%); COLLEGES & UNIVERSITIES (74%); DEMOGRAPHIC GROUPS (74%); HEALTH DEPARTMENTS (74%); MEDICAL ETHICS (73%); NEWS REPORTING (73%); WRITERS (73%); HUMAN SUBJECTS (64%); Oxford;United Kingdom;Europe;Artificial Intelligence;Drugs and Therapies;Emerging Technologies;Machine Learning;Personalized Medicine;Personalized Therapy (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); DECISION SUPPORT SYSTEMS (89%); HEALTH CARE (89%); COLLEGES & UNIVERSITIES (74%); HEALTH DEPARTMENTS (74%); NEWS REPORTING (73%); WRITERS (73%)
Geographic: OXFORD, ENGLAND (90%); UNITED KINGDOM (88%); EUROPE (78%); ENGLAND (58%)
Load-Date: June 29, 2023","2023 JUN 29 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Drugs and Therapies - Personalized Medicine is the subject of a report. According to news reporting originating in Oxford, United Kingdom, by NewsRx journalists, research stated, ""Despite the recognition that developing artificial intelligence (AI) that is trustworthy is necessary for public acceptability and the successful implementation of AI in healthcare contexts, perspectives from key stakeholders are often absent from discourse on the ethical design, development, and deployment of AI. This study explores the perspectives of birth parents and mothers on the introduction of AI-based cardiotocography (CTG) in the context of intrapartum care, focusing on issues pertaining to trust and trustworthiness."" 
 Financial support for this research came from UK National Institute of Health and Care Research. 
 The news reporters obtained a quote from the research from the University of Oxford, ""Seventeen semi-structured interviews were conducted with birth parents and mothers based on a speculative case study. Interviewees were based in England and were pregnant and/or had given birth in the last two years. Thematic analysis was used to analyze transcribed interviews with the use of NVivo. Major recurring themes acted as the basis for identifying the values most important to this population group for evaluating the trustworthiness of AI. Three themes pertaining to the perceived trustworthiness of AI emerged from interviews: (1) trustworthy AI-developing institutions, (2) trustworthy data from which AI is built, and (3) trustworthy decisions made with the assistance of AI. We found that birth parents and mothers trusted public institutions over private companies to develop AI, that they evaluated the trustworthiness of data by how representative it is of all population groups, and that they perceived trustworthy decisions as being mediated by humans even when supported by AI. The ethical values that underscore birth parents and mothers' perceptions of trustworthy AI include fairness and reliability, as well as practices like patient-centered care, the promotion of publicly funded healthcare, holistic care, and personalized medicine. Ultimately, these are also the ethical values that people want to protect in the healthcare system. Therefore, trustworthy AI is best understood not as a list of design features but in relation to how it undermines or promotes the ethical values that matter most to its end users."" 
 According to the news reporters, the research concluded: ""An ethical commitment to these values when creating AI in healthcare contexts opens up new challenges and possibilities for the design and deployment of AI."" 
 For more information on this research see: Trustworthy artificial intelligence and ethical design: public perceptions of trustworthiness of an AI-based decision-support tool in the context of intrapartum care. BMC Medical Ethics, 2023;24(1):42. BMC Medical Ethics can be contacted at: Bmc, Campus, 4 Crinan St, London N1 9XW, England. (BioMed Central - www.biomedcentral.com/; BMC Medical Ethics - www.biomedcentral.com/bmcmedethics/) 
 Our news correspondents report that additional information may be obtained by contacting Antoniya Georgieva, Nuffield Dept. of Women's and Reproductive Health, University of Oxford, Level 3, Women's Centre, John Radcliffe Hospital, Oxford, OX3 9DU, UK. Additional authors for this research include Rachel Dlugatch and Angeliki Kerasidou. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1186/s12910-023-00917-w. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal BMC Medical Ethics can be contacted at: Bmc, Campus, 4 Crinan St, London N1 9XW, England. 
 Keywords for this news article include: Oxford, United Kingdom, Europe, Artificial Intelligence, Drugs and Therapies, Emerging Technologies, Machine Learning, Personalized Medicine, Personalized Therapy. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: PRECISION MEDICINE (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MACHINE LEARNING (90%); PARENTS (90%); ROBOTICS (90%); DECISION SUPPORT SYSTEMS (89%); INTERVIEWS (89%); CASE STUDIES (77%); RESEARCH INSTITUTES (77%); COLLEGES & UNIVERSITIES (74%); DEMOGRAPHIC GROUPS (74%); HEALTH DEPARTMENTS (74%); MEDICAL ETHICS (73%); NEWS REPORTING (73%); WRITERS (73%); HUMAN SUBJECTS (64%); Oxford;United Kingdom;Europe;Artificial Intelligence;Drugs and Therapies;Emerging Technologies;Machine Learning;Personalized Medicine;Personalized Therapy (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); DECISION SUPPORT SYSTEMS (89%); HEALTH CARE (89%); COLLEGES & UNIVERSITIES (74%); HEALTH DEPARTMENTS (74%); NEWS REPORTING (73%); WRITERS (73%)
Geographic: OXFORD, ENGLAND (90%); UNITED KINGDOM (88%); EUROPE (78%); ENGLAND (58%)
Load-Date: June 29, 2023",neutral,0.9029508829116821,balanced/neutral,['fairness'],['fairness'],[],"['machine learning', 'robotics']",1,1,0,2
2023,Unknown Title,"Body
2023 SEP 04 (NewsRx) -- By a News Reporter-Staff News Editor at Internet Daily News -- Fresh data on internet of things are presented in a new report. According to news reporting out of Gangtok, India, by NewsRx editors, research stated, ""In recent years, artificial intelligence (AI) and machine learning have been transforming the landscape of scientific research. Out of which, the chatbot technology has experienced tremendous advancements in recent years, especially with ChatGPT emerging as a notable AI language model."" 
 Our news journalists obtained a quote from the research from Sikkim University: ""This comprehensive review delves into the background, applications, key challenges, and future directions of ChatGPT. We begin by exploring its origins, development, and underlying technology, before examining its wide-ranging applications across industries such as customer service, healthcare, and education. We also highlight the critical challenges that ChatGPT faces, including ethical concerns, data biases, and safety issues, while discussing potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientific research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion."" 
 According to the news reporters, the research concluded: ""This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time."" 
 For more information on this research see: ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems, 2023,3():121-154. The publisher for Internet of Things and Cyber-Physical Systems is KeAi Communications Co., Ltd. 
 A free version of this journal article is available at https://doi.org/10.1016/j.iotcps.2023.04.003. 
 Our news editors report that additional information may be obtained by contacting Partha Pratim Ray, Sikkim University, Gangtok, India. 
 Keywords for this news article include: Sikkim University, Gangtok, India, Asia, Internet and World Wide Web, Internet of Things, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); GENERATIVE AI (90%); JOURNALISM (90%); COLLEGES & UNIVERSITIES (89%); DIGITAL DIVIDE (79%); RESEARCH & DEVELOPMENT (78%); EXPERIMENTATION & RESEARCH (77%); MACHINE LEARNING (73%); NEWS REPORTING (73%); WRITERS (73%); SCIENCE & TECHNOLOGY (72%); CUSTOMER SERVICE (68%); SAFETY (53%); Internet and World Wide Web;Internet of Things;Technology (%)
Industry: CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); INTERNET OF THINGS (90%); COLLEGES & UNIVERSITIES (89%); INTERNET & WWW (89%); MEDIA & TELECOMMUNICATIONS (79%); MACHINE LEARNING (73%); NEWS REPORTING (73%); WRITERS (73%)
Geographic: SIKKIM, INDIA (94%); INDIA (88%); ASIA (78%)
Load-Date: September 4, 2023","2023 SEP 04 (NewsRx) -- By a News Reporter-Staff News Editor at Internet Daily News -- Fresh data on internet of things are presented in a new report. According to news reporting out of Gangtok, India, by NewsRx editors, research stated, ""In recent years, artificial intelligence (AI) and machine learning have been transforming the landscape of scientific research. Out of which, the chatbot technology has experienced tremendous advancements in recent years, especially with ChatGPT emerging as a notable AI language model."" 
 Our news journalists obtained a quote from the research from Sikkim University: ""This comprehensive review delves into the background, applications, key challenges, and future directions of ChatGPT. We begin by exploring its origins, development, and underlying technology, before examining its wide-ranging applications across industries such as customer service, healthcare, and education. We also highlight the critical challenges that ChatGPT faces, including ethical concerns, data biases, and safety issues, while discussing potential mitigation strategies. Finally, we envision the future of ChatGPT by exploring areas of further research and development, focusing on its integration with other technologies, improved human-AI interaction, and addressing the digital divide. This review offers valuable insights for researchers, developers, and stakeholders interested in the ever-evolving landscape of AI-driven conversational agents. This study explores the various ways ChatGPT has been revolutionizing scientific research, spanning from data processing and hypothesis generation to collaboration and public outreach. Furthermore, the paper examines the potential challenges and ethical concerns surrounding the use of ChatGPT in research, while highlighting the importance of striking a balance between AI-assisted innovation and human expertise. The paper presents several ethical issues in existing computing domain and how ChatGPT can invoke challenges to such notion."" 
 According to the news reporters, the research concluded: ""This work also includes some biases and limitations of ChatGPT. It is worth to note that despite of several controversies and ethical concerns, ChatGPT has attracted remarkable attentions from academia, research, and industries in a very short span of time."" 
 For more information on this research see: ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems, 2023,3():121-154. The publisher for Internet of Things and Cyber-Physical Systems is KeAi Communications Co., Ltd. 
 A free version of this journal article is available at https://doi.org/10.1016/j.iotcps.2023.04.003. 
 Our news editors report that additional information may be obtained by contacting Partha Pratim Ray, Sikkim University, Gangtok, India. 
 Keywords for this news article include: Sikkim University, Gangtok, India, Asia, Internet and World Wide Web, Internet of Things, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2023, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); GENERATIVE AI (90%); JOURNALISM (90%); COLLEGES & UNIVERSITIES (89%); DIGITAL DIVIDE (79%); RESEARCH & DEVELOPMENT (78%); EXPERIMENTATION & RESEARCH (77%); MACHINE LEARNING (73%); NEWS REPORTING (73%); WRITERS (73%); SCIENCE & TECHNOLOGY (72%); CUSTOMER SERVICE (68%); SAFETY (53%); Internet and World Wide Web;Internet of Things;Technology (%)
Industry: CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); GENERATIVE AI (90%); INTERNET OF THINGS (90%); COLLEGES & UNIVERSITIES (89%); INTERNET & WWW (89%); MEDIA & TELECOMMUNICATIONS (79%); MACHINE LEARNING (73%); NEWS REPORTING (73%); WRITERS (73%)
Geographic: SIKKIM, INDIA (94%); INDIA (88%); ASIA (78%)
Load-Date: September 4, 2023",neutral,0.7731571197509766,balanced/neutral,"['bias', 'safety', 'digital divide']",[],[],"['machine learning', 'generative ai', 'chatgpt']",3,0,0,3
2023,Unknown Title,"Body
In the rapidly evolving landscape of artificial intelligence (AI), governance frameworks play a pivotal role in ensuring that technological advances align with ethical standards and human rights protection. China combines regulation, ethical norms, and a focus on human rights in a comprehensive approach to AI governance.
The global nature of AI technology and its impact necessitates a perspective that embraces international cooperation and shared ethical frameworks. China advocates for global collaboration in navigating the complex terrain of ethics and human rights in the digital age.
Comprehensive framework
China is at the forefront of digital resource management, closely following international standards in regulating the ethics of emerging technologies such as AI. In addition to enacting relevant legislation, the country has made strides in creating a comprehensive framework. This includes well-rounded institutional norms that encompass development planning, governance principles, policies, ethical standards, and ethical review processes.
This holistic approach underlines China's commitment to not just harnessing the power of digital technologies but also ensuring their responsible and ethical application in the broader global context.
This approach not only promotes technological innovation, but also ensures that it progresses hand-in-hand with the protection of human rights, demonstrating a balanced and progressive model for the governance of digital technology.
One of the cornerstones of China's approach is the integration of ethical principles into the fabric of AI development and application.
This includes the establishment of ethics committees and guidelines for the responsible use of AI. These guidelines cover a range of issues, from ensuring transparency in AI systems to respecting user privacy and promoting AI literacy among the public. By institutionalizing these ethical considerations, China is setting a precedent for how nations can systematically address the many challenges posed by AI.
For instance, on September 25, 2021, the National Governance Committee for the New Generation Artificial Intelligence in China released the Ethics Norms for New Generation Artificial Intelligence. This seminal document laid out six core ethical principles: enhancing human well-being, promoting fairness and justice, safeguarding privacy and security, ensuring control and credibility, emphasizing responsibility, and fostering ethical literacy.
This initiative is a testament to China's foundational policy of harnessing science and technology for the benefit of its people. It embodies the nation's commitment to the principle of ""science for good"" and integrates the country's contemporary human rights perspective that ""living a happy life is the primary human right"" into both the design and implementation of its ethical AI governance system.
AI ethics
AI technology is significantly more disruptive than traditional technologies. Its rapid iteration and evolution, while driving technological progress, also introduces a range of uncertainties, conflicts and negative impacts that may go beyond their intended scope and evolve into social risks.
The ethical dimension of AI is complex, intricately woven into the technical design, product behavior, and application scenarios throughout the life-cycles of AI systems and services. It involves navigating the often conflicting interests of various stakeholders, including implementers, technical path developers, infrastructure owners and the general public. 
Recognizing the need for rigorous oversight, on September 7, 10 government departments in China, including the Ministry of Science and Technology, jointly drafted and issued the Measures on Science and Technology Ethics Review (Trial Implementation).
This initiative, which was approved by the Central Science and Technology Commission, marked a significant step forward. In particular, it mandated the establishment of a scientific and technological ethics (review) committee and specifically included AI in the committee's scope.
The new framework requires AI ethics review for four of seven categories of emerging technology activities deemed to pose significant risks, all of which are subject to list-based management.
This development underscores a proactive approach in China towards managing the ethical challenges posed by AI, ensuring that technological advancement is carefully balanced with ethical considerations and societal wellbeing. 
The ethical governance of AI is not just a matter of regulatory compliance; it is a fundamental necessity to ensure that technological advances benefit society as a whole. AI technologies have the potential to revolutionize industries, enhance efficiency and solve complex societal problems. However, without a strong ethical framework, the same technologies can exacerbate inequalities, infringe on privacy rights and perpetuate biases.
By prioritizing ethical considerations, China is acknowledging the complex interplay between technology and society and taking steps to ensure that AI serves the public interest.
Beyond borders
In a speech delivered on February 21, Chinese President Xi Jinping underscored the imperative of adopting a forward-looking approach in planning and participating in global science and technology governance. He emphasized the necessity to refine laws, regulations, ethical review standards and regulatory frameworks.
Xi highlighted the critical need to strengthen AI ethics governance as a means to promote international human rights in the digital era. This involves several key strategies, including: advocating science and technology for good; strengthening science and technology ethics governance; and defining responsibilities, including clearly delineating the responsibilities of various stakeholders in the AI industry.
AI technologies and their impacts do not stop at national borders; their effects are felt worldwide.
The world is in urgent need of a global framework for AI governance that encompasses diverse cultural, ethical and legal perspectives. China's vision for AI governance is not only about technological control, but also about aligning technological advancements with social values.
By doing so, the country aims to ensure that its digital strategy and AI advancements contribute positively to both national and global human rights governance in the digital age.
The concept of human rights is both historically grounded and contemporaneously relevant. The fundamental purpose of science, aimed at alleviating human suffering, resonates with the core principle of deploying science and technology for the betterment of people and for the greater good.
This principle aligns seamlessly with the essence of human rights as we understand them today. Different from the world 75 years ago, when the Universal Declaration of Human Rights was first proclaimed, in the current digital age, the impact of science and technology on individual well-being is unprecedented.
The advent of intelligent technology has not only transformed traditional social structures but also infused new theoretical depth and practical relevance into the concept of human rights in this new era.
In conclusion, to effectively advance global human rights governance in the age of intelligent technology, it is imperative to adapt to the evolving landscape, trends and characteristics of the human rights discourse. This involves placing significant emphasis on the ethical review of science and technology, refining the governance of scientific and technological ethics, and achieving a balance between technological innovation and human rights protection.
The author is the executive director of the Center for Sci&Tech and Human Rights Studies, Beijing Institute of Technology
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (97%); HUMAN RIGHTS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EMERGING TECHNOLOGY (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); SCIENCE POLICY (78%); PRIVACY RIGHTS (77%); DISRUPTIVE INNOVATION (73%); INTERNATIONAL RELATIONS (73%); STANDARDS & MEASUREMENTS (73%); PRODUCT INNOVATION (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION SECURITY & PRIVACY (78%); PUBLISHING (73%)
Geographic: BEIJING, CHINA (74%); NORTH CENTRAL CHINA (89%); CHINA (96%)
Load-Date: December 26, 2023","In the rapidly evolving landscape of artificial intelligence (AI), governance frameworks play a pivotal role in ensuring that technological advances align with ethical standards and human rights protection. China combines regulation, ethical norms, and a focus on human rights in a comprehensive approach to AI governance.
The global nature of AI technology and its impact necessitates a perspective that embraces international cooperation and shared ethical frameworks. China advocates for global collaboration in navigating the complex terrain of ethics and human rights in the digital age.
Comprehensive framework
China is at the forefront of digital resource management, closely following international standards in regulating the ethics of emerging technologies such as AI. In addition to enacting relevant legislation, the country has made strides in creating a comprehensive framework. This includes well-rounded institutional norms that encompass development planning, governance principles, policies, ethical standards, and ethical review processes.
This holistic approach underlines China's commitment to not just harnessing the power of digital technologies but also ensuring their responsible and ethical application in the broader global context.
This approach not only promotes technological innovation, but also ensures that it progresses hand-in-hand with the protection of human rights, demonstrating a balanced and progressive model for the governance of digital technology.
One of the cornerstones of China's approach is the integration of ethical principles into the fabric of AI development and application.
This includes the establishment of ethics committees and guidelines for the responsible use of AI. These guidelines cover a range of issues, from ensuring transparency in AI systems to respecting user privacy and promoting AI literacy among the public. By institutionalizing these ethical considerations, China is setting a precedent for how nations can systematically address the many challenges posed by AI.
For instance, on September 25, 2021, the National Governance Committee for the New Generation Artificial Intelligence in China released the Ethics Norms for New Generation Artificial Intelligence. This seminal document laid out six core ethical principles: enhancing human well-being, promoting fairness and justice, safeguarding privacy and security, ensuring control and credibility, emphasizing responsibility, and fostering ethical literacy.
This initiative is a testament to China's foundational policy of harnessing science and technology for the benefit of its people. It embodies the nation's commitment to the principle of ""science for good"" and integrates the country's contemporary human rights perspective that ""living a happy life is the primary human right"" into both the design and implementation of its ethical AI governance system.
AI ethics
AI technology is significantly more disruptive than traditional technologies. Its rapid iteration and evolution, while driving technological progress, also introduces a range of uncertainties, conflicts and negative impacts that may go beyond their intended scope and evolve into social risks.
The ethical dimension of AI is complex, intricately woven into the technical design, product behavior, and application scenarios throughout the life-cycles of AI systems and services. It involves navigating the often conflicting interests of various stakeholders, including implementers, technical path developers, infrastructure owners and the general public. 
Recognizing the need for rigorous oversight, on September 7, 10 government departments in China, including the Ministry of Science and Technology, jointly drafted and issued the Measures on Science and Technology Ethics Review (Trial Implementation).
This initiative, which was approved by the Central Science and Technology Commission, marked a significant step forward. In particular, it mandated the establishment of a scientific and technological ethics (review) committee and specifically included AI in the committee's scope.
The new framework requires AI ethics review for four of seven categories of emerging technology activities deemed to pose significant risks, all of which are subject to list-based management.
This development underscores a proactive approach in China towards managing the ethical challenges posed by AI, ensuring that technological advancement is carefully balanced with ethical considerations and societal wellbeing. 
The ethical governance of AI is not just a matter of regulatory compliance; it is a fundamental necessity to ensure that technological advances benefit society as a whole. AI technologies have the potential to revolutionize industries, enhance efficiency and solve complex societal problems. However, without a strong ethical framework, the same technologies can exacerbate inequalities, infringe on privacy rights and perpetuate biases.
By prioritizing ethical considerations, China is acknowledging the complex interplay between technology and society and taking steps to ensure that AI serves the public interest.
Beyond borders
In a speech delivered on February 21, Chinese President Xi Jinping underscored the imperative of adopting a forward-looking approach in planning and participating in global science and technology governance. He emphasized the necessity to refine laws, regulations, ethical review standards and regulatory frameworks.
Xi highlighted the critical need to strengthen AI ethics governance as a means to promote international human rights in the digital era. This involves several key strategies, including: advocating science and technology for good; strengthening science and technology ethics governance; and defining responsibilities, including clearly delineating the responsibilities of various stakeholders in the AI industry.
AI technologies and their impacts do not stop at national borders; their effects are felt worldwide.
The world is in urgent need of a global framework for AI governance that encompasses diverse cultural, ethical and legal perspectives. China's vision for AI governance is not only about technological control, but also about aligning technological advancements with social values.
By doing so, the country aims to ensure that its digital strategy and AI advancements contribute positively to both national and global human rights governance in the digital age.
The concept of human rights is both historically grounded and contemporaneously relevant. The fundamental purpose of science, aimed at alleviating human suffering, resonates with the core principle of deploying science and technology for the betterment of people and for the greater good.
This principle aligns seamlessly with the essence of human rights as we understand them today. Different from the world 75 years ago, when the Universal Declaration of Human Rights was first proclaimed, in the current digital age, the impact of science and technology on individual well-being is unprecedented.
The advent of intelligent technology has not only transformed traditional social structures but also infused new theoretical depth and practical relevance into the concept of human rights in this new era.
In conclusion, to effectively advance global human rights governance in the age of intelligent technology, it is imperative to adapt to the evolving landscape, trends and characteristics of the human rights discourse. This involves placing significant emphasis on the ethical review of science and technology, refining the governance of scientific and technological ethics, and achieving a balance between technological innovation and human rights protection.
The author is the executive director of the Center for Sci&Tech and Human Rights Studies, Beijing Institute of Technology
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (97%); HUMAN RIGHTS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EMERGING TECHNOLOGY (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); SCIENCE POLICY (78%); PRIVACY RIGHTS (77%); DISRUPTIVE INNOVATION (73%); INTERNATIONAL RELATIONS (73%); STANDARDS & MEASUREMENTS (73%); PRODUCT INNOVATION (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); INFORMATION SECURITY & PRIVACY (78%); PUBLISHING (73%)
Geographic: BEIJING, CHINA (74%); NORTH CENTRAL CHINA (89%); CHINA (96%)
Load-Date: December 26, 2023",positive,0.5757573843002319,balanced/neutral,"['privacy', 'fairness', 'transparency', 'security', 'human rights']","['justice', 'fairness', 'justice']","['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'framework', 'legislation', 'compliance', 'need to']",[],5,3,10,0
2023,Unknown Title,"Byline: Sara Sugita
Body
In 2014, Harry Susilo endowed Boston University's Questrom School of Business with the Susilo Institute for Ethics in the Global Economy, Questrom's first permanently endowed institute. Since then, the unique institute has promoted ethical business practices and leadership through its original research and educational offerings.
Executive Director of the Institute David Epstein said what sets the Susilo Institute apart from similar institutes in different universities is that it is part of the business school, instead of being a part of the wider university.
""Ethics should be taught as part of business, and it shouldn't be the differential between business and ethics,"" said Epstein, a visiting professor of global leadership and information systems in Questrom.
Questrom School of Business. The Susilo Institute for Ethics in the Global Economy is Questrom's first permanently endowed institute. ISABELLE MEGOSH/DFP PHOTOGRAPHER
Traveling to Singapore
Epstein said a ""staple"" of the Susilo Institute is its annual symposiums - this year's took place in Singapore on Nov. 1. With industry leaders, government officials and academics as speakers, the symposium attracted over 400 people, who varied from corporate executives to politicians.
The symposium goes back and forth between Boston and another city in the world each year. Epstein said this is in alignment with the focus of the Institute to better understand ethics internationally and how it differs all over the world.
This year's symposium, ""Visionary Leadership for the Future; Leading Resilient and Ethical Businesses in our Changing World,"" included a panel on the implications AI would have for the future, from the perspectives of different industries.
Epstein said while he is thrilled to see technological innovations in AI, there are ""many ethical issues"" to consider.
""We try to address some of those issues in these conferences and webinars that we do and dive deep into it,"" Epstein said.
The Institute also hosts multiple webinars inviting leading industry professionals to discuss ethics in different contexts. One of the recent webinars focused on creativity in AI, where advertising professionals and BU professors spoke on the use of AI in the advertising industry.
Evolving ethics courses
Dean of Questrom Susan Fournier has been involved in the Susilo Institute since it was endowed. Within Questrom, she said, ""the Institute allows us to create and perfect and continually evolve the courses that we teach in ethics.""
Ethical Leadership in the Global Economy is a required course for first-year MBA students in Questrom. The course was remade a few years ago by Nina Mazar and Evan Apfelbaum, who are both faculty fellows for the Susilo Institute.
Apfelbaum, an associate professor who currently teaches the course, said contrary to what many students expect, the course does not teach them ""what is right or wrong.""
""It's a course that gets them to think about their values, what they stand for, what businesses and leaders should be responsible for,"" Apfelbaum said.
Throughout the course, students are put through a number of exercises and simulations to ""challenge their own views and their ability to think about taking care of people and doing business at the same time,"" Apfelbaum said.
Lima Kim, a first-year in the MBA program at Questrom who took the course, previously worked as an international sales manager at electronics manufacturer Foxconn, where he described the culture at the company as ""revenue-oriented.""
Throughout the course, Kim said he learned that when ethics are ignored in order to gain revenue in the short term, there are detrimental long-term effects on the corporation and its employees.
""I was starting to think about all the implications of my behaviors,"" Kim said.
Getting students involved
In recent years, Fournier said, the Institute has been evolving to be ""student-centric."" She said the Business and Ethics Case Competition, which started this year, is representative of this mission.
The Business and Ethics Case Competition is directed by
, a master lecturer in Questrom. Stoller said the competition received 71 submissions from 15 countries, of which about 20 teams were selected by a group of over 20 judges, who divided the teams into different regions. The five finalists and a team from BU will receive a subsidy from BU to compete in the global final in southeast Asia in June.
Stoller has been holding different case competitions for 17 years, but this is the first time he is doing it on ethics and business.
Fournier said it is ""incredibly valuable"" to have the teams from around the world come together in person and learn from each other.
Among other institutes in Questrom, Fournier said the Susilo Institute is ""emblematic"" because it forms a strong foundation for Questrom's mission to create global, ethical leaders who ""leverage the power of business to create value for the world.""
""We could never teach that in a classroom.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); BUSINESS EDUCATION (90%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); BUSINESS NEWS (90%); CONFERENCES & CONVENTIONS (90%); ECONOMY & ECONOMIC INDICATORS (90%); GLOBALIZATION (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); TEACHING & TEACHERS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); EXECUTIVES (77%); GOVERNMENT & PUBLIC ADMINISTRATION (73%); PROFESSIONAL WORKERS (71%); ELECTIONS & POLITICS (67%); GOVERNMENT BODIES & OFFICES (67%); PUBLIC OFFICIALS (67%); PRODUCT INNOVATION (63%)
Organization: BOSTON UNIVERSITY (93%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); TELECONFERENCING (85%); GRADUATE & PROFESSIONAL SCHOOLS (78%); MARKETING & ADVERTISING SERVICES (66%); MARKETING & ADVERTISING (62%)
Geographic: BOSTON, MA, USA (94%); SINGAPORE (92%); Boston; MA
Load-Date: November 17, 2023","In 2014, Harry Susilo endowed Boston University's Questrom School of Business with the Susilo Institute for Ethics in the Global Economy, Questrom's first permanently endowed institute. Since then, the unique institute has promoted ethical business practices and leadership through its original research and educational offerings.
Executive Director of the Institute David Epstein said what sets the Susilo Institute apart from similar institutes in different universities is that it is part of the business school, instead of being a part of the wider university.
""Ethics should be taught as part of business, and it shouldn't be the differential between business and ethics,"" said Epstein, a visiting professor of global leadership and information systems in Questrom.
Questrom School of Business. The Susilo Institute for Ethics in the Global Economy is Questrom's first permanently endowed institute. ISABELLE MEGOSH/DFP PHOTOGRAPHER
Traveling to Singapore
Epstein said a ""staple"" of the Susilo Institute is its annual symposiums - this year's took place in Singapore on Nov. 1. With industry leaders, government officials and academics as speakers, the symposium attracted over 400 people, who varied from corporate executives to politicians.
The symposium goes back and forth between Boston and another city in the world each year. Epstein said this is in alignment with the focus of the Institute to better understand ethics internationally and how it differs all over the world.
This year's symposium, ""Visionary Leadership for the Future; Leading Resilient and Ethical Businesses in our Changing World,"" included a panel on the implications AI would have for the future, from the perspectives of different industries.
Epstein said while he is thrilled to see technological innovations in AI, there are ""many ethical issues"" to consider.
""We try to address some of those issues in these conferences and webinars that we do and dive deep into it,"" Epstein said.
The Institute also hosts multiple webinars inviting leading industry professionals to discuss ethics in different contexts. One of the recent webinars focused on creativity in AI, where advertising professionals and BU professors spoke on the use of AI in the advertising industry.
Evolving ethics courses
Dean of Questrom Susan Fournier has been involved in the Susilo Institute since it was endowed. Within Questrom, she said, ""the Institute allows us to create and perfect and continually evolve the courses that we teach in ethics.""
Ethical Leadership in the Global Economy is a required course for first-year MBA students in Questrom. The course was remade a few years ago by Nina Mazar and Evan Apfelbaum, who are both faculty fellows for the Susilo Institute.
Apfelbaum, an associate professor who currently teaches the course, said contrary to what many students expect, the course does not teach them ""what is right or wrong.""
""It's a course that gets them to think about their values, what they stand for, what businesses and leaders should be responsible for,"" Apfelbaum said.
Throughout the course, students are put through a number of exercises and simulations to ""challenge their own views and their ability to think about taking care of people and doing business at the same time,"" Apfelbaum said.
Lima Kim, a first-year in the MBA program at Questrom who took the course, previously worked as an international sales manager at electronics manufacturer Foxconn, where he described the culture at the company as ""revenue-oriented.""
Throughout the course, Kim said he learned that when ethics are ignored in order to gain revenue in the short term, there are detrimental long-term effects on the corporation and its employees.
""I was starting to think about all the implications of my behaviors,"" Kim said.
Getting students involved
In recent years, Fournier said, the Institute has been evolving to be ""student-centric."" She said the Business and Ethics Case Competition, which started this year, is representative of this mission.
The Business and Ethics Case Competition is directed by
, a master lecturer in Questrom. Stoller said the competition received 71 submissions from 15 countries, of which about 20 teams were selected by a group of over 20 judges, who divided the teams into different regions. The five finalists and a team from BU will receive a subsidy from BU to compete in the global final in southeast Asia in June.
Stoller has been holding different case competitions for 17 years, but this is the first time he is doing it on ethics and business.
Fournier said it is ""incredibly valuable"" to have the teams from around the world come together in person and learn from each other.
Among other institutes in Questrom, Fournier said the Susilo Institute is ""emblematic"" because it forms a strong foundation for Questrom's mission to create global, ethical leaders who ""leverage the power of business to create value for the world.""
""We could never teach that in a classroom.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (93%); BUSINESS EDUCATION (90%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); BUSINESS NEWS (90%); CONFERENCES & CONVENTIONS (90%); ECONOMY & ECONOMIC INDICATORS (90%); GLOBALIZATION (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); TEACHING & TEACHERS (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); GRADUATE & PROFESSIONAL SCHOOLS (78%); EXECUTIVES (77%); GOVERNMENT & PUBLIC ADMINISTRATION (73%); PROFESSIONAL WORKERS (71%); ELECTIONS & POLITICS (67%); GOVERNMENT BODIES & OFFICES (67%); PUBLIC OFFICIALS (67%); PRODUCT INNOVATION (63%)
Organization: BOSTON UNIVERSITY (93%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); TELECONFERENCING (85%); GRADUATE & PROFESSIONAL SCHOOLS (78%); MARKETING & ADVERTISING SERVICES (66%); MARKETING & ADVERTISING (62%)
Geographic: BOSTON, MA, USA (94%); SINGAPORE (92%); Boston; MA
Load-Date: November 17, 2023",neutral,0.6348945498466492,balanced/neutral,[],[],['should'],[],0,0,1,0
2023,Unknown Title,"Byline: Aanchal Ghatak
Body
As Generative AI emerges as a transformative force across industries, Salesforce is at the forefront of ensuring its responsible development and deployment. Deepak Pargaonkar, Vice President of Solution Engineering at Salesforce India, unveils their commitment to ethical AI, emphasizing transparency, bias mitigation, and data privacy. With a vision to empower businesses of all sizes, Pargaonkar highlights how Salesforce's Trusted AI Principles pave the way for a future where Generative AI drives innovation without compromising ethical standards.
Generative AI, a powerful force in various industries, raises ethical concerns that demand careful consideration. In this exclusive conversation with Deepak Pargaonkar, Vice President of Solution Engineering at Salesforce India, we delve into how Salesforce approaches the responsible development and deployment of Generative AI solutions. From bias mitigation to data privacy, Pargaonkar sheds light on the ethical guardrails and guidelines that underpin their innovative strides. Excerpts from an interview:
Generative AI has shown tremendous potential in various domains, but it also raises concerns about ethical implications. How does Salesforce approach the responsible development and deployment of Generative AI solutions?
Salesforce takes a responsible and ethical approach to the development and deployment of Generative AI solutions. Our commitment lies in providing safe and accurate AI services to our customers while mitigating potential risks and ethical concerns. Like all of our innovations, we are embedding ethical guardrails and guidance across our products to help customers innovate responsibly. We see tremendous opportunities and challenges emerging in this space, and to ensure responsible development and implementation of generative AI, we're building on our Trusted AI Principles with a new set of guidelines. Our guidelines for Responsible Generative AI aim to assist users of generative AI in addressing potential challenges responsibly during development.
Ethics and bias in AI are critical considerations. What steps does Salesforce take to identify and mitigate potential biases in Generative AI models to ensure fairness and inclusivity?
Salesforce is bringing trusted generative AI to the enterprise. OurOffice of Ethical and Humane Use of Technologyis involved in every step of product development and deployment. We've created a set of guidelines specific to generative AI based on ourTrusted AI Principles, an industry-leading framework to help companies think through how to thoughtfully work with generative AI. Salesforce has always had a multi tenant architecture that ensures our customers have complete control over their data, and customers' data never mixes. Our generative AI products are no different.
In the context of Generative AI, data privacy and security become paramount. How does Salesforce prioritize user data protection while leveraging large datasets to train these advanced models?
We provide several recommendations for enterprises to defend against bias, including ensuring you have consent for the data you're using, being transparent when content has been created by AI, and creating guardrails that prevent some tasks from being fully automated. Our customers - and organizations in general - are responsible for ensuring they are evaluating the representativeness and bias in their data sets, because the models will be grounded in their own data and documents. We believe the benefits of AI should be accessible to everyone but that every company also needs to have strict policies and strategies in place before implementation in order to ensure they're developing and using AI safely, accurately, and ethically.
Can you share any successful use cases where Generative AI has significantly improved processes or decision-making for Salesforce customers, while ensuring responsible AI practices?
A global customer, luxury retailer Gucci, at one of our events spoke about testing and using Salesforce's AI products to enhance its call centre employees' performance. The call centre service agents were augmented into sales and marketing agents. It gave them capabilities they didn't have before. The goal is to enhance workers, not make them obsolete - the vision is ""human touch powered by technology. Case handling efficiency with Einstein GPT (Service GPT) was 30% higher compared to users not using the technology - a very promising pilot.
Explainable AI is crucial for building trust and understanding model behaviour. How does Salesforce tackle the explainability challenge in complex Generative AI models?
We have a strong presence within the world's largest corporations, connecting with billions of people through diverse channels. Our services cater to industries that significantly influence society in every aspect. To maintain the highest level of trust, it is crucial that all our solutions demonstrate mission-critical reliability. Although we recognize the potential of generative AI, building trust in its capabilities remains a challenging endeavor. We are helping users validate the accuracy of content created, helping them understand the confidence of the content created, and of course keeping a human-in-the-loop. Through the application of explainable AI, we are looking at citing sources and shedding light on the reasoning behind the generated outputs, such as with chain-of-thought prompts that may lead to the kinds of outputs seen in the media so far.
In the fast-paced technology landscape, regulations surrounding AI are evolving. How does Salesforce navigate the legal and regulatory landscape to ensure compliance with responsible AI principles?
In the ever-advancing landscape of AI adoption, establishing trust becomes paramount, and Salesforce places it as a top priority. To ensure responsible AI usage, we support risk-based AI regulation, that differentiates contexts and uses of the technology and assigns responsibilities based on the different roles that various entities play in the AI ecosystem. We remain dedicated to embedding ethical guardrails and providing guidance throughout our product offerings, aligning with our commitment to responsible innovation. Moreover, we are actively building on our Trusted AI Principles, developing a new set of guidelinesthat specifically address the responsible development and implementation of generative AI. By emphasizing trust, responsible practices, and continuous improvement, we aim to enable our customers to leverage AI technologies while upholding high ethical standards.
Finally, what is your vision for the future of Generative AI and its impact on Salesforce's products and services, while upholding the highest standards of responsible AI development? 
We believe Generative AI has the potential to change every industry in the future. It has the power to transform the way we live and work in profound ways and will challenge even the most innovative companies for years to come. While today big companies are racing to leverage generative AI, we believe in the future it can also help small- and medium-sized businesses (SMBs) sell smarter and more efficiently, regardless of a company's resources. For example, SMBs can use generative AI through our Sales Cloud to streamline the sales process and close more deals faster and with fewer resources. When it comes to responsible AI development, Salesforce has been working on generative AI for years and our views have remained the same. We've created a set of guidelines specific to generative AI based on our Trusted AI Principles, an industry-leading framework to help companies think through how to thoughtfully work with generative AI.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INTERVIEWS (78%); PRODUCT DEVELOPMENT (78%)
Industry: GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DATA SECURITY (77%); BIG DATA (72%)
Load-Date: October 6, 2023","As Generative AI emerges as a transformative force across industries, Salesforce is at the forefront of ensuring its responsible development and deployment. Deepak Pargaonkar, Vice President of Solution Engineering at Salesforce India, unveils their commitment to ethical AI, emphasizing transparency, bias mitigation, and data privacy. With a vision to empower businesses of all sizes, Pargaonkar highlights how Salesforce's Trusted AI Principles pave the way for a future where Generative AI drives innovation without compromising ethical standards.
Generative AI, a powerful force in various industries, raises ethical concerns that demand careful consideration. In this exclusive conversation with Deepak Pargaonkar, Vice President of Solution Engineering at Salesforce India, we delve into how Salesforce approaches the responsible development and deployment of Generative AI solutions. From bias mitigation to data privacy, Pargaonkar sheds light on the ethical guardrails and guidelines that underpin their innovative strides. Excerpts from an interview:
Generative AI has shown tremendous potential in various domains, but it also raises concerns about ethical implications. How does Salesforce approach the responsible development and deployment of Generative AI solutions?
Salesforce takes a responsible and ethical approach to the development and deployment of Generative AI solutions. Our commitment lies in providing safe and accurate AI services to our customers while mitigating potential risks and ethical concerns. Like all of our innovations, we are embedding ethical guardrails and guidance across our products to help customers innovate responsibly. We see tremendous opportunities and challenges emerging in this space, and to ensure responsible development and implementation of generative AI, we're building on our Trusted AI Principles with a new set of guidelines. Our guidelines for Responsible Generative AI aim to assist users of generative AI in addressing potential challenges responsibly during development.
Ethics and bias in AI are critical considerations. What steps does Salesforce take to identify and mitigate potential biases in Generative AI models to ensure fairness and inclusivity?
Salesforce is bringing trusted generative AI to the enterprise. OurOffice of Ethical and Humane Use of Technologyis involved in every step of product development and deployment. We've created a set of guidelines specific to generative AI based on ourTrusted AI Principles, an industry-leading framework to help companies think through how to thoughtfully work with generative AI. Salesforce has always had a multi tenant architecture that ensures our customers have complete control over their data, and customers' data never mixes. Our generative AI products are no different.
In the context of Generative AI, data privacy and security become paramount. How does Salesforce prioritize user data protection while leveraging large datasets to train these advanced models?
We provide several recommendations for enterprises to defend against bias, including ensuring you have consent for the data you're using, being transparent when content has been created by AI, and creating guardrails that prevent some tasks from being fully automated. Our customers - and organizations in general - are responsible for ensuring they are evaluating the representativeness and bias in their data sets, because the models will be grounded in their own data and documents. We believe the benefits of AI should be accessible to everyone but that every company also needs to have strict policies and strategies in place before implementation in order to ensure they're developing and using AI safely, accurately, and ethically.
Can you share any successful use cases where Generative AI has significantly improved processes or decision-making for Salesforce customers, while ensuring responsible AI practices?
A global customer, luxury retailer Gucci, at one of our events spoke about testing and using Salesforce's AI products to enhance its call centre employees' performance. The call centre service agents were augmented into sales and marketing agents. It gave them capabilities they didn't have before. The goal is to enhance workers, not make them obsolete - the vision is ""human touch powered by technology. Case handling efficiency with Einstein GPT (Service GPT) was 30% higher compared to users not using the technology - a very promising pilot.
Explainable AI is crucial for building trust and understanding model behaviour. How does Salesforce tackle the explainability challenge in complex Generative AI models?
We have a strong presence within the world's largest corporations, connecting with billions of people through diverse channels. Our services cater to industries that significantly influence society in every aspect. To maintain the highest level of trust, it is crucial that all our solutions demonstrate mission-critical reliability. Although we recognize the potential of generative AI, building trust in its capabilities remains a challenging endeavor. We are helping users validate the accuracy of content created, helping them understand the confidence of the content created, and of course keeping a human-in-the-loop. Through the application of explainable AI, we are looking at citing sources and shedding light on the reasoning behind the generated outputs, such as with chain-of-thought prompts that may lead to the kinds of outputs seen in the media so far.
In the fast-paced technology landscape, regulations surrounding AI are evolving. How does Salesforce navigate the legal and regulatory landscape to ensure compliance with responsible AI principles?
In the ever-advancing landscape of AI adoption, establishing trust becomes paramount, and Salesforce places it as a top priority. To ensure responsible AI usage, we support risk-based AI regulation, that differentiates contexts and uses of the technology and assigns responsibilities based on the different roles that various entities play in the AI ecosystem. We remain dedicated to embedding ethical guardrails and providing guidance throughout our product offerings, aligning with our commitment to responsible innovation. Moreover, we are actively building on our Trusted AI Principles, developing a new set of guidelinesthat specifically address the responsible development and implementation of generative AI. By emphasizing trust, responsible practices, and continuous improvement, we aim to enable our customers to leverage AI technologies while upholding high ethical standards.
Finally, what is your vision for the future of Generative AI and its impact on Salesforce's products and services, while upholding the highest standards of responsible AI development? 
We believe Generative AI has the potential to change every industry in the future. It has the power to transform the way we live and work in profound ways and will challenge even the most innovative companies for years to come. While today big companies are racing to leverage generative AI, we believe in the future it can also help small- and medium-sized businesses (SMBs) sell smarter and more efficiently, regardless of a company's resources. For example, SMBs can use generative AI through our Sales Cloud to streamline the sales process and close more deals faster and with fewer resources. When it comes to responsible AI development, Salesforce has been working on generative AI for years and our views have remained the same. We've created a set of guidelines specific to generative AI based on our Trusted AI Principles, an industry-leading framework to help companies think through how to thoughtfully work with generative AI.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ETHICS (93%); GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INTERVIEWS (78%); PRODUCT DEVELOPMENT (78%)
Industry: GENERATIVE AI (93%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); DATA SECURITY (77%); BIG DATA (72%)
Load-Date: October 6, 2023",positive,0.710339367389679,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'explainability', 'security', 'consent', 'inclusivity']",['fairness'],"['regulation', 'standards', 'guidelines', 'framework', 'compliance', 'should']","['generative ai', 'gpt']",8,1,6,2
2023,Unknown Title,"Byline: Targeted News Service
Dateline: BASEL, Switzerland 
Body
AI and Ethics, a peer-reviewed journal that says it features artificial intelligence techniques, tools and technologies, published research articles on the following topics in its August 2023 edition:
Opinion Papers:
* Towards artificial virtuous agents: games, dilemmas and machine learning
* A policy primer and roadmap on AI worker surveillance and productivity scoring tools
* Social and ethical challenges of the metaverse
Original Research:
* Speciesist bias in AI: how AI applications perpetuate discrimination and unfair outcomes against animals
* Assessing the ethical and social concerns of artificial intelligence in neuroinformatics research: an empirical test of the European Union Assessment List for Trustworthy AI (ALTAI)
* A narrative review of fairness and morality in neuroscience: insights to artificial intelligence
* Privacy without persons: a Buddhist critique of surveillance capitalism
* A principled governance for emerging AI regimes: lessons from China, the European Union, and the United States
* Segmentation of ethics, legal, and social issues (ELSI) related to AI in Japan, the United States, and Germany
* AI for hiring in context: a perspective on overcoming the unique challenges of employment research to mitigate disparate impact
* Artificial intelligence and the model of rules: better than us?
* Value elicitation on a scenario of autonomous weapon system deployment: a qualitative study based on the value deliberation process
* Against explainability requirements for ethical artificial intelligence in health care
* Ethics in human-AI teaming: principles and perspectives
* Facial identity protection using deep learning technologies: an application in affective computing
The August 2023 edition of AI and Ethics can be viewed at https://link.springer.com/journal/43681/volumes-and-issues/3-3. The journal is published by Springer Nature Switzerland.
[Category: Computer Technology]
MSTRUCK-8221566 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EUROPEAN UNION (90%); NEGATIVE SOCIETAL NEWS (90%); RESEARCH REPORTS (90%); SOCIETAL ISSUES (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); DEEP LEARNING (79%); MACHINE LEARNING (79%); PRODUCTIVITY (78%); SURVEILLANCE (78%); DISCRIMINATION (76%); NEUROSCIENCE (69%); RELIGION (54%); MILITARY WEAPONS (51%); WEAPONS & ARMS (51%)
Organization:  EUROPEAN UNION (83%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); DEEP LEARNING (79%); MACHINE LEARNING (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); COMPUTER EQUIPMENT (77%); METAVERSE (74%); MILITARY WEAPONS (51%)
Geographic: BASEL, SWITZERLAND (79%); UNITED STATES (91%); EUROPE (90%); SWITZERLAND (90%); CHINA (77%); JAPAN (77%); EUROPEAN UNION MEMBER STATES (71%); GERMANY (56%)
Load-Date: July 21, 2023","AI and Ethics, a peer-reviewed journal that says it features artificial intelligence techniques, tools and technologies, published research articles on the following topics in its August 2023 edition:
Opinion Papers:
* Towards artificial virtuous agents: games, dilemmas and machine learning
* A policy primer and roadmap on AI worker surveillance and productivity scoring tools
* Social and ethical challenges of the metaverse
Original Research:
* Speciesist bias in AI: how AI applications perpetuate discrimination and unfair outcomes against animals
* Assessing the ethical and social concerns of artificial intelligence in neuroinformatics research: an empirical test of the European Union Assessment List for Trustworthy AI (ALTAI)
* A narrative review of fairness and morality in neuroscience: insights to artificial intelligence
* Privacy without persons: a Buddhist critique of surveillance capitalism
* A principled governance for emerging AI regimes: lessons from China, the European Union, and the United States
* Segmentation of ethics, legal, and social issues (ELSI) related to AI in Japan, the United States, and Germany
* AI for hiring in context: a perspective on overcoming the unique challenges of employment research to mitigate disparate impact
* Artificial intelligence and the model of rules: better than us?
* Value elicitation on a scenario of autonomous weapon system deployment: a qualitative study based on the value deliberation process
* Against explainability requirements for ethical artificial intelligence in health care
* Ethics in human-AI teaming: principles and perspectives
* Facial identity protection using deep learning technologies: an application in affective computing
The August 2023 edition of AI and Ethics can be viewed at https://link.springer.com/journal/43681/volumes-and-issues/3-3. The journal is published by Springer Nature Switzerland.
[Category: Computer Technology]
MSTRUCK-8221566 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EUROPEAN UNION (90%); NEGATIVE SOCIETAL NEWS (90%); RESEARCH REPORTS (90%); SOCIETAL ISSUES (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); DEEP LEARNING (79%); MACHINE LEARNING (79%); PRODUCTIVITY (78%); SURVEILLANCE (78%); DISCRIMINATION (76%); NEUROSCIENCE (69%); RELIGION (54%); MILITARY WEAPONS (51%); WEAPONS & ARMS (51%)
Organization:  EUROPEAN UNION (83%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); DEEP LEARNING (79%); MACHINE LEARNING (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); COMPUTER EQUIPMENT (77%); METAVERSE (74%); MILITARY WEAPONS (51%)
Geographic: BASEL, SWITZERLAND (79%); UNITED STATES (91%); EUROPE (90%); SWITZERLAND (90%); CHINA (77%); JAPAN (77%); EUROPEAN UNION MEMBER STATES (71%); GERMANY (56%)
Load-Date: July 21, 2023",neutral,0.8688913583755493,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'fairness', 'explainability']",['fairness'],"['policy', 'governance']","['machine learning', 'deep learning']",6,1,2,2
2023,Unknown Title,"Byline: Aamir Sheikh
Body
Oct 09, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In the throes of a technological revolution, a new frontier in mental healthcare is emerging as AI takes center stage. Recent advancements in generative Artificial Intelligence, particularly in the form of chatbots like ChatGPT and Woebot, have sparked a conversation about their potential role in treating mental health issues. While the promise of accessible and affordable therapy is enticing, the implementation of AI in mental healthcare comes with a myriad of ethical quandaries, regulatory gaps, and concerns about patient well-being. 
AI's potential in mental health 
As the prevalence of mental health issues reaches unprecedented levels, the integration of AI chatbots as therapy tools has garnered attention. These digital companions, equipped with machine learning capabilities, can engage in online conversations, providing support and treatment for conditions like depression and anxiety. Despite being privately funded, several AI chatbots have received FDA recognition for their effectiveness, earning them a 'breakthrough' designation. 
While the potential benefits are evident, ethical concerns loom large. Informed consent, a cornerstone of responsible medical practice, becomes a challenge in the realm of AI chatbot therapy. The difficulty in obtaining consent online raises questions about the user's understanding of the AI's functioning and potential side effects. Furthermore, ethical debates emerge regarding the obligation of AI bots to report critical information, from suicidal thoughts to confessions of illegal activities. 
Navigating ethical quandaries of AI 
Beyond consent, a plethora of ethical dilemmas surrounds AI in mental healthcare. Issues of transparency, autonomy, and the responsibility for failed treatments present a complex landscape. The absence of defined malpractice standards for AI treatments leaves a void in accountability, raising questions about the repercussions of unsuccessful outcomes. 
Patient privacy and confidentiality, paramount in therapeutic settings, face unprecedented challenges with AI chatbots. The very interactions designed to aid the AI's learning process may compromise the confidentiality that is crucial for patients to open up about sensitive matters. Additionally, the potential usage of AI chatbots by minors poses a distinct ethical challenge, as the understanding and impact of these interventions on young minds remain uncertain. 
Balance and pitfalls of AI in mental healthcare 
Despite these ethical hurdles, the use of AI chatbots in mental health holds promise, especially in terms of accessibility. In a mental health landscape strained by limited resources and a surge in cases, AI offers a direct and cost-effective avenue for treatment. The ability of AI chatbots to identify cases of depression efficiently and direct patients to appropriate resources could revolutionize the way mental health is approached. 
However, the path forward necessitates a delicate balance. While AI chatbots can augment mental health care, they should operate under the guidance and responsibility of trained professionals. As these digital companions continue to evolve, regulatory frameworks, possibly led by organizations like the FDA, must be established to address ethical concerns, ensure patient safety, and provide a roadmap for responsible AI integration[1] in mental healthcare. 
The integration of AI in mental healthcare represents a dual-edged sword—offering a lifeline of accessible treatment while navigating uncharted ethical territories. The future of mental health care lies in striking a balance between the promise of AI and the imperative to uphold ethical standards, ensuring that innovation aligns with the well-being of those seeking solace in the digital realm. 
 [ 1]: https://www.cryptopolitan.com/advances-in-ai-transform-healthcare/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: CONVERSATIONAL AI (92%); GENERATIVE AI (92%); MENTAL HEALTH (92%); CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MEDICINE & HEALTH (90%); MENTAL ILLNESS (90%); DEPRESSION (89%); NEGATIVE NEWS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); HEALTH CARE COST TRANSPARENCY (78%); HEALTH CARE POLICY (78%); PATIENT CONSENT (78%); PATIENT PRIVACY (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (77%); MACHINE LEARNING (73%); HUMAN SUBJECTS (71%); SUICIDE (68%); PROFESSIONAL WORKERS (66%); PRIVACY RIGHTS (62%); CRIME, LAW ENFORCEMENT & CORRECTIONS (50%); Trending News (%); AI (%); artificial intelligence (%); chatbots (%); healthcare (%); Mental health (%)
Organization: FOOD & DRUG ADMINISTRATION (56%)
Industry: CONVERSATIONAL AI (92%); GENERATIVE AI (92%); CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); HEALTH CARE COST TRANSPARENCY (78%); HEALTH CARE POLICY (78%); PATIENT CONSENT (78%); PATIENT PRIVACY (78%); MACHINE LEARNING (73%)
Load-Date: October 9, 2023","Oct 09, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In the throes of a technological revolution, a new frontier in mental healthcare is emerging as AI takes center stage. Recent advancements in generative Artificial Intelligence, particularly in the form of chatbots like ChatGPT and Woebot, have sparked a conversation about their potential role in treating mental health issues. While the promise of accessible and affordable therapy is enticing, the implementation of AI in mental healthcare comes with a myriad of ethical quandaries, regulatory gaps, and concerns about patient well-being. 
AI's potential in mental health 
As the prevalence of mental health issues reaches unprecedented levels, the integration of AI chatbots as therapy tools has garnered attention. These digital companions, equipped with machine learning capabilities, can engage in online conversations, providing support and treatment for conditions like depression and anxiety. Despite being privately funded, several AI chatbots have received FDA recognition for their effectiveness, earning them a 'breakthrough' designation. 
While the potential benefits are evident, ethical concerns loom large. Informed consent, a cornerstone of responsible medical practice, becomes a challenge in the realm of AI chatbot therapy. The difficulty in obtaining consent online raises questions about the user's understanding of the AI's functioning and potential side effects. Furthermore, ethical debates emerge regarding the obligation of AI bots to report critical information, from suicidal thoughts to confessions of illegal activities. 
Navigating ethical quandaries of AI 
Beyond consent, a plethora of ethical dilemmas surrounds AI in mental healthcare. Issues of transparency, autonomy, and the responsibility for failed treatments present a complex landscape. The absence of defined malpractice standards for AI treatments leaves a void in accountability, raising questions about the repercussions of unsuccessful outcomes. 
Patient privacy and confidentiality, paramount in therapeutic settings, face unprecedented challenges with AI chatbots. The very interactions designed to aid the AI's learning process may compromise the confidentiality that is crucial for patients to open up about sensitive matters. Additionally, the potential usage of AI chatbots by minors poses a distinct ethical challenge, as the understanding and impact of these interventions on young minds remain uncertain. 
Balance and pitfalls of AI in mental healthcare 
Despite these ethical hurdles, the use of AI chatbots in mental health holds promise, especially in terms of accessibility. In a mental health landscape strained by limited resources and a surge in cases, AI offers a direct and cost-effective avenue for treatment. The ability of AI chatbots to identify cases of depression efficiently and direct patients to appropriate resources could revolutionize the way mental health is approached. 
However, the path forward necessitates a delicate balance. While AI chatbots can augment mental health care, they should operate under the guidance and responsibility of trained professionals. As these digital companions continue to evolve, regulatory frameworks, possibly led by organizations like the FDA, must be established to address ethical concerns, ensure patient safety, and provide a roadmap for responsible AI integration[1] in mental healthcare. 
The integration of AI in mental healthcare represents a dual-edged sword—offering a lifeline of accessible treatment while navigating uncharted ethical territories. The future of mental health care lies in striking a balance between the promise of AI and the imperative to uphold ethical standards, ensuring that innovation aligns with the well-being of those seeking solace in the digital realm. 
 [ 1]: https://www.cryptopolitan.com/advances-in-ai-transform-healthcare/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: CONVERSATIONAL AI (92%); GENERATIVE AI (92%); MENTAL HEALTH (92%); CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MEDICINE & HEALTH (90%); MENTAL ILLNESS (90%); DEPRESSION (89%); NEGATIVE NEWS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); HEALTH CARE COST TRANSPARENCY (78%); HEALTH CARE POLICY (78%); PATIENT CONSENT (78%); PATIENT PRIVACY (78%); SAFETY (78%); SAFETY, ACCIDENTS & DISASTERS (77%); MACHINE LEARNING (73%); HUMAN SUBJECTS (71%); SUICIDE (68%); PROFESSIONAL WORKERS (66%); PRIVACY RIGHTS (62%); CRIME, LAW ENFORCEMENT & CORRECTIONS (50%); Trending News (%); AI (%); artificial intelligence (%); chatbots (%); healthcare (%); Mental health (%)
Organization: FOOD & DRUG ADMINISTRATION (56%)
Industry: CONVERSATIONAL AI (92%); GENERATIVE AI (92%); CHATBOTS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BLOGS & MESSAGE BOARDS (78%); HEALTH CARE COST TRANSPARENCY (78%); HEALTH CARE POLICY (78%); PATIENT CONSENT (78%); PATIENT PRIVACY (78%); MACHINE LEARNING (73%)
Load-Date: October 9, 2023",neutral,0.6143842339515686,balanced/neutral,"['privacy', 'transparency', 'accountability', 'safety', 'autonomy', 'consent']",['autonomy'],"['policy', 'standards', 'law', 'should', 'must']","['machine learning', 'generative ai', 'chatgpt']",6,1,5,3
2023,Unknown Title,"Byline: Brenda Kanana
Body
Sep 11, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In a significant move, Google has introduced the Digital Futures Project, demonstrating its commitment to financing ethical AI research[1]. This initiative aims to bring together a diverse range of experts to understand and address the myriad opportunities and challenges of artificial intelligence (AI). 
Google.org, the company's philanthropic arm, has allocated a substantial fund of $20 million to provide grants to leading think tanks and academic institutions worldwide. These grants will facilitate discussions, research inquiries, and debates on public policy solutions to promote AI's ethical development. 
Growing concerns surrounding ethical AI 
This announcement[2] comes at a crucial juncture as the tech industry witnesses a proliferation of AI technologies. While AI offers numerous advantages, concerns have escalated regarding its ethical use. Users have expressed reservations about AI 'hallucinations' observed in services like ChatGPT 4 and Bing AI, highlighting this technology's evolving yet nascent nature. 
Content creators are apprehensive about AI potentially plagiarizing their work and enabling its unauthorized reuse. Concurrently, businesses are concerned about the potential misuse of AI tools and inadvertent data breaches. 
A fund for ethical AI beyond Google 
Despite discussing 'ethical AI' for several years, Google's Digital Futures Project signifies a notable shift by establishing a fund to promote ethical AI research beyond the company's initiatives. Collaboration is paramount in this endeavor, and Google has garnered the support of several influential organizations as inaugural recipients of the Digital Futures Project grants. 
These organizations include the Aspen Institute, Brookings Institution, Carnegie Endowment for International Peace, the Center for a New American Security, the Center for Strategic and International Studies, the Institute for Security and Technology, Leadership Conference Education Fund, MIT Work of the Future, R Street Institute, and SeedAI. 
Urgent calls for industry standardization 
Amidst concerns regarding ethical AI, there is a growing demand for establishing industry-wide standards. These standards are expected to address issues such as fairness, bias, misinformation, security, and the future of work in the context of AI technologies. Google's initiative, which emphasizes collaboration with various stakeholders, underscores the recognition that these questions require collective efforts from industry players, academia, governments, and civil society. 
The Digital Futures Project, with its dedication to advancing ethical AI, seeks to foster a more comprehensive understanding of AI's societal implications. This project will catalyze meaningful discussions and research inquiries into AI's impact. Google's $20 million fund will enable think tanks and academic institutions worldwide to engage in productive dialogue and research endeavors focused on ethical AI development. 
Brigitte Hoyer Gosselink, Director at Google, underscores the significance of this initiative, stating, 'AI raises questions about fairness, bias, misinformation, security, and the future of work. Addressing these questions necessitates extensive collaboration among industry stakeholders, academia, governments, and civil society.' This acknowledgment underscores the imperative need for multifaceted cooperation to confront AI technology's complex challenges. 
Partnering for progress 
Google's collaboration with esteemed organizations underscores the gravity of its commitment to ethical AI. These partners bring their expertise to the table and will actively contribute to the dialogue and research facilitated by the Digital Futures Project. Their involvement signifies a collective effort to steer AI development toward ethical and responsible directions. 
In the swiftly evolving realm of artificial intelligence, Google's Digital Futures Project is a significant milestone in pursuing ethical AI development. With substantial funding and partnerships with esteemed organizations, this initiative aims to address pressing concerns while promoting a global dialogue on ethical AI. 
As the project unfolds, it is poised to provide valuable insights and contribute to developing industry standards that ensure AI technologies are leveraged for the benefit of society while upholding ethical principles and fairness. Collaborative efforts across sectors are increasingly crucial as the world grapples with the transformative potential of AI. 
 [ 1]: https://www.cryptopolitan.com/termination-chatterjee-ai-research-team/ [ 2]: https://blog.google/outreach-initiatives/google-org/launching-the-digital-futures-project-to-support-responsible-ai/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); EDUCATION SYSTEMS & INSTITUTIONS (89%); ENDOWMENTS (89%); FUTURE OF WORK (89%); GRANTS & GIFTS (89%); RESEARCH INSTITUTES (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); CHATBOTS (79%); CONVERSATIONAL AI (79%); GENERATIVE AI (79%); CHARITIES (78%); FOUNDATIONS (78%); PUBLIC POLICY (78%); CORPORATE GIVING (76%); PHILANTHROPY (76%); OUTPUT & DEMAND (74%); CONFERENCES & CONVENTIONS (73%); EDUCATION FUNDING (73%); NEGATIVE TECHNOLOGY NEWS (73%); PLAGIARISM (72%); DATA BREACHES (66%); DISINFORMATION & MISINFORMATION (65%); STANDARDS & MEASUREMENTS (61%); AI in Daily Life (%); AI (%); Ethical AI Research (%); Funding (%); Google (%)
Company:  GOOGLE LLC (97%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (97%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); EDUCATIONAL SERVICES (89%); CHATBOTS (79%); CONVERSATIONAL AI (79%); GENERATIVE AI (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); DATA BREACHES (66%); DATA SECURITY (66%)
Load-Date: September 11, 2023","Sep 11, 2023( Cryptopolitan: https://www.cryptopolitan.com Delivered by Newstex)  
 In a significant move, Google has introduced the Digital Futures Project, demonstrating its commitment to financing ethical AI research[1]. This initiative aims to bring together a diverse range of experts to understand and address the myriad opportunities and challenges of artificial intelligence (AI). 
Google.org, the company's philanthropic arm, has allocated a substantial fund of $20 million to provide grants to leading think tanks and academic institutions worldwide. These grants will facilitate discussions, research inquiries, and debates on public policy solutions to promote AI's ethical development. 
Growing concerns surrounding ethical AI 
This announcement[2] comes at a crucial juncture as the tech industry witnesses a proliferation of AI technologies. While AI offers numerous advantages, concerns have escalated regarding its ethical use. Users have expressed reservations about AI 'hallucinations' observed in services like ChatGPT 4 and Bing AI, highlighting this technology's evolving yet nascent nature. 
Content creators are apprehensive about AI potentially plagiarizing their work and enabling its unauthorized reuse. Concurrently, businesses are concerned about the potential misuse of AI tools and inadvertent data breaches. 
A fund for ethical AI beyond Google 
Despite discussing 'ethical AI' for several years, Google's Digital Futures Project signifies a notable shift by establishing a fund to promote ethical AI research beyond the company's initiatives. Collaboration is paramount in this endeavor, and Google has garnered the support of several influential organizations as inaugural recipients of the Digital Futures Project grants. 
These organizations include the Aspen Institute, Brookings Institution, Carnegie Endowment for International Peace, the Center for a New American Security, the Center for Strategic and International Studies, the Institute for Security and Technology, Leadership Conference Education Fund, MIT Work of the Future, R Street Institute, and SeedAI. 
Urgent calls for industry standardization 
Amidst concerns regarding ethical AI, there is a growing demand for establishing industry-wide standards. These standards are expected to address issues such as fairness, bias, misinformation, security, and the future of work in the context of AI technologies. Google's initiative, which emphasizes collaboration with various stakeholders, underscores the recognition that these questions require collective efforts from industry players, academia, governments, and civil society. 
The Digital Futures Project, with its dedication to advancing ethical AI, seeks to foster a more comprehensive understanding of AI's societal implications. This project will catalyze meaningful discussions and research inquiries into AI's impact. Google's $20 million fund will enable think tanks and academic institutions worldwide to engage in productive dialogue and research endeavors focused on ethical AI development. 
Brigitte Hoyer Gosselink, Director at Google, underscores the significance of this initiative, stating, 'AI raises questions about fairness, bias, misinformation, security, and the future of work. Addressing these questions necessitates extensive collaboration among industry stakeholders, academia, governments, and civil society.' This acknowledgment underscores the imperative need for multifaceted cooperation to confront AI technology's complex challenges. 
Partnering for progress 
Google's collaboration with esteemed organizations underscores the gravity of its commitment to ethical AI. These partners bring their expertise to the table and will actively contribute to the dialogue and research facilitated by the Digital Futures Project. Their involvement signifies a collective effort to steer AI development toward ethical and responsible directions. 
In the swiftly evolving realm of artificial intelligence, Google's Digital Futures Project is a significant milestone in pursuing ethical AI development. With substantial funding and partnerships with esteemed organizations, this initiative aims to address pressing concerns while promoting a global dialogue on ethical AI. 
As the project unfolds, it is poised to provide valuable insights and contribute to developing industry standards that ensure AI technologies are leveraged for the benefit of society while upholding ethical principles and fairness. Collaborative efforts across sectors are increasingly crucial as the world grapples with the transformative potential of AI. 
 [ 1]: https://www.cryptopolitan.com/termination-chatterjee-ai-research-team/ [ 2]: https://blog.google/outreach-initiatives/google-org/launching-the-digital-futures-project-to-support-responsible-ai/ 
Link to the original story.
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CTAN-10009995
Subject: ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); EDUCATION SYSTEMS & INSTITUTIONS (89%); ENDOWMENTS (89%); FUTURE OF WORK (89%); GRANTS & GIFTS (89%); RESEARCH INSTITUTES (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); CHATBOTS (79%); CONVERSATIONAL AI (79%); GENERATIVE AI (79%); CHARITIES (78%); FOUNDATIONS (78%); PUBLIC POLICY (78%); CORPORATE GIVING (76%); PHILANTHROPY (76%); OUTPUT & DEMAND (74%); CONFERENCES & CONVENTIONS (73%); EDUCATION FUNDING (73%); NEGATIVE TECHNOLOGY NEWS (73%); PLAGIARISM (72%); DATA BREACHES (66%); DISINFORMATION & MISINFORMATION (65%); STANDARDS & MEASUREMENTS (61%); AI in Daily Life (%); AI (%); Ethical AI Research (%); Funding (%); Google (%)
Company:  GOOGLE LLC (97%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (97%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); EDUCATION SYSTEMS & INSTITUTIONS (89%); EDUCATIONAL SERVICES (89%); CHATBOTS (79%); CONVERSATIONAL AI (79%); GENERATIVE AI (79%); INFORMATION TECHNOLOGY INDUSTRY (79%); DATA BREACHES (66%); DATA SECURITY (66%)
Load-Date: September 11, 2023",positive,0.5309352278709412,balanced/neutral,"['bias', 'fairness', 'security', 'misinformation', 'disinformation']",['fairness'],"['policy', 'standards', 'should', 'calls for']","['generative ai', 'chatgpt']",5,1,4,2
2023,Unknown Title,"Byline: DONAL O'DONOVAN
Body
Trinity Business School has launched a new Trinity Corporate Governance Lab, which it says intends to define corporate governance best practice for the next decade.
Governance has become a major focus for investors as the 'G' in environmental, social and governance (ESG), while so-called frontier technologies like artificial intelligence (AI) are throwing up new ethical dilemmas.
Generative AI start-up, OPENAI, has become a case in point, where boardlevel clashes have been characterised as a battle between financial imperatives to growth the business and ethical concerns around how far and fast the technology can safely develop.
Trinity Corporate Governance Lab will deliver innovative, collaborative projects and research in the areas of corporate governance and business ethics.
The lab is a spin-out of the Trinity Centre for Social Innovation and will work closely with the Trinity Centre for Digital Business and Analytics.
Currently, the lab is responsible for the Trinity Business Ethics Speaker Series and also plans to introduce an ""Executive in Residence"" programme as well as other offerings in the executive education space. Business advisory firm FTI Consulting has been announced as its inaugural knowledge partner, with Mason Hayes & Curran on board as its second knowledge partner.
The project is being launched today at an event at Trinity Business School, with Dr Stephen Davis, senior fellow at the Harvard Law School Program on Corporate Governance, providing a keynote speech.
Research projects at the new lab will include Frontier Technology, Corporate Moral Progress - which aims to identify the responsibility of firms, explore the sources of their immorality and chart a path for their improvement; and Socially Acceptable and Fair AI, which proposes to develop a methodology for the design of fair AI applications.
Dr Daniel Malan, assistant professor in Business Ethics and director of the Trinity Corporate Governance Lab, said the lab will provide a platform to integrate governance and business ethics into the delivery of research and world-class education.
""The Lab is perfectly aligned with the Business School strategy... and we look forward to work with our academic and industry partners to have real impact,"" he said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: IIN
Subject: CORPORATE GOVERNANCE (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS EDUCATION (90%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); ESG FACTORS - GOVERNANCE (90%); TECHNOLOGY (90%); GRADUATE & PROFESSIONAL SCHOOLS (89%); BEST PRACTICES (78%); COMPANY STRATEGY (78%); ESG FACTORS (78%); LAW SCHOOLS (78%); RESEARCH & DEVELOPMENT (78%); SCHOOL BUSINESS PARTNERSHIPS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ALLIANCES & PARTNERSHIPS (77%); SUSTAINABLE INVESTING (77%); DATA ANALYTICS (76%); GENERATIVE AI (73%); LAWYERS (72%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Company:  FTI CONSULTING INC (54%)
Ticker: FCN (NYSE) (54%)
Industry: NAICS541618 OTHER MANAGEMENT CONSULTING SERVICES (54%); NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (54%); SIC8748 BUSINESS CONSULTING SERVICES, NEC (54%); SIC8742 MANAGEMENT CONSULTING SERVICES (54%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GRADUATE & PROFESSIONAL SCHOOLS (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); LAW SCHOOLS (78%); SUSTAINABLE INVESTING (77%); DATA ANALYTICS (76%); GENERATIVE AI (73%); SPACE INDUSTRY (73%); LAWYERS (72%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Geographic: IRELAND (59%); National Edition
Load-Date: December 4, 2023","Trinity Business School has launched a new Trinity Corporate Governance Lab, which it says intends to define corporate governance best practice for the next decade.
Governance has become a major focus for investors as the 'G' in environmental, social and governance (ESG), while so-called frontier technologies like artificial intelligence (AI) are throwing up new ethical dilemmas.
Generative AI start-up, OPENAI, has become a case in point, where boardlevel clashes have been characterised as a battle between financial imperatives to growth the business and ethical concerns around how far and fast the technology can safely develop.
Trinity Corporate Governance Lab will deliver innovative, collaborative projects and research in the areas of corporate governance and business ethics.
The lab is a spin-out of the Trinity Centre for Social Innovation and will work closely with the Trinity Centre for Digital Business and Analytics.
Currently, the lab is responsible for the Trinity Business Ethics Speaker Series and also plans to introduce an ""Executive in Residence"" programme as well as other offerings in the executive education space. Business advisory firm FTI Consulting has been announced as its inaugural knowledge partner, with Mason Hayes & Curran on board as its second knowledge partner.
The project is being launched today at an event at Trinity Business School, with Dr Stephen Davis, senior fellow at the Harvard Law School Program on Corporate Governance, providing a keynote speech.
Research projects at the new lab will include Frontier Technology, Corporate Moral Progress - which aims to identify the responsibility of firms, explore the sources of their immorality and chart a path for their improvement; and Socially Acceptable and Fair AI, which proposes to develop a methodology for the design of fair AI applications.
Dr Daniel Malan, assistant professor in Business Ethics and director of the Trinity Corporate Governance Lab, said the lab will provide a platform to integrate governance and business ethics into the delivery of research and world-class education.
""The Lab is perfectly aligned with the Business School strategy... and we look forward to work with our academic and industry partners to have real impact,"" he said.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: IIN
Subject: CORPORATE GOVERNANCE (94%); ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS EDUCATION (90%); BUSINESS ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); ESG FACTORS - GOVERNANCE (90%); TECHNOLOGY (90%); GRADUATE & PROFESSIONAL SCHOOLS (89%); BEST PRACTICES (78%); COMPANY STRATEGY (78%); ESG FACTORS (78%); LAW SCHOOLS (78%); RESEARCH & DEVELOPMENT (78%); SCHOOL BUSINESS PARTNERSHIPS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ALLIANCES & PARTNERSHIPS (77%); SUSTAINABLE INVESTING (77%); DATA ANALYTICS (76%); GENERATIVE AI (73%); LAWYERS (72%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Company:  FTI CONSULTING INC (54%)
Ticker: FCN (NYSE) (54%)
Industry: NAICS541618 OTHER MANAGEMENT CONSULTING SERVICES (54%); NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (54%); SIC8748 BUSINESS CONSULTING SERVICES, NEC (54%); SIC8742 MANAGEMENT CONSULTING SERVICES (54%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); GRADUATE & PROFESSIONAL SCHOOLS (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); LAW SCHOOLS (78%); SUSTAINABLE INVESTING (77%); DATA ANALYTICS (76%); GENERATIVE AI (73%); SPACE INDUSTRY (73%); LAWYERS (72%); COLLEGE & UNIVERSITY PROFESSORS (65%)
Geographic: IRELAND (59%); National Edition
Load-Date: December 4, 2023",neutral,0.5914955735206604,balanced/neutral,[],[],"['governance', 'law']",['generative ai'],0,0,2,1
2023,Unknown Title,"Body
Recognized for demonstrating business integrity through best-in-class ethics, compliance, and governance practices.
Infosys (NSE, BSE, NYSE: INFY), a global leader in next-generation digital services and consulting, today announced that it has been recognized, by Ethisphere, a global leader in defining and advancing the standards of ethical business practices, as one of the 2023 World's Most Ethical Companies. Infosys received the honour, for the third consecutive year, for demonstrating the high standards of business integrity through best-in-class ethics, compliance, and governance practices.
Infosys has become the only Company in India, and one of the four companies globally, in the software and services industry to receive this recognition. This recognition is awarded to global companies that have exceptional business ethics and are committed to advance business integrity.
Infosys has been recognized among 135 honorees spanning 19 countries and 46 industries. These companies were evaluated based on the Ethisphere Ethics Quotient across multiple categories, including culture, environmental and social practices, ethics and compliance, governance, diversity, and initiatives to support a strong value chain.
'Ethics matter. Organizations that commit to business integrity through robust programs and practices not only elevate standards and expectations for all, but also have better long-term performance,' said, Ethisphere CEO, Erica Salmon Byrne. 'We continue to be inspired by the World's Most Ethical Companies honorees and their dedication to making real impact for their stakeholders and displaying exemplary values-based leadership. Congratulations to Infosys for earning a place in the World's Most Ethical Companies community.'
Salil Parekh, Chief Executive Officer and Managing Director, Infosys, said, 'We are honoured to be part of the 2023 World's Most Ethical Companies community. This recognition is a testament to the strong foundation of ethical business practices and accountability that we continue to build on. As a responsible corporate entity, we are fully committed to nurturing excellence and transparency of operations and outcomes for the businesses that we drive.'
The complete list of 2023 World's Most Ethical Companies can be found here: https://worldsmostethicalcompanies.com/honorees
Methodology  Scoring
Grounded in Ethisphere's proprietary Ethics Quotient, the World's Most Ethical Companies assessment process includes more than 200 questions on culture, environmental and social practices, ethics and compliance activities, governance, diversity, and initiatives that support a strong value chain. The process serves as an operating framework to capture and codify the leading practices of organizations across industries and around the globe.
About Infosys
Infosys is a global leader in next-generation digital services and consulting. Over 300,000 of our people work to amplify human potential and create the next opportunity for people, businesses and communities. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer clients, in more than 50 countries, as they navigate their digital transformation powered by the cloud. We enable them with an AI-powered core, empower the business with agile digital at scale and drive continuous improvement with always-on learning through the transfer of digital skills, expertise, and ideas from our innovation ecosystem. We are deeply committed to being a well-governed, environmentally sustainable organization where diverse talent thrives in an inclusive workplace.
Visit www.infosys.com to see how Infosys (NSE, BSE, NYSE: INFY) can help your enterprise navigate your next.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (94%); BUSINESS ETHICS (92%); CORPORATE GOVERNANCE (90%); PRESS RELEASES (90%); PUBLIC COMPANIES (90%); COMPANY ACTIVITIES & MANAGEMENT (89%); ENTERPRISE GLOBALIZATION (89%); EXECUTIVES (89%); ASSOCIATIONS & ORGANIZATIONS (87%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); MANAGERS & SUPERVISORS (78%); MULTINATIONAL CORPORATIONS (73%); REGULATORY COMPLIANCE (73%); VALUE CHAIN (72%)
Company:  INFOSYS LTD (90%)
Ticker: INFY (PAR) (90%); INFY (NYSE) (90%); INFY (NSE) (90%)
Industry: NAICS541511 CUSTOM COMPUTER PROGRAMMING SERVICES (90%); SIC7371 COMPUTER PROGRAMMING SERVICES (90%); SOFTWARE SERVICES & APPLICATIONS (77%); DIGITALIZATION & DIGITAL TRANSFORMATION (72%)
Person: SALIL PAREKH (79%)
Geographic: INDIA (77%)
Load-Date: March 14, 2023","Recognized for demonstrating business integrity through best-in-class ethics, compliance, and governance practices.
Infosys (NSE, BSE, NYSE: INFY), a global leader in next-generation digital services and consulting, today announced that it has been recognized, by Ethisphere, a global leader in defining and advancing the standards of ethical business practices, as one of the 2023 World's Most Ethical Companies. Infosys received the honour, for the third consecutive year, for demonstrating the high standards of business integrity through best-in-class ethics, compliance, and governance practices.
Infosys has become the only Company in India, and one of the four companies globally, in the software and services industry to receive this recognition. This recognition is awarded to global companies that have exceptional business ethics and are committed to advance business integrity.
Infosys has been recognized among 135 honorees spanning 19 countries and 46 industries. These companies were evaluated based on the Ethisphere Ethics Quotient across multiple categories, including culture, environmental and social practices, ethics and compliance, governance, diversity, and initiatives to support a strong value chain.
'Ethics matter. Organizations that commit to business integrity through robust programs and practices not only elevate standards and expectations for all, but also have better long-term performance,' said, Ethisphere CEO, Erica Salmon Byrne. 'We continue to be inspired by the World's Most Ethical Companies honorees and their dedication to making real impact for their stakeholders and displaying exemplary values-based leadership. Congratulations to Infosys for earning a place in the World's Most Ethical Companies community.'
Salil Parekh, Chief Executive Officer and Managing Director, Infosys, said, 'We are honoured to be part of the 2023 World's Most Ethical Companies community. This recognition is a testament to the strong foundation of ethical business practices and accountability that we continue to build on. As a responsible corporate entity, we are fully committed to nurturing excellence and transparency of operations and outcomes for the businesses that we drive.'
The complete list of 2023 World's Most Ethical Companies can be found here: https://worldsmostethicalcompanies.com/honorees
Methodology  Scoring
Grounded in Ethisphere's proprietary Ethics Quotient, the World's Most Ethical Companies assessment process includes more than 200 questions on culture, environmental and social practices, ethics and compliance activities, governance, diversity, and initiatives that support a strong value chain. The process serves as an operating framework to capture and codify the leading practices of organizations across industries and around the globe.
About Infosys
Infosys is a global leader in next-generation digital services and consulting. Over 300,000 of our people work to amplify human potential and create the next opportunity for people, businesses and communities. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer clients, in more than 50 countries, as they navigate their digital transformation powered by the cloud. We enable them with an AI-powered core, empower the business with agile digital at scale and drive continuous improvement with always-on learning through the transfer of digital skills, expertise, and ideas from our innovation ecosystem. We are deeply committed to being a well-governed, environmentally sustainable organization where diverse talent thrives in an inclusive workplace.
Visit www.infosys.com to see how Infosys (NSE, BSE, NYSE: INFY) can help your enterprise navigate your next.
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (94%); BUSINESS ETHICS (92%); CORPORATE GOVERNANCE (90%); PRESS RELEASES (90%); PUBLIC COMPANIES (90%); COMPANY ACTIVITIES & MANAGEMENT (89%); ENTERPRISE GLOBALIZATION (89%); EXECUTIVES (89%); ASSOCIATIONS & ORGANIZATIONS (87%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); MANAGERS & SUPERVISORS (78%); MULTINATIONAL CORPORATIONS (73%); REGULATORY COMPLIANCE (73%); VALUE CHAIN (72%)
Company:  INFOSYS LTD (90%)
Ticker: INFY (PAR) (90%); INFY (NYSE) (90%); INFY (NSE) (90%)
Industry: NAICS541511 CUSTOM COMPUTER PROGRAMMING SERVICES (90%); SIC7371 COMPUTER PROGRAMMING SERVICES (90%); SOFTWARE SERVICES & APPLICATIONS (77%); DIGITALIZATION & DIGITAL TRANSFORMATION (72%)
Person: SALIL PAREKH (79%)
Geographic: INDIA (77%)
Load-Date: March 14, 2023",positive,0.8448109030723572,balanced/neutral,"['transparency', 'accountability']",[],"['governance', 'standards', 'framework', 'compliance', 'should']",[],2,0,5,0
2023,Unknown Title,"Body
Link to Story
"""" Data and AI Ethics Market """" Research Report Provides Valuable Insights into The Market, Focusing On Types (Solutions, Services), Applications (BFSI, Government and Defense, Healthcare and Life Sciences, Media and Entertainment, Retail, Telecom, Automotive, Others), Regions, And A Forecast till 2031. This Comprehensive Report Spans 124 Pages and Includes a Detailed Table of Contents, Figures, And Charts, Enabling In-Depth Analysis . Additionally, The Report Offers a Comprehensive Assessment of the Market's Impact Before and After The COVID-19 Outbreak , Along with The Current Situation in Each Region.
The Global Data and AI Ethics market is projected to rise at a significant rate during the forecast period, between 2023 and 2031. In 2022, the market is increasing at a steady rate and with the growing adoption of strategies by key players, the market is expected to rise over the projected horizon.
Data and AI Ethics Market Top Companies (Manufactures) Are as Follow:
Microsoft
IBM
SAP
Google
Salesforce
Facebook
Get a Sample PDF of report -
Data and AI Ethics Market - Competitive and Segmentation Analysis: As well as providing an overview of successful marketing strategies, market contributions, and recent developments of leading companies, the report also offers a dashboard overview of leading companies' past and present performance. Several methodologies and analyses are used in the research report to provide in-depth and accurate information about the Data and AI Ethics Market.
The current market dossier provides market growth potential, opportunities, drivers, industry-specific challenges and risks market share along with the growth rate of the global Data and AI Ethics market. The report also covers monetary and exchange fluctuations, import-export trade, and global market
status in a smooth-tongued pattern. The SWOT analysis, compiled by industry experts, Industry Concentration Ratio and the latest developments for the global Data and AI Ethics market share are covered in a statistical way in the form of tables and figures including graphs and charts for easy understanding.
The report is divided into three parts:
Part I Data and AI Ethics Market Overview
Part II Data and AI Ethics Market Data
Part III- Strategic Recommendations
Final Report will add the analysis of the impact of COVID-19 on this industry.
TO KNOW HOW COVID-19 PANDEMIC AND RUSSIA UKRAINE WAR WILL IMPACT THIS MARKET - REQUEST SAMPLE
Moreover, it helps new businesses perform a positive assessment of their business plans because it covers a range of topics market participants must be aware of to remain competitive.
Data and AI Ethics Market Report identifies various key players in the market and sheds light on their strategies and collaborations to combat competition. The comprehensive report provides a two-dimensional picture of the market. By knowing the global revenue of manufacturers, the global price of manufacturers, and the production by manufacturers during the forecast period of 2023 to 2031, the reader can identify the footprints of manufacturers in the Data and AI Ethics industry.
Market Overview of Global Data and AI Ethics market:
According to our latest research, the global Data and AI Ethics market looks promising in the next 5 years. As of 2022, the global Data and AI Ethics market was estimated at USD million, and itâ€™s anticipated to reach USD million in 2028, with a CAGR of Percent during the forecast years.
Get a Sample Copy of the Data and AI Ethics Market Report 2023
A thorough evaluation of the restrains included in the report portrays the contrast to drivers and gives room for strategic planning. Factors that overshadow the market growth are pivotal as they can be understood to devise different bends for getting hold of the lucrative opportunities that are present in the ever-growing market. Additionally, insights into market expert's opinions have been taken to understand the market better.
Report further studies the market development status and future Data and AI Ethics Market trend across the world. Also, it splits Data and AI Ethics market Segmentation by Type and by Applications to fully and deeply research and reveal market profile and prospects.
Data and AI Ethics Marketproduct type this report displays the production, revenue, price, market share and growth rate of each type, primarily split into:
Solutions
Services
Data and AI Ethics Marketend users/applications this report focuses on the status and outlook for major applications/end users, consumption (sales), market share and growth rate for each application, including:
BFSI
Government and Defense
Healthcare and Life Sciences
Media and Entertainment
Retail
Telecom
Automotive
Others
Data and AI Ethics Market - Regional Analysis:
Geographically , this report is segmented into several key regions, with sales, revenue, market share and growth Rate of Data and AI Ethics in these regions, from 2015 to 2027, covering
Some of the key questions answered in this report:
Our research analysts will help you to get customized details for your report, which can be modified in terms of a specific region, application or any statistical details. In addition, we are always willing to comply with the study, which triangulated with your own data to make the market research more comprehensive in your perspective.
Inquire more and share questions if any before the purchase on this report at -
With tables and figures helping analyse worldwide Global Data and AI Ethics market trends, this research provides key statistics on the state of the industry and is a valuable source of guidance and direction for companies and individuals interested in the market.
Detailed TOC of Global Data and AI Ethics Market Research Report 2023 1 Scope of the Report
1.1 Market Introduction
1.2 Years Considered
1.3 Research Objectives
1.4 Market Research Methodology
1.5 Research Process and Data Source
1.6 Economic Indicators
1.7 Currency Considered
2 Executive Summary
2.1 World Market Overview
2.1.1 Global Data and AI Ethics Annual Sales 2017-2031
2.1.2 World Current and Future Analysis by Geographic Region, 2017, 2023 and 2031
2.1.3 World Current and Future Analysis by Country/Region, 2017, 2023 and 2031
2.2 Data and AI Ethics Segment by Type
2.3 Sales by Type
2.3.1 Global Sales Market Share by Type (2017-2023)
2.3.2 Global Data and AI Ethics Revenue and Market Share by Type (2017-2023)
2.3.3 Global Sale Price by Type (2017-2023)
2.4 Data and AI Ethics Segment by Applications
2.5 Sales by Application
2.5.1 Global Data and AI Ethics Sale Market Share by Application (2017-2023)
2.5.2 Global Data and AI Ethics Revenue and Market Share by Application (2017-2023)
2.5.3 Global Data and AI Ethics Sale Price by Application (2017-2023)
3 Global Data and AI Ethics by Company
3.1 Global Breakdown Data by Company
3.1.1 Global Data and AI Ethics Annual Sales by Company (2020-2023)
3.1.2 Global Data and AI Ethics Sales Market Share by Company (2020-2023)
3.2 Global Annual Revenue by Company (2020-2023)
3.2.1 Global Data and AI Ethics Revenue by Company (2020-2023)
3.2.2 Global Data and AI Ethics Revenue Market Share by Company (2020-2023)
3.3 Global Sale Price by Company
3.4 Key Manufacturers Producing Area Distribution, Sales Area, Product Type
3.4.1 Key Manufacturers Data and AI Ethics Product Location Distribution
3.4.2 Players Products Offered
3.5 Market Concentration Rate Analysis
3.5.1 Competition Landscape Analysis
3.5.2 Concentration Ratio (CR3, CR5 and CR10) and (2020-2023)
3.6 New Products and Potential Entrants
3.7 Mergers and Acquisitions, Expansion
4 World Historic Review for Data and AI Ethics by Geographic Region
4.1 World Historic Data and AI Ethics Market Size by Geographic Region (2017-2023)
4.1.1 Global Annual Sales by Geographic Region (2017-2023)
4.1.2 Global Annual Revenue by Geographic Region
4.2 World Historic Data and AI Ethics Market Size by Country/Region (2017-2023)
4.2.1 Global Annual Sales by Country/Region (2017-2023)
4.2.2 Global Annual Revenue by Country/Region
4.3 Americas Data and AI Ethics Sales Growth
4.4 APAC Data and AI Ethics Sales Growth
4.5 Europe Sales Growth
4.6 Middle East and Africa Sales Growth
5 Americas
5.1 Americas Sales by Country
5.1.1 Americas Sales by Country (2017-2023)
5.1.2 Americas Revenue by Country (2017-2023)
5.2 Americas Sales by Type
5.3 Americas Sales by Application
5.4 United States
5.5 Canada
5.6 Mexico
5.7 Brazil
6 APAC
6.1 APAC Data and AI Ethics Sales by Region
6.1.1 APAC Data and AI Ethics Sales by Region (2017-2023)
6.1.2 APAC Revenue by Region (2017-2023)
6.2 APAC Data and AI Ethics Sales by Type
6.3 APAC Sales by Application
6.4 China
6.5 Japan
6.6 South Korea
6.7 Southeast Asia
6.8 India
6.9 Australia
6.10 China Taiwan
7 Europe
7.1 Europe by Country
7.1.1 Europe Sales by Country (2017-2023)
7.1.2 Europe Revenue by Country (2017-2023)
7.2 Europe Sales by Type
7.3 Europe Sales by Application
7.4 Germany
7.5 France
7.6 UK
7.7 Italy
7.8 Russia
8 Middle East and Africa
8.1 Middle East and Africa by Country
8.1.1 Middle East and Africa Sales by Country (2017-2023)
8.1.2 Middle East and Africa Data and AI Ethics Revenue by Country (2017-2023)
8.2 Middle East and Africa Data and AI Ethics Sales by Type
8.3 Middle East and Africa Data and AI Ethics Sales by Application
8.4 Egypt
8.5 South Africa
8.6 Israel
8.7 Turkey
8.8 GCC Countries
9 Market Drivers, Challenges and Trends
9.1 Market Drivers and Growth Opportunities
9.2 Market Challenges and Risks
9.3 Industry Trends
10 Manufacturing Cost Structure Analysis
10.1 Raw Material and Suppliers
10.2 Manufacturing Cost Structure Analysis
10.3 Manufacturing Process Analysis
10.4 Industry Chain Structure
11 Marketing, Distributors and Customer
11.1 Sales Channel
11.1.1 Direct Channels
11.1.2 Indirect Channels
11.2 Data and AI Ethics Distributors
11.3 Data and AI Ethics Customer
12 World Forecast Review for Data and AI Ethics by Geographic Region
12.1 Global Data and AI Ethics Market Size Forecast by Region
12.1.1 Global Data and AI Ethics Forecast by Region (2023-2031)
12.1.2 Global Data and AI Ethics Annual Revenue Forecast by Region (2023-2031)
12.2 Americas Forecast by Country
12.3 APAC Forecast by Region
12.4 Europe Forecast by Country
12.5 Middle East and Africa Forecast by Country
12.6 Global Data and AI Ethics Forecast by Type
12.7 Global Data and AI Ethics Forecast by Application
13 Key Players Analysis
13.1.1 Company Information
13.1.2 Data and AI Ethics Product Offered
13.1.3 Data and AI Ethics Sales, Revenue, Price and Gross Margin (2020-2023)
13.1.4 Main Business Overview
13.1.5 Latest Developments
14 Research Findings and Conclusion
Purchase this report (Price 3380 USD for a single-user license) - About Us:
Market is changing rapidly with the ongoing expansion of the industry. Advancement in the technology has provided today's businesses with multifaceted advantages resulting in daily economic shifts. Thus, it is very important for a company to comprehend the patterns of the market movements in order to strategize better. An efficient strategy offers the companies with a head start in planning and an edge over the competitors. Market Growth Reports is the credible source for gaining the market reports that will provide you with the lead your business needs.
Contact Us:
Market growth reports
Phone : US +1 424 253 0946
UK +44 203 239 8187
Email : ...
Web :
MENAFN04122023004576010663ID1107535524
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: REPORTS, REVIEWS & SECTIONS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); BUSINESS REPORTS & FORECASTS (91%); COMPANY STRATEGY (90%); ETHICS (90%); BUSINESS FORECASTS (89%); COVID CORONAVIRUS (89%); COVID-19 CORONAVIRUS (89%); INFECTIOUS DISEASE (89%); RESEARCH REPORTS (89%); MARKET RESEARCH REPORTS (78%); PRICES (78%); BUSINESS PLANS (77%); EPIDEMICS (77%); INDUSTRY ANALYSTS (77%); IMPORT TRADE (75%); INTERNATIONAL TRADE (75%); PANDEMICS (75%); 2022 RUSSIAN WAR ON UKRAINE (74%); NEW BUSINESSES (72%); EXPORT TRADE (63%); NEWS BRIEFS (50%); RUSSIA-UKRAINE CONFLICTS (50%)
Company:  GOOGLE LLC (55%);  META PLATFORMS INC (55%);  MICROSOFT CORP (55%)
Ticker: META (NASDAQ) (55%); MSFT (NASDAQ) (55%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (55%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (55%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (55%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (92%); MARKET SIZE (90%); MANUFACTURING (89%); MARKET SHARE (89%); MARKET RESEARCH REPORTS (78%); MARKET SEGMENTATION (78%); MARKETING STRATEGY (78%); ENTERTAINMENT & ARTS (77%); INDUSTRY ANALYSTS (77%); RETAIL & WHOLESALE TRADE (73%); TELECOMMUNICATIONS (73%)
Geographic: UKRAINE (79%)
Load-Date: May 14, 2024","Link to Story
"""" Data and AI Ethics Market """" Research Report Provides Valuable Insights into The Market, Focusing On Types (Solutions, Services), Applications (BFSI, Government and Defense, Healthcare and Life Sciences, Media and Entertainment, Retail, Telecom, Automotive, Others), Regions, And A Forecast till 2031. This Comprehensive Report Spans 124 Pages and Includes a Detailed Table of Contents, Figures, And Charts, Enabling In-Depth Analysis . Additionally, The Report Offers a Comprehensive Assessment of the Market's Impact Before and After The COVID-19 Outbreak , Along with The Current Situation in Each Region.
The Global Data and AI Ethics market is projected to rise at a significant rate during the forecast period, between 2023 and 2031. In 2022, the market is increasing at a steady rate and with the growing adoption of strategies by key players, the market is expected to rise over the projected horizon.
Data and AI Ethics Market Top Companies (Manufactures) Are as Follow:
Microsoft
IBM
SAP
Google
Salesforce
Facebook
Get a Sample PDF of report -
Data and AI Ethics Market - Competitive and Segmentation Analysis: As well as providing an overview of successful marketing strategies, market contributions, and recent developments of leading companies, the report also offers a dashboard overview of leading companies' past and present performance. Several methodologies and analyses are used in the research report to provide in-depth and accurate information about the Data and AI Ethics Market.
The current market dossier provides market growth potential, opportunities, drivers, industry-specific challenges and risks market share along with the growth rate of the global Data and AI Ethics market. The report also covers monetary and exchange fluctuations, import-export trade, and global market
status in a smooth-tongued pattern. The SWOT analysis, compiled by industry experts, Industry Concentration Ratio and the latest developments for the global Data and AI Ethics market share are covered in a statistical way in the form of tables and figures including graphs and charts for easy understanding.
The report is divided into three parts:
Part I Data and AI Ethics Market Overview
Part II Data and AI Ethics Market Data
Part III- Strategic Recommendations
Final Report will add the analysis of the impact of COVID-19 on this industry.
TO KNOW HOW COVID-19 PANDEMIC AND RUSSIA UKRAINE WAR WILL IMPACT THIS MARKET - REQUEST SAMPLE
Moreover, it helps new businesses perform a positive assessment of their business plans because it covers a range of topics market participants must be aware of to remain competitive.
Data and AI Ethics Market Report identifies various key players in the market and sheds light on their strategies and collaborations to combat competition. The comprehensive report provides a two-dimensional picture of the market. By knowing the global revenue of manufacturers, the global price of manufacturers, and the production by manufacturers during the forecast period of 2023 to 2031, the reader can identify the footprints of manufacturers in the Data and AI Ethics industry.
Market Overview of Global Data and AI Ethics market:
According to our latest research, the global Data and AI Ethics market looks promising in the next 5 years. As of 2022, the global Data and AI Ethics market was estimated at USD million, and itâ€™s anticipated to reach USD million in 2028, with a CAGR of Percent during the forecast years.
Get a Sample Copy of the Data and AI Ethics Market Report 2023
A thorough evaluation of the restrains included in the report portrays the contrast to drivers and gives room for strategic planning. Factors that overshadow the market growth are pivotal as they can be understood to devise different bends for getting hold of the lucrative opportunities that are present in the ever-growing market. Additionally, insights into market expert's opinions have been taken to understand the market better.
Report further studies the market development status and future Data and AI Ethics Market trend across the world. Also, it splits Data and AI Ethics market Segmentation by Type and by Applications to fully and deeply research and reveal market profile and prospects.
Data and AI Ethics Marketproduct type this report displays the production, revenue, price, market share and growth rate of each type, primarily split into:
Solutions
Services
Data and AI Ethics Marketend users/applications this report focuses on the status and outlook for major applications/end users, consumption (sales), market share and growth rate for each application, including:
BFSI
Government and Defense
Healthcare and Life Sciences
Media and Entertainment
Retail
Telecom
Automotive
Others
Data and AI Ethics Market - Regional Analysis:
Geographically , this report is segmented into several key regions, with sales, revenue, market share and growth Rate of Data and AI Ethics in these regions, from 2015 to 2027, covering
Some of the key questions answered in this report:
Our research analysts will help you to get customized details for your report, which can be modified in terms of a specific region, application or any statistical details. In addition, we are always willing to comply with the study, which triangulated with your own data to make the market research more comprehensive in your perspective.
Inquire more and share questions if any before the purchase on this report at -
With tables and figures helping analyse worldwide Global Data and AI Ethics market trends, this research provides key statistics on the state of the industry and is a valuable source of guidance and direction for companies and individuals interested in the market.
Detailed TOC of Global Data and AI Ethics Market Research Report 2023 1 Scope of the Report
1.1 Market Introduction
1.2 Years Considered
1.3 Research Objectives
1.4 Market Research Methodology
1.5 Research Process and Data Source
1.6 Economic Indicators
1.7 Currency Considered
2 Executive Summary
2.1 World Market Overview
2.1.1 Global Data and AI Ethics Annual Sales 2017-2031
2.1.2 World Current and Future Analysis by Geographic Region, 2017, 2023 and 2031
2.1.3 World Current and Future Analysis by Country/Region, 2017, 2023 and 2031
2.2 Data and AI Ethics Segment by Type
2.3 Sales by Type
2.3.1 Global Sales Market Share by Type (2017-2023)
2.3.2 Global Data and AI Ethics Revenue and Market Share by Type (2017-2023)
2.3.3 Global Sale Price by Type (2017-2023)
2.4 Data and AI Ethics Segment by Applications
2.5 Sales by Application
2.5.1 Global Data and AI Ethics Sale Market Share by Application (2017-2023)
2.5.2 Global Data and AI Ethics Revenue and Market Share by Application (2017-2023)
2.5.3 Global Data and AI Ethics Sale Price by Application (2017-2023)
3 Global Data and AI Ethics by Company
3.1 Global Breakdown Data by Company
3.1.1 Global Data and AI Ethics Annual Sales by Company (2020-2023)
3.1.2 Global Data and AI Ethics Sales Market Share by Company (2020-2023)
3.2 Global Annual Revenue by Company (2020-2023)
3.2.1 Global Data and AI Ethics Revenue by Company (2020-2023)
3.2.2 Global Data and AI Ethics Revenue Market Share by Company (2020-2023)
3.3 Global Sale Price by Company
3.4 Key Manufacturers Producing Area Distribution, Sales Area, Product Type
3.4.1 Key Manufacturers Data and AI Ethics Product Location Distribution
3.4.2 Players Products Offered
3.5 Market Concentration Rate Analysis
3.5.1 Competition Landscape Analysis
3.5.2 Concentration Ratio (CR3, CR5 and CR10) and (2020-2023)
3.6 New Products and Potential Entrants
3.7 Mergers and Acquisitions, Expansion
4 World Historic Review for Data and AI Ethics by Geographic Region
4.1 World Historic Data and AI Ethics Market Size by Geographic Region (2017-2023)
4.1.1 Global Annual Sales by Geographic Region (2017-2023)
4.1.2 Global Annual Revenue by Geographic Region
4.2 World Historic Data and AI Ethics Market Size by Country/Region (2017-2023)
4.2.1 Global Annual Sales by Country/Region (2017-2023)
4.2.2 Global Annual Revenue by Country/Region
4.3 Americas Data and AI Ethics Sales Growth
4.4 APAC Data and AI Ethics Sales Growth
4.5 Europe Sales Growth
4.6 Middle East and Africa Sales Growth
5 Americas
5.1 Americas Sales by Country
5.1.1 Americas Sales by Country (2017-2023)
5.1.2 Americas Revenue by Country (2017-2023)
5.2 Americas Sales by Type
5.3 Americas Sales by Application
5.4 United States
5.5 Canada
5.6 Mexico
5.7 Brazil
6 APAC
6.1 APAC Data and AI Ethics Sales by Region
6.1.1 APAC Data and AI Ethics Sales by Region (2017-2023)
6.1.2 APAC Revenue by Region (2017-2023)
6.2 APAC Data and AI Ethics Sales by Type
6.3 APAC Sales by Application
6.4 China
6.5 Japan
6.6 South Korea
6.7 Southeast Asia
6.8 India
6.9 Australia
6.10 China Taiwan
7 Europe
7.1 Europe by Country
7.1.1 Europe Sales by Country (2017-2023)
7.1.2 Europe Revenue by Country (2017-2023)
7.2 Europe Sales by Type
7.3 Europe Sales by Application
7.4 Germany
7.5 France
7.6 UK
7.7 Italy
7.8 Russia
8 Middle East and Africa
8.1 Middle East and Africa by Country
8.1.1 Middle East and Africa Sales by Country (2017-2023)
8.1.2 Middle East and Africa Data and AI Ethics Revenue by Country (2017-2023)
8.2 Middle East and Africa Data and AI Ethics Sales by Type
8.3 Middle East and Africa Data and AI Ethics Sales by Application
8.4 Egypt
8.5 South Africa
8.6 Israel
8.7 Turkey
8.8 GCC Countries
9 Market Drivers, Challenges and Trends
9.1 Market Drivers and Growth Opportunities
9.2 Market Challenges and Risks
9.3 Industry Trends
10 Manufacturing Cost Structure Analysis
10.1 Raw Material and Suppliers
10.2 Manufacturing Cost Structure Analysis
10.3 Manufacturing Process Analysis
10.4 Industry Chain Structure
11 Marketing, Distributors and Customer
11.1 Sales Channel
11.1.1 Direct Channels
11.1.2 Indirect Channels
11.2 Data and AI Ethics Distributors
11.3 Data and AI Ethics Customer
12 World Forecast Review for Data and AI Ethics by Geographic Region
12.1 Global Data and AI Ethics Market Size Forecast by Region
12.1.1 Global Data and AI Ethics Forecast by Region (2023-2031)
12.1.2 Global Data and AI Ethics Annual Revenue Forecast by Region (2023-2031)
12.2 Americas Forecast by Country
12.3 APAC Forecast by Region
12.4 Europe Forecast by Country
12.5 Middle East and Africa Forecast by Country
12.6 Global Data and AI Ethics Forecast by Type
12.7 Global Data and AI Ethics Forecast by Application
13 Key Players Analysis
13.1.1 Company Information
13.1.2 Data and AI Ethics Product Offered
13.1.3 Data and AI Ethics Sales, Revenue, Price and Gross Margin (2020-2023)
13.1.4 Main Business Overview
13.1.5 Latest Developments
14 Research Findings and Conclusion
Purchase this report (Price 3380 USD for a single-user license) - About Us:
Market is changing rapidly with the ongoing expansion of the industry. Advancement in the technology has provided today's businesses with multifaceted advantages resulting in daily economic shifts. Thus, it is very important for a company to comprehend the patterns of the market movements in order to strategize better. An efficient strategy offers the companies with a head start in planning and an edge over the competitors. Market Growth Reports is the credible source for gaining the market reports that will provide you with the lead your business needs.
Contact Us:
Market growth reports
Phone : US +1 424 253 0946
UK +44 203 239 8187
Email : ...
Web :
MENAFN04122023004576010663ID1107535524
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: REPORTS, REVIEWS & SECTIONS (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); BUSINESS REPORTS & FORECASTS (91%); COMPANY STRATEGY (90%); ETHICS (90%); BUSINESS FORECASTS (89%); COVID CORONAVIRUS (89%); COVID-19 CORONAVIRUS (89%); INFECTIOUS DISEASE (89%); RESEARCH REPORTS (89%); MARKET RESEARCH REPORTS (78%); PRICES (78%); BUSINESS PLANS (77%); EPIDEMICS (77%); INDUSTRY ANALYSTS (77%); IMPORT TRADE (75%); INTERNATIONAL TRADE (75%); PANDEMICS (75%); 2022 RUSSIAN WAR ON UKRAINE (74%); NEW BUSINESSES (72%); EXPORT TRADE (63%); NEWS BRIEFS (50%); RUSSIA-UKRAINE CONFLICTS (50%)
Company:  GOOGLE LLC (55%);  META PLATFORMS INC (55%);  MICROSOFT CORP (55%)
Ticker: META (NASDAQ) (55%); MSFT (NASDAQ) (55%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (55%); NAICS516210 MEDIA STREAMING DIST SVCS, SOCIAL NETWORKS, AND OTHER MEDIA NETWORKS AND CONTENT PROVIDERS (55%); SIC7374 COMPUTER PROCESSING & DATA PREPARATION & PROCESSING SERVICES (55%); SIC7372 PREPACKAGED SOFTWARE (55%); ARTIFICIAL INTELLIGENCE ETHICS (92%); MARKET SIZE (90%); MANUFACTURING (89%); MARKET SHARE (89%); MARKET RESEARCH REPORTS (78%); MARKET SEGMENTATION (78%); MARKETING STRATEGY (78%); ENTERTAINMENT & ARTS (77%); INDUSTRY ANALYSTS (77%); RETAIL & WHOLESALE TRADE (73%); TELECOMMUNICATIONS (73%)
Geographic: UKRAINE (79%)
Load-Date: May 14, 2024",neutral,0.7934415340423584,balanced/neutral,[],[],['must'],[],0,0,1,0
