year,title,body,clean_body,sentiment_label,sentiment_score,tone,ethical_issues,ethical_principles,recommendations,technologies,issue_count,principle_count,recommendation_count,technology_count
2021,Unknown Title,"Body
2022 JUN 15 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx Science Daily -- According to news reporting based on a preprint abstract, our journalists obtained the following quote sourced from osf.io:
 “Around the world, we are seeing a significant growth in interest and investment in AI in healthcare.
 “This has been coupled with rising concerns about the ethical implications of these technologies and an array of ethical guidelines for the use of AI and data in healthcare has arisen. Nevertheless, the question of if and how AI and data technologies can be ethical remains open to debate.
 “This paper aims to contribute to this debate by considering the wide range of implications that have been attributed to these technologies and asking whether current ethical guidelines take these factors into account.
 “In particular, the paper argues that current ethics guidelines for AI in healthcare effectively account for the four key issues identified in the ethics literature (transparency; fairness; responsibility and privacy), they have largely neglected wider issues relating to the way in which these technologies shape institutional and social arrangements. This, we argue, has given current ethics guidelines a strong focus on evaluating the impact of these technologies on the individual, while not accounting for the powerful social shaping effects of these technologies. To address this, the paper proposes a Multiscale Ethics Framework, which aims to help technology developers and ethical evaluations to consider the wider implications of these technologies.”
 This preprint has not been peer-reviewed.
 For more information on this research see: osf.io/preprints/socarxiv/uj6my/
 Keywords for this news article include: Social Sciences, Technology.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (90%); JOURNALISM (90%); NEWS REPORTING (90%); SOCIOLOGY (90%); HUMANITIES & SOCIAL SCIENCE (89%); WRITERS (78%); Social Sciences;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (90%); NEWS REPORTING (90%); WRITERS (78%)
Load-Date: July 28, 2022","2022 JUN 15 (NewsRx) -- By a News Reporter-Staff News Editor at NewsRx Science Daily -- According to news reporting based on a preprint abstract, our journalists obtained the following quote sourced from osf.io:
 “Around the world, we are seeing a significant growth in interest and investment in AI in healthcare.
 “This has been coupled with rising concerns about the ethical implications of these technologies and an array of ethical guidelines for the use of AI and data in healthcare has arisen. Nevertheless, the question of if and how AI and data technologies can be ethical remains open to debate.
 “This paper aims to contribute to this debate by considering the wide range of implications that have been attributed to these technologies and asking whether current ethical guidelines take these factors into account.
 “In particular, the paper argues that current ethics guidelines for AI in healthcare effectively account for the four key issues identified in the ethics literature (transparency; fairness; responsibility and privacy), they have largely neglected wider issues relating to the way in which these technologies shape institutional and social arrangements. This, we argue, has given current ethics guidelines a strong focus on evaluating the impact of these technologies on the individual, while not accounting for the powerful social shaping effects of these technologies. To address this, the paper proposes a Multiscale Ethics Framework, which aims to help technology developers and ethical evaluations to consider the wider implications of these technologies.”
 This preprint has not been peer-reviewed.
 For more information on this research see: osf.io/preprints/socarxiv/uj6my/
 Keywords for this news article include: Social Sciences, Technology.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); ARTIFICIAL INTELLIGENCE ETHICS (90%); JOURNALISM (90%); NEWS REPORTING (90%); SOCIOLOGY (90%); HUMANITIES & SOCIAL SCIENCE (89%); WRITERS (78%); Social Sciences;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (90%); NEWS REPORTING (90%); WRITERS (78%)
Load-Date: July 28, 2022",neutral,0.9179443717002869,balanced/neutral,"['privacy', 'fairness', 'transparency']",['fairness'],"['guidelines', 'framework']",[],3,1,2,0
2021,Unknown Title,"Body
Link to Story
Integration of Convercent by OneTrust Ethics & Compliance technology empowers ethics teams to build strong cultures
ATLANTA, May 16, 2022 /PRNewswire/ -- Today at Compliance Week, OneTrust, the software platform to operationalize trust, launched the OneTrust Ethics & Compliance Cloud to foster and promote an ethical culture within organizations, maximize insights into the health of their culture, and support leaders in acting decisively upon areas of risk. 
'People want to work for companies they can trust,' said Asha Palmer, OneTrust Chief Ethics and Compliance Officer. 'Ethical business practices provide the foundation for businesses to inspire that trust, allowing them to showcase their values to stakeholders at every level. The OneTrust Ethics & Compliance Cloud empowers businesses to build and promote ethical and transparent behaviors, create speak-up cultures, and provide strategic value to business operations so leaders can manage risk while building and maintaining trust.'
The OneTrust Ethics & Compliance Cloud empowers businesses to build and promote ethical and transparent behaviors.
Tweet this The OneTrust Ethics & Compliance Cloud builds the Convercent by OneTrust technology directly into the OneTrust platform, enabling compliance, ethics, HR, and legal teams to unite people, process, and technology across Ethics Program Management, Speak-Up Culture Assurance, and Third-Party Due Diligence programs in a unified cloud platform.
See the OneTrust Ethics & Compliance Cloud in Action at TrustWeek 2022 May 24-26 in Atlanta
Today more than ever, people want to work for companies that match their words with actions, align with their values and treat employees with respect. Treating employees and customers well is one of the top ways1 brands can build and regain trust. A recent study2 found that of the one in four Americans who left their job during the 'Great Resignation,' 59% cited leaving because the new company fit their values. In contrast, only 31% cited pay or career advancement as a reason to change roles.
Trusted organizations create strong cultures that foster ethical behavior and build workplaces where everyone feels empowered to speak up, share their perspectives, ask challenging questions, and raise concerns without fear of retaliation. These cultures are strongest when ethical values are shared by everyone within the organization, underpinned by a shared sense of purpose, and backed by a leadership team that leads by example.
The Ethics & Compliance Cloud delivers solutions to encourage and reinforce positive behavior while delivering value to business partners by focusing on three trust management areas: 
Ethics Program Management : Inform, engage, and train employees with an Interactive Code of Conduct, Ethics Policy Management, and Ethics Training.
Speak-Up Culture Assurance : Enhance your speak-up culture with targeted engagement, streamline investigations with Helpline Case Management, and proactively mitigate risk with Disclosure Management.
Third-Party Due Diligence : Manage third-party risk with automated screening, due diligence, risk management, and ongoing monitoring.
Learn more at Compliance Week in Washington, DC at the OneTrust Booth #13
Ethics and compliance teams know that to build great, ethical cultures, they need to transform from merely complying with regulations to building ethical cultures that can proactively identify and mitigate corporate risks and drive behavioral and organizational change. The OneTrust Ethics & Compliance Cloud will bring intelligence, scale, and automation to ethics and compliance so companies can manage their ethics data, teams, and workflows in a single platform.
'Over the last year, we've been working hard to integrate people, process, and the Convercent technology into the OneTrust platform,' said Patrick Quinlan, General Manager of Ethics & Compliance at OneTrust . 'The combined solution strengthens ethics and compliance programs, enabling the business to build trust from the inside out while still having the opportunity to focus on privacy, security, and ESG related goals.'
To learn more about the OneTrust Ethics & Compliance Cloud, read our blog or request a demo .
1Adobe (2022). Adobe Trust Report , p 4.
2Edelman (2021). Edelman Trust Barometer Special Report: The Belief-Driven Employee , p. 12.
OneTrust, TrustWeek, Convercent, and OneTrust Athena are either registered trademarks or trademarks of OneTrust LLC in the United States and/or other countries. All other trademarks are the property of their respective owners.
About OneTrust OneTrust is the category-defining enterprise platform to operationalize trust. More than 12,000 customers, including half of the Fortune Global 500, use OneTrust to make trust a competitive differentiator, implementing central agile workflows across Privacy and Data Governance, GRC and Security Assurance, Ethics and Compliance, and ESG and Sustainability. The OneTrust platform is backed by 200 patents and powered by the OneTrust Athena AI and robotic automation engine.
In 2020, OneTrust was named the #1 fastest-growing company in America on the Inc. 500 with a 48,000% three-year growth rate. According to the IDC Worldwide Data Privacy Management Software Market Shares Report , 2020, 'OneTrust is leading the market outright and showing no signs of slowing down or stopping.'
OneTrust has raised $920 million in funding at a $5.3 billion valuation from Insight Partners, Coatue, TCV, SoftBank Vision Fund 2, and Franklin Templeton. OneTrust's fast-growing team of 3,000 employees is co-headquartered in Atlanta and London with office hubs across Australia, Brazil, Canada, France, Germany, Japan, United Kingdom, and the United States.
To learn more, visit OneTrust.com or connect on LinkedIn , Twitter , and YouTube .
Media Contact Gabrielle Ferree+1 770-294-4668[email protected]
SOURCE OneTrust
MENAFN16052022003732001241ID1104219865
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); FINANCIAL TECHNOLOGY (89%); PSYCHOLOGICAL SAFETY (89%); INVESTIGATIONS (78%); NEGATIVE PERSONAL NEWS (78%); REGULATORY COMPLIANCE (78%); BUSINESS OPERATIONS (76%); EMPLOYEE TRAINING (76%); RISK MANAGEMENT (73%); RESIGNATIONS (68%)
Organization: ASHA (57%)
Industry: SOFTWARE SERVICES & APPLICATIONS (90%); FINANCIAL TECHNOLOGY (89%); PSYCHOLOGICAL SAFETY (89%); CLOUD COMPUTING (78%); RISK MANAGEMENT (73%); COMPUTER SOFTWARE (72%)
Geographic: UNITED STATES (79%)
Load-Date: September 2, 2022","Link to Story
Integration of Convercent by OneTrust Ethics & Compliance technology empowers ethics teams to build strong cultures
ATLANTA, May 16, 2022 /PRNewswire/ -- Today at Compliance Week, OneTrust, the software platform to operationalize trust, launched the OneTrust Ethics & Compliance Cloud to foster and promote an ethical culture within organizations, maximize insights into the health of their culture, and support leaders in acting decisively upon areas of risk. 
'People want to work for companies they can trust,' said Asha Palmer, OneTrust Chief Ethics and Compliance Officer. 'Ethical business practices provide the foundation for businesses to inspire that trust, allowing them to showcase their values to stakeholders at every level. The OneTrust Ethics & Compliance Cloud empowers businesses to build and promote ethical and transparent behaviors, create speak-up cultures, and provide strategic value to business operations so leaders can manage risk while building and maintaining trust.'
The OneTrust Ethics & Compliance Cloud empowers businesses to build and promote ethical and transparent behaviors.
Tweet this The OneTrust Ethics & Compliance Cloud builds the Convercent by OneTrust technology directly into the OneTrust platform, enabling compliance, ethics, HR, and legal teams to unite people, process, and technology across Ethics Program Management, Speak-Up Culture Assurance, and Third-Party Due Diligence programs in a unified cloud platform.
See the OneTrust Ethics & Compliance Cloud in Action at TrustWeek 2022 May 24-26 in Atlanta
Today more than ever, people want to work for companies that match their words with actions, align with their values and treat employees with respect. Treating employees and customers well is one of the top ways1 brands can build and regain trust. A recent study2 found that of the one in four Americans who left their job during the 'Great Resignation,' 59% cited leaving because the new company fit their values. In contrast, only 31% cited pay or career advancement as a reason to change roles.
Trusted organizations create strong cultures that foster ethical behavior and build workplaces where everyone feels empowered to speak up, share their perspectives, ask challenging questions, and raise concerns without fear of retaliation. These cultures are strongest when ethical values are shared by everyone within the organization, underpinned by a shared sense of purpose, and backed by a leadership team that leads by example.
The Ethics & Compliance Cloud delivers solutions to encourage and reinforce positive behavior while delivering value to business partners by focusing on three trust management areas: 
Ethics Program Management : Inform, engage, and train employees with an Interactive Code of Conduct, Ethics Policy Management, and Ethics Training.
Speak-Up Culture Assurance : Enhance your speak-up culture with targeted engagement, streamline investigations with Helpline Case Management, and proactively mitigate risk with Disclosure Management.
Third-Party Due Diligence : Manage third-party risk with automated screening, due diligence, risk management, and ongoing monitoring.
Learn more at Compliance Week in Washington, DC at the OneTrust Booth #13
Ethics and compliance teams know that to build great, ethical cultures, they need to transform from merely complying with regulations to building ethical cultures that can proactively identify and mitigate corporate risks and drive behavioral and organizational change. The OneTrust Ethics & Compliance Cloud will bring intelligence, scale, and automation to ethics and compliance so companies can manage their ethics data, teams, and workflows in a single platform.
'Over the last year, we've been working hard to integrate people, process, and the Convercent technology into the OneTrust platform,' said Patrick Quinlan, General Manager of Ethics & Compliance at OneTrust . 'The combined solution strengthens ethics and compliance programs, enabling the business to build trust from the inside out while still having the opportunity to focus on privacy, security, and ESG related goals.'
To learn more about the OneTrust Ethics & Compliance Cloud, read our blog or request a demo .
1Adobe (2022). Adobe Trust Report , p 4.
2Edelman (2021). Edelman Trust Barometer Special Report: The Belief-Driven Employee , p. 12.
OneTrust, TrustWeek, Convercent, and OneTrust Athena are either registered trademarks or trademarks of OneTrust LLC in the United States and/or other countries. All other trademarks are the property of their respective owners.
About OneTrust OneTrust is the category-defining enterprise platform to operationalize trust. More than 12,000 customers, including half of the Fortune Global 500, use OneTrust to make trust a competitive differentiator, implementing central agile workflows across Privacy and Data Governance, GRC and Security Assurance, Ethics and Compliance, and ESG and Sustainability. The OneTrust platform is backed by 200 patents and powered by the OneTrust Athena AI and robotic automation engine.
In 2020, OneTrust was named the #1 fastest-growing company in America on the Inc. 500 with a 48,000% three-year growth rate. According to the IDC Worldwide Data Privacy Management Software Market Shares Report , 2020, 'OneTrust is leading the market outright and showing no signs of slowing down or stopping.'
OneTrust has raised $920 million in funding at a $5.3 billion valuation from Insight Partners, Coatue, TCV, SoftBank Vision Fund 2, and Franklin Templeton. OneTrust's fast-growing team of 3,000 employees is co-headquartered in Atlanta and London with office hubs across Australia, Brazil, Canada, France, Germany, Japan, United Kingdom, and the United States.
To learn more, visit OneTrust.com or connect on LinkedIn , Twitter , and YouTube .
Media Contact Gabrielle Ferree+1 770-294-4668[email protected]
SOURCE OneTrust
MENAFN16052022003732001241ID1104219865
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); FINANCIAL TECHNOLOGY (89%); PSYCHOLOGICAL SAFETY (89%); INVESTIGATIONS (78%); NEGATIVE PERSONAL NEWS (78%); REGULATORY COMPLIANCE (78%); BUSINESS OPERATIONS (76%); EMPLOYEE TRAINING (76%); RISK MANAGEMENT (73%); RESIGNATIONS (68%)
Organization: ASHA (57%)
Industry: SOFTWARE SERVICES & APPLICATIONS (90%); FINANCIAL TECHNOLOGY (89%); PSYCHOLOGICAL SAFETY (89%); CLOUD COMPUTING (78%); RISK MANAGEMENT (73%); COMPUTER SOFTWARE (72%)
Geographic: UNITED STATES (79%)
Load-Date: September 2, 2022",neutral,0.5011248588562012,balanced/neutral,"['privacy', 'safety', 'security']",[],"['policy', 'governance', 'compliance', 'need to']",[],3,0,4,0
2021,Unknown Title,"Byline: 刘欣
Body
BEIJING, April 1 (Xinhua) -- China's first national guideline on the ethical governance of science and technology will effectively prevent potential risks that could arise from sci-tech development, according to senior officials from the Ministry of Science and Technology. The country recently issued the guideline, which noted that accelerating the construction of a sci-tech ethics system with Chinese characteristics should be integrated with innovation and risk-prevention. The guideline clarified the principles of sci-tech ethics, including enhancing human well-being, respecting life rights, adhering to fairness and justice, managing risks appropriately, and being open and transparent. 
The principles fully absorbed international rules and consensus on sci-tech ethics, and combined the historical stage and sociocultural characteristics of China's sci-tech development, said Xiangli Bin, vice minister of Science and Technology. The principles were formed by experts and scholars from the fields of science and technology, ethics and law after extensive research and examination, said Xiangli, adding that opinions and suggestions were also collected from many scientists and technologists. He also said the principles clarified the position and attitudes of the Chinese government and the sci-tech circle toward the governance of sci-tech ethics, which is of great significance in strengthening international sci-tech exchanges and improving the global ethical governance of science and technology. The sci-tech ethics guideline called for speeding up the development of a legal system for ethical governance in science and technology, strengthening the early warning and tracking of sci-tech ethical risks, and quickly and flexibly responding to the ethical challenges brought by innovation. Sci-tech activities should adhere to a people-centered development philosophy, which is conducive to economic development, social progress, the improvement of people's livelihoods and ecological protection, according to the guideline. It also specified that sci-tech activities should avoid harm or potential threats to people's lives, as well as their physical, mental and psychological health to the greatest extent, and respect human dignity and personal privacy. Sci-tech activities should respect differences in religious beliefs and cultural traditions, treat different social groups in a fair, just and inclusive manner, and prevent discrimination and prejudice, said the guideline, which also emphasized preventing the misuse and abuse of sci-tech achievements and avoiding endangering social, public, biological and ecological security. The guideline called for improving standards for sci-tech ethics in key fields such as bioscience, medicine and artificial intelligence, which will provide guidance to sci-tech institutions and researchers in their activities. Minister of Science and Technology Wang Zhigang said that the sci-tech ethics guideline focuses on the major issues, such as improving the ethical governance system of science and technology in China. The guideline will provide strong support for high-level sci-tech self-reliance and the building of a community with a shared future for mankind, noted Wang. Enditem
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); ECOLOGY & ENVIRONMENTAL SCIENCE (89%); GOVERNMENT ADVISORS & MINISTERS (89%); ECONOMIC DEVELOPMENT (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); INTERNATIONAL ECONOMIC DEVELOPMENT (78%); PSYCHOLOGY (78%); SCIENCE & TECHNOLOGY (78%); PUBLIC OFFICIALS (77%); DRUG FAST TRACKING (76%); DISCRIMINATION (75%); LAW & LEGAL SYSTEM (75%); NEGATIVE SOCIETAL NEWS (74%); RISK MANAGEMENT (73%); BUSINESS NEWS (72%); CUSTOMS & CULTURAL HERITAGE (69%); NEGATIVE NEWS (66%); CONSERVATION (62%); MENTAL HEALTH (61%); ARTIFICIAL INTELLIGENCE (50%); RELIGION (50%); 05 Science & Technology (%)
Industry: PRESS AGENCY RELEASES (90%); NEWS SYNDICATION (78%); PSYCHOLOGY (78%); DRUG FAST TRACKING (76%); RISK MANAGEMENT (73%); ARTIFICIAL INTELLIGENCE (50%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (79%); CHINA (95%)
Load-Date: April 1, 2022","BEIJING, April 1 (Xinhua) -- China's first national guideline on the ethical governance of science and technology will effectively prevent potential risks that could arise from sci-tech development, according to senior officials from the Ministry of Science and Technology. The country recently issued the guideline, which noted that accelerating the construction of a sci-tech ethics system with Chinese characteristics should be integrated with innovation and risk-prevention. The guideline clarified the principles of sci-tech ethics, including enhancing human well-being, respecting life rights, adhering to fairness and justice, managing risks appropriately, and being open and transparent. 
The principles fully absorbed international rules and consensus on sci-tech ethics, and combined the historical stage and sociocultural characteristics of China's sci-tech development, said Xiangli Bin, vice minister of Science and Technology. The principles were formed by experts and scholars from the fields of science and technology, ethics and law after extensive research and examination, said Xiangli, adding that opinions and suggestions were also collected from many scientists and technologists. He also said the principles clarified the position and attitudes of the Chinese government and the sci-tech circle toward the governance of sci-tech ethics, which is of great significance in strengthening international sci-tech exchanges and improving the global ethical governance of science and technology. The sci-tech ethics guideline called for speeding up the development of a legal system for ethical governance in science and technology, strengthening the early warning and tracking of sci-tech ethical risks, and quickly and flexibly responding to the ethical challenges brought by innovation. Sci-tech activities should adhere to a people-centered development philosophy, which is conducive to economic development, social progress, the improvement of people's livelihoods and ecological protection, according to the guideline. It also specified that sci-tech activities should avoid harm or potential threats to people's lives, as well as their physical, mental and psychological health to the greatest extent, and respect human dignity and personal privacy. Sci-tech activities should respect differences in religious beliefs and cultural traditions, treat different social groups in a fair, just and inclusive manner, and prevent discrimination and prejudice, said the guideline, which also emphasized preventing the misuse and abuse of sci-tech achievements and avoiding endangering social, public, biological and ecological security. The guideline called for improving standards for sci-tech ethics in key fields such as bioscience, medicine and artificial intelligence, which will provide guidance to sci-tech institutions and researchers in their activities. Minister of Science and Technology Wang Zhigang said that the sci-tech ethics guideline focuses on the major issues, such as improving the ethical governance system of science and technology in China. The guideline will provide strong support for high-level sci-tech self-reliance and the building of a community with a shared future for mankind, noted Wang. Enditem
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (93%); ECOLOGY & ENVIRONMENTAL SCIENCE (89%); GOVERNMENT ADVISORS & MINISTERS (89%); ECONOMIC DEVELOPMENT (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); INTERNATIONAL ECONOMIC DEVELOPMENT (78%); PSYCHOLOGY (78%); SCIENCE & TECHNOLOGY (78%); PUBLIC OFFICIALS (77%); DRUG FAST TRACKING (76%); DISCRIMINATION (75%); LAW & LEGAL SYSTEM (75%); NEGATIVE SOCIETAL NEWS (74%); RISK MANAGEMENT (73%); BUSINESS NEWS (72%); CUSTOMS & CULTURAL HERITAGE (69%); NEGATIVE NEWS (66%); CONSERVATION (62%); MENTAL HEALTH (61%); ARTIFICIAL INTELLIGENCE (50%); RELIGION (50%); 05 Science & Technology (%)
Industry: PRESS AGENCY RELEASES (90%); NEWS SYNDICATION (78%); PSYCHOLOGY (78%); DRUG FAST TRACKING (76%); RISK MANAGEMENT (73%); ARTIFICIAL INTELLIGENCE (50%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (79%); CHINA (95%)
Load-Date: April 1, 2022",neutral,0.6650026440620422,balanced/neutral,"['privacy', 'discrimination', 'fairness', 'security', 'agency']","['justice', 'fairness', 'dignity', 'justice']","['governance', 'standards', 'law', 'should']",[],5,4,4,0
2021,Unknown Title,"Body
Conflict erupts between a family member and the clinical team over whether to withdraw life-sustaining interventions. Instead of requesting an ethics consultation, a clinician turns to an artificial intelligence (AI) tool for answers. Some ethicists are wondering about this possibility, as machine learning is used in more areas of healthcare. ""The realm of medical ethics, however, has so far been an exception,"" says Lukas J. Meier, PhD, a junior research fellow at University of Cambridge. 
AI and machine learning programs will ""dramatically affect clinical ethics,"" predicts Gavin G. Enck, PhD, HEC-C, a clinical ethicist at OhioHealth. The tools can serve as decision aids and identify errors in clinical ethics judgments, but there are limitations. ""We must set realistic expectations,"" Enck says.
It is unlikely anyone would use an AI tool to determine if they should marry their partner, embark on a new career, or start a family. ""Similarly, we cannot expect AI or machine learning programs to provide a conclusive answer in every clinical ethics situation in healthcare,"" Enck says.
Unlike ethicists, the tools can be programmed to avoid systematic biases and errors. ""While it may seem strange, I would argue that patients, providers, and ethicists should expect, and even want, AI and machine learning programs to serve as decision aids in clinical ethics consultations,"" Enck says.
AI ethics ""has evolved as a field, drawing ethicists from both health ethics and engineering ethics,"" says Craig M. Klugman, PhD, who co-authored several papers on this topic.1,2 The unanswered question is whether a sophisticated AI tool can perform the job of a clinical ethicist. If so, it could mean the end of some hospital-based clinical ethics roles. 
""If you can buy an ethics AI off the shelf, the role of a human clinical ethicist may go away,"" suggests Klugman, a professor of bioethics and health humanities at DePaul University and ethics committee member at Northwestern Memorial Hospital. 
It is more likely to happen at smaller hospitals without full-time ethicists. Even for larger hospitals, software is much cheaper than full-time ethicists' salaries. ""However, as they currently exist, AIs are only supposed to be decision aids. They are not supposed to be the final word,"" Klugman cautions.
AI has been used successfully to maximize use of OR space. ""The AI is a much better predictor of how long a procedure will take. This is one of the most successful examples of AI in medicine,"" Klugman says.
Similarly, AI could be used for distribution-related suggestions in ethics (e.g., questions about allocation of scarce resources). However, there are concerns that AI ethics tools could incorporate various biases. ""For example, an AI built on a million records from a single hospital system assumes those are all of the records that exist,"" Klugman offers.
It could be most of those patients presented with health insurance, were employed, or were the same race. The rules and guidance an AI gives does not ""know"" the data set on which it evolved included biases. Even if all identifying information is stripped, systems still develop biases.3 ""That's because medicine asks different questions of different patients, even if they have the same disease. We even run different tests for different patients with the same disease. AI bias will force us to confront human bias,"" Klugman explains.
Using a tool that could introduce bias into a clinical situation or during an ethics consult is problematic. To address these and other issues, says Klugman, ""ethicists can and should be part of AI oversight boards in a hospital.""
Researchers are working on bioethics AI tools that are trained to make moral decisions. ""These tools raise complex issues. For example, there is a risk of automation bias,"" says Sara Gerke, Dipl-Jur Univ, MA, assistant professor at Penn State Dickinson Law whose research focuses on ethical and legal challenges of AI in healthcare.
Humans tend to rely on machines rather than making complex decisions by themselves. This can be dangerous if an AI tool is untrustworthy. If AI tools make complex moral decisions in the future or ""assist"" physicians in doing so, it raises the question of whether the tools should be required to undergo the same training as certified human clinical healthcare ethics consultants. ""We still have much to figure out before we trust bioethics AI to make moral decisions,"" Gerke says.
AI tools are unlikely to ever be compassionate, empathic, or understand human emotion - all cornerstones of the ethics consult process. ""It may have protocols that look like those things, but the appearance of compassion is very different than actual compassion,"" Klugman notes.
Can clinicians ever put total trust into an AI to make ethical decisions? ""No matter how sophisticated an AI gets, it will never be a moral agent. It will never have to face the emotional and existential consequences that its decision may end a life,"" Klugman says.
Say an ethicist decides to save money for her hospital by no longer offering treatment to any diabetic patient with heart or kidney disease. That would save money, but also would result in a lot of sick or dying patients. ""A human being could recognize that saving money has to come second to some other value. But the AI doesn't have that ability to check itself, see the moral and emotional outcomes of its choices, and then go back and refine them,"" Klugman explains. 
In a pilot study, Meier and colleagues from the Technical University of Munich set out to answer two questions: Is it technologically possible for algorithms to solve bioethical problems? If so, would that be desirable? The researchers created an algorithm that could be used to advise clinicians on moral dilemmas.4 ""It was not our goal to develop a product for actual clinical application that would replace human decision-making, "" Meier reports.
Rather, Meier and colleagues tried to create an example of what such a system would look like, and how it would work. For example, they wanted to know if the algorithm could answer questions on whether a patient should be able to refuse a treatment that is likely to extend their life. They concluded machine intelligence is not sophisticated enough to risk passing judgment on real patients. ""However, as in the case of other innovations, it is important that we have discussions about the virtues and vices of novel technologies before they become widely available,"" Meier suggests.
There are two important questions to ask about use of AI in the clinical ethics field, according to Meier: In which areas would automated decision-making be beneficial, and where should we avoid it? How would it affect relationships between patients and clinicians? ""The sooner ethicists and other stakeholders address these and other questions, the better,"" Meier says.
Some concerns also apply to AI used in healthcare generally, but the field of medical ethics presents some additional considerations. ""If machine intelligence was employed in this area, one would need to proceed with the utmost care,"" Meier cautions.
Researchers must consider whether human empathy is a necessary component of ethical case discussions, and whether the data set on the basis of which the algorithm issues its recommendations is inclusive and representative. Also, who should be held legally responsible for the algorithm's decisions? Is it the programmers who ""trained"" the AI, or the hospital staff who use it? ""All of these issues must be addressed before the clinical application of machine intelligence in ethics can even be considered,"" Meier adds.
Fabrice Jotterand, PhD, MA, says it is important for ethicists to understand the difference between AI (i.e., when computer systems perform tasks that mimic human intelligence, such as problem-solving or learning) and machine learning tools (i.e., algorithms that allow computers to learn from data instead of just operating according to human programmers' instructions). Jotterand says it is unlikely any clinical ethicists are using AI during consults because AI cannot grasp the complexities of moral issues in the clinical context - patient/family values and patient/physician relationships.
""That said, I could imagine a clinical ethicist doing research on cancer, for instance, and using a large data set to determine the outcome of a particular controversial procedure,"" says Jotterand, director of the bioethics graduate program at the Medical College of Wisconsin.
During a consultation, ethicists could use data from the study to help the decision-making process. In that context, machine learning could provide helpful insights regarding the ethical justification of a procedure, by factoring in risk/benefit assessments, cost estimates, and long-term outcomes. ""But I would not want an AI making an ethical claim without human agency - ethicist, physician, patient, family, or proxy - and interpretation,"" Jotterand cautions.
The complexities of clinical practice, the structure of the healthcare system, and how ethical decisions are made in the clinical context cannot be captured via algorithms. 
""In addition, I don't know whether clinicians or patients and families would want to have 'RoboEthicus' as a consultant,"" Jotterand adds. ""This is an empirical question worth exploring.""
    REFERENCES    
1. Klugman CM, Gerke S. Rise of the bioethics AI: Curse or blessing? Am J Bioeth 2022;22:35-37.
2. Michelson KN, Klugman CM, Kho AN, Gerke S. Ethical considerations related to using machine learning-based prediction of mortality in the pediatric intensive care unit. J Pediatr 2022;247:125-128.
3. Gichoya JW, Banerjee I, Bhimireddy AR, et al. AI recognition of patient race in medical imaging: A modelling study. Lancet Digit Health 2022;4:e406-e414.
4. Meier LJ, Hein A, Diepold K, Buyx A. Algorithms for ethical decision-making in the clinic: A proof of concept. Am J Bioeth 2022;22:4-20.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); HUMAN SUBJECTS (90%); MACHINE LEARNING (90%); MEDICAL ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); BIOETHICS (79%); FAMILY (78%); COLLEGES & UNIVERSITIES (76%); WAR & CONFLICT (74%); COLLEGE & UNIVERSITY PROFESSORS (71%); HUMANITIES & SOCIAL SCIENCE (71%); WAGES & SALARIES (63%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ACADEMIC MEDICAL CENTERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HOSPITALS (89%); COLLEGES & UNIVERSITIES (76%); MEDIA & TELECOMMUNICATIONS (73%); COLLEGE & UNIVERSITY PROFESSORS (71%)
Load-Date: January 31, 2023","Conflict erupts between a family member and the clinical team over whether to withdraw life-sustaining interventions. Instead of requesting an ethics consultation, a clinician turns to an artificial intelligence (AI) tool for answers. Some ethicists are wondering about this possibility, as machine learning is used in more areas of healthcare. ""The realm of medical ethics, however, has so far been an exception,"" says Lukas J. Meier, PhD, a junior research fellow at University of Cambridge. 
AI and machine learning programs will ""dramatically affect clinical ethics,"" predicts Gavin G. Enck, PhD, HEC-C, a clinical ethicist at OhioHealth. The tools can serve as decision aids and identify errors in clinical ethics judgments, but there are limitations. ""We must set realistic expectations,"" Enck says.
It is unlikely anyone would use an AI tool to determine if they should marry their partner, embark on a new career, or start a family. ""Similarly, we cannot expect AI or machine learning programs to provide a conclusive answer in every clinical ethics situation in healthcare,"" Enck says.
Unlike ethicists, the tools can be programmed to avoid systematic biases and errors. ""While it may seem strange, I would argue that patients, providers, and ethicists should expect, and even want, AI and machine learning programs to serve as decision aids in clinical ethics consultations,"" Enck says.
AI ethics ""has evolved as a field, drawing ethicists from both health ethics and engineering ethics,"" says Craig M. Klugman, PhD, who co-authored several papers on this topic.1,2 The unanswered question is whether a sophisticated AI tool can perform the job of a clinical ethicist. If so, it could mean the end of some hospital-based clinical ethics roles. 
""If you can buy an ethics AI off the shelf, the role of a human clinical ethicist may go away,"" suggests Klugman, a professor of bioethics and health humanities at DePaul University and ethics committee member at Northwestern Memorial Hospital. 
It is more likely to happen at smaller hospitals without full-time ethicists. Even for larger hospitals, software is much cheaper than full-time ethicists' salaries. ""However, as they currently exist, AIs are only supposed to be decision aids. They are not supposed to be the final word,"" Klugman cautions.
AI has been used successfully to maximize use of OR space. ""The AI is a much better predictor of how long a procedure will take. This is one of the most successful examples of AI in medicine,"" Klugman says.
Similarly, AI could be used for distribution-related suggestions in ethics (e.g., questions about allocation of scarce resources). However, there are concerns that AI ethics tools could incorporate various biases. ""For example, an AI built on a million records from a single hospital system assumes those are all of the records that exist,"" Klugman offers.
It could be most of those patients presented with health insurance, were employed, or were the same race. The rules and guidance an AI gives does not ""know"" the data set on which it evolved included biases. Even if all identifying information is stripped, systems still develop biases.3 ""That's because medicine asks different questions of different patients, even if they have the same disease. We even run different tests for different patients with the same disease. AI bias will force us to confront human bias,"" Klugman explains.
Using a tool that could introduce bias into a clinical situation or during an ethics consult is problematic. To address these and other issues, says Klugman, ""ethicists can and should be part of AI oversight boards in a hospital.""
Researchers are working on bioethics AI tools that are trained to make moral decisions. ""These tools raise complex issues. For example, there is a risk of automation bias,"" says Sara Gerke, Dipl-Jur Univ, MA, assistant professor at Penn State Dickinson Law whose research focuses on ethical and legal challenges of AI in healthcare.
Humans tend to rely on machines rather than making complex decisions by themselves. This can be dangerous if an AI tool is untrustworthy. If AI tools make complex moral decisions in the future or ""assist"" physicians in doing so, it raises the question of whether the tools should be required to undergo the same training as certified human clinical healthcare ethics consultants. ""We still have much to figure out before we trust bioethics AI to make moral decisions,"" Gerke says.
AI tools are unlikely to ever be compassionate, empathic, or understand human emotion - all cornerstones of the ethics consult process. ""It may have protocols that look like those things, but the appearance of compassion is very different than actual compassion,"" Klugman notes.
Can clinicians ever put total trust into an AI to make ethical decisions? ""No matter how sophisticated an AI gets, it will never be a moral agent. It will never have to face the emotional and existential consequences that its decision may end a life,"" Klugman says.
Say an ethicist decides to save money for her hospital by no longer offering treatment to any diabetic patient with heart or kidney disease. That would save money, but also would result in a lot of sick or dying patients. ""A human being could recognize that saving money has to come second to some other value. But the AI doesn't have that ability to check itself, see the moral and emotional outcomes of its choices, and then go back and refine them,"" Klugman explains. 
In a pilot study, Meier and colleagues from the Technical University of Munich set out to answer two questions: Is it technologically possible for algorithms to solve bioethical problems? If so, would that be desirable? The researchers created an algorithm that could be used to advise clinicians on moral dilemmas.4 ""It was not our goal to develop a product for actual clinical application that would replace human decision-making, "" Meier reports.
Rather, Meier and colleagues tried to create an example of what such a system would look like, and how it would work. For example, they wanted to know if the algorithm could answer questions on whether a patient should be able to refuse a treatment that is likely to extend their life. They concluded machine intelligence is not sophisticated enough to risk passing judgment on real patients. ""However, as in the case of other innovations, it is important that we have discussions about the virtues and vices of novel technologies before they become widely available,"" Meier suggests.
There are two important questions to ask about use of AI in the clinical ethics field, according to Meier: In which areas would automated decision-making be beneficial, and where should we avoid it? How would it affect relationships between patients and clinicians? ""The sooner ethicists and other stakeholders address these and other questions, the better,"" Meier says.
Some concerns also apply to AI used in healthcare generally, but the field of medical ethics presents some additional considerations. ""If machine intelligence was employed in this area, one would need to proceed with the utmost care,"" Meier cautions.
Researchers must consider whether human empathy is a necessary component of ethical case discussions, and whether the data set on the basis of which the algorithm issues its recommendations is inclusive and representative. Also, who should be held legally responsible for the algorithm's decisions? Is it the programmers who ""trained"" the AI, or the hospital staff who use it? ""All of these issues must be addressed before the clinical application of machine intelligence in ethics can even be considered,"" Meier adds.
Fabrice Jotterand, PhD, MA, says it is important for ethicists to understand the difference between AI (i.e., when computer systems perform tasks that mimic human intelligence, such as problem-solving or learning) and machine learning tools (i.e., algorithms that allow computers to learn from data instead of just operating according to human programmers' instructions). Jotterand says it is unlikely any clinical ethicists are using AI during consults because AI cannot grasp the complexities of moral issues in the clinical context - patient/family values and patient/physician relationships.
""That said, I could imagine a clinical ethicist doing research on cancer, for instance, and using a large data set to determine the outcome of a particular controversial procedure,"" says Jotterand, director of the bioethics graduate program at the Medical College of Wisconsin.
During a consultation, ethicists could use data from the study to help the decision-making process. In that context, machine learning could provide helpful insights regarding the ethical justification of a procedure, by factoring in risk/benefit assessments, cost estimates, and long-term outcomes. ""But I would not want an AI making an ethical claim without human agency - ethicist, physician, patient, family, or proxy - and interpretation,"" Jotterand cautions.
The complexities of clinical practice, the structure of the healthcare system, and how ethical decisions are made in the clinical context cannot be captured via algorithms. 
""In addition, I don't know whether clinicians or patients and families would want to have 'RoboEthicus' as a consultant,"" Jotterand adds. ""This is an empirical question worth exploring.""
    REFERENCES    
1. Klugman CM, Gerke S. Rise of the bioethics AI: Curse or blessing? Am J Bioeth 2022;22:35-37.
2. Michelson KN, Klugman CM, Kho AN, Gerke S. Ethical considerations related to using machine learning-based prediction of mortality in the pediatric intensive care unit. J Pediatr 2022;247:125-128.
3. Gichoya JW, Banerjee I, Bhimireddy AR, et al. AI recognition of patient race in medical imaging: A modelling study. Lancet Digit Health 2022;4:e406-e414.
4. Meier LJ, Hein A, Diepold K, Buyx A. Algorithms for ethical decision-making in the clinic: A proof of concept. Am J Bioeth 2022;22:4-20.
Classification
Language: ENGLISH
Publication-Type: Newsletter
Journal Code: MEA
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); HUMAN SUBJECTS (90%); MACHINE LEARNING (90%); MEDICAL ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); BIOETHICS (79%); FAMILY (78%); COLLEGES & UNIVERSITIES (76%); WAR & CONFLICT (74%); COLLEGE & UNIVERSITY PROFESSORS (71%); HUMANITIES & SOCIAL SCIENCE (71%); WAGES & SALARIES (63%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ACADEMIC MEDICAL CENTERS (89%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HOSPITALS (89%); COLLEGES & UNIVERSITIES (76%); MEDIA & TELECOMMUNICATIONS (73%); COLLEGE & UNIVERSITY PROFESSORS (71%)
Load-Date: January 31, 2023",neutral,0.7574695348739624,balanced/neutral,"['bias', 'agency']",['virtues'],"['oversight', 'law', 'should', 'must', 'need to']","['machine learning', 'algorithm']",2,1,5,2
2021,Unknown Title,"Body
 Chief Executive Officer, ID Africa, Femi Falodun has called on public relations professionals to study new trends and critically interrogate how emerging technologies like AI, cryptocurrencies, web3, metaverse and others can enhance or mar the human experience.
In a contribution to the Public Relations and Communications Association (PRCA) Ethics Council's 2022 Annual Perspective report, Falodun stated that PR practitioners who work in and around the web3 ecosystem must pay close attention to ethical issues in web3, in order to properly guide their stakeholders.
The PRCA Ethics Council's 2022 Annual Perspective report, which is published annually by the world's largest professional PR body, features insights from 30 global leaders, and explores the ethical challenges when engaging in the Metaverse, NFTs, Artificial Intelligence (AI), and other new technology.
According to Falodun, as long as PR practitioners stay adequately informed on the tech, and remain people-centric, they will emerge as trusted partners for governments, web3 builders and society of users, helping them to find and communicate the best ways that these technologies can enrich the human experience.
He added that many of the concerns about web3-related technologies are the ambiguity about what is right or wrong.
'A key concern with web3 is sustainability. According to Digiconomist, Bitcoin mining generates up to 96 million tons of CO2 emissions yearly, while Ethereum mining produces 47 million tons. The Bitcoin network also produces 30,000 tons of electronic waste per year. Although proponents are introducing new methods that are less energy-intensive, it is expected that crypto's carbon footprint will continue to increase as adoption grows.
'The biggest ethical concerns with AI include racial bias from robots, inequality in the distribution of wealth created by robots, cybersecurity risks, robot rights, unemployment due to loss of jobs to machines, and the Singularity, fear that someday, humanity will lose control to complex intelligent systems,' Falodun stated.
He pointed out that through its understanding of emerging technologies, industry and consumer trends, ID Africa helps provide strategic advisory and communications services to brands and organisations in Africa looking to connect better with their stakeholders. ID Africa is a part of the BlackHouse Media (BHM) family, where Falodun is also a Director.
Speaking on the report, Co-Chair, PRCA Global Ethics Council, Mary Beth West urged the whole of the PR industry - at every level of experience and practice - to embrace new areas of learning, awareness, and strategic consideration tied to the ethics of AI and how digital technology might be engaged in ways that potentially risk stakeholder trust and brand reputation.
'This year's PRCA Ethics Council Annual Perspective provides PR professionals with the tools to push their clients to be ethical and use every touch point as an opportunity to tell human stories that truly make an impact and build a deeper connection with the people the industry serves,' PRCA Global Ethics Council Co-Chair Nitin Mantri added.
Classification
Language: English US
Publication-Type: Newspaper
Subject: DIGITAL CURRENCY (91%); EMERGING TECHNOLOGY (91%); CRYPTOCURRENCY (90%); ETHICS (90%); TRENDS (90%); ARTIFICIAL INTELLIGENCE (89%); EXECUTIVES (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INDUSTRY TRENDS (78%); ASSOCIATIONS & ORGANIZATIONS (77%); ENVIRONMENTAL FOOTPRINT (77%); SUSTAINABLE DEVELOPMENT (76%); ANNUAL FINANCIAL RESULTS (75%); CONSUMER TRENDS (73%); ECONOMIC INEQUALITY (71%); EMISSIONS (70%); GREENHOUSE GASES (65%); LAYOFFS (62%); LAYOFFS & DISMISSALS (62%); NEGATIVE EMPLOYMENT NEWS (62%); BRANDING (60%)
Industry: WEB3 (93%); PUBLIC RELATIONS (92%); DIGITAL CURRENCY (91%); CRYPTOCURRENCY (90%); METAVERSE (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTO ASSETS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); SUSTAINABLE DEVELOPMENT (76%); EMISSIONS (70%); BRANDING (60%)
Geographic: AFRICA (93%); NIGERIA (92%)
Load-Date: May 10, 2022","Chief Executive Officer, ID Africa, Femi Falodun has called on public relations professionals to study new trends and critically interrogate how emerging technologies like AI, cryptocurrencies, web3, metaverse and others can enhance or mar the human experience.
In a contribution to the Public Relations and Communications Association (PRCA) Ethics Council's 2022 Annual Perspective report, Falodun stated that PR practitioners who work in and around the web3 ecosystem must pay close attention to ethical issues in web3, in order to properly guide their stakeholders.
The PRCA Ethics Council's 2022 Annual Perspective report, which is published annually by the world's largest professional PR body, features insights from 30 global leaders, and explores the ethical challenges when engaging in the Metaverse, NFTs, Artificial Intelligence (AI), and other new technology.
According to Falodun, as long as PR practitioners stay adequately informed on the tech, and remain people-centric, they will emerge as trusted partners for governments, web3 builders and society of users, helping them to find and communicate the best ways that these technologies can enrich the human experience.
He added that many of the concerns about web3-related technologies are the ambiguity about what is right or wrong.
'A key concern with web3 is sustainability. According to Digiconomist, Bitcoin mining generates up to 96 million tons of CO2 emissions yearly, while Ethereum mining produces 47 million tons. The Bitcoin network also produces 30,000 tons of electronic waste per year. Although proponents are introducing new methods that are less energy-intensive, it is expected that crypto's carbon footprint will continue to increase as adoption grows.
'The biggest ethical concerns with AI include racial bias from robots, inequality in the distribution of wealth created by robots, cybersecurity risks, robot rights, unemployment due to loss of jobs to machines, and the Singularity, fear that someday, humanity will lose control to complex intelligent systems,' Falodun stated.
He pointed out that through its understanding of emerging technologies, industry and consumer trends, ID Africa helps provide strategic advisory and communications services to brands and organisations in Africa looking to connect better with their stakeholders. ID Africa is a part of the BlackHouse Media (BHM) family, where Falodun is also a Director.
Speaking on the report, Co-Chair, PRCA Global Ethics Council, Mary Beth West urged the whole of the PR industry - at every level of experience and practice - to embrace new areas of learning, awareness, and strategic consideration tied to the ethics of AI and how digital technology might be engaged in ways that potentially risk stakeholder trust and brand reputation.
'This year's PRCA Ethics Council Annual Perspective provides PR professionals with the tools to push their clients to be ethical and use every touch point as an opportunity to tell human stories that truly make an impact and build a deeper connection with the people the industry serves,' PRCA Global Ethics Council Co-Chair Nitin Mantri added.
Classification
Language: English US
Publication-Type: Newspaper
Subject: DIGITAL CURRENCY (91%); EMERGING TECHNOLOGY (91%); CRYPTOCURRENCY (90%); ETHICS (90%); TRENDS (90%); ARTIFICIAL INTELLIGENCE (89%); EXECUTIVES (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INDUSTRY TRENDS (78%); ASSOCIATIONS & ORGANIZATIONS (77%); ENVIRONMENTAL FOOTPRINT (77%); SUSTAINABLE DEVELOPMENT (76%); ANNUAL FINANCIAL RESULTS (75%); CONSUMER TRENDS (73%); ECONOMIC INEQUALITY (71%); EMISSIONS (70%); GREENHOUSE GASES (65%); LAYOFFS (62%); LAYOFFS & DISMISSALS (62%); NEGATIVE EMPLOYMENT NEWS (62%); BRANDING (60%)
Industry: WEB3 (93%); PUBLIC RELATIONS (92%); DIGITAL CURRENCY (91%); CRYPTOCURRENCY (90%); METAVERSE (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTO ASSETS (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INFORMATION TECHNOLOGY INDUSTRY (78%); SUSTAINABLE DEVELOPMENT (76%); EMISSIONS (70%); BRANDING (60%)
Geographic: AFRICA (93%); NIGERIA (92%)
Load-Date: May 10, 2022",neutral,0.8369411826133728,balanced/neutral,"['bias', 'unemployment', 'inequality']",[],['must'],['robot'],3,0,1,1
2021,Unknown Title,"Body
2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at Transportation Daily News -- Research findings on artificial intelligence are discussed in a new report. According to news reporting from Hangzhou, People's Republic of China, by NewsRx journalists, research stated, ""The age of algorithms is here, and it is really changing people's lives."" 
 Funders for this research include National Social Science Major Project. 
 Our news editors obtained a quote from the research from Peking University: ""More and more ethical problems related to algorithms have attracted people's attention, but the related ethical research is still far behind the research of algorithms. As more intelligent algorithms emerge in an endless stream, there will also be a lot of algorithmic ethical issues. On the other hand, with the continuous improvement of the development level of the automobile industry, people have a stronger demand for the safety and stability of modern transportation, and more and more autonomous driving technology has been promoted and applied in the market. At present, most of the studies on the longitudinal collision avoidance system of vehicles use collision warning or emergency braking to avoid collision. However, when the vehicle is in a special situation such as high speed and slippery road, emergency steering is more effective. In order to further improve the vehicle safety and ethical algorithm design points, this article revolves around vehicle lateral active collision avoidance control method research, the collision avoidance decision-making, and path planning and collision avoidance transverse vehicle longitudinal motion control is analyzed, and based on automated driving simulation experiment, the tests carried out to verify the designed control strategy."" 
 According to the news editors, the research concluded: ""The experimental results show that the proposed method not only has a good effect of preventing automatic driving collision but also can meet the requirements of algorithm ethics. This research can effectively guide the research of algorithmic ethics in the field of autonomous driving and effectively reduce the occurrence of traffic accidents."" 
 For more information on this research see: Application of Machine Learning in Ethical Design of Autonomous Driving Crash Algorithms. Computational Intelligence and Neuroscience, 2022,2022. (Computational Intelligence and Neuroscience - https://www.hindawi.com/journals/cin/). The publisher for Computational Intelligence and Neuroscience is Hindawi Limited. 
 A free version of this journal article is available at https://doi.org/10.1155/2022/2938011. 
 Our news journalists report that additional information may be obtained by contacting Yineng Xiao, Advanced Institute of Information Technology, Peking University, Hangzhou 311200, People's Republic of China.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Yineng Xiao (orcid.org/0000-0001-5872-2071). 
 Keywords for this news article include: Peking University, Hangzhou, People's Republic of China, Asia, Algorithms, Cyborgs, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); SAFETY (90%); COLLEGES & UNIVERSITIES (89%); NEUROSCIENCE (89%); RESEARCH REPORTS (89%); WRITERS (89%); EMPLOYEE PROMOTIONS (78%); HUMANITIES & SOCIAL SCIENCE (78%); NEWS REPORTING (78%); TRAFFIC ACCIDENTS (76%); AUTOMOTIVE SAFETY (73%); AUTOMOTIVE SECTOR PERFORMANCE (73%); OUTPUT & DEMAND (73%); ACCIDENTS & DISASTERS (71%); AIR TRANSPORTATION SAFETY (69%); Algorithms;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (91%); ADVANCED DRIVER ASSISTANCE SYSTEMS (90%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); AUTONOMOUS MOTOR VEHICLES (89%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); NEWS REPORTING (78%); TRAFFIC ACCIDENTS (76%); AUTOMOTIVE SAFETY (73%); AUTOMOTIVE SECTOR PERFORMANCE (73%); AIR TRANSPORTATION SAFETY (69%); AUTOMOTIVE (68%)
Geographic: BEIJING, CHINA (93%); CHINA (92%)
Load-Date: October 7, 2022","2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at Transportation Daily News -- Research findings on artificial intelligence are discussed in a new report. According to news reporting from Hangzhou, People's Republic of China, by NewsRx journalists, research stated, ""The age of algorithms is here, and it is really changing people's lives."" 
 Funders for this research include National Social Science Major Project. 
 Our news editors obtained a quote from the research from Peking University: ""More and more ethical problems related to algorithms have attracted people's attention, but the related ethical research is still far behind the research of algorithms. As more intelligent algorithms emerge in an endless stream, there will also be a lot of algorithmic ethical issues. On the other hand, with the continuous improvement of the development level of the automobile industry, people have a stronger demand for the safety and stability of modern transportation, and more and more autonomous driving technology has been promoted and applied in the market. At present, most of the studies on the longitudinal collision avoidance system of vehicles use collision warning or emergency braking to avoid collision. However, when the vehicle is in a special situation such as high speed and slippery road, emergency steering is more effective. In order to further improve the vehicle safety and ethical algorithm design points, this article revolves around vehicle lateral active collision avoidance control method research, the collision avoidance decision-making, and path planning and collision avoidance transverse vehicle longitudinal motion control is analyzed, and based on automated driving simulation experiment, the tests carried out to verify the designed control strategy."" 
 According to the news editors, the research concluded: ""The experimental results show that the proposed method not only has a good effect of preventing automatic driving collision but also can meet the requirements of algorithm ethics. This research can effectively guide the research of algorithmic ethics in the field of autonomous driving and effectively reduce the occurrence of traffic accidents."" 
 For more information on this research see: Application of Machine Learning in Ethical Design of Autonomous Driving Crash Algorithms. Computational Intelligence and Neuroscience, 2022,2022. (Computational Intelligence and Neuroscience - https://www.hindawi.com/journals/cin/). The publisher for Computational Intelligence and Neuroscience is Hindawi Limited. 
 A free version of this journal article is available at https://doi.org/10.1155/2022/2938011. 
 Our news journalists report that additional information may be obtained by contacting Yineng Xiao, Advanced Institute of Information Technology, Peking University, Hangzhou 311200, People's Republic of China.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Yineng Xiao (orcid.org/0000-0001-5872-2071). 
 Keywords for this news article include: Peking University, Hangzhou, People's Republic of China, Asia, Algorithms, Cyborgs, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); SAFETY (90%); COLLEGES & UNIVERSITIES (89%); NEUROSCIENCE (89%); RESEARCH REPORTS (89%); WRITERS (89%); EMPLOYEE PROMOTIONS (78%); HUMANITIES & SOCIAL SCIENCE (78%); NEWS REPORTING (78%); TRAFFIC ACCIDENTS (76%); AUTOMOTIVE SAFETY (73%); AUTOMOTIVE SECTOR PERFORMANCE (73%); OUTPUT & DEMAND (73%); ACCIDENTS & DISASTERS (71%); AIR TRANSPORTATION SAFETY (69%); Algorithms;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (91%); ADVANCED DRIVER ASSISTANCE SYSTEMS (90%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); AUTONOMOUS MOTOR VEHICLES (89%); COLLEGES & UNIVERSITIES (89%); WRITERS (89%); NEWS REPORTING (78%); TRAFFIC ACCIDENTS (76%); AUTOMOTIVE SAFETY (73%); AUTOMOTIVE SECTOR PERFORMANCE (73%); AIR TRANSPORTATION SAFETY (69%); AUTOMOTIVE (68%)
Geographic: BEIJING, CHINA (93%); CHINA (92%)
Load-Date: October 7, 2022",neutral,0.8888162970542908,balanced/neutral,['safety'],[],[],"['machine learning', 'algorithm']",1,0,0,2
2021,Unknown Title,"Body
The code of artificial intelligence (AI) ethics has not yet sufficiently addressed the current realities and requires being finalized, while duly considering AI admissibility in society, MTS team leader Elena Suragina said at the Technoprom Forum.
""The problems of ethics in artificial intelligence must be redefined, given the current breakthrough situation, and under what circumstances and under what conditions this situation is acceptable in human society,"" the expert said.
Suragina cited a foreign company that had authorized AI-assisted monitoring of smartphone user accounts to find scenes of child abuse. ""It is critical to determine where a red line on ethics is drawn, because on the one hand you have user privacy and on the other you have the right of children to be safe,"" the expert explained.
Developers are speaking about the need for an unambiguous understanding of ethical problems for their application to AI, Suragina said. ""We are working on identifying these ethical problems, and hammering out a code of practice addressing ethical aspects,"" she added.
The AI Alliance and certain other entities signed the Code of AI Ethics on October 26, 2021. The Code of Ethics heralds a human-oriented and humanistic approach in AI technologies development, the principles of non-discrimination, safe data handling and information security, AI identification in contacts with humans and respect for the autonomy of human will, and responsibility for the consequences of AI use.
Source: Russian News Agency
Classification
Language: ENGLISH
Publication-Type: Wire
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); NEGATIVE SOCIETAL NEWS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); CHILDREN'S RIGHTS (78%); NEGATIVE NEWS (77%); CHILDREN, ADOLESCENTS & TEENS (75%); ABUSE & NEGLECT (73%); CHILD ABUSE & NEGLECT (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); NEWS SYNDICATION (78%); PRESS AGENCY RELEASES (78%); INFORMATION SECURITY & PRIVACY (74%); MOBILE & CELLULAR TELEPHONES (55%)
Load-Date: August 24, 2022","The code of artificial intelligence (AI) ethics has not yet sufficiently addressed the current realities and requires being finalized, while duly considering AI admissibility in society, MTS team leader Elena Suragina said at the Technoprom Forum.
""The problems of ethics in artificial intelligence must be redefined, given the current breakthrough situation, and under what circumstances and under what conditions this situation is acceptable in human society,"" the expert said.
Suragina cited a foreign company that had authorized AI-assisted monitoring of smartphone user accounts to find scenes of child abuse. ""It is critical to determine where a red line on ethics is drawn, because on the one hand you have user privacy and on the other you have the right of children to be safe,"" the expert explained.
Developers are speaking about the need for an unambiguous understanding of ethical problems for their application to AI, Suragina said. ""We are working on identifying these ethical problems, and hammering out a code of practice addressing ethical aspects,"" she added.
The AI Alliance and certain other entities signed the Code of AI Ethics on October 26, 2021. The Code of Ethics heralds a human-oriented and humanistic approach in AI technologies development, the principles of non-discrimination, safe data handling and information security, AI identification in contacts with humans and respect for the autonomy of human will, and responsibility for the consequences of AI use.
Source: Russian News Agency
Classification
Language: ENGLISH
Publication-Type: Wire
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); NEGATIVE SOCIETAL NEWS (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); CHILDREN'S RIGHTS (78%); NEGATIVE NEWS (77%); CHILDREN, ADOLESCENTS & TEENS (75%); ABUSE & NEGLECT (73%); CHILD ABUSE & NEGLECT (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); NEWS SYNDICATION (78%); PRESS AGENCY RELEASES (78%); INFORMATION SECURITY & PRIVACY (74%); MOBILE & CELLULAR TELEPHONES (55%)
Load-Date: August 24, 2022",neutral,0.7804709076881409,balanced/neutral,"['privacy', 'discrimination', 'security', 'autonomy', 'agency']",['autonomy'],['must'],[],5,1,1,0
2021,Unknown Title,"Body
2022 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Health Policy and Law Daily -- Current study results on Climate Change have been published. According to news reporting out of Melbourne, Australia, by NewsRx editors, research stated, ""To commemorate 40 years since the founding of the Journal of Business Ethics, the editors in chief of the journal have invited the editors to provide commentaries on the future of business ethics. This essay comprises a selection of commentaries aimed at creating dialogue around the theme Ethics at the centre of global and local challenges."" 
 Financial support for this research came from CAUL and Member Institutions. 
 Our news journalists obtained a quote from the research from Monash University, ""For much of the history of the Journal of Business Ethics, ethics was seen within the academy as a peripheral aspect of business. However, in recent years, the stakes have risen dramatically, with global and local worlds destabilized by financial crisis, climate change, internet technologies and artificial intelligence, and global health crises. The authors of these commentaries address these grand challenges by placing business ethics at their centre. What if all grand challenges were framed as grand ethical challenges? Tanusree Jain, Arno Kourula and Suhaib Riaz posit that an ethical lens allows for a humble response, in which those with greater capacity take greater responsibility but remain inclusive and cognizant of different voices and experiences. Focussing on business ethics in connection to the grand(est) challenge of environmental emergencies, Steffen Bohm introduces the deceptively simple yet radical position that business is nature, and nature is business. His quick but profound side-step from arguments against human-nature dualism to an ontological undoing of the business-nature dichotomy should have all business ethics scholars rethinking their 'business and society' assumptions. Also, singularly concerned with the climate emergency, Boudewijn de Bruin posits a scenario where, 40 years from now, our field will be evaluated by its ability to have helped humanity emerge from this emergency. He contends that Milieudefensie (Friends of the Earth) v. Royal Dutch Shell illustrates how human rights take centre stage in climate change litigation, and how business ethics enters the courtroom. From a consumer ethics perspective, Deirdre Shaw, Michal Carrington and Louise Hassan argue that ecologically sustainable and socially just marketplace systems demand cultural change, a reconsideration of future interpretations of 'consumer society', a challenge to the dominant 'growth logic' and stimulation of alternative ways to address our consumption needs. Still concerned with global issues, but turning attention to social inequalities, Nelarine Cornelius links the capability approach (CA) to global and corporate governance, arguing that CA will continue to lie at the foundation of human development policy, and, increasingly, CSR and corporate governance. Continuing debate on the grand challenges associated with justice and equality, Laurence Romani identifies a significant shift in the centrality of business ethics in debates on managing (cultural) differences, positing that dialogue between diversity management and international management can ground future debate in business ethics. Finally, the essay concludes with a commentary by Charlotte Karam and Michelle Greenwood on the possibilities of feminist-inspired theories, methods, and positionality for many spheres of business ethics, not least stakeholder theory, to broaden and deepen its capacity for nuance, responsiveness, and transformation."" 
 According to the news editors, the research concluded: ""In the words of our commentators, grand challenges must be addressed urgently, and the Journal of Business Ethics should be at the forefront of tackling them."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethics At the Centre of Global and Local Challenges: Thoughts On the Future of Business Ethics. Journal of Business Ethics, 2022. Journal of Business Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Journal of Business Ethics - www.springerlink.com/content/0167-4544/) 
 Our news journalists report that additional information may be obtained by contacting Michelle Greenwood, Monash University, Dept. of Management, Melbourne, Vic, Australia. Additional authors for this research include Steffen Boehm, Michal Carrington, Nelarine Cornelius, Boudewijn de Bruin, Louise Hassan, Tanusree Jain, Charlotte Karam, Arno Kourula, Laurence Romani, Suhaib Riaz and Deirdre Shaw. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s10551-022-05239-2. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Melbourne, Australia, Australia and New Zealand, Climate Change, Global Warming, Legal Issues, Monash University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (99%); BUSINESS ETHICS (94%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); HEALTH CARE REGULATION & POLICY (90%); JOURNALISM (90%); RESEARCH REPORTS (90%); CLIMATE CHANGE (89%); CLIMATOLOGY (89%); NEGATIVE ENVIRONMENTAL NEWS (89%); PUBLIC POLICY (89%); SOCIAL JUSTICE (89%); NEGATIVE NEWS (87%); ECOLOGY & ENVIRONMENTAL SCIENCE (79%); ENVIRONMENTAL & WILDLIFE ORGANIZATIONS (79%); GREEN FINANCE (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); CORPORATE GOVERNANCE (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (78%); NEWS REPORTING (78%); WRITERS (78%); ECONOMIC CRISIS (75%); SUSTAINABILITY (74%); EXPERIMENTATION & RESEARCH (73%); NEGATIVE SOCIETAL NEWS (72%); ARTIFICIAL INTELLIGENCE (67%); LITIGATION (60%); Melbourne;Australia;Australia and New Zealand;Climate Change;Global Warming;Legal Issues (%)
Company:  ROYAL DUTCH SHELL PLC (63%)
Ticker: RDS.A (NYSE) (63%); RDS.A (LSE) (63%); RDS.A (EUR) (63%)
Industry: NAICS447110 GASOLINE STATIONS WITH CONVENIENCE STORES (63%); NAICS325110 PETROCHEMICAL MANUFACTURING (63%); NAICS211130 NATURAL GAS EXTRACTION (63%); NAICS211120 CRUDE PETROLEUM EXTRACTION (63%); HEALTH CARE REGULATION & POLICY (90%); GREEN FINANCE (79%); NEWS REPORTING (78%); WRITERS (78%); ARTIFICIAL INTELLIGENCE (67%); INTERNET & WWW (67%); COMPUTER NETWORKS (52%)
Geographic: MELBOURNE, AUSTRALIA (74%); VICTORIA, AUSTRALIA (89%); AUSTRALIA (90%); NEW ZEALAND (79%); AUSTRALIA & NEW ZEALAND (73%)
Load-Date: November 4, 2022","2022 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Health Policy and Law Daily -- Current study results on Climate Change have been published. According to news reporting out of Melbourne, Australia, by NewsRx editors, research stated, ""To commemorate 40 years since the founding of the Journal of Business Ethics, the editors in chief of the journal have invited the editors to provide commentaries on the future of business ethics. This essay comprises a selection of commentaries aimed at creating dialogue around the theme Ethics at the centre of global and local challenges."" 
 Financial support for this research came from CAUL and Member Institutions. 
 Our news journalists obtained a quote from the research from Monash University, ""For much of the history of the Journal of Business Ethics, ethics was seen within the academy as a peripheral aspect of business. However, in recent years, the stakes have risen dramatically, with global and local worlds destabilized by financial crisis, climate change, internet technologies and artificial intelligence, and global health crises. The authors of these commentaries address these grand challenges by placing business ethics at their centre. What if all grand challenges were framed as grand ethical challenges? Tanusree Jain, Arno Kourula and Suhaib Riaz posit that an ethical lens allows for a humble response, in which those with greater capacity take greater responsibility but remain inclusive and cognizant of different voices and experiences. Focussing on business ethics in connection to the grand(est) challenge of environmental emergencies, Steffen Bohm introduces the deceptively simple yet radical position that business is nature, and nature is business. His quick but profound side-step from arguments against human-nature dualism to an ontological undoing of the business-nature dichotomy should have all business ethics scholars rethinking their 'business and society' assumptions. Also, singularly concerned with the climate emergency, Boudewijn de Bruin posits a scenario where, 40 years from now, our field will be evaluated by its ability to have helped humanity emerge from this emergency. He contends that Milieudefensie (Friends of the Earth) v. Royal Dutch Shell illustrates how human rights take centre stage in climate change litigation, and how business ethics enters the courtroom. From a consumer ethics perspective, Deirdre Shaw, Michal Carrington and Louise Hassan argue that ecologically sustainable and socially just marketplace systems demand cultural change, a reconsideration of future interpretations of 'consumer society', a challenge to the dominant 'growth logic' and stimulation of alternative ways to address our consumption needs. Still concerned with global issues, but turning attention to social inequalities, Nelarine Cornelius links the capability approach (CA) to global and corporate governance, arguing that CA will continue to lie at the foundation of human development policy, and, increasingly, CSR and corporate governance. Continuing debate on the grand challenges associated with justice and equality, Laurence Romani identifies a significant shift in the centrality of business ethics in debates on managing (cultural) differences, positing that dialogue between diversity management and international management can ground future debate in business ethics. Finally, the essay concludes with a commentary by Charlotte Karam and Michelle Greenwood on the possibilities of feminist-inspired theories, methods, and positionality for many spheres of business ethics, not least stakeholder theory, to broaden and deepen its capacity for nuance, responsiveness, and transformation."" 
 According to the news editors, the research concluded: ""In the words of our commentators, grand challenges must be addressed urgently, and the Journal of Business Ethics should be at the forefront of tackling them."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethics At the Centre of Global and Local Challenges: Thoughts On the Future of Business Ethics. Journal of Business Ethics, 2022. Journal of Business Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Journal of Business Ethics - www.springerlink.com/content/0167-4544/) 
 Our news journalists report that additional information may be obtained by contacting Michelle Greenwood, Monash University, Dept. of Management, Melbourne, Vic, Australia. Additional authors for this research include Steffen Boehm, Michal Carrington, Nelarine Cornelius, Boudewijn de Bruin, Louise Hassan, Tanusree Jain, Charlotte Karam, Arno Kourula, Laurence Romani, Suhaib Riaz and Deirdre Shaw. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s10551-022-05239-2. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Melbourne, Australia, Australia and New Zealand, Climate Change, Global Warming, Legal Issues, Monash University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (99%); BUSINESS ETHICS (94%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); HEALTH CARE REGULATION & POLICY (90%); JOURNALISM (90%); RESEARCH REPORTS (90%); CLIMATE CHANGE (89%); CLIMATOLOGY (89%); NEGATIVE ENVIRONMENTAL NEWS (89%); PUBLIC POLICY (89%); SOCIAL JUSTICE (89%); NEGATIVE NEWS (87%); ECOLOGY & ENVIRONMENTAL SCIENCE (79%); ENVIRONMENTAL & WILDLIFE ORGANIZATIONS (79%); GREEN FINANCE (79%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); CORPORATE GOVERNANCE (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (78%); NEWS REPORTING (78%); WRITERS (78%); ECONOMIC CRISIS (75%); SUSTAINABILITY (74%); EXPERIMENTATION & RESEARCH (73%); NEGATIVE SOCIETAL NEWS (72%); ARTIFICIAL INTELLIGENCE (67%); LITIGATION (60%); Melbourne;Australia;Australia and New Zealand;Climate Change;Global Warming;Legal Issues (%)
Company:  ROYAL DUTCH SHELL PLC (63%)
Ticker: RDS.A (NYSE) (63%); RDS.A (LSE) (63%); RDS.A (EUR) (63%)
Industry: NAICS447110 GASOLINE STATIONS WITH CONVENIENCE STORES (63%); NAICS325110 PETROCHEMICAL MANUFACTURING (63%); NAICS211130 NATURAL GAS EXTRACTION (63%); NAICS211120 CRUDE PETROLEUM EXTRACTION (63%); HEALTH CARE REGULATION & POLICY (90%); GREEN FINANCE (79%); NEWS REPORTING (78%); WRITERS (78%); ARTIFICIAL INTELLIGENCE (67%); INTERNET & WWW (67%); COMPUTER NETWORKS (52%)
Geographic: MELBOURNE, AUSTRALIA (74%); VICTORIA, AUSTRALIA (89%); AUSTRALIA (90%); NEW ZEALAND (79%); AUSTRALIA & NEW ZEALAND (73%)
Load-Date: November 4, 2022",neutral,0.8984730243682861,balanced/neutral,['human rights'],"['justice', 'equality', 'justice']","['regulation', 'policy', 'governance', 'law', 'should', 'must']",[],1,3,6,0
2021,Unknown Title,"Body
More than ""always doing the right thing"", being ethical in the workplace is not always an easy task, as it depends on many factors in the day-to-day, but it is necessary for those who aim for professional success.
In an extremely competitive world, but one that clamors for collaborative teams and companies, acting with an ethical attitude is often seen as an outstanding differential in the collaborator.
But, after all, what are ethics?
The definition of ethics, in itself, is quite simple: a reflection on human attitude and relationships that tries to define what is good or bad, fair or unfair, appropriate or inappropriate, right or wrong.
But, in practice, it is not always that simple... Unlike laws, the professional code of ethics has no written rules; in fact, they try to explain why laws exist and their respective contents.
So, bringing this concept into the corporate world, professional ethics is the way each employee acts in work relationships, whether collective or individual (his with his own position or function).
Practically all the time, in everything he does, professional ethics must be there; after all, every job is formed by micro-decisions that involve, in different degrees, the inherent principles of each worker.
Thus, it is possible to identify a good professional when he or she acts with ethical correctness and professionalism all the time, and not just in a controlled environment like their sector or the company itself.
It is expected, then, that the entire collectivity of the company will act according to these principles of what is good, fair, appropriate or correct. But if each person is unique, wouldn't these principles also be unique?
The answer is yes and no. Yes, because each person has values that were shaped by their experience; but no, because within the company, with a higher goal common to all, the entire collectivity expects certain actions and attitudes for each situation, that is, it is expected that the employee acts with professional ethics.
But this does not mean an imposition, on the contrary: acting in an ethical and moral manner brings benefits both for the employee and for the company, because these are attitudes that awaken credibility, trust, and mutual respect between employees and company.
The importance of professional ethics in the corporate world
In fact, the most important thing of professional ethics is to provide a peaceful sleep, without the famous ""weight on the conscience"". When we are ethical all the time, we know that we are doing the right and just thing, in a good and proper way, without harming anyone around us.
But, besides this, the ethical professional is more valued by companies precisely because this means, in practice, greater productivity, focus, and sense of collaboration.
It is important to emphasize here that a collaborative environment is built on mutual respect, trust, and friendly relationships. Not coincidentally, these are basic attitudes of those who work ethically.
The companies that act with professional ethics towards their employees stand out in the labor market and guarantee a harmonious corporate environment, full of engaged professionals with a better quality of life.
What are the characteristics of an ethical professional? A professional who always acts with professional ethics has values and soft skills based on what is good, right, appropriate and fair.
Some characteristics are basic (such as honesty and respect), that is, they should form the character of each person; others, however, are important not only for the professional aspect, but also for the employee's life.
Altruism
An altruistic professional is positively concerned with the interests of others, and jointly seeks a solution for them.
Integrity
A very important value in professional ethics, the integrity of a collaborator shows that he/she has everything to be a trustworthy person, because he/she will always act in the right way, no matter how many pressures to act in the opposite way he/she suffers.
Justice The employee who acts with justice has an easier time dealing with and promoting diversity in his team, not to mention the gains in relation to his leadership position within them.
Commitment
This characteristic of the ethical worker also shows the level of concern he has for his word. In the context of professional ethics, commitment is more than just going to work every day and being accountable for all one's actions, it is also being committed to the company's goals and, why not, to one's own.
Prudence
A prudent professional knows when to take a risk when he calculates the consequences for everyone involved. It also involves being secretive when necessary and careful with communication between colleagues.
Competence
It is part of professional ethics, yes, to act with competence. After all, it is the minimum that the company expects from its hired employee, who has demonstrated in various stages of selection and recruitment his or her ability to do the job.
In summary, professional ethics permeates all the actions of the employee and the company, and should be observed at all times, even more so when one is alone in the workplace.
About Reachr 
Reachr is an HR Tech pioneer in the use of technology in recruitment whose mission is to find the ideal match between your company and your next employee.
Through a complete platform for Recruitment & Selection, we unite the vast knowledge of an elite hunting team to the power of technology through artificial intelligence and machine learning for you to hire more assertively and effectively.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (95%); BUSINESS ETHICS (90%); INTERPERSONAL RELATIONSHIPS (73%); DC (%)
Load-Date: September 20, 2022","More than ""always doing the right thing"", being ethical in the workplace is not always an easy task, as it depends on many factors in the day-to-day, but it is necessary for those who aim for professional success.
In an extremely competitive world, but one that clamors for collaborative teams and companies, acting with an ethical attitude is often seen as an outstanding differential in the collaborator.
But, after all, what are ethics?
The definition of ethics, in itself, is quite simple: a reflection on human attitude and relationships that tries to define what is good or bad, fair or unfair, appropriate or inappropriate, right or wrong.
But, in practice, it is not always that simple... Unlike laws, the professional code of ethics has no written rules; in fact, they try to explain why laws exist and their respective contents.
So, bringing this concept into the corporate world, professional ethics is the way each employee acts in work relationships, whether collective or individual (his with his own position or function).
Practically all the time, in everything he does, professional ethics must be there; after all, every job is formed by micro-decisions that involve, in different degrees, the inherent principles of each worker.
Thus, it is possible to identify a good professional when he or she acts with ethical correctness and professionalism all the time, and not just in a controlled environment like their sector or the company itself.
It is expected, then, that the entire collectivity of the company will act according to these principles of what is good, fair, appropriate or correct. But if each person is unique, wouldn't these principles also be unique?
The answer is yes and no. Yes, because each person has values that were shaped by their experience; but no, because within the company, with a higher goal common to all, the entire collectivity expects certain actions and attitudes for each situation, that is, it is expected that the employee acts with professional ethics.
But this does not mean an imposition, on the contrary: acting in an ethical and moral manner brings benefits both for the employee and for the company, because these are attitudes that awaken credibility, trust, and mutual respect between employees and company.
The importance of professional ethics in the corporate world
In fact, the most important thing of professional ethics is to provide a peaceful sleep, without the famous ""weight on the conscience"". When we are ethical all the time, we know that we are doing the right and just thing, in a good and proper way, without harming anyone around us.
But, besides this, the ethical professional is more valued by companies precisely because this means, in practice, greater productivity, focus, and sense of collaboration.
It is important to emphasize here that a collaborative environment is built on mutual respect, trust, and friendly relationships. Not coincidentally, these are basic attitudes of those who work ethically.
The companies that act with professional ethics towards their employees stand out in the labor market and guarantee a harmonious corporate environment, full of engaged professionals with a better quality of life.
What are the characteristics of an ethical professional? A professional who always acts with professional ethics has values and soft skills based on what is good, right, appropriate and fair.
Some characteristics are basic (such as honesty and respect), that is, they should form the character of each person; others, however, are important not only for the professional aspect, but also for the employee's life.
Altruism
An altruistic professional is positively concerned with the interests of others, and jointly seeks a solution for them.
Integrity
A very important value in professional ethics, the integrity of a collaborator shows that he/she has everything to be a trustworthy person, because he/she will always act in the right way, no matter how many pressures to act in the opposite way he/she suffers.
Justice The employee who acts with justice has an easier time dealing with and promoting diversity in his team, not to mention the gains in relation to his leadership position within them.
Commitment
This characteristic of the ethical worker also shows the level of concern he has for his word. In the context of professional ethics, commitment is more than just going to work every day and being accountable for all one's actions, it is also being committed to the company's goals and, why not, to one's own.
Prudence
A prudent professional knows when to take a risk when he calculates the consequences for everyone involved. It also involves being secretive when necessary and careful with communication between colleagues.
Competence
It is part of professional ethics, yes, to act with competence. After all, it is the minimum that the company expects from its hired employee, who has demonstrated in various stages of selection and recruitment his or her ability to do the job.
In summary, professional ethics permeates all the actions of the employee and the company, and should be observed at all times, even more so when one is alone in the workplace.
About Reachr 
Reachr is an HR Tech pioneer in the use of technology in recruitment whose mission is to find the ideal match between your company and your next employee.
Through a complete platform for Recruitment & Selection, we unite the vast knowledge of an elite hunting team to the power of technology through artificial intelligence and machine learning for you to hire more assertively and effectively.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ETHICS (95%); BUSINESS ETHICS (90%); INTERPERSONAL RELATIONSHIPS (73%); DC (%)
Load-Date: September 20, 2022",neutral,0.7109993696212769,balanced/neutral,[],"['character', 'justice', 'justice']","['should', 'must']",['machine learning'],0,3,2,1
2021,Unknown Title,"Body
2022 JUL 07 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Artificial Intelligence and Ethics is the subject of a report. According to news reporting originating from Paris, France, by NewsRx correspondents, research stated, ""We propose a comparative analysis of the AI ethical guidelines endorsed by China (from the Chinese National New Generation Artificial Intelligence Governance Professional Committee) and by the EU (from the European High-level Expert Group on AI). We show that behind an apparent likeness in the concepts mobilized, the two documents largely differ in their normative approaches, which we explain by distinct ambitions resulting from different philosophical traditions, cultural heritages and historical contexts.""
 Our news editors obtained a quote from the research from Ecole Normale Superieure, ""In highlighting such differences, we show that it is erroneous to believe that a similarity in concepts necessarily translates into a similarity in ethics as even the same words may have different meanings from a country to another-as exemplified by that of 'privacy'. It would, therefore, be erroneous to believe that the world would have adopted a common set of ethical principles in only three years.""
 According to the news editors, the research concluded: ""China and the EU, however, share a common scientific method, inherited in the former from the 'Chinese Enlightenment', which could contribute to better collaboration and understanding in the building of technical standards for the implementation of such ethics principles.""
 This research has been peer-reviewed.
 For more information on this research see: Confucius, cyberpunk and Mr. Science: comparing AI ethics principles between China and the EU. AI and Ethics, 2022:1-7.
 The news editors report that additional information may be obtained by contacting Hubert Etienne, Dept. of Philosophy, Ecole Normale Superieure, Paris, France.
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00180-6. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation.
 Keywords for this news article include: Paris, France, Europe, Artificial Intelligence and Ethics, Asia, China.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (96%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EUROPEAN UNION (90%); EXPERIMENTATION & RESEARCH (90%); MACHINE LEARNING (90%); ROBOTICS (90%); SCIENCE & TECHNOLOGY (90%); JOURNALISM (78%); NEWS REPORTING (78%); PHILOSOPHY (78%); CUSTOMS & CULTURAL HERITAGE (74%); Paris;France;Europe;Artificial Intelligence and Ethics;Asia;China (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%)
Geographic: PARIS, FRANCE (93%); CHINA (94%); EUROPEAN UNION MEMBER STATES (92%); FRANCE (90%); EUROPE (88%); ASIA (73%)
Load-Date: July 28, 2022","2022 JUL 07 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Artificial Intelligence and Ethics is the subject of a report. According to news reporting originating from Paris, France, by NewsRx correspondents, research stated, ""We propose a comparative analysis of the AI ethical guidelines endorsed by China (from the Chinese National New Generation Artificial Intelligence Governance Professional Committee) and by the EU (from the European High-level Expert Group on AI). We show that behind an apparent likeness in the concepts mobilized, the two documents largely differ in their normative approaches, which we explain by distinct ambitions resulting from different philosophical traditions, cultural heritages and historical contexts.""
 Our news editors obtained a quote from the research from Ecole Normale Superieure, ""In highlighting such differences, we show that it is erroneous to believe that a similarity in concepts necessarily translates into a similarity in ethics as even the same words may have different meanings from a country to another-as exemplified by that of 'privacy'. It would, therefore, be erroneous to believe that the world would have adopted a common set of ethical principles in only three years.""
 According to the news editors, the research concluded: ""China and the EU, however, share a common scientific method, inherited in the former from the 'Chinese Enlightenment', which could contribute to better collaboration and understanding in the building of technical standards for the implementation of such ethics principles.""
 This research has been peer-reviewed.
 For more information on this research see: Confucius, cyberpunk and Mr. Science: comparing AI ethics principles between China and the EU. AI and Ethics, 2022:1-7.
 The news editors report that additional information may be obtained by contacting Hubert Etienne, Dept. of Philosophy, Ecole Normale Superieure, Paris, France.
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00180-6. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation.
 Keywords for this news article include: Paris, France, Europe, Artificial Intelligence and Ethics, Asia, China.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (96%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); EUROPEAN UNION (90%); EXPERIMENTATION & RESEARCH (90%); MACHINE LEARNING (90%); ROBOTICS (90%); SCIENCE & TECHNOLOGY (90%); JOURNALISM (78%); NEWS REPORTING (78%); PHILOSOPHY (78%); CUSTOMS & CULTURAL HERITAGE (74%); Paris;France;Europe;Artificial Intelligence and Ethics;Asia;China (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (96%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%)
Geographic: PARIS, FRANCE (93%); CHINA (94%); EUROPEAN UNION MEMBER STATES (92%); FRANCE (90%); EUROPE (88%); ASIA (73%)
Load-Date: July 28, 2022",neutral,0.9049149751663208,balanced/neutral,['privacy'],[],"['governance', 'standards', 'guidelines', 'propose']","['machine learning', 'robotics']",1,0,4,2
2021,Unknown Title,"Byline: Dr. Tim Sandle
Body
Jun 27, 2022( Digital Journal: http://www.digitaljournal.com Delivered by Newstex)  
 Artificial intelligence is becoming more commonplace (albeit that the definitions of what constitutes artificial intelligence are in themselves an area for debate). One area of application is in clinical settings. 
For artificial intelligence to progress and to gain societal acceptance, clear ethical standards and guidance need to be developed and agreed, as well as widely understood by researchers and the general populace. This is particularly so in healthcare settings. 
Of greatest applicability in terms of ethics is the necessity to maintain the relationship of trust between doctors and patients. There is also a wider consideration, in relation to safeguarding human rights. 
These important issues are indicated within a Council of Europe report[1], from the Steering Committee for Human Rights in the fields of Biomedicine and Health. The report is authored by Dr Brent Mittelstadt, the Director of Research at the Oxford Internet Institute and a leading data ethicist. 
Examples of where artificial intelligence[2] can be used in the healthcare arena are for direct communication with patients, as a diagnostic tool and as a care agent. 
Central to the ethics debate is the doctor-patient relationship. The report cautions that the suitability of artificial intelligence remains 'unproven' and this could, if implemented poorly or too widely, undermine the 'healing relationship'. 
According to the report: 'A radical reconfiguration of the doctor-patient relationship of the type imagined by some commentators, in which artificial systems diagnose and treat patients directly with minimal interference from human clinicians, continues to seem far in the distance.' 
The main cautionary note from Dr Mittelstadt is[3]: 'The doctor-patient relationship is a keystone of 'good' medical practice, and yet it is seemingly being transformed into a doctor-patient-AI relationship. The challengeis to set robust standards and requirements for this new type of 'healing relationship' to ensure patients' interests and the moral integrity of medicine as a profession are not fundamentally damaged by the introduction of AI.' 
In other words, the relationship between doctor and patient is subject to digital transformation but the patient and their needs remain unaltered. The patient remains as vulnerable as before. A question also arises as to whether the vulnerability becomes worsened through the disruptive nature of the technology. 
The primary bioethics issues[4] that stem from this and which all healthcare systems need to consider carefully are: 
Inequality in access to high quality healthcare.Transparency to health professionals and patients.Risk of social bias in AI systems.Dilution of the patient's account of well-being.Risk of automation bias, de-skilling, and displaced liability.Impact on the right to privacy. 
On stand-out issue for resolution is with the impact of artificial intelligence upon transparency and informed consent. A second is with bias, and how social biases inherent within artificial intelligence are acknowledged. The third area is with data handling and the individual patient's right to privacy. 
https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/share#url=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&title=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversation 
The post AI advances in healthcare urgently need an ethical conversation[5] appeared first on Digital Journal[6]. 
 [ 1]: https://rm.coe.int/inf-2022-5-report-impact-of-ai-on-doctor-patient-relations-e/1680a68859 [ 2]: https://www.coe.int/en/web/bioethics/report-impact-of-ai-on-the-doctor-patient-relationship [ 3]: https://www.oii.ox.ac.uk/news-events/news/ai-standards-essential-to-protect-doctor-patient-relationships-and-human-rights-report/ [ 4]: https://www.coe.int/en/web/bioethics/artificial-intelligence [ 5]: https://www.digitaljournal.com/tech-science/ai-advances-in-healthcare-urgently-need-an-ethical-conversation/article [ 6]: https://www.digitaljournal.com 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: DIJO-0001
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BLOGS & MESSAGE BOARDS (90%); PHYSICIANS & SURGEONS (90%); BIOETHICS (78%); HEALTH CARE PROFESSIONALS (78%); HUMAN RIGHTS (78%); HUMAN SUBJECTS (78%); PATIENT CONSENT (78%); RESEARCH REPORTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PROFESSIONAL WORKERS (74%); BIOMEDICINE (73%); HEALTH CARE ACCESS (73%); HUMAN RIGHTS ORGANIZATIONS (73%); PRIVACY RIGHTS (60%); Tech & Science (%); Artifical intelligence (%); Bioethics (%); Data (%); Healthcare (%); Machine Learning (%)
Company:  AI SYSTEMS (50%)
Organization: PHYSICIANS FOR HUMAN RIGHTS (56%); COUNCIL OF EUROPE (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE (90%); BLOGS & MESSAGE BOARDS (90%); PHYSICIANS & SURGEONS (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (79%); HEALTH CARE PROFESSIONALS (78%); PATIENT CONSENT (78%); BIOMEDICINE (73%); HEALTH CARE ACCESS (73%)
Geographic: EUROPE (72%)
Load-Date: July 20, 2022","Jun 27, 2022( Digital Journal: http://www.digitaljournal.com Delivered by Newstex)  
 Artificial intelligence is becoming more commonplace (albeit that the definitions of what constitutes artificial intelligence are in themselves an area for debate). One area of application is in clinical settings. 
For artificial intelligence to progress and to gain societal acceptance, clear ethical standards and guidance need to be developed and agreed, as well as widely understood by researchers and the general populace. This is particularly so in healthcare settings. 
Of greatest applicability in terms of ethics is the necessity to maintain the relationship of trust between doctors and patients. There is also a wider consideration, in relation to safeguarding human rights. 
These important issues are indicated within a Council of Europe report[1], from the Steering Committee for Human Rights in the fields of Biomedicine and Health. The report is authored by Dr Brent Mittelstadt, the Director of Research at the Oxford Internet Institute and a leading data ethicist. 
Examples of where artificial intelligence[2] can be used in the healthcare arena are for direct communication with patients, as a diagnostic tool and as a care agent. 
Central to the ethics debate is the doctor-patient relationship. The report cautions that the suitability of artificial intelligence remains 'unproven' and this could, if implemented poorly or too widely, undermine the 'healing relationship'. 
According to the report: 'A radical reconfiguration of the doctor-patient relationship of the type imagined by some commentators, in which artificial systems diagnose and treat patients directly with minimal interference from human clinicians, continues to seem far in the distance.' 
The main cautionary note from Dr Mittelstadt is[3]: 'The doctor-patient relationship is a keystone of 'good' medical practice, and yet it is seemingly being transformed into a doctor-patient-AI relationship. The challengeis to set robust standards and requirements for this new type of 'healing relationship' to ensure patients' interests and the moral integrity of medicine as a profession are not fundamentally damaged by the introduction of AI.' 
In other words, the relationship between doctor and patient is subject to digital transformation but the patient and their needs remain unaltered. The patient remains as vulnerable as before. A question also arises as to whether the vulnerability becomes worsened through the disruptive nature of the technology. 
The primary bioethics issues[4] that stem from this and which all healthcare systems need to consider carefully are: 
Inequality in access to high quality healthcare.Transparency to health professionals and patients.Risk of social bias in AI systems.Dilution of the patient's account of well-being.Risk of automation bias, de-skilling, and displaced liability.Impact on the right to privacy. 
On stand-out issue for resolution is with the impact of artificial intelligence upon transparency and informed consent. A second is with bias, and how social biases inherent within artificial intelligence are acknowledged. The third area is with data handling and the individual patient's right to privacy. 
https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&linkname=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversationhttps://www.addtoany.com/share#url=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fai-advances-in-healthcare-urgently-need-an-ethical-conversation%2Farticle&title=AI%20advances%20in%20healthcare%20urgently%20need%20an%20ethical%20conversation 
The post AI advances in healthcare urgently need an ethical conversation[5] appeared first on Digital Journal[6]. 
 [ 1]: https://rm.coe.int/inf-2022-5-report-impact-of-ai-on-doctor-patient-relations-e/1680a68859 [ 2]: https://www.coe.int/en/web/bioethics/report-impact-of-ai-on-the-doctor-patient-relationship [ 3]: https://www.oii.ox.ac.uk/news-events/news/ai-standards-essential-to-protect-doctor-patient-relationships-and-human-rights-report/ [ 4]: https://www.coe.int/en/web/bioethics/artificial-intelligence [ 5]: https://www.digitaljournal.com/tech-science/ai-advances-in-healthcare-urgently-need-an-ethical-conversation/article [ 6]: https://www.digitaljournal.com 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: DIJO-0001
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); BLOGS & MESSAGE BOARDS (90%); PHYSICIANS & SURGEONS (90%); BIOETHICS (78%); HEALTH CARE PROFESSIONALS (78%); HUMAN RIGHTS (78%); HUMAN SUBJECTS (78%); PATIENT CONSENT (78%); RESEARCH REPORTS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PROFESSIONAL WORKERS (74%); BIOMEDICINE (73%); HEALTH CARE ACCESS (73%); HUMAN RIGHTS ORGANIZATIONS (73%); PRIVACY RIGHTS (60%); Tech & Science (%); Artifical intelligence (%); Bioethics (%); Data (%); Healthcare (%); Machine Learning (%)
Company:  AI SYSTEMS (50%)
Organization: PHYSICIANS FOR HUMAN RIGHTS (56%); COUNCIL OF EUROPE (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE (90%); BLOGS & MESSAGE BOARDS (90%); PHYSICIANS & SURGEONS (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (79%); HEALTH CARE PROFESSIONALS (78%); PATIENT CONSENT (78%); BIOMEDICINE (73%); HEALTH CARE ACCESS (73%)
Geographic: EUROPE (72%)
Load-Date: July 20, 2022",neutral,0.8496530055999756,balanced/neutral,"['privacy', 'bias', 'transparency', 'human rights', 'consent', 'access', 'inequality']",[],"['standards', 'should', 'need to']",['machine learning'],7,0,3,1
2021,Unknown Title,"Body
A new national guideline on research ethics and governance will enhance China's oversight of projects in frontier fields, including life sciences, medicine and artificial intelligence, aiming to ensure that scientific and technological progress serves the greater good of humankind, officials and experts said.
 The guideline also demands that international research projects abide by the regulations of the participants' home countries and pass ethical reviews. Chinese authorities can organize experts to reevaluate international projects that have high ethical risks, it said.
 On Sunday, the general offices of the Communist Party of China Central Committee and the State Council, China's Cabinet, issued the country's first comprehensive guideline on enhancing governance over ethics in science and technology.
 Xiang Libin, vice-minister of science and technology, said the current ethic governance system cannot keep up with China's rapid sci-tech growth, given how some of the country's cutting-edge scientific endeavors are exploring unchartered territories with many uncertainties.
 ""Science and technology is a double-edged sword,"" Xiang said. ""Therefore, the guideline plays a key role in building consensus, improving public awareness on the importance of research ethics and governance, and mitigating ethical risks in scientific undertakings.""
 A key requirement of the guideline is that research ethics should be emphasized and upheld throughout the entire process of scientific research and technological development, Xiang said.
 Managing sci-tech ethics in accordance with laws and regulations, swiftly and properly handling emerging ethical challenges, establishing a system of ethical standards based on Chinese characteristics, and enhancing international cooperation in sci-tech governance are also among the top objectives, he added.
 Scientific activities should serve the greater good of humankind, respect human and animal rights, treat social groups from different backgrounds fairly and equally, properly prevent and manage ethical risks, and maintain openness and transparency during research, according to the guideline.
 ""No agency, organization or individual can conduct scientific activities that damage social, public, biological and ecological security, nor can they undermine the safety and well-being of people's lives, health and dignity,"" it said.
 Universities are encouraged to bolster education about research ethics in undergraduate and graduate studies. Chinese authorities should guide universities, research institutions, medical agencies, social groups and companies to optimize their monitoring and early warning mechanisms to spot ethical risks.
 Violators of research ethics will be investigated and punished in accordance with relevant laws and regulations, with measures ranging from revoking research grants and titles to banning offenders from conducting future studies.
 In regard to ethical review of high-risk research, Dai Guoqing, director of the Department of Supervision and Scientific Integrity at the Ministry of Science and Technology, said there will be a multilayered review mechanism in which a proposal is not only required to pass a review by the ethical committee of the researchers' institution, but also several rounds of reviews by local regulatory agencies.
 Feng Chujian, deputy director of the department, said the purpose of enhancing ethical oversight is to nip unethical experiments in the bud, so ""ethical supervision should not be an afterthought, nor should it be a simplified or perfunctory process"".
 Zhai Xiaomei, a member of the National Science and Technology Ethics Committee, said the profound respect for the right to life and personal dignity highlighted in the guideline is in the same spirit that led to the creation of China's first Civil Code, which went into effect in January last year.
 In the medical experiments, the rights of trial participants should be fully protected, including their right to privacy and the right to make informed decisions, Zhai said. ""They should be treated fairly and justly, and not be forced to make a compromise due to their circumstances.""
 Zeng Yi, director of the International Research Center for AI Ethics and Governance at the Institute of Automation of the Chinese Academy of Sciences, said the level of research ethics varies greatly among different scientific disciplines.
 Artificial intelligence is one of the fields that sorely needs a comprehensive ethical review and oversight system, he said. ""There is still a lot of room for improvements in AI ethics, especially those related to personal data and the user's right to know and choose, but this is also a global challenge.""
 A major takeaway from the guideline for Zeng is the requirement for international projects to pass ethical reviews in the participants' home countries. ""This is a big deal because foreign researchers can no longer carry out studies in China that are deemed too ethically risky in their home countries,"" he added.
 The release of the new guideline, along with the country's efforts to improve research ethics and governance in recent years, show that China has begun a systematic building of ethics in scientific activities, which will benefit the country's sci-tech development and open new areas for international cooperation, Zeng said.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (97%); INVESTIGATIONS (89%); CABINET OFFICES (78%); COMMUNISM (78%); CORPORATE GOVERNANCE (78%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); REGULATORY COMPLIANCE (78%); RESEARCH & DEVELOPMENT (78%); RESEARCH INSTITUTES (78%); SAFETY (78%); SCIENCE & TECHNOLOGY (78%); LAW & LEGAL SYSTEM (76%); REGULATORY ACTIONS (76%); GOVERNMENT ADVISORS & MINISTERS (75%); ANIMAL RIGHTS (73%); ANIMALS & SOCIETY (73%); ARTIFICIAL INTELLIGENCE (73%); INTERNATIONAL RELATIONS (72%); GRADUATE & PROFESSIONAL SCHOOLS (60%); POLITICAL PARTIES (55%)
Industry: ARTIFICIAL INTELLIGENCE (73%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Geographic: CHINA (95%)
Load-Date: March 23, 2022","A new national guideline on research ethics and governance will enhance China's oversight of projects in frontier fields, including life sciences, medicine and artificial intelligence, aiming to ensure that scientific and technological progress serves the greater good of humankind, officials and experts said.
 The guideline also demands that international research projects abide by the regulations of the participants' home countries and pass ethical reviews. Chinese authorities can organize experts to reevaluate international projects that have high ethical risks, it said.
 On Sunday, the general offices of the Communist Party of China Central Committee and the State Council, China's Cabinet, issued the country's first comprehensive guideline on enhancing governance over ethics in science and technology.
 Xiang Libin, vice-minister of science and technology, said the current ethic governance system cannot keep up with China's rapid sci-tech growth, given how some of the country's cutting-edge scientific endeavors are exploring unchartered territories with many uncertainties.
 ""Science and technology is a double-edged sword,"" Xiang said. ""Therefore, the guideline plays a key role in building consensus, improving public awareness on the importance of research ethics and governance, and mitigating ethical risks in scientific undertakings.""
 A key requirement of the guideline is that research ethics should be emphasized and upheld throughout the entire process of scientific research and technological development, Xiang said.
 Managing sci-tech ethics in accordance with laws and regulations, swiftly and properly handling emerging ethical challenges, establishing a system of ethical standards based on Chinese characteristics, and enhancing international cooperation in sci-tech governance are also among the top objectives, he added.
 Scientific activities should serve the greater good of humankind, respect human and animal rights, treat social groups from different backgrounds fairly and equally, properly prevent and manage ethical risks, and maintain openness and transparency during research, according to the guideline.
 ""No agency, organization or individual can conduct scientific activities that damage social, public, biological and ecological security, nor can they undermine the safety and well-being of people's lives, health and dignity,"" it said.
 Universities are encouraged to bolster education about research ethics in undergraduate and graduate studies. Chinese authorities should guide universities, research institutions, medical agencies, social groups and companies to optimize their monitoring and early warning mechanisms to spot ethical risks.
 Violators of research ethics will be investigated and punished in accordance with relevant laws and regulations, with measures ranging from revoking research grants and titles to banning offenders from conducting future studies.
 In regard to ethical review of high-risk research, Dai Guoqing, director of the Department of Supervision and Scientific Integrity at the Ministry of Science and Technology, said there will be a multilayered review mechanism in which a proposal is not only required to pass a review by the ethical committee of the researchers' institution, but also several rounds of reviews by local regulatory agencies.
 Feng Chujian, deputy director of the department, said the purpose of enhancing ethical oversight is to nip unethical experiments in the bud, so ""ethical supervision should not be an afterthought, nor should it be a simplified or perfunctory process"".
 Zhai Xiaomei, a member of the National Science and Technology Ethics Committee, said the profound respect for the right to life and personal dignity highlighted in the guideline is in the same spirit that led to the creation of China's first Civil Code, which went into effect in January last year.
 In the medical experiments, the rights of trial participants should be fully protected, including their right to privacy and the right to make informed decisions, Zhai said. ""They should be treated fairly and justly, and not be forced to make a compromise due to their circumstances.""
 Zeng Yi, director of the International Research Center for AI Ethics and Governance at the Institute of Automation of the Chinese Academy of Sciences, said the level of research ethics varies greatly among different scientific disciplines.
 Artificial intelligence is one of the fields that sorely needs a comprehensive ethical review and oversight system, he said. ""There is still a lot of room for improvements in AI ethics, especially those related to personal data and the user's right to know and choose, but this is also a global challenge.""
 A major takeaway from the guideline for Zeng is the requirement for international projects to pass ethical reviews in the participants' home countries. ""This is a big deal because foreign researchers can no longer carry out studies in China that are deemed too ethically risky in their home countries,"" he added.
 The release of the new guideline, along with the country's efforts to improve research ethics and governance in recent years, show that China has begun a systematic building of ethics in scientific activities, which will benefit the country's sci-tech development and open new areas for international cooperation, Zeng said.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (97%); INVESTIGATIONS (89%); CABINET OFFICES (78%); COMMUNISM (78%); CORPORATE GOVERNANCE (78%); ECOLOGY & ENVIRONMENTAL SCIENCE (78%); EXPERIMENTATION & RESEARCH (78%); GOVERNMENT DEPARTMENTS & AUTHORITIES (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); REGULATORY COMPLIANCE (78%); RESEARCH & DEVELOPMENT (78%); RESEARCH INSTITUTES (78%); SAFETY (78%); SCIENCE & TECHNOLOGY (78%); LAW & LEGAL SYSTEM (76%); REGULATORY ACTIONS (76%); GOVERNMENT ADVISORS & MINISTERS (75%); ANIMAL RIGHTS (73%); ANIMALS & SOCIETY (73%); ARTIFICIAL INTELLIGENCE (73%); INTERNATIONAL RELATIONS (72%); GRADUATE & PROFESSIONAL SCHOOLS (60%); POLITICAL PARTIES (55%)
Industry: ARTIFICIAL INTELLIGENCE (73%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Geographic: CHINA (95%)
Load-Date: March 23, 2022",neutral,0.5650160312652588,balanced/neutral,"['privacy', 'transparency', 'safety', 'security', 'agency']",['dignity'],"['governance', 'oversight', 'standards', 'law', 'compliance', 'should']",[],5,1,6,0
2021,Unknown Title,"Body
2022 OCT 06 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Researchers detail new data in artificial intelligence. According to news reporting originating from Fu Jen Catholic University by NewsRx correspondents, research stated, ""Issues related to artificial intelligence (AI) and ethics have gained much traction worldwide. The impact of AI on society has been extensively discussed. This study presents a bibliometric analysis of research results, citation relationships among researchers, and highly referenced journals on AI and ethics on a global scale."" 
 The news correspondents obtained a quote from the research from Fu Jen Catholic University: ""Papers published on AI and ethics were recovered from the Microsoft Academic Graph Collection data set, and the subject terms included 'artificial intelligence' and 'ethics.' With 66 nations' researchers contributing to AI and ethics research, 1585 papers on AI and ethics were recovered, up to 5 July 2021. North America, Western Europe, and East Asia were the regions with the highest productivity. The top ten nations produced about 94.37% of the wide variety of papers. The United States accounted for 47.59% (286 articles) of all papers. Switzerland had the highest research production with a million-person ratio (1.39) when adjusted for populace size. It was followed by the Netherlands (1.26) and the United Kingdom (1.19). The most productive authors were found to be Khatib, O. (n = 10), Verner, I. (n = 9), Bekey, G. A. (n = 7), Gennert, M. A. (n = 7), and Chatila, R., (n = 7)."" 
 According to the news reporters, the research concluded: ""Current research shows that research on artificial intelligence and ethics has evolved dramatically over the past 70 years. Moreover, the United States is more involved with AI and ethics research than developing or emerging countries."" 
 For more information on this research see: A Worldwide Bibliometric Analysis of Publications on Artificial Intelligence and Ethics in the Past Seven Decades. Sustainability, 2022,14(11125):11125. (Sustainability - http://www.mdpi.com/journal/sustainability). The publisher for Sustainability is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/su141811125. 
 Our news editors report that more information may be obtained by contacting Chien-Wei Chuang, Graduate Institute of Business Administration, Fu Jen Catholic University, New Taipei City 242062, Taiwan. Additional authors for this research include Ariana Chang, Mingchih Chen, Maria John P. Selvamani, Ben-Chang Shia. 
 Keywords for this news article include: Fu Jen Catholic University, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INFORMATION SCIENCE (90%); MACHINE LEARNING (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); JOURNALISM (89%); EMERGING TECHNOLOGY (79%); NEWS REPORTING (78%); WRITERS (78%); EMERGING MARKETS (75%); PRODUCTIVITY (74%); BUSINESS EDUCATION (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  MICROSOFT CORP (56%)
Industry: NAICS511210 SOFTWARE PUBLISHERS (56%); SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INDUSTRIAL AUTOMATION (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (78%)
Geographic: TAIPEI, TAIWAN (79%); TAIWAN (91%); UNITED STATES (91%); ASIA (79%); EASTERN ASIA (79%); EUROPE (79%); NORTH AMERICA (79%); WESTERN EUROPE (79%); UNITED KINGDOM (75%); NETHERLANDS (70%)
Load-Date: October 6, 2022","2022 OCT 06 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Researchers detail new data in artificial intelligence. According to news reporting originating from Fu Jen Catholic University by NewsRx correspondents, research stated, ""Issues related to artificial intelligence (AI) and ethics have gained much traction worldwide. The impact of AI on society has been extensively discussed. This study presents a bibliometric analysis of research results, citation relationships among researchers, and highly referenced journals on AI and ethics on a global scale."" 
 The news correspondents obtained a quote from the research from Fu Jen Catholic University: ""Papers published on AI and ethics were recovered from the Microsoft Academic Graph Collection data set, and the subject terms included 'artificial intelligence' and 'ethics.' With 66 nations' researchers contributing to AI and ethics research, 1585 papers on AI and ethics were recovered, up to 5 July 2021. North America, Western Europe, and East Asia were the regions with the highest productivity. The top ten nations produced about 94.37% of the wide variety of papers. The United States accounted for 47.59% (286 articles) of all papers. Switzerland had the highest research production with a million-person ratio (1.39) when adjusted for populace size. It was followed by the Netherlands (1.26) and the United Kingdom (1.19). The most productive authors were found to be Khatib, O. (n = 10), Verner, I. (n = 9), Bekey, G. A. (n = 7), Gennert, M. A. (n = 7), and Chatila, R., (n = 7)."" 
 According to the news reporters, the research concluded: ""Current research shows that research on artificial intelligence and ethics has evolved dramatically over the past 70 years. Moreover, the United States is more involved with AI and ethics research than developing or emerging countries."" 
 For more information on this research see: A Worldwide Bibliometric Analysis of Publications on Artificial Intelligence and Ethics in the Past Seven Decades. Sustainability, 2022,14(11125):11125. (Sustainability - http://www.mdpi.com/journal/sustainability). The publisher for Sustainability is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/su141811125. 
 Our news editors report that more information may be obtained by contacting Chien-Wei Chuang, Graduate Institute of Business Administration, Fu Jen Catholic University, New Taipei City 242062, Taiwan. Additional authors for this research include Ariana Chang, Mingchih Chen, Maria John P. Selvamani, Ben-Chang Shia. 
 Keywords for this news article include: Fu Jen Catholic University, Artificial Intelligence, Emerging Technologies, Machine Learning. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INFORMATION SCIENCE (90%); MACHINE LEARNING (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); JOURNALISM (89%); EMERGING TECHNOLOGY (79%); NEWS REPORTING (78%); WRITERS (78%); EMERGING MARKETS (75%); PRODUCTIVITY (74%); BUSINESS EDUCATION (72%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  MICROSOFT CORP (56%)
Industry: NAICS511210 SOFTWARE PUBLISHERS (56%); SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INDUSTRIAL AUTOMATION (90%); MACHINE LEARNING (90%); ROBOTICS (90%); NEWS REPORTING (78%); PUBLISHING (78%); WRITERS (78%)
Geographic: TAIPEI, TAIWAN (79%); TAIWAN (91%); UNITED STATES (91%); ASIA (79%); EASTERN ASIA (79%); EUROPE (79%); NORTH AMERICA (79%); WESTERN EUROPE (79%); UNITED KINGDOM (75%); NETHERLANDS (70%)
Load-Date: October 6, 2022",neutral,0.8661084175109863,balanced/neutral,[],[],[],"['machine learning', 'robotics']",0,0,0,2
2021,Unknown Title,"Byline: ANI
Body
Beijing [China], March 20 (ANI/Xinhua): China has released a set of guidelines to strengthen the governance over ethics in science and technology, given the rapid progress of the country's sci-tech innovation and the growing challenges facing ethics in the field.
Ethics compliance should be emphasized throughout the process of scientific research and technological development, according to the guidelines, which were issued by the General Office of the Communist Party of China Central Committee and the General Office of the State Council.
The governance should be based on laws and regulations, and should suit the conditions of the country, the document said. Opening-up and cooperation were also emphasized.
The document clarified the ethical principles in science and technology, saying that scientific activities should serve the well-being of humanity, respect people's right to life, adhere to fairness and justice, control risks in an appropriate way, and maintain openness and transparency.
It urged efforts to make and improve regulations and standards for ethics in key areas such as the life sciences, medicine and artificial intelligence, improve the rules and processes of ethical review, risk management and the handling of violations, and boost theoretical research in ethics.
Ethical review and regulations should be strengthened, the guidelines said. A contingency mechanism should also be prepared for public health emergencies.
Authorities should push colleges and universities, scientific research institutions, medical institutions, social groups and enterprises to improve the monitoring and early warning mechanism for ethical risks, and follow up development in emerging sci-tech fields. (ANI/Xinhua)
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 239
Subject: ETHICS (93%); EXPERIMENTATION & RESEARCH (90%); RISK MANAGEMENT (88%); COMMUNISM (78%); SCIENCE & TECHNOLOGY (78%); RESEARCH INSTITUTES (76%); HEALTH CARE REGULATION & POLICY (75%); LAW & LEGAL SYSTEM (75%); PUBLIC HEALTH (74%); PUBLIC HEALTH ADMINISTRATION (72%); POLITICAL PARTIES (56%); ARTIFICIAL INTELLIGENCE (52%)
Industry: RISK MANAGEMENT (88%); HEALTH CARE REGULATION & POLICY (75%); EDUCATIONAL SERVICES (73%); ARTIFICIAL INTELLIGENCE (52%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (59%); CHINA (94%)
Load-Date: March 20, 2022","Beijing [China], March 20 (ANI/Xinhua): China has released a set of guidelines to strengthen the governance over ethics in science and technology, given the rapid progress of the country's sci-tech innovation and the growing challenges facing ethics in the field.
Ethics compliance should be emphasized throughout the process of scientific research and technological development, according to the guidelines, which were issued by the General Office of the Communist Party of China Central Committee and the General Office of the State Council.
The governance should be based on laws and regulations, and should suit the conditions of the country, the document said. Opening-up and cooperation were also emphasized.
The document clarified the ethical principles in science and technology, saying that scientific activities should serve the well-being of humanity, respect people's right to life, adhere to fairness and justice, control risks in an appropriate way, and maintain openness and transparency.
It urged efforts to make and improve regulations and standards for ethics in key areas such as the life sciences, medicine and artificial intelligence, improve the rules and processes of ethical review, risk management and the handling of violations, and boost theoretical research in ethics.
Ethical review and regulations should be strengthened, the guidelines said. A contingency mechanism should also be prepared for public health emergencies.
Authorities should push colleges and universities, scientific research institutions, medical institutions, social groups and enterprises to improve the monitoring and early warning mechanism for ethical risks, and follow up development in emerging sci-tech fields. (ANI/Xinhua)
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 239
Subject: ETHICS (93%); EXPERIMENTATION & RESEARCH (90%); RISK MANAGEMENT (88%); COMMUNISM (78%); SCIENCE & TECHNOLOGY (78%); RESEARCH INSTITUTES (76%); HEALTH CARE REGULATION & POLICY (75%); LAW & LEGAL SYSTEM (75%); PUBLIC HEALTH (74%); PUBLIC HEALTH ADMINISTRATION (72%); POLITICAL PARTIES (56%); ARTIFICIAL INTELLIGENCE (52%)
Industry: RISK MANAGEMENT (88%); HEALTH CARE REGULATION & POLICY (75%); EDUCATIONAL SERVICES (73%); ARTIFICIAL INTELLIGENCE (52%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (59%); CHINA (94%)
Load-Date: March 20, 2022",neutral,0.5815144181251526,balanced/neutral,"['fairness', 'transparency']","['justice', 'fairness', 'justice']","['regulation', 'policy', 'governance', 'standards', 'guidelines', 'law', 'compliance', 'should']",[],2,3,8,0
2021,Unknown Title,"Byline: Bamidele Ogunwusi
Body
The Chief Executive Officer, ID Africa, Femi Falodun has called on professionals to study new trends and critically interrogate how emerging technologies like AI, cryptocurrencies, Web3, metaverse and others can enhance or mar the human experience.
He stated this in his submission to the PRCA Ethics Council's 2022 Annual Perspective report unveiled on Tuesday.
The report which is published annually by the world's largest professional PR body, the Public Relations and Communications Association (PRCA) features insights from 30 global leaders and explores the ethical challenges when engaging in the Metaverse, NFTs, Artificial Intelligence (AI), and other new technology.
Speaking on the report, PRCA Global Ethics Council Co-Chair Mary Beth West MPRCA said: ""The PRCA Ethics Council urges the whole of the PR industry - at every level of experience and practice - to embrace new areas of learning, awareness, and strategic consideration tied to the ethics of AI and how digital technology might be engaged in ways that potentially risk stakeholder trust and brand reputation"".
""This year's PRCA Ethics Council Annual Perspective provides PR professionals with the tools to push their clients to be ethical and use every touchpoint as an opportunity to tell human stories that truly make an impact and build a deeper connection with the people the industry serves,"" PRCA Global Ethics Council Co-Chair Nitin Mantri added.
On his contribution, Femi stated that ""PR practitioners who work in and around the web3 ecosystem must pay close attention to ethical issues in web3, in order to properly guide their stakeholders. As long as PR practitioners stay adequately informed on the tech, and remain people-centric, they will emerge as trusted partners for governments, web3 builders and society of users, helping them to find and communicate the best ways that these technologies can enrich the human experience.""
He added that many of the concerns about web3-related technologies are the ambiguity about what is right or wrong.
""A key concern with web3 is sustainability. According to Digiconomist, Bitcoin mining generates up to 96 million tons of CO2 emissions yearly, while Ethereum mining produces 47 million tons. The Bitcoin network also produces 30,000 tons of electronic waste per year. Although proponents are introducing new methods that are less energy-intensive, it is expected that crypto's carbon footprint will continue to increase as adoption grows.
""The biggest ethical concerns with AI include racial bias from robots, inequality in the distribution of wealth created by robots, cybersecurity risks, robot rights, unemployment due to loss of jobs to machines, and the Singularity, fear that someday, humanity will lose control to complex intelligent systems,"" he added.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1803
Subject: ETHICS (94%); EXECUTIVES (90%); TECHNOLOGY TRENDS (90%); TRENDS (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTOCURRENCY (89%); DIGITAL CURRENCY (89%); EMERGING TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ANNUAL FINANCIAL RESULTS (76%); SUSTAINABLE DEVELOPMENT (73%); ENVIRONMENTAL FOOTPRINT (70%); EMISSIONS (65%); ECONOMIC INEQUALITY (64%); GREENHOUSE GASES (60%); LAYOFFS (60%); LAYOFFS & DISMISSALS (60%); NEGATIVE EMPLOYMENT NEWS (60%); BRANDING (52%)
Industry: PUBLIC RELATIONS (91%); METAVERSE (90%); WEB3 (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTO ASSETS (89%); CRYPTOCURRENCY (89%); DIGITAL CURRENCY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (73%); EMISSIONS (65%); BRANDING (52%)
Geographic: NIGERIA (92%); AFRICA (88%)
Load-Date: May 6, 2022","The Chief Executive Officer, ID Africa, Femi Falodun has called on professionals to study new trends and critically interrogate how emerging technologies like AI, cryptocurrencies, Web3, metaverse and others can enhance or mar the human experience.
He stated this in his submission to the PRCA Ethics Council's 2022 Annual Perspective report unveiled on Tuesday.
The report which is published annually by the world's largest professional PR body, the Public Relations and Communications Association (PRCA) features insights from 30 global leaders and explores the ethical challenges when engaging in the Metaverse, NFTs, Artificial Intelligence (AI), and other new technology.
Speaking on the report, PRCA Global Ethics Council Co-Chair Mary Beth West MPRCA said: ""The PRCA Ethics Council urges the whole of the PR industry - at every level of experience and practice - to embrace new areas of learning, awareness, and strategic consideration tied to the ethics of AI and how digital technology might be engaged in ways that potentially risk stakeholder trust and brand reputation"".
""This year's PRCA Ethics Council Annual Perspective provides PR professionals with the tools to push their clients to be ethical and use every touchpoint as an opportunity to tell human stories that truly make an impact and build a deeper connection with the people the industry serves,"" PRCA Global Ethics Council Co-Chair Nitin Mantri added.
On his contribution, Femi stated that ""PR practitioners who work in and around the web3 ecosystem must pay close attention to ethical issues in web3, in order to properly guide their stakeholders. As long as PR practitioners stay adequately informed on the tech, and remain people-centric, they will emerge as trusted partners for governments, web3 builders and society of users, helping them to find and communicate the best ways that these technologies can enrich the human experience.""
He added that many of the concerns about web3-related technologies are the ambiguity about what is right or wrong.
""A key concern with web3 is sustainability. According to Digiconomist, Bitcoin mining generates up to 96 million tons of CO2 emissions yearly, while Ethereum mining produces 47 million tons. The Bitcoin network also produces 30,000 tons of electronic waste per year. Although proponents are introducing new methods that are less energy-intensive, it is expected that crypto's carbon footprint will continue to increase as adoption grows.
""The biggest ethical concerns with AI include racial bias from robots, inequality in the distribution of wealth created by robots, cybersecurity risks, robot rights, unemployment due to loss of jobs to machines, and the Singularity, fear that someday, humanity will lose control to complex intelligent systems,"" he added.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1803
Subject: ETHICS (94%); EXECUTIVES (90%); TECHNOLOGY TRENDS (90%); TRENDS (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTOCURRENCY (89%); DIGITAL CURRENCY (89%); EMERGING TECHNOLOGY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); ANNUAL FINANCIAL RESULTS (76%); SUSTAINABLE DEVELOPMENT (73%); ENVIRONMENTAL FOOTPRINT (70%); EMISSIONS (65%); ECONOMIC INEQUALITY (64%); GREENHOUSE GASES (60%); LAYOFFS (60%); LAYOFFS & DISMISSALS (60%); NEGATIVE EMPLOYMENT NEWS (60%); BRANDING (52%)
Industry: PUBLIC RELATIONS (91%); METAVERSE (90%); WEB3 (90%); ARTIFICIAL INTELLIGENCE (89%); CRYPTO ASSETS (89%); CRYPTOCURRENCY (89%); DIGITAL CURRENCY (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SUSTAINABLE DEVELOPMENT (73%); EMISSIONS (65%); BRANDING (52%)
Geographic: NIGERIA (92%); AFRICA (88%)
Load-Date: May 6, 2022",neutral,0.8376626968383789,balanced/neutral,"['bias', 'unemployment', 'inequality']",[],"['must', 'urges']",['robot'],3,0,2,1
2021,Unknown Title,"Byline: DQINDIA Online
Body
79% of CEOs surveyed are prepared to implement AI ethics practices but less than a quarter of organizations have acted on it.
A new IBM Institute for Business Value study revealed a radical shift in the roles responsible for leading and upholding AI ethics at an organization. When asked which function is primarily accountable for AI ethics, 80% of respondents pointed to a non-technical executive, such as a CEO, as the primary ""champion"" for AI ethics, a sharp uptick from 15% in 2018.
The global study* also indicates that despite a strong imperative for advancing trustworthy AI, including better performance compared to peers in sustainability, social responsibility, and diversity and inclusion, there remains a gap between leaders' intention and meaningful actions. The study found:
Business executives are now seen as the driving force in AI ethics
* CEOs (28%) - but also Board members (10%), General Counsels (10%), Privacy Officers (8%), and Risk & Compliance Officers (6%) are viewed as being most accountable for AI ethics by those surveyed.
* While 66% of respondents cite the CEO or other C-level executive as having a strong influence on their organization's ethics strategy, more than half cite board directives (58%) and the shareholder community (53%).
Building Trustworthy AI is perceived as a strategic differentiator and organizations are beginning to implement AI ethics mechanisms.
* More than three-quarters of business leaders surveyed this year agree AI ethics is important to their organizations, up from about 50% in 2018.
* At the same time, 75% of respondents believe ethics is a source of competitive differentiation, and more than 67% of respondents that view AI and AI ethics as important indicate their organizations outperform their peers in sustainability, social responsibility, and diversity and inclusion.
* Many companies have started making strides. In fact, more than half of respondents say their organizations have taken steps to embed AI ethics into their existing approach to business ethics.
* More than 45% of respondents say their organizations have created AI-specific ethics mechanisms, such as an AI project risk assessment framework and auditing/review process.
Ensuring ethical principles are embedded in AI solutions is an urgent need for organizations, but progress is still too slow
* More surveyed CEOs (79%) are now prepared to embed AI ethics into their AI practices - up from 20% in 2018 - and more than half of responding organizations have publicly endorsed common principles of AI ethics.
* Yet, less than a quarter of responding organizations have operationalized AI ethics, and fewer than 20% of respondents strongly agreed that their organization's practices and actions match (or exceed) their stated principles and values.
* 68% of surveyed organizations acknowledge that having a diverse and inclusive workplace is important to mitigating bias in AI, but findings indicate that AI teams are still substantially less diverse than their organizations' workforces: 5.5 times less inclusive of women, 4 times less inclusive of LGBT+ individuals and 1.7 times less racially inclusive.
""As many companies today use AI algorithms across their business, they potentially face increasing internal and external demands to design these algorithms to be fair, secured and trustworthy; yet, there has been little progress across the industry in embedding AI ethics into their practices,"" said Jesus Mantas, Global Managing Partner, IBM Consulting. ""Our IBV study findings demonstrate that building trustworthy AI is a business imperative and a societal expectation, not just a compliance issue. As such, companies can implement a governance model and embed ethical principles across the full AI life cycle.""
The time for companies to act is now. The study data suggests that those organizations who implement a broad AI ethics strategy interwoven throughout business units may have a competitive advantage moving forward. The study provides recommended actions for business leaders including:
* Take a cross-functional, collaborative approach - ethical AI requires a holistic approach, and a holistic set of skills across all stakeholders involved in the AI ethics process. C-Suite executives, designers, behavioral scientists, data scientists, and AI engineers each have a distinct role to play in the trustworthy AI journey.
* Establish both organizational and AI lifecycle governance to operationalize the discipline of AI ethics - take a holistic approach to incentivizing, managing and governing AI solutions across the full AI lifecycle, from establishing the right culture to nurture AI responsibly, to practices and policies to products.
* Reach beyond your organization for partnership - expand your approach by identifying and engaging key AI-focused technology partners, academics, startups, and other ecosystem partners to establish ""ethical interoperability.""
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EXECUTIVES (92%); ASSOCIATIONS & ORGANIZATIONS (91%); ETHICS (90%); POLLS & SURVEYS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); DIVERSITY & INCLUSION (88%); ARTIFICIAL INTELLIGENCE (78%); BUSINESS ETHICS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BOARDS OF DIRECTORS (76%); WORKPLACE DIVERSITY & INCLUSION (74%); REGULATORY COMPLIANCE (73%); RESEARCH REPORTS (73%); RISK MANAGEMENT (70%); LAWYERS (53%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (78%); RISK MANAGEMENT (70%); LAWYERS (53%)
Load-Date: April 14, 2022","79% of CEOs surveyed are prepared to implement AI ethics practices but less than a quarter of organizations have acted on it.
A new IBM Institute for Business Value study revealed a radical shift in the roles responsible for leading and upholding AI ethics at an organization. When asked which function is primarily accountable for AI ethics, 80% of respondents pointed to a non-technical executive, such as a CEO, as the primary ""champion"" for AI ethics, a sharp uptick from 15% in 2018.
The global study* also indicates that despite a strong imperative for advancing trustworthy AI, including better performance compared to peers in sustainability, social responsibility, and diversity and inclusion, there remains a gap between leaders' intention and meaningful actions. The study found:
Business executives are now seen as the driving force in AI ethics
* CEOs (28%) - but also Board members (10%), General Counsels (10%), Privacy Officers (8%), and Risk & Compliance Officers (6%) are viewed as being most accountable for AI ethics by those surveyed.
* While 66% of respondents cite the CEO or other C-level executive as having a strong influence on their organization's ethics strategy, more than half cite board directives (58%) and the shareholder community (53%).
Building Trustworthy AI is perceived as a strategic differentiator and organizations are beginning to implement AI ethics mechanisms.
* More than three-quarters of business leaders surveyed this year agree AI ethics is important to their organizations, up from about 50% in 2018.
* At the same time, 75% of respondents believe ethics is a source of competitive differentiation, and more than 67% of respondents that view AI and AI ethics as important indicate their organizations outperform their peers in sustainability, social responsibility, and diversity and inclusion.
* Many companies have started making strides. In fact, more than half of respondents say their organizations have taken steps to embed AI ethics into their existing approach to business ethics.
* More than 45% of respondents say their organizations have created AI-specific ethics mechanisms, such as an AI project risk assessment framework and auditing/review process.
Ensuring ethical principles are embedded in AI solutions is an urgent need for organizations, but progress is still too slow
* More surveyed CEOs (79%) are now prepared to embed AI ethics into their AI practices - up from 20% in 2018 - and more than half of responding organizations have publicly endorsed common principles of AI ethics.
* Yet, less than a quarter of responding organizations have operationalized AI ethics, and fewer than 20% of respondents strongly agreed that their organization's practices and actions match (or exceed) their stated principles and values.
* 68% of surveyed organizations acknowledge that having a diverse and inclusive workplace is important to mitigating bias in AI, but findings indicate that AI teams are still substantially less diverse than their organizations' workforces: 5.5 times less inclusive of women, 4 times less inclusive of LGBT+ individuals and 1.7 times less racially inclusive.
""As many companies today use AI algorithms across their business, they potentially face increasing internal and external demands to design these algorithms to be fair, secured and trustworthy; yet, there has been little progress across the industry in embedding AI ethics into their practices,"" said Jesus Mantas, Global Managing Partner, IBM Consulting. ""Our IBV study findings demonstrate that building trustworthy AI is a business imperative and a societal expectation, not just a compliance issue. As such, companies can implement a governance model and embed ethical principles across the full AI life cycle.""
The time for companies to act is now. The study data suggests that those organizations who implement a broad AI ethics strategy interwoven throughout business units may have a competitive advantage moving forward. The study provides recommended actions for business leaders including:
* Take a cross-functional, collaborative approach - ethical AI requires a holistic approach, and a holistic set of skills across all stakeholders involved in the AI ethics process. C-Suite executives, designers, behavioral scientists, data scientists, and AI engineers each have a distinct role to play in the trustworthy AI journey.
* Establish both organizational and AI lifecycle governance to operationalize the discipline of AI ethics - take a holistic approach to incentivizing, managing and governing AI solutions across the full AI lifecycle, from establishing the right culture to nurture AI responsibly, to practices and policies to products.
* Reach beyond your organization for partnership - expand your approach by identifying and engaging key AI-focused technology partners, academics, startups, and other ecosystem partners to establish ""ethical interoperability.""
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EXECUTIVES (92%); ASSOCIATIONS & ORGANIZATIONS (91%); ETHICS (90%); POLLS & SURVEYS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); DIVERSITY & INCLUSION (88%); ARTIFICIAL INTELLIGENCE (78%); BUSINESS ETHICS (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); BOARDS OF DIRECTORS (76%); WORKPLACE DIVERSITY & INCLUSION (74%); REGULATORY COMPLIANCE (73%); RESEARCH REPORTS (73%); RISK MANAGEMENT (70%); LAWYERS (53%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (78%); RISK MANAGEMENT (70%); LAWYERS (53%)
Load-Date: April 14, 2022",neutral,0.6871373653411865,balanced/neutral,"['privacy', 'bias']",[],"['governance', 'framework', 'compliance']",[],2,0,3,0
2021,Unknown Title,"Body
2022 DEC 06 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- Data detailed on Technology have been presented. According to news reporting originating from Vienna, Austria, by NewsRx correspondents, research stated, ""Recent years have yielded many discussions on how to endow autonomous agents with the ability to make ethical decisions, and the need for explicit ethical reasoning and transparency is a persistent theme in this literature. We present a modular and transparent approach to equip autonomous agents with the ability to comply with ethical prescriptions, while still enacting pre-learned optimal behaviour."" 
 Funders for this research include WWTF project, DC-RES. 
 Our news editors obtained a quote from the research from Technical University Wien (TU Wien), ""Our approach relies on a normative supervisor module, that integrates a theorem prover for defeasible deontic logic within the control loop of a reinforcement learning agent. The supervisor operates as both an event recorder and an on-the-fly compliance checker w.r.t. an external norm base."" 
 According to the news editors, the research concluded: ""We successfully evaluated our approach with several tests using variations of the game Pac-Man, subject to a variety of 'ethical' constraints."" 
 This research has been peer-reviewed. 
 For more information on this research see: Enforcing Ethical Goals Over Reinforcement-learning Policies. Ethics and Information Technology, 2022;24(4). Ethics and Information Technology can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Ethics and Information Technology - www.springerlink.com/content/1388-1957/) 
 The news editors report that additional information may be obtained by contacting Emery A. Neufeld, Technical University Wien (TU Wien), Vienna, Austria. Additional authors for this research include Ezio Bartocci, Agata Ciabattoni and Guido Governatori. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s10676-022-09665-8. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Vienna, Austria, Europe, Technology, Emerging Technologies, Machine Learning, Reinforcement Learning, Technical University Wien (TU Wien). 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); MACHINE LEARNING (89%); EMERGING TECHNOLOGY (74%); ARTIFICIAL INTELLIGENCE (73%); WRITERS (73%); Vienna;Austria;Europe;Technology;Emerging Technologies;Machine Learning;Reinforcement Learning (%)
Industry: COLLEGES & UNIVERSITIES (90%); NEWS REPORTING (90%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE (73%); WRITERS (73%)
Geographic: VIENNA, AUSTRIA (90%); EUROPE (73%); NETHERLANDS (58%)
Load-Date: December 6, 2022","2022 DEC 06 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- Data detailed on Technology have been presented. According to news reporting originating from Vienna, Austria, by NewsRx correspondents, research stated, ""Recent years have yielded many discussions on how to endow autonomous agents with the ability to make ethical decisions, and the need for explicit ethical reasoning and transparency is a persistent theme in this literature. We present a modular and transparent approach to equip autonomous agents with the ability to comply with ethical prescriptions, while still enacting pre-learned optimal behaviour."" 
 Funders for this research include WWTF project, DC-RES. 
 Our news editors obtained a quote from the research from Technical University Wien (TU Wien), ""Our approach relies on a normative supervisor module, that integrates a theorem prover for defeasible deontic logic within the control loop of a reinforcement learning agent. The supervisor operates as both an event recorder and an on-the-fly compliance checker w.r.t. an external norm base."" 
 According to the news editors, the research concluded: ""We successfully evaluated our approach with several tests using variations of the game Pac-Man, subject to a variety of 'ethical' constraints."" 
 This research has been peer-reviewed. 
 For more information on this research see: Enforcing Ethical Goals Over Reinforcement-learning Policies. Ethics and Information Technology, 2022;24(4). Ethics and Information Technology can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Ethics and Information Technology - www.springerlink.com/content/1388-1957/) 
 The news editors report that additional information may be obtained by contacting Emery A. Neufeld, Technical University Wien (TU Wien), Vienna, Austria. Additional authors for this research include Ezio Bartocci, Agata Ciabattoni and Guido Governatori. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s10676-022-09665-8. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Vienna, Austria, Europe, Technology, Emerging Technologies, Machine Learning, Reinforcement Learning, Technical University Wien (TU Wien). 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (95%); COLLEGES & UNIVERSITIES (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); MACHINE LEARNING (89%); EMERGING TECHNOLOGY (74%); ARTIFICIAL INTELLIGENCE (73%); WRITERS (73%); Vienna;Austria;Europe;Technology;Emerging Technologies;Machine Learning;Reinforcement Learning (%)
Industry: COLLEGES & UNIVERSITIES (90%); NEWS REPORTING (90%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE (73%); WRITERS (73%)
Geographic: VIENNA, AUSTRIA (90%); EUROPE (73%); NETHERLANDS (58%)
Load-Date: December 6, 2022",neutral,0.9058907628059387,balanced/neutral,['transparency'],[],['compliance'],"['machine learning', 'reinforcement learning']",1,0,1,2
2021,Unknown Title,"Body
2022 AUG 22 (NewsRx) -- By a News Reporter-Staff News Editor at Health & Medicine Daily -- A new study on human factors and ergonomics is now available. According to news originating from Clemson, South Carolina, by NewsRx correspondents, research stated, ""Determining the efficacy of two trust repair strategies (apology and denial) for trust violations of an ethical nature by an autonomous teammate. While ethics in human-AI interaction is extensively studied, little research has investigated how decisions with ethical implications impact trust and performance within human-AI teams and their subsequent repair."" 
 Financial supporters for this research include Air Force Office of Scientific Research. 
 The news reporters obtained a quote from the research from Clemson University: ""Forty teams of two participants and one autonomous teammate completed three team missions within a synthetic task environment. The autonomous teammate made an ethical or unethical action during each mission, followed by an apology or denial. Measures of individual team trust, autonomous teammate trust, human teammate trust, perceived autonomous teammate ethicality, and team performance were taken. Teams with unethical autonomous teammates had significantly lower trust in the team and trust in the autonomous teammate. Unethical autonomous teammates were also perceived as substantially more unethical. Neither trust repair strategy effectively restored trust after an ethical violation, and autonomous teammate ethicality was not related to the team score, but unethical autonomous teammates did have shorter times."" 
 According to the news editors, the research concluded: ""Ethical violations significantly harm trust in the overall team and autonomous teammate but do not negatively impact team score. However, current trust repair strategies like apologies and denials appear ineffective in restoring trust after this type of violation. Application: This research highlights the need to develop trust repair strategies specific to human-AI teams and trust violations of an ethical nature."" 
 For more information on this research see: Towards Ethical AI: Empirically Investigating Dimensions of AI Ethics, Trust Repair, and Performance in Human-AI Teaming. Human Factors: The Journal of the Human Factors and Ergonomics Society, 2022. The publisher for Human Factors: The Journal of the Human Factors and Ergonomics Society is SAGE Publications. 
 A free version of this journal article is available at https://doi.org/10.1177/00187208221116952. 
 Our news journalists report that more information may be obtained by contacting Beau G. Schelble, Human-Centered Computing, Clemson University, Clemson, SC, United States. Additional authors for this research include Jeremy Lopez, Claire Textor, Rui Zhang, Nathan J. McNeese, Richard Pak, Guo Freeman.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the authors of this research: Beau G. Schelble (orcid.org/0000-0003-3704-697X), Jeremy Lopez (orcid.org/0000-0002-5451-5048). 
 Keywords for this news article include: Clemson University, Clemson, South Carolina, United States, North and Central America, Health and Medicine, Human Factors and Ergonomics. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); HUMAN FACTORS ENGINEERING (91%); ATHLETES (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); MEDICINE & HEALTH (90%); JOURNALISM (89%); RESEARCH REPORTS (89%); WRITERS (89%); AIR FORCES (73%); SCIENCE & TECHNOLOGY (73%); DEFENSE RESEARCH (72%); COLLEGES & UNIVERSITIES (70%); Health and Medicine;Human Factors and Ergonomics (%)
Organization: CLEMSON UNIVERSITY (91%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); HUMAN FACTORS ENGINEERING (91%); WRITERS (89%); AIR FORCES (73%); DEFENSE RESEARCH (72%); COLLEGES & UNIVERSITIES (70%)
Geographic: SOUTH CAROLINA, USA (90%)
Load-Date: August 22, 2022","2022 AUG 22 (NewsRx) -- By a News Reporter-Staff News Editor at Health & Medicine Daily -- A new study on human factors and ergonomics is now available. According to news originating from Clemson, South Carolina, by NewsRx correspondents, research stated, ""Determining the efficacy of two trust repair strategies (apology and denial) for trust violations of an ethical nature by an autonomous teammate. While ethics in human-AI interaction is extensively studied, little research has investigated how decisions with ethical implications impact trust and performance within human-AI teams and their subsequent repair."" 
 Financial supporters for this research include Air Force Office of Scientific Research. 
 The news reporters obtained a quote from the research from Clemson University: ""Forty teams of two participants and one autonomous teammate completed three team missions within a synthetic task environment. The autonomous teammate made an ethical or unethical action during each mission, followed by an apology or denial. Measures of individual team trust, autonomous teammate trust, human teammate trust, perceived autonomous teammate ethicality, and team performance were taken. Teams with unethical autonomous teammates had significantly lower trust in the team and trust in the autonomous teammate. Unethical autonomous teammates were also perceived as substantially more unethical. Neither trust repair strategy effectively restored trust after an ethical violation, and autonomous teammate ethicality was not related to the team score, but unethical autonomous teammates did have shorter times."" 
 According to the news editors, the research concluded: ""Ethical violations significantly harm trust in the overall team and autonomous teammate but do not negatively impact team score. However, current trust repair strategies like apologies and denials appear ineffective in restoring trust after this type of violation. Application: This research highlights the need to develop trust repair strategies specific to human-AI teams and trust violations of an ethical nature."" 
 For more information on this research see: Towards Ethical AI: Empirically Investigating Dimensions of AI Ethics, Trust Repair, and Performance in Human-AI Teaming. Human Factors: The Journal of the Human Factors and Ergonomics Society, 2022. The publisher for Human Factors: The Journal of the Human Factors and Ergonomics Society is SAGE Publications. 
 A free version of this journal article is available at https://doi.org/10.1177/00187208221116952. 
 Our news journalists report that more information may be obtained by contacting Beau G. Schelble, Human-Centered Computing, Clemson University, Clemson, SC, United States. Additional authors for this research include Jeremy Lopez, Claire Textor, Rui Zhang, Nathan J. McNeese, Richard Pak, Guo Freeman.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the authors of this research: Beau G. Schelble (orcid.org/0000-0003-3704-697X), Jeremy Lopez (orcid.org/0000-0002-5451-5048). 
 Keywords for this news article include: Clemson University, Clemson, South Carolina, United States, North and Central America, Health and Medicine, Human Factors and Ergonomics. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); HUMAN FACTORS ENGINEERING (91%); ATHLETES (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); MEDICINE & HEALTH (90%); JOURNALISM (89%); RESEARCH REPORTS (89%); WRITERS (89%); AIR FORCES (73%); SCIENCE & TECHNOLOGY (73%); DEFENSE RESEARCH (72%); COLLEGES & UNIVERSITIES (70%); Health and Medicine;Human Factors and Ergonomics (%)
Organization: CLEMSON UNIVERSITY (91%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); HUMAN FACTORS ENGINEERING (91%); WRITERS (89%); AIR FORCES (73%); DEFENSE RESEARCH (72%); COLLEGES & UNIVERSITIES (70%)
Geographic: SOUTH CAROLINA, USA (90%)
Load-Date: August 22, 2022",neutral,0.9190533757209778,balanced/neutral,[],[],['need to'],[],0,0,1,0
2021,Unknown Title,"Body
2022 OCT 11 (NewsRx) -- By a News Reporter-Staff News Editor at CDC & FDA Daily -- Investigators publish new report on science and technology. According to news originating from the University of California by NewsRx correspondents, research stated, ""The challenges of research in ethics and technology require attentive listening."" 
 The news reporters obtained a quote from the research from University of California: ""Geoffrey Charles Bowker, began to give attention to the theme over twenty years ago. What ensues is a contemporary commentary on the ethics of emerging technologies with extracts from an audio interview (by Zoom) between Elen Nas and Bowker, which took place during the early part of the Covid-19 pandemic."" 
 According to the news editors, the research concluded: ""The main question of this open dialogue is regarding the use of technologies such as AI to ask-what has changed with the problems identified now and in the past in relation to ethical computing? To paraphrase Bowker-it is impossible to think of new technologies that would not change human values then and now."" 
 For more information on this research see: Ethics of Emerging Technologies: An Interview with Geoffrey C. Bowker. Engaging Science, Technology, and Society, 2022,8(2). (Engaging Science, Technology, and Society - http://estsjournal.org). The publisher for Engaging Science, Technology, and Society is Society for Social Studies of Science. 
 A free version of this journal article is available at https://doi.org/10.17351/ests2022.1253. 
 Our news journalists report that more information may be obtained by contacting Elen Nas, University of California - Irvine. 
 Keywords for this news article include: University of California, Science, Science and Technology, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: EMERGING TECHNOLOGY (91%); ETHICS (91%); EXPERIMENTATION & RESEARCH (90%); INFECTIOUS DISEASE (90%); INVESTIGATIONS (90%); JOURNALISM (89%); COVID CORONAVIRUS (74%); EPIDEMICS (74%); HUMANITIES & SOCIAL SCIENCE (74%); PANDEMICS (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); COVID-19 CORONAVIRUS (69%); Science;Science and Technology;Technology (%)
Organization: UNIVERSITY OF CALIFORNIA (93%); FOOD & DRUG ADMINISTRATION (84%)
Industry: PUBLISHING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%)
Geographic: CALIFORNIA, USA (90%)
Load-Date: October 11, 2022","2022 OCT 11 (NewsRx) -- By a News Reporter-Staff News Editor at CDC & FDA Daily -- Investigators publish new report on science and technology. According to news originating from the University of California by NewsRx correspondents, research stated, ""The challenges of research in ethics and technology require attentive listening."" 
 The news reporters obtained a quote from the research from University of California: ""Geoffrey Charles Bowker, began to give attention to the theme over twenty years ago. What ensues is a contemporary commentary on the ethics of emerging technologies with extracts from an audio interview (by Zoom) between Elen Nas and Bowker, which took place during the early part of the Covid-19 pandemic."" 
 According to the news editors, the research concluded: ""The main question of this open dialogue is regarding the use of technologies such as AI to ask-what has changed with the problems identified now and in the past in relation to ethical computing? To paraphrase Bowker-it is impossible to think of new technologies that would not change human values then and now."" 
 For more information on this research see: Ethics of Emerging Technologies: An Interview with Geoffrey C. Bowker. Engaging Science, Technology, and Society, 2022,8(2). (Engaging Science, Technology, and Society - http://estsjournal.org). The publisher for Engaging Science, Technology, and Society is Society for Social Studies of Science. 
 A free version of this journal article is available at https://doi.org/10.17351/ests2022.1253. 
 Our news journalists report that more information may be obtained by contacting Elen Nas, University of California - Irvine. 
 Keywords for this news article include: University of California, Science, Science and Technology, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: EMERGING TECHNOLOGY (91%); ETHICS (91%); EXPERIMENTATION & RESEARCH (90%); INFECTIOUS DISEASE (90%); INVESTIGATIONS (90%); JOURNALISM (89%); COVID CORONAVIRUS (74%); EPIDEMICS (74%); HUMANITIES & SOCIAL SCIENCE (74%); PANDEMICS (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); COVID-19 CORONAVIRUS (69%); Science;Science and Technology;Technology (%)
Organization: UNIVERSITY OF CALIFORNIA (93%); FOOD & DRUG ADMINISTRATION (84%)
Industry: PUBLISHING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%)
Geographic: CALIFORNIA, USA (90%)
Load-Date: October 11, 2022",neutral,0.9341657757759094,balanced/neutral,[],[],[],[],0,0,0,0
2021,Unknown Title,"Body
 14 September 2022 (Saudi Press Agency) Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy and security, humanity, social and environmental benefits, reliability and safety, transparency and explainability, and accountability and responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data and AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit 'We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom's efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (67%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (77%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (97%)
Load-Date: September 15, 2022","14 September 2022 (Saudi Press Agency) Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy and security, humanity, social and environmental benefits, reliability and safety, transparency and explainability, and accountability and responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data and AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit 'We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom's efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
Classification
Language: English US
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (67%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (77%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (97%)
Load-Date: September 15, 2022",positive,0.5965657830238342,balanced/neutral,"['privacy', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'agency']",['fairness'],"['standards', 'guidelines', 'framework']",[],8,1,3,0
2021,Unknown Title,"Byline: Thaddeus Mason Pope, JD, PhD
Body
Sep 01, 2022( Medical Futility Blog: http://www.medicalfutility.blogspot.com Delivered by Newstex)  
 This new 420-pagebioethics handbook[1] offers concise, up-to-date, and easy to read chapters on a broad range of bioethical topics in the following categories: foundational concepts, theory and method, healthcare ethics, research ethics, public health, technology, and the environment.  
Section I: Foundations & Methods in Bioethics 
1. Moral Status - Ezio Di Nucci 
2. Health, Disease and Wellbeing - S Engelsen, S Harnow Klausen & R Christiansen 
3. Bioethical Principles - Nana Cecilie Halmsted Kongsholm 
4. Neurodiversity - Kenneth Shields 
Section II: Decision-making in Healthcare 
5. Substituted Decision-making - Anna-Karin Margareta Andersson 
6. Autonomy and Responsibility - Lisa Dive 
7. Paternalism - Jason Hanna 
8. Conscientious Objection in Health Care - Udo Schuklenk 
Section III: Discrimination in Bioethics 
9. Epistemic Injustice in Healthcare - Ji-Young Lee 
10. Bias in Medicine - Mayli Mertens 
11. Race and Gender in Research - Christopher ChoGlueck & Elisabeth A Lloyd 
Section IV: The Politics of Healthcare 
12. Priority Setting in Health Care - Eric Roark 
13. Health Care Rights - Richard Lauer 
14. Vulnerability - Costanza Porro 
15. Nudging in Public Health - Paul Hamilton 
Section V: Medical Case Studies 
16. Organ Markets - Andreas Albertsen 
17. Physician-Assisted Death - Iain Brassington 
18. Interpretation and Medical Technologies - Jan Kyrre Berg Olsen Friis 
19. Disability - Melinda C Hall 
Section VI: Epidemics and Pandemics 
20. Responsible Pain Medicine - TN Rieder, D Manoharan & VV Altiery De Jesus 
21. Pandemic Ethics - Anne Lykkeskov 
22. Vaccination Ethics - Stephen John 
Section VII: Reproduction 
23. The Ethics of Parenthood - Teresa Baron 
24. Reproductive Technologies for Queer and Trans People - Doris Leibetseder 
25. Population Governance - Karin Kuhlemann 
26. The Ethics of Circumcision - Brian Earp 
Section VIII: Biotechnology and Society 
27. Data Ethics - Aaro Tupasela 
28. AI in Medical Practice - Karin Jongsma & Martin Sand 
29. Performance Enhancing Drugs - Thomas Søbirk Petersen 
30. Medical Instagram in Russia - Yulia Karpova & Pavel Vasilyev 
Section IX: Beyond Bioethics? 
31. Neuroethics - Mary Jean Walker 
32. Nursing Ethics - Ann Gallagher 
33. Climate Change - Trevor Hedberg 
34. The Ethics of Animal Experimentation - Adam Shriver https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghKWjKBeWjyd1qo9AKw58T1I7U4r1sf4b9sSjXdXzi9YikJhAkdcueg3t3CLuBeFNm1TLjFaRSrFBDUg3sK1Z2QlulMPlH1xGTSXsGa0OEOaSJoIoyc5lkS98g_4Oudn9krPXgDL90LUDNHXXSo_Cb5afqZlnx4e0cGfzMdYPuzLHXfY6ZWImDsHwa/s416/9781538162378.jpg 
 [ 1]: https://rowman.com/ISBN/9781538162378/The-Rowman-and-Littlefield-Handbook-of-Bioethics 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: FUTL-7224
Subject: ETHICS (93%); BIOETHICS (92%); PUBLIC HEALTH (91%); BLOGS & MESSAGE BOARDS (90%); PUBLIC HEALTH ADMINISTRATION (90%); DISEASES & DISORDERS (89%); EPIDEMICS (89%); PANDEMICS (89%); MEDICAL TECHNOLOGY (78%); PATIENT RIGHTS (78%); BIOLOGY (76%); DISCRIMINATION (76%); MEDICAL ETHICS (76%); NEURODIVERSITY (75%); NEGATIVE SOCIETAL NEWS (73%); NEUROSCIENCE (73%); TRANSGENDER PERSONS (73%); BIOTECHNOLOGY & GENETIC SCIENCE (72%); VACCINES (72%); ANIMAL EXPERIMENTS (71%); CASE STUDIES (71%); DEATH & DYING (71%); GENDER IDENTITY (67%); REPRODUCTIVE TECHNOLOGY (62%); ASSISTED SUICIDE (53%)
Industry: BLOGS & MESSAGE BOARDS (90%); HEALTH CARE (90%); MEDICAL TECHNOLOGY (78%); PATIENT RIGHTS (78%); PHARMACEUTICALS & BIOTECHNOLOGY (78%); VACCINES (72%)
Geographic: RUSSIAN FEDERATION (52%)
Load-Date: September 1, 2022","Sep 01, 2022( Medical Futility Blog: http://www.medicalfutility.blogspot.com Delivered by Newstex)  
 This new 420-pagebioethics handbook[1] offers concise, up-to-date, and easy to read chapters on a broad range of bioethical topics in the following categories: foundational concepts, theory and method, healthcare ethics, research ethics, public health, technology, and the environment.  
Section I: Foundations & Methods in Bioethics 
1. Moral Status - Ezio Di Nucci 
2. Health, Disease and Wellbeing - S Engelsen, S Harnow Klausen & R Christiansen 
3. Bioethical Principles - Nana Cecilie Halmsted Kongsholm 
4. Neurodiversity - Kenneth Shields 
Section II: Decision-making in Healthcare 
5. Substituted Decision-making - Anna-Karin Margareta Andersson 
6. Autonomy and Responsibility - Lisa Dive 
7. Paternalism - Jason Hanna 
8. Conscientious Objection in Health Care - Udo Schuklenk 
Section III: Discrimination in Bioethics 
9. Epistemic Injustice in Healthcare - Ji-Young Lee 
10. Bias in Medicine - Mayli Mertens 
11. Race and Gender in Research - Christopher ChoGlueck & Elisabeth A Lloyd 
Section IV: The Politics of Healthcare 
12. Priority Setting in Health Care - Eric Roark 
13. Health Care Rights - Richard Lauer 
14. Vulnerability - Costanza Porro 
15. Nudging in Public Health - Paul Hamilton 
Section V: Medical Case Studies 
16. Organ Markets - Andreas Albertsen 
17. Physician-Assisted Death - Iain Brassington 
18. Interpretation and Medical Technologies - Jan Kyrre Berg Olsen Friis 
19. Disability - Melinda C Hall 
Section VI: Epidemics and Pandemics 
20. Responsible Pain Medicine - TN Rieder, D Manoharan & VV Altiery De Jesus 
21. Pandemic Ethics - Anne Lykkeskov 
22. Vaccination Ethics - Stephen John 
Section VII: Reproduction 
23. The Ethics of Parenthood - Teresa Baron 
24. Reproductive Technologies for Queer and Trans People - Doris Leibetseder 
25. Population Governance - Karin Kuhlemann 
26. The Ethics of Circumcision - Brian Earp 
Section VIII: Biotechnology and Society 
27. Data Ethics - Aaro Tupasela 
28. AI in Medical Practice - Karin Jongsma & Martin Sand 
29. Performance Enhancing Drugs - Thomas Søbirk Petersen 
30. Medical Instagram in Russia - Yulia Karpova & Pavel Vasilyev 
Section IX: Beyond Bioethics? 
31. Neuroethics - Mary Jean Walker 
32. Nursing Ethics - Ann Gallagher 
33. Climate Change - Trevor Hedberg 
34. The Ethics of Animal Experimentation - Adam Shriver https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghKWjKBeWjyd1qo9AKw58T1I7U4r1sf4b9sSjXdXzi9YikJhAkdcueg3t3CLuBeFNm1TLjFaRSrFBDUg3sK1Z2QlulMPlH1xGTSXsGa0OEOaSJoIoyc5lkS98g_4Oudn9krPXgDL90LUDNHXXSo_Cb5afqZlnx4e0cGfzMdYPuzLHXfY6ZWImDsHwa/s416/9781538162378.jpg 
 [ 1]: https://rowman.com/ISBN/9781538162378/The-Rowman-and-Littlefield-Handbook-of-Bioethics 
Notes
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: FUTL-7224
Subject: ETHICS (93%); BIOETHICS (92%); PUBLIC HEALTH (91%); BLOGS & MESSAGE BOARDS (90%); PUBLIC HEALTH ADMINISTRATION (90%); DISEASES & DISORDERS (89%); EPIDEMICS (89%); PANDEMICS (89%); MEDICAL TECHNOLOGY (78%); PATIENT RIGHTS (78%); BIOLOGY (76%); DISCRIMINATION (76%); MEDICAL ETHICS (76%); NEURODIVERSITY (75%); NEGATIVE SOCIETAL NEWS (73%); NEUROSCIENCE (73%); TRANSGENDER PERSONS (73%); BIOTECHNOLOGY & GENETIC SCIENCE (72%); VACCINES (72%); ANIMAL EXPERIMENTS (71%); CASE STUDIES (71%); DEATH & DYING (71%); GENDER IDENTITY (67%); REPRODUCTIVE TECHNOLOGY (62%); ASSISTED SUICIDE (53%)
Industry: BLOGS & MESSAGE BOARDS (90%); HEALTH CARE (90%); MEDICAL TECHNOLOGY (78%); PATIENT RIGHTS (78%); PHARMACEUTICALS & BIOTECHNOLOGY (78%); VACCINES (72%)
Geographic: RUSSIAN FEDERATION (52%)
Load-Date: September 1, 2022",neutral,0.7872523665428162,balanced/neutral,"['bias', 'discrimination', 'autonomy']",['autonomy'],"['governance', 'should']",[],3,1,2,0
2021,Unknown Title,"Byline: Targeted News Service
Dateline: EDINBURGH, Scotland 
Body
The International Journal of Artificial Intelligence in Education, a peer-reviewed journal from the International Artificial Intelligence in Education Society, published research articles on the following topics in its September 2022 edition:
ARTICLES:
* Ethics of AI in Education: Towards a Community-Wide Framework
* Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies
* Disparities in Students' Propensity to Consent to Learning Analytics
* Data-Related Ethics Issues in Technologies for Informal Professional Learning
* Equality of Learning Opportunity via Individual Fairness in Personalized Recommendations
* Context Matters: Differing Implications of Motivation and Help-Seeking in Educational Technology
* Advancing the Design and Implementation of Artificial Intelligence in Education through Continuous Improvement
* Teaching Responsible Data Science: Charting New Pedagogical Territory
* Educating Software and AI Stakeholders About Algorithmic Fairness, Accountability, Transparency and Ethics
The September 2022 edition of the International Journal of Artificial Intelligence in Education can be viewed at https://link.springer.com/journal/40593/volumes-and-issues/32-3. The journal is published by Springer Nature Switzerland.
[Category: Education]
MSTRUCK-7933043 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); RESEARCH REPORTS (90%); ACCESS TO EDUCATION (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); TEACHING MATERIALS & MEDIA (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); PUBLIC POLICY (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%)
Geographic: EDINBURGH, SCOTLAND (59%); SCOTLAND (79%)
Load-Date: September 1, 2022","The International Journal of Artificial Intelligence in Education, a peer-reviewed journal from the International Artificial Intelligence in Education Society, published research articles on the following topics in its September 2022 edition:
ARTICLES:
* Ethics of AI in Education: Towards a Community-Wide Framework
* Education for AI, not AI for Education: The Role of Education and Ethics in National AI Policy Strategies
* Disparities in Students' Propensity to Consent to Learning Analytics
* Data-Related Ethics Issues in Technologies for Informal Professional Learning
* Equality of Learning Opportunity via Individual Fairness in Personalized Recommendations
* Context Matters: Differing Implications of Motivation and Help-Seeking in Educational Technology
* Advancing the Design and Implementation of Artificial Intelligence in Education through Continuous Improvement
* Teaching Responsible Data Science: Charting New Pedagogical Territory
* Educating Software and AI Stakeholders About Algorithmic Fairness, Accountability, Transparency and Ethics
The September 2022 edition of the International Journal of Artificial Intelligence in Education can be viewed at https://link.springer.com/journal/40593/volumes-and-issues/32-3. The journal is published by Springer Nature Switzerland.
[Category: Education]
MSTRUCK-7933043 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); RESEARCH REPORTS (90%); ACCESS TO EDUCATION (78%); DATA ANALYTICS (78%); DATA SCIENCE (78%); TEACHING MATERIALS & MEDIA (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); PUBLIC POLICY (71%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DATA ANALYTICS (78%); DATA SCIENCE (78%); PERIODICAL PUBLISHING (78%); PUBLISHING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%)
Geographic: EDINBURGH, SCOTLAND (59%); SCOTLAND (79%)
Load-Date: September 1, 2022",neutral,0.9018648862838745,balanced/neutral,"['fairness', 'transparency', 'accountability', 'consent', 'access']","['fairness', 'equality']","['regulation', 'policy', 'framework']",[],5,2,3,0
2021,Unknown Title,"Dateline: New Delhi, 2022-01-18 13:29:55 
Body
 January 18 -- If you want artificial intelligence to have human ethics, you have to teach it to evolve ethics like we do. At least that's what a pair of researchers from the International Institute of Information Technology in Bangalore, India proposed in a pre-print paper published today.
Titled ""AI and the Sense of Self,"" the paper describes a methodology called ""elastic identity"" by which the researchers say AI might learn to gain a greater sense of agency while simultaneously understanding how to avoid ""collateral damage.""
In short, the researchers are suggesting that we teach AI to be more ethically-aligned with humans by allowing it to learn when it's appropriate to optimize for self and when its necessary to optimize for the good of a community.
Will Google kill banks?How banks can compete with big tech
Per the paper:
While we may be far from a comprehensive computational model of self, in this work, we focus on a specific characteristic of our sense of self that may hold the key for the innate sense of responsibility and ethics in humans. We call this the elastic sense of self, extending over a set of external objects called the identity set.
Our sense of self, is not limited to the boundaries of our physical being, and often extends to include other objects and concepts from our environment. This forms the basis for social identity that builds a sense of belongingness and loyalty towards something other than, or beyond one's physical being.
The researchers describe a sort of equilibrium between altruism and selfish behavior where an agent would be able to understand ethical nuances.
Unfortunately, there's no calculus for ethics. Humans have been trying to sort out the right way for everyone to conduct themselves in a civilized society for millennia and he lack of Utopian nations in modern society tells you how far we've gotten.
As to exactly what measure of ""elasticity"" an AI model should have, that may be more of a philosophical question than a scientific one.
According to the researchers:
At a systemic level, there are also open questions about the evolutionary stability of a system of agents with elastic identity. Can a system of empathetic agents be successfully ""invaded"" by a small group of non-empathetic agents who don't identify with others? Or does there exist a strategy for deciding the optimal level of one's empathy or extent of one's identity set, that makes it evolutionarily stable?
Do we really want AI capable of learning ethics the human way? Our socio-ethical point of view has been forged in the fires of countless wars and an unbroken tradition of committing horrific atrocities. We broke a lot of eggs on our way to making the omelet that is human society.
And, it's fair to say we've got a lot of work left yet. Teaching AI our ethics and then training it to evolve like we do could be recipe for automating disaster.
It could also lead to a greater philosophical understanding of human ethics and the ability to simulate civilization with artificial agents. Maybe the machines will deal with uncertainty better than humans historically have.
Either way, the research is fascinating and well worth the read. You can check it out here on arXiv.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MODELING & SIMULATION (77%)
Company: GOOGLE LLC (58%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (58%); ARTIFICIAL INTELLIGENCE (90%); BIG TECH (77%); MODELING & SIMULATION (77%)
Geographic: NEW DELHI, INDIA (59%); BANGALORE, KARNATAKA, INDIA (58%); INDIA (90%)
Load-Date: January 18, 2022","January 18 -- If you want artificial intelligence to have human ethics, you have to teach it to evolve ethics like we do. At least that's what a pair of researchers from the International Institute of Information Technology in Bangalore, India proposed in a pre-print paper published today.
Titled ""AI and the Sense of Self,"" the paper describes a methodology called ""elastic identity"" by which the researchers say AI might learn to gain a greater sense of agency while simultaneously understanding how to avoid ""collateral damage.""
In short, the researchers are suggesting that we teach AI to be more ethically-aligned with humans by allowing it to learn when it's appropriate to optimize for self and when its necessary to optimize for the good of a community.
Will Google kill banks?How banks can compete with big tech
Per the paper:
While we may be far from a comprehensive computational model of self, in this work, we focus on a specific characteristic of our sense of self that may hold the key for the innate sense of responsibility and ethics in humans. We call this the elastic sense of self, extending over a set of external objects called the identity set.
Our sense of self, is not limited to the boundaries of our physical being, and often extends to include other objects and concepts from our environment. This forms the basis for social identity that builds a sense of belongingness and loyalty towards something other than, or beyond one's physical being.
The researchers describe a sort of equilibrium between altruism and selfish behavior where an agent would be able to understand ethical nuances.
Unfortunately, there's no calculus for ethics. Humans have been trying to sort out the right way for everyone to conduct themselves in a civilized society for millennia and he lack of Utopian nations in modern society tells you how far we've gotten.
As to exactly what measure of ""elasticity"" an AI model should have, that may be more of a philosophical question than a scientific one.
According to the researchers:
At a systemic level, there are also open questions about the evolutionary stability of a system of agents with elastic identity. Can a system of empathetic agents be successfully ""invaded"" by a small group of non-empathetic agents who don't identify with others? Or does there exist a strategy for deciding the optimal level of one's empathy or extent of one's identity set, that makes it evolutionarily stable?
Do we really want AI capable of learning ethics the human way? Our socio-ethical point of view has been forged in the fires of countless wars and an unbroken tradition of committing horrific atrocities. We broke a lot of eggs on our way to making the omelet that is human society.
And, it's fair to say we've got a lot of work left yet. Teaching AI our ethics and then training it to evolve like we do could be recipe for automating disaster.
It could also lead to a greater philosophical understanding of human ethics and the ability to simulate civilization with artificial agents. Maybe the machines will deal with uncertainty better than humans historically have.
Either way, the research is fascinating and well worth the read. You can check it out here on arXiv.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); MODELING & SIMULATION (77%)
Company: GOOGLE LLC (58%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (58%); ARTIFICIAL INTELLIGENCE (90%); BIG TECH (77%); MODELING & SIMULATION (77%)
Geographic: NEW DELHI, INDIA (59%); BANGALORE, KARNATAKA, INDIA (58%); INDIA (90%)
Load-Date: January 18, 2022",neutral,0.8643057942390442,balanced/neutral,['agency'],[],['should'],['ai model'],1,0,1,1
2021,Unknown Title,"Byline: Express Computer
Body
Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.
Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purpose-""to make the world more sustainable by building trust in society through innovation."" To realize the vision of a sustainable world through its global business brand ""FUJITSU Uvance"" which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.
In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the ""Fujitsu Group External Advisory Committee on AI Ethics"" to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.
On February 1, Fujitsu will newly establish the ""AI Ethics and Governance Office"" (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.
This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); MACHINE LEARNING (73%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%); SAFETY (69%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%); SUSTAINABLE DEVELOPMENT (72%)
Load-Date: January 28, 2022","Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.
Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purpose-""to make the world more sustainable by building trust in society through innovation."" To realize the vision of a sustainable world through its global business brand ""FUJITSU Uvance"" which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.
In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the ""Fujitsu Group External Advisory Committee on AI Ethics"" to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.
On February 1, Fujitsu will newly establish the ""AI Ethics and Governance Office"" (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.
This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); MACHINE LEARNING (73%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%); SAFETY (69%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%); SUSTAINABLE DEVELOPMENT (72%)
Load-Date: January 28, 2022",positive,0.5923939943313599,balanced/neutral,['safety'],[],"['governance', 'framework']",['machine learning'],1,0,2,1
2021,Unknown Title,"Byline: Dr. Tim Sandle
Body
Apr 11, 2022( Digital Journal: http://www.digitaljournal.com Delivered by Newstex)  
 Researchers have called upon the community of ethical hackers to work together to help prevent the looming 'crisis of trust' that is set to impact artificial intelligence. 
Specifically, the researchers are putting forward[1] the need fora global hacker 'red team', macheted by the incentive of rewards, for hunting algorithmic biases. This type of activity is needed to help reduce the so-termed 'tech-lash' that artificial intelligence faces unless firm measures are taken to increase public trust. 
The reason for proposing this issue is because technology sector is facing concerns that underpin advances in artificial intelligence, such as the progress with driverless cars and autonomous drones. 
There is also concern with aspects like social media algorithms that spread misinformation and provoke political turmoil. 
The researchers are also concerned with the level of ferocious competition which is leading to some errors in the development of artificial intelligence, such as creeping bias[2]. This includes a lack of auditing or robust third party analysis. Artificial intelligence bias is an anomaly in the output of machine learning algorithms, due to the prejudiced assumptions made during the algorithm development process. 
While regulation can assist with combatting some of these errors, there is a need for greater activity within the technology sector. 
This is where the 'red team' concept comes in. A red team is a group that plays the role of an enemy or competitor, and provide security feedback from that perspective. 
Within the artificial intelligence sphere, the red teams would be formed of ethical hackers playing the role of malign external agents. Ethical hacking (or penetration testing)[3] is the exploitation of an information technology system with the permission of its owner to determine its vulnerabilities. 
The idea is that they would be called in to attack any new artificial intelligence, or to strategize on how to use it for malicious purposes. The objective would be to reveal any weaknesses or potential for harm. 
Since many companies would not have the resources to 'red team', the researchers are calling for a third-party community to independently interrogate new inventions and to share any findings for the benefit of all developers. 
The research appears[4] in the journal Science, in a paper titled 'Filling gaps in trustworthy development of AI.' 
https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/share#url=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&title=Ethical%20hacking%20can%20improve%20AI%20bias 
The post Ethical hacking can improve AI bias[5] appeared first on Digital Journal[6]. 
 [ 1]: https://www.cam.ac.uk/research/news/community-of-ethical-hackers-needed-to-prevent-ais-looming-crisis-of-trust [ 2]: https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/ [ 3]: https://www.techtarget.com/searchsecurity/definition/ethical-hacker [ 4]: http://dx.doi.org/10.1126/science.abi7176 [ 5]: https://www.digitaljournal.com/tech-science/ethical-hacking-can-improve-ai-bias/article [ 6]: https://www.digitaljournal.com 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: DIJO-0001
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPUTER CRIME (90%); CYBERCRIME (90%); ETHICS (90%); NEGATIVE TECHNOLOGY NEWS (90%); NEGATIVE NEWS (89%); BLOGS & MESSAGE BOARDS (78%); DISINFORMATION & MISINFORMATION (78%); INTERNET SOCIAL NETWORKING (78%); MACHINE LEARNING (73%); SCIENCE & TECHNOLOGY (73%); SOCIAL MEDIA (73%); NEGATIVE POLITICAL NEWS (72%); Tech & Science (%); Bias (%); Hackers (%); Artificial Intelligence (%); Information technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COMPUTER CRIME (90%); CYBERCRIME (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); BLOGS & MESSAGE BOARDS (78%); INTERNET SOCIAL NETWORKING (78%); AUTONOMOUS VEHICLES (74%); COMPUTING & INFORMATION TECHNOLOGY (74%); MACHINE LEARNING (73%); SOCIAL MEDIA (73%); AUTONOMOUS MOTOR VEHICLES (54%)
Load-Date: April 11, 2022","Apr 11, 2022( Digital Journal: http://www.digitaljournal.com Delivered by Newstex)  
 Researchers have called upon the community of ethical hackers to work together to help prevent the looming 'crisis of trust' that is set to impact artificial intelligence. 
Specifically, the researchers are putting forward[1] the need fora global hacker 'red team', macheted by the incentive of rewards, for hunting algorithmic biases. This type of activity is needed to help reduce the so-termed 'tech-lash' that artificial intelligence faces unless firm measures are taken to increase public trust. 
The reason for proposing this issue is because technology sector is facing concerns that underpin advances in artificial intelligence, such as the progress with driverless cars and autonomous drones. 
There is also concern with aspects like social media algorithms that spread misinformation and provoke political turmoil. 
The researchers are also concerned with the level of ferocious competition which is leading to some errors in the development of artificial intelligence, such as creeping bias[2]. This includes a lack of auditing or robust third party analysis. Artificial intelligence bias is an anomaly in the output of machine learning algorithms, due to the prejudiced assumptions made during the algorithm development process. 
While regulation can assist with combatting some of these errors, there is a need for greater activity within the technology sector. 
This is where the 'red team' concept comes in. A red team is a group that plays the role of an enemy or competitor, and provide security feedback from that perspective. 
Within the artificial intelligence sphere, the red teams would be formed of ethical hackers playing the role of malign external agents. Ethical hacking (or penetration testing)[3] is the exploitation of an information technology system with the permission of its owner to determine its vulnerabilities. 
The idea is that they would be called in to attack any new artificial intelligence, or to strategize on how to use it for malicious purposes. The objective would be to reveal any weaknesses or potential for harm. 
Since many companies would not have the resources to 'red team', the researchers are calling for a third-party community to independently interrogate new inventions and to share any findings for the benefit of all developers. 
The research appears[4] in the journal Science, in a paper titled 'Filling gaps in trustworthy development of AI.' 
https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&linkname=Ethical%20hacking%20can%20improve%20AI%20biashttps://www.addtoany.com/share#url=https%3A%2F%2Fwww.digitaljournal.com%2Ftech-science%2Fethical-hacking-can-improve-ai-bias%2Farticle&title=Ethical%20hacking%20can%20improve%20AI%20bias 
The post Ethical hacking can improve AI bias[5] appeared first on Digital Journal[6]. 
 [ 1]: https://www.cam.ac.uk/research/news/community-of-ethical-hackers-needed-to-prevent-ais-looming-crisis-of-trust [ 2]: https://www.weforum.org/agenda/2021/07/ai-machine-learning-bias-discrimination/ [ 3]: https://www.techtarget.com/searchsecurity/definition/ethical-hacker [ 4]: http://dx.doi.org/10.1126/science.abi7176 [ 5]: https://www.digitaljournal.com/tech-science/ethical-hacking-can-improve-ai-bias/article [ 6]: https://www.digitaljournal.com 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: DIJO-0001
Subject: ARTIFICIAL INTELLIGENCE (90%); COMPUTER CRIME (90%); CYBERCRIME (90%); ETHICS (90%); NEGATIVE TECHNOLOGY NEWS (90%); NEGATIVE NEWS (89%); BLOGS & MESSAGE BOARDS (78%); DISINFORMATION & MISINFORMATION (78%); INTERNET SOCIAL NETWORKING (78%); MACHINE LEARNING (73%); SCIENCE & TECHNOLOGY (73%); SOCIAL MEDIA (73%); NEGATIVE POLITICAL NEWS (72%); Tech & Science (%); Bias (%); Hackers (%); Artificial Intelligence (%); Information technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); COMPUTER CRIME (90%); CYBERCRIME (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); BLOGS & MESSAGE BOARDS (78%); INTERNET SOCIAL NETWORKING (78%); AUTONOMOUS VEHICLES (74%); COMPUTING & INFORMATION TECHNOLOGY (74%); MACHINE LEARNING (73%); SOCIAL MEDIA (73%); AUTONOMOUS MOTOR VEHICLES (54%)
Load-Date: April 11, 2022",neutral,0.8640309572219849,balanced/neutral,"['bias', 'discrimination', 'security', 'misinformation', 'disinformation']",[],"['regulation', 'should']","['machine learning', 'algorithm']",5,0,2,2
2021,Unknown Title,"Dateline: LONDON, Oct. 19 2022 
Body
PR Newswire
CFA Institute, the global association of investment professionals, has released new research and an accompanying ethical decision framework to motivate the evolution of ethical practices in the development of artificial intelligence (AI) technologies in investment management.
The new research,Ethics and Artificial Intelligence in Investment Management, a Framework for Professionals,recognizes the spectrum of issues brought about by AI tools and big data in investing, and sets out questions for professionals and investment teams to consider when working with AI technologies at each step of the AI workflow. The paper combines fundamental ethical principles with the applicability of relevant professional standards as set out in theCFA Institute Code of Ethics and Standards of Professional Conductto offer a decision framework to guide the development of responsible AI applications in investment management.
The research also identifies organization-level requisites for AI to be successfully used in a variety of applications that include investment analysis, portfolio management, risk management, trading, automated advice, and client onboarding.
Rhodri Preece, CFA, Senior Head, Research, CFA Institute comments:
""AI adoption offers significant potential benefits, yet also entails several risks. The expansion of data sources and availability of AI tools to harness big data can improve investment decision making but can also introduce more complexity in investing. With ever more data sources and more complex decision-making algorithms, the application of AI must prompt firms and professionals to re-examine the span of ethical considerations in investing. The framework aims to support professionals in the ethical design, development, and deployment of AI tools.""
Key Takeaways:
Investment organizations must establish a culture conducive to client-centric AI innovation, and incorporate a robust risk management and governance framework that includes regular model testing. A talent development programme to ensure the acquisition of appropriate knowledge, skills, and abilities within investment teams can give firms an edge.Ethical considerations regarding the use of AI in investment management include the integrity of data, the accuracy and validity of models, transparency and interpretability of algorithms, and accountability structures.AI models should avoid bias and excessive complexity or opacity so that they can be interpreted and understood by all relevant stakeholders. They should yield fair and accurate outcomes. Interpretability methods play an important role supporting model transparency.Regular model testing and review should be part of the governance framework surrounding the use of AI to ensure that applications perform and evolve as expected.Model development and evaluation should consider the existence or emergence of biases in data or in the way that models learn from features, the interpretability of the contribution of features to the outcome, the fairness and accuracy of outcomes, and the ongoing suitability of models to client needs.An ethical decision framework sets out the relevant questions professionals and investment teams should consider when working with AI technologies at each step of the AI workflow.
Rhodri Preece, CFA, continues:
""Instilling an ethical decision framework in AI-driven investment processes is critical to ensure applications serve the best interests of clients. Given the complexity of AI projects, senior leadership must establish a strategic vision and ethical culture for AI development within the organization. While the use of AI in investment management is still relatively formative, it is appropriate that we examine the ethical aspects of AI implementation to guide future developments responsibly. We offer our research and framework as guidance for investment professionals to advance the industry's efforts to incorporate AI responsibly.""
For more information, contact:PR@CFAInstitute.org
Notes to EditorsLink to theCFA Institute Code of Ethics and Standards of Professional Conduct
CFA Institute offers a number of short online courses covering data science curriculums which includeData and Statistics Foundation for Investment Professionals,Statistics for Machine Learning for Investment Professionals, Machine Learning for Investment Professionals, andNatural Language Processing for Investment Professionals. For all courses and curriculum information, visitProfessional Learning.
About CFA Institute
CFA Institute is the global association of investment professionals that sets the standard for professional excellence and credentials. The organization is a champion of ethical behavior in investment markets and a respected source of knowledge in the global financial community. Our aim is to create an environment where investors' interests come first, markets function at their best, and economics grow. There are more than 190,000 CFA charterholders worldwide in more than 160 markets. CFA Institute has nine offices worldwide and 160 local societies. For more information, visithttp://www.cfainstitute.orgor follow us onLinkedinand Twitter at @CFAInstitute.
 View original content:https://www.prnewswire.com/news-releases/introducing-an-ethical-decision-framework-to-guide-responsible-ai-in-investment-management-301652839.html
SOURCE CFA Institute
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: INVESTMENT MANAGEMENT (95%); ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); BANKING & FINANCE ASSOCIATIONS (90%); BUSINESS & PROFESSIONAL ASSOCIATIONS (90%); INVESTMENT ADVISERS (90%); INVESTMENT SERVICES (90%); PRESS RELEASES (90%); PROFESSIONAL WORKERS (90%); CORPORATE GOVERNANCE (89%); RISK MANAGEMENT (89%); CFA-INSTITUTE (%); PDT New Products and Services (%); SVY Surveys, polls & research studies (%)
Company: CFA Institute
Industry: INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BANKING & FINANCE ASSOCIATIONS (90%); INVESTMENT ADVISERS (90%); INVESTMENT SERVICES (90%); RISK MANAGEMENT (89%); FIN Banking; Financial Services (%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: October 19, 2022","PR Newswire
CFA Institute, the global association of investment professionals, has released new research and an accompanying ethical decision framework to motivate the evolution of ethical practices in the development of artificial intelligence (AI) technologies in investment management.
The new research,Ethics and Artificial Intelligence in Investment Management, a Framework for Professionals,recognizes the spectrum of issues brought about by AI tools and big data in investing, and sets out questions for professionals and investment teams to consider when working with AI technologies at each step of the AI workflow. The paper combines fundamental ethical principles with the applicability of relevant professional standards as set out in theCFA Institute Code of Ethics and Standards of Professional Conductto offer a decision framework to guide the development of responsible AI applications in investment management.
The research also identifies organization-level requisites for AI to be successfully used in a variety of applications that include investment analysis, portfolio management, risk management, trading, automated advice, and client onboarding.
Rhodri Preece, CFA, Senior Head, Research, CFA Institute comments:
""AI adoption offers significant potential benefits, yet also entails several risks. The expansion of data sources and availability of AI tools to harness big data can improve investment decision making but can also introduce more complexity in investing. With ever more data sources and more complex decision-making algorithms, the application of AI must prompt firms and professionals to re-examine the span of ethical considerations in investing. The framework aims to support professionals in the ethical design, development, and deployment of AI tools.""
Key Takeaways:
Investment organizations must establish a culture conducive to client-centric AI innovation, and incorporate a robust risk management and governance framework that includes regular model testing. A talent development programme to ensure the acquisition of appropriate knowledge, skills, and abilities within investment teams can give firms an edge.Ethical considerations regarding the use of AI in investment management include the integrity of data, the accuracy and validity of models, transparency and interpretability of algorithms, and accountability structures.AI models should avoid bias and excessive complexity or opacity so that they can be interpreted and understood by all relevant stakeholders. They should yield fair and accurate outcomes. Interpretability methods play an important role supporting model transparency.Regular model testing and review should be part of the governance framework surrounding the use of AI to ensure that applications perform and evolve as expected.Model development and evaluation should consider the existence or emergence of biases in data or in the way that models learn from features, the interpretability of the contribution of features to the outcome, the fairness and accuracy of outcomes, and the ongoing suitability of models to client needs.An ethical decision framework sets out the relevant questions professionals and investment teams should consider when working with AI technologies at each step of the AI workflow.
Rhodri Preece, CFA, continues:
""Instilling an ethical decision framework in AI-driven investment processes is critical to ensure applications serve the best interests of clients. Given the complexity of AI projects, senior leadership must establish a strategic vision and ethical culture for AI development within the organization. While the use of AI in investment management is still relatively formative, it is appropriate that we examine the ethical aspects of AI implementation to guide future developments responsibly. We offer our research and framework as guidance for investment professionals to advance the industry's efforts to incorporate AI responsibly.""
For more information, contact:PR@CFAInstitute.org
Notes to EditorsLink to theCFA Institute Code of Ethics and Standards of Professional Conduct
CFA Institute offers a number of short online courses covering data science curriculums which includeData and Statistics Foundation for Investment Professionals,Statistics for Machine Learning for Investment Professionals, Machine Learning for Investment Professionals, andNatural Language Processing for Investment Professionals. For all courses and curriculum information, visitProfessional Learning.
About CFA Institute
CFA Institute is the global association of investment professionals that sets the standard for professional excellence and credentials. The organization is a champion of ethical behavior in investment markets and a respected source of knowledge in the global financial community. Our aim is to create an environment where investors' interests come first, markets function at their best, and economics grow. There are more than 190,000 CFA charterholders worldwide in more than 160 markets. CFA Institute has nine offices worldwide and 160 local societies. For more information, visithttp://www.cfainstitute.orgor follow us onLinkedinand Twitter at @CFAInstitute.
 View original content:https://www.prnewswire.com/news-releases/introducing-an-ethical-decision-framework-to-guide-responsible-ai-in-investment-management-301652839.html
SOURCE CFA Institute
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: INVESTMENT MANAGEMENT (95%); ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ASSOCIATIONS & ORGANIZATIONS (90%); BANKING & FINANCE ASSOCIATIONS (90%); BUSINESS & PROFESSIONAL ASSOCIATIONS (90%); INVESTMENT ADVISERS (90%); INVESTMENT SERVICES (90%); PRESS RELEASES (90%); PROFESSIONAL WORKERS (90%); CORPORATE GOVERNANCE (89%); RISK MANAGEMENT (89%); CFA-INSTITUTE (%); PDT New Products and Services (%); SVY Surveys, polls & research studies (%)
Company: CFA Institute
Industry: INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BANKING & FINANCE ASSOCIATIONS (90%); INVESTMENT ADVISERS (90%); INVESTMENT SERVICES (90%); RISK MANAGEMENT (89%); FIN Banking; Financial Services (%); CPR Computer; Electronics Products (%)
Geographic: New York
Load-Date: October 19, 2022",neutral,0.6220715641975403,balanced/neutral,"['bias', 'fairness', 'transparency', 'accountability']",['fairness'],"['governance', 'standards', 'framework', 'should', 'must']",['machine learning'],4,1,5,1
2021,Unknown Title,"Byline: vs1108@ic.ac.uk
Body
To the Editor — The evaluation of health technologies, such as artificial intelligence (AI), through robust, reliable and reproducible scientific research is one of the cornerstones of evidence-based medicine and ethical patient care. Although completeness of reporting is imperative for all scientific endeavours, it is of particular importance within the health sciences as scientific and ethical transgressions may manifest in harm to individual patients or impose disparate quality of care across patient populations.
Reporting guidelines reflect ethical commitments to transparency and honesty in science. However, reporting guidelines in the health sciences have so far not included much detail related to the ethical dimensions of study design or conduct. Typically, the only requirements are that Ethical Review Board (ERB) approval is noted along with a statement confirming that participants provided informed consent when consent is required. Details regarding the specific ethical challenges involved and the methods used to address them are not typically described. This state of affairs suggests that the ethical aspects of study design are not salient vis-à-vis the critical appraisal or replication of the studies in question.
In this paper, we advocate for the inclusion of ‘ethics methods’ items in AI reporting guidelines, following the call from Anderson et al. for transparent reporting of research ethics methods in biomedical research. We argue that attention to ethical methods as part of research reporting AI research is urgent, for the following reasons. First, incorporating ethics methods as components of scientific reporting encourages scientists to consider and address the ethical implications of their work when they are developing, designing and executing their studies, much as they already do in regard to scientific methods. The numerous calls for better integration of ethics into the field of AI underscore the importance of this advancement; reporting guidelines can be another supportive mechanism. The second reason is to improve accountability. By providing an account of the reasoning behind specific model choices, researchers will make these decisions transparent and available for scrutiny by the scientific community, promoting accountability. The final benefit is to promote the reproducibility of AI research in general—a noted problem—and the ethical reproducibility of AI research specifically. The proximate aims of reporting guidelines are to facilitate critical appraisal, replication and implementation. The ultimate goal for the scientific community is to learn how best to minimize the harms associated with AI. It is not immediately obvious how best to achieve this goal, and with transparent reporting of ethics methods, we maximize the opportunity to learn from others’ efforts to mitigate bias and minimize harms.
In the original conceptualization, ethics methods referred to elements of study design undertaken for ethical reasons (by analogy with the scientific methods undertaken for scientific reasons), and their reporting is intended to promote ‘ethical reproducibility’ (Box ). Ethical reproducibility, operationalized through transparent reporting of ethics methods, mandates a certain level of engagement with the ethical issues inherent to health research, and subjects these methods to the scrutiny and response of the scientific community.
AI-centred studies have exposed some of the challenges caused by the de facto segregation of ‘ethics methods’ from scientific reporting. Choices about data sources, representation, algorithm development, modelling and outcome selection are all fundamentally intertwined with values. Furthermore, these choices may have a dramatic impact on the scientific—as well as the ethical—validity of these studies. Thus, concerns about poor reporting of clinical AI, should extend beyond scientific methods to elements of AI study design undertaken for ethical reasons, including management of algorithmic bias, stakeholder engagement and compliance with relevant oversight frameworks.
Ethics methods should describe elements of study design undertaken for ethical reasons. Examples are choices about how ‘bias’ is defined, which class of patients is considered disadvantaged and why, and what technical choices are made on this basis. Park and colleagues report on each of these aspects in their comparison of algorithmic fairness methods in the case of predicting postpartum depression. Algorithmic fairness is a particularly salient example to highlight as a candidate item for reporting as an element of ethics methods because it is undertaken explicitly to promote equity, distributive justice or equality. Moreover, these choices directly affect the scientific and ethical reproducibility of the studies involved. By being explicit about the choices that were made and on what basis, authors can ensure that the scientific community will be able to critically analyse their work and replicate it.
There is an increasing corpus of AI ethics literature outlining core principles, notably the recent World Health Organisation guidance on ‘Ethics and Governance’. As highlighted by Mittelstadt, there need to be multiple levers through which these principles are operationalised and protected. Reporting guidelines represent a core mechanism through which ethical principles may be embedded into published AI evidence. In a step toward recognizing the ethical aspects of scientific research, the SPIRIT-AI and CONSORT-AI guidelines, have included requirements on reporting error analysis, providing an opportunity to explore discrepancies in AI system outputs across key population subgroups. The guidelines already stipulate that reporting cases of error and defining risk mitigation strategies are important for informing when, and for which populations, a given intervention can be safely implemented, in effect mandating the identification of any systematic disadvantages imposed by use of the AI system in population subgroups. Without such analyses, any stratification in performance across subgroups would be masked within a single AI output for the aggregate group. This represents but one step forward in this process. Measured inclusion of such items in forthcoming guidelines, in conjunction with broader impact statements, can provide a platform to raise ethics on par with scientific methods to better evaluate health AI.
Box 1 Ethics methods in traditional clinical trials
Procedures for obtaining informed consent such as audiovisual communication aids and age-appropriate language guides
Tools for assessing capacity
Adaptive dose-escalation schemes
Equipoise requirements
Monitoring procedures
Stopping rules
Post-study debriefing strategies
Provisions for post-study access
Acknowledgements
Infrastructure support for this research was provided by the National Institute for Health Research Imperial Biomedical Research Centre (BRC), UK.
Notes
Declaration: The lead author affirms that this manuscript is an honest, accurate and transparent account of the study being reported.
Classification
Language: ENGLISH
Publication-Type: Magazine
Journal Code: 42256
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); MEDICAL SCIENCE (90%); MEDICAL TECHNOLOGY (90%); SCIENCE & TECHNOLOGY (90%); MEDICINE & HEALTH (89%); SCIENTIFIC METHOD (89%); BIOETHICS (78%); BIOMEDICINE (78%); HUMAN SUBJECTS (78%); MEDICAL RESEARCH (78%); PATIENT CONSENT (78%); WRITERS (73%)
Organization: Institute of Global Health Innovation; Imperial College London; Department of Bioethics; The Hospital for Sick Children; Genetics & Genome Biology; Peter Gilgan Centre for Research & Learning; Division of Clinical and Public Health; Dalla Lana School of Public Health; Institute of Inflammation and Ageing, College of Medical and Dental Sciences; University of Birmingham; Center for Health Policy and Department of Health Policy; NIHR Oxford Biomedical Research Centre; Oxford University Hospitals NHS Foundation Trust; Centre for Statistics in Medicine, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences; University of Oxford; Institute for Health Management Policy & Evaluation; University of Toronto; Department of Epidemiology and Data Science; Amsterdam University Medical Centre, University of Amsterdam; Ottawa Hospital Research Institute
Industry: ARTIFICIAL INTELLIGENCE (90%); EVIDENCE BASED MEDICINE (90%); MEDICAL TECHNOLOGY (90%); BIOMEDICINE (78%); PATIENT CONSENT (78%); WRITERS (73%)
Person: Sounderajah Viknesh; McCradden Melissa D.; Liu Xiaoxuan; Rose Sherri; Ashrafian Hutan; Collins Gary S.; Anderson James; Bossuyt Patrick M.; Moher David; Darzi Ara
Geographic: OTTAWA, ON, CANADA (77%); AMSTERDAM, NETHERLANDS (72%); LONDON, ENGLAND (58%); OXFORD, ENGLAND (57%); ONTARIO, CANADA (73%)
Load-Date: September 6, 2023","To the Editor — The evaluation of health technologies, such as artificial intelligence (AI), through robust, reliable and reproducible scientific research is one of the cornerstones of evidence-based medicine and ethical patient care. Although completeness of reporting is imperative for all scientific endeavours, it is of particular importance within the health sciences as scientific and ethical transgressions may manifest in harm to individual patients or impose disparate quality of care across patient populations.
Reporting guidelines reflect ethical commitments to transparency and honesty in science. However, reporting guidelines in the health sciences have so far not included much detail related to the ethical dimensions of study design or conduct. Typically, the only requirements are that Ethical Review Board (ERB) approval is noted along with a statement confirming that participants provided informed consent when consent is required. Details regarding the specific ethical challenges involved and the methods used to address them are not typically described. This state of affairs suggests that the ethical aspects of study design are not salient vis-à-vis the critical appraisal or replication of the studies in question.
In this paper, we advocate for the inclusion of ‘ethics methods’ items in AI reporting guidelines, following the call from Anderson et al. for transparent reporting of research ethics methods in biomedical research. We argue that attention to ethical methods as part of research reporting AI research is urgent, for the following reasons. First, incorporating ethics methods as components of scientific reporting encourages scientists to consider and address the ethical implications of their work when they are developing, designing and executing their studies, much as they already do in regard to scientific methods. The numerous calls for better integration of ethics into the field of AI underscore the importance of this advancement; reporting guidelines can be another supportive mechanism. The second reason is to improve accountability. By providing an account of the reasoning behind specific model choices, researchers will make these decisions transparent and available for scrutiny by the scientific community, promoting accountability. The final benefit is to promote the reproducibility of AI research in general—a noted problem—and the ethical reproducibility of AI research specifically. The proximate aims of reporting guidelines are to facilitate critical appraisal, replication and implementation. The ultimate goal for the scientific community is to learn how best to minimize the harms associated with AI. It is not immediately obvious how best to achieve this goal, and with transparent reporting of ethics methods, we maximize the opportunity to learn from others’ efforts to mitigate bias and minimize harms.
In the original conceptualization, ethics methods referred to elements of study design undertaken for ethical reasons (by analogy with the scientific methods undertaken for scientific reasons), and their reporting is intended to promote ‘ethical reproducibility’ (Box ). Ethical reproducibility, operationalized through transparent reporting of ethics methods, mandates a certain level of engagement with the ethical issues inherent to health research, and subjects these methods to the scrutiny and response of the scientific community.
AI-centred studies have exposed some of the challenges caused by the de facto segregation of ‘ethics methods’ from scientific reporting. Choices about data sources, representation, algorithm development, modelling and outcome selection are all fundamentally intertwined with values. Furthermore, these choices may have a dramatic impact on the scientific—as well as the ethical—validity of these studies. Thus, concerns about poor reporting of clinical AI, should extend beyond scientific methods to elements of AI study design undertaken for ethical reasons, including management of algorithmic bias, stakeholder engagement and compliance with relevant oversight frameworks.
Ethics methods should describe elements of study design undertaken for ethical reasons. Examples are choices about how ‘bias’ is defined, which class of patients is considered disadvantaged and why, and what technical choices are made on this basis. Park and colleagues report on each of these aspects in their comparison of algorithmic fairness methods in the case of predicting postpartum depression. Algorithmic fairness is a particularly salient example to highlight as a candidate item for reporting as an element of ethics methods because it is undertaken explicitly to promote equity, distributive justice or equality. Moreover, these choices directly affect the scientific and ethical reproducibility of the studies involved. By being explicit about the choices that were made and on what basis, authors can ensure that the scientific community will be able to critically analyse their work and replicate it.
There is an increasing corpus of AI ethics literature outlining core principles, notably the recent World Health Organisation guidance on ‘Ethics and Governance’. As highlighted by Mittelstadt, there need to be multiple levers through which these principles are operationalised and protected. Reporting guidelines represent a core mechanism through which ethical principles may be embedded into published AI evidence. In a step toward recognizing the ethical aspects of scientific research, the SPIRIT-AI and CONSORT-AI guidelines, have included requirements on reporting error analysis, providing an opportunity to explore discrepancies in AI system outputs across key population subgroups. The guidelines already stipulate that reporting cases of error and defining risk mitigation strategies are important for informing when, and for which populations, a given intervention can be safely implemented, in effect mandating the identification of any systematic disadvantages imposed by use of the AI system in population subgroups. Without such analyses, any stratification in performance across subgroups would be masked within a single AI output for the aggregate group. This represents but one step forward in this process. Measured inclusion of such items in forthcoming guidelines, in conjunction with broader impact statements, can provide a platform to raise ethics on par with scientific methods to better evaluate health AI.
Box 1 Ethics methods in traditional clinical trials
Procedures for obtaining informed consent such as audiovisual communication aids and age-appropriate language guides
Tools for assessing capacity
Adaptive dose-escalation schemes
Equipoise requirements
Monitoring procedures
Stopping rules
Post-study debriefing strategies
Provisions for post-study access
Acknowledgements
Infrastructure support for this research was provided by the National Institute for Health Research Imperial Biomedical Research Centre (BRC), UK.
Notes
Declaration: The lead author affirms that this manuscript is an honest, accurate and transparent account of the study being reported.
Classification
Language: ENGLISH
Publication-Type: Magazine
Journal Code: 42256
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); MEDICAL SCIENCE (90%); MEDICAL TECHNOLOGY (90%); SCIENCE & TECHNOLOGY (90%); MEDICINE & HEALTH (89%); SCIENTIFIC METHOD (89%); BIOETHICS (78%); BIOMEDICINE (78%); HUMAN SUBJECTS (78%); MEDICAL RESEARCH (78%); PATIENT CONSENT (78%); WRITERS (73%)
Organization: Institute of Global Health Innovation; Imperial College London; Department of Bioethics; The Hospital for Sick Children; Genetics & Genome Biology; Peter Gilgan Centre for Research & Learning; Division of Clinical and Public Health; Dalla Lana School of Public Health; Institute of Inflammation and Ageing, College of Medical and Dental Sciences; University of Birmingham; Center for Health Policy and Department of Health Policy; NIHR Oxford Biomedical Research Centre; Oxford University Hospitals NHS Foundation Trust; Centre for Statistics in Medicine, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences; University of Oxford; Institute for Health Management Policy & Evaluation; University of Toronto; Department of Epidemiology and Data Science; Amsterdam University Medical Centre, University of Amsterdam; Ottawa Hospital Research Institute
Industry: ARTIFICIAL INTELLIGENCE (90%); EVIDENCE BASED MEDICINE (90%); MEDICAL TECHNOLOGY (90%); BIOMEDICINE (78%); PATIENT CONSENT (78%); WRITERS (73%)
Person: Sounderajah Viknesh; McCradden Melissa D.; Liu Xiaoxuan; Rose Sherri; Ashrafian Hutan; Collins Gary S.; Anderson James; Bossuyt Patrick M.; Moher David; Darzi Ara
Geographic: OTTAWA, ON, CANADA (77%); AMSTERDAM, NETHERLANDS (72%); LONDON, ENGLAND (58%); OXFORD, ENGLAND (57%); ONTARIO, CANADA (73%)
Load-Date: September 6, 2023",neutral,0.656257152557373,balanced/neutral,"['bias', 'fairness', 'transparency', 'accountability', 'consent', 'access']","['justice', 'fairness', 'equity', 'equality', 'justice']","['policy', 'governance', 'oversight', 'guidelines', 'compliance', 'should', 'need to', 'advocate', 'calls for']",['algorithm'],6,5,9,1
2021,Unknown Title,"Body
2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- Investigators publish new report on Technology. According to news reporting originating from New Haven, Connecticut, by NewsRx correspondents, research stated, ""The present paper uses a Flourishing Ethics analysis to address the question of which ethical values and principles should be 'instilled' into artificially intelligent agents."" 
 Our news editors obtained a quote from the research from Southern Connecticut State University, ""This is an urgent question that is still being asked seven decades after philosopher/scientist Norbert Wiener first asked it. An answer is developed by assuming that human flourishing is the central ethical value, which other ethical values, and related principles, can be used to defend and advance."" 
 According to the news editors, the research concluded: ""The upshot is that Flourishing Ethics can provide a common underlying ethical foundation for a wide diversity of cultures and communities around the globe; and the members of each specific culture or community can add their own specific cultural values-ones which they treasure, and which help them to make sense of their moral lives."" 
 This research has been peer-reviewed. 
 For more information on this research see: Flourishing Ethics and Identifying Ethical Values To Instill Into Artificially Intelligent Agents. Metaphilosophy, 2022. Metaphilosophy can be contacted at: Wiley, 111 River St, Hoboken 07030-5774, NJ, USA. (Wiley-Blackwell - www.wiley.com/; Metaphilosophy - onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-9973) 
 The news editors report that additional information may be obtained by contacting Terrell Ward Bynum, Southern Connecticut State University, Dept. of Philosophy, New Haven, CT, United States. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1111/meta.12583. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: New Haven, Connecticut, United States, North and Central America, Technology, Emerging Technologies, Intelligent Agents, Machine Learning, Southern Connecticut State University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE (90%); INTELLIGENT AGENTS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); NEWS REPORTING (90%); PHILOSOPHY (77%); EMERGING TECHNOLOGY (74%); ASSOCIATIONS & ORGANIZATIONS (72%); CUSTOMS & CULTURAL HERITAGE (67%); MACHINE LEARNING (58%); New Haven;State:Connecticut;United States;North and Central America;Technology;Emerging Technologies;Intelligent Agents;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INTELLIGENT AGENTS (90%); NEWS REPORTING (90%); MACHINE LEARNING (58%)
Geographic: NEW HAVEN, CT, USA (90%); CONNECTICUT, USA (96%); CENTRAL AMERICA (91%)
Load-Date: October 7, 2022","2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- Investigators publish new report on Technology. According to news reporting originating from New Haven, Connecticut, by NewsRx correspondents, research stated, ""The present paper uses a Flourishing Ethics analysis to address the question of which ethical values and principles should be 'instilled' into artificially intelligent agents."" 
 Our news editors obtained a quote from the research from Southern Connecticut State University, ""This is an urgent question that is still being asked seven decades after philosopher/scientist Norbert Wiener first asked it. An answer is developed by assuming that human flourishing is the central ethical value, which other ethical values, and related principles, can be used to defend and advance."" 
 According to the news editors, the research concluded: ""The upshot is that Flourishing Ethics can provide a common underlying ethical foundation for a wide diversity of cultures and communities around the globe; and the members of each specific culture or community can add their own specific cultural values-ones which they treasure, and which help them to make sense of their moral lives."" 
 This research has been peer-reviewed. 
 For more information on this research see: Flourishing Ethics and Identifying Ethical Values To Instill Into Artificially Intelligent Agents. Metaphilosophy, 2022. Metaphilosophy can be contacted at: Wiley, 111 River St, Hoboken 07030-5774, NJ, USA. (Wiley-Blackwell - www.wiley.com/; Metaphilosophy - onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-9973) 
 The news editors report that additional information may be obtained by contacting Terrell Ward Bynum, Southern Connecticut State University, Dept. of Philosophy, New Haven, CT, United States. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1111/meta.12583. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: New Haven, Connecticut, United States, North and Central America, Technology, Emerging Technologies, Intelligent Agents, Machine Learning, Southern Connecticut State University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE (90%); INTELLIGENT AGENTS (90%); INVESTIGATIONS (90%); JOURNALISM (90%); NEWS REPORTING (90%); PHILOSOPHY (77%); EMERGING TECHNOLOGY (74%); ASSOCIATIONS & ORGANIZATIONS (72%); CUSTOMS & CULTURAL HERITAGE (67%); MACHINE LEARNING (58%); New Haven;State:Connecticut;United States;North and Central America;Technology;Emerging Technologies;Intelligent Agents;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INTELLIGENT AGENTS (90%); NEWS REPORTING (90%); MACHINE LEARNING (58%)
Geographic: NEW HAVEN, CT, USA (90%); CONNECTICUT, USA (96%); CENTRAL AMERICA (91%)
Load-Date: October 7, 2022",neutral,0.9342882633209229,balanced/neutral,[],[],['should'],['machine learning'],0,0,1,1
2021,Unknown Title,"Dateline: BEIJING, Nov. 28, 2022 
Body
PR Newswire
This is a news report from Science and Technology Daily:
The ethical issues brought by science and technology development concern the security and destiny of humankind. The research ethics, which includes a broad set of standards, values, and institutional arrangements that regulate research activities, will help to ensure that researchers can be held accountable to the public. 
According to Zhang Wenxia, researcher at the Chinese Academy of Science and Technology for Development, the research ethics is about maximizing the benefits and minimizing the harm and risks that may occur in R&D activities.
To ensure effective ethical supervision of different sectors, China established the National Ethics Committee on Science and Technology in 2020. In the revisedLaw on Progress of Science and Technology, article 103 states the committee should perfect the ethical norms. Zhang said that strengthening ethical governance is an intrinsic requirement for promoting the sustainable progress of sci-tech innovation in the new development stage.
Enhancing ethics education
Article 103 also states the country would strengthen the ethics education and research, and improve the review, evaluation and supervision system.
Zhang said the research on ethics includes the study on the risks, cultures, laws, social influences and the communication with the public. And the ethical education not only covers the researchers and postgraduates, but also extends to the training of management ability of workers in charge of ethical review, and the cultivation of professional talent teams.
The research associations and societies are expected to play an active role in ethics education in their respective fields, added Zhang.
Completing ethical system
The research institutes, universities, enterprises and other public institutions are responsible for research ethics governance. The ethics review mechanism should be established and improved for reviewing the research activities, says article 103.
In this regard, Zhang explained that these organizations should establish a regular working mechanism, and be active to analyze and resolve the ethical problems that appeared in research activities in time.
As for the management of research activities, Zhang said the ethical review of research projects and papers involving animal use, human subjects, and living environment should be strengthened before being approved or published.
Zhang pointed out that many provinces in China have established or are establishing their committees for research ethics. To ensure a high-quality review, for the regions and institutes whose qualifications are not sound enough for a committee, a shared committee at a provincial level is an option.
China's ethics is relatively mature in the fields of medicine and life science, and leads the world in artificial intelligence, said Zhang, suggesting that other key fields that are prone to ethical risks should formulate their own ethical norms as soon as possible, and adjust and improve them according to the new situations encountered in practice.
No pursuing benefits blindly
Risks and benefits are the two sides of research activities. Modern sciences, especially emerging technologies, are full of uncertainties.
The study and assessment of potential risks are needed before developing new technologies, and preventive measures should be put forward to tackle any emergency, said Zhang, noting that research should be suspended if the risks are higher than the actual benefits, such as the economic value and application prospects.
It also should be noted that a researcher can't fully get to the bottom of research at the outset, said Zhang, adding that the research is like an iceberg. The deeper the research goes, the more the iceberg will rise to the surface. Facing new uncertainties during research, the researchers are required to have an ethical awareness in making decisions and adjusting strategies accordingly, so as to ensure responsible research for the welfare of humankind.
 View original content:https://www.prnewswire.com/news-releases/ethical-norms-ensure-scientific-research-on-right-way-301688471.html
SOURCE Science and Technology Daily
CONTACT: Media ：Fang Linlin, fangll@stdaily.com  , +86 13911995172
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (99%); EXPERIMENTATION & RESEARCH (90%); SCIENCE & TECHNOLOGY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RESEARCH & DEVELOPMENT (89%); PRESS RELEASES (79%); EMERGING TECHNOLOGY (78%); RESEARCH INSTITUTES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMAN SUBJECTS (73%); MANAGER TRAINING (72%); EDITORIALS & OPINIONS (57%); ARTIFICIAL INTELLIGENCE (50%); Sci-TechDaily-ethic (%); AVO Advocacy Group Opinion (%)
Company: Science and Technology Daily
Industry: ARTIFICIAL INTELLIGENCE (50%); STM STEM (Science, Technology, Engineering, Mathematics) (%); CPR Computer; Electronics Products (%)
Geographic: BEIJING, CHINA (79%); NORTH CENTRAL CHINA (79%); CHINA (94%); China
Load-Date: November 29, 2022","PR Newswire
This is a news report from Science and Technology Daily:
The ethical issues brought by science and technology development concern the security and destiny of humankind. The research ethics, which includes a broad set of standards, values, and institutional arrangements that regulate research activities, will help to ensure that researchers can be held accountable to the public. 
According to Zhang Wenxia, researcher at the Chinese Academy of Science and Technology for Development, the research ethics is about maximizing the benefits and minimizing the harm and risks that may occur in R&D activities.
To ensure effective ethical supervision of different sectors, China established the National Ethics Committee on Science and Technology in 2020. In the revisedLaw on Progress of Science and Technology, article 103 states the committee should perfect the ethical norms. Zhang said that strengthening ethical governance is an intrinsic requirement for promoting the sustainable progress of sci-tech innovation in the new development stage.
Enhancing ethics education
Article 103 also states the country would strengthen the ethics education and research, and improve the review, evaluation and supervision system.
Zhang said the research on ethics includes the study on the risks, cultures, laws, social influences and the communication with the public. And the ethical education not only covers the researchers and postgraduates, but also extends to the training of management ability of workers in charge of ethical review, and the cultivation of professional talent teams.
The research associations and societies are expected to play an active role in ethics education in their respective fields, added Zhang.
Completing ethical system
The research institutes, universities, enterprises and other public institutions are responsible for research ethics governance. The ethics review mechanism should be established and improved for reviewing the research activities, says article 103.
In this regard, Zhang explained that these organizations should establish a regular working mechanism, and be active to analyze and resolve the ethical problems that appeared in research activities in time.
As for the management of research activities, Zhang said the ethical review of research projects and papers involving animal use, human subjects, and living environment should be strengthened before being approved or published.
Zhang pointed out that many provinces in China have established or are establishing their committees for research ethics. To ensure a high-quality review, for the regions and institutes whose qualifications are not sound enough for a committee, a shared committee at a provincial level is an option.
China's ethics is relatively mature in the fields of medicine and life science, and leads the world in artificial intelligence, said Zhang, suggesting that other key fields that are prone to ethical risks should formulate their own ethical norms as soon as possible, and adjust and improve them according to the new situations encountered in practice.
No pursuing benefits blindly
Risks and benefits are the two sides of research activities. Modern sciences, especially emerging technologies, are full of uncertainties.
The study and assessment of potential risks are needed before developing new technologies, and preventive measures should be put forward to tackle any emergency, said Zhang, noting that research should be suspended if the risks are higher than the actual benefits, such as the economic value and application prospects.
It also should be noted that a researcher can't fully get to the bottom of research at the outset, said Zhang, adding that the research is like an iceberg. The deeper the research goes, the more the iceberg will rise to the surface. Facing new uncertainties during research, the researchers are required to have an ethical awareness in making decisions and adjusting strategies accordingly, so as to ensure responsible research for the welfare of humankind.
 View original content:https://www.prnewswire.com/news-releases/ethical-norms-ensure-scientific-research-on-right-way-301688471.html
SOURCE Science and Technology Daily
CONTACT: Media ：Fang Linlin, fangll@stdaily.com  , +86 13911995172
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (99%); EXPERIMENTATION & RESEARCH (90%); SCIENCE & TECHNOLOGY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RESEARCH & DEVELOPMENT (89%); PRESS RELEASES (79%); EMERGING TECHNOLOGY (78%); RESEARCH INSTITUTES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); HUMAN SUBJECTS (73%); MANAGER TRAINING (72%); EDITORIALS & OPINIONS (57%); ARTIFICIAL INTELLIGENCE (50%); Sci-TechDaily-ethic (%); AVO Advocacy Group Opinion (%)
Company: Science and Technology Daily
Industry: ARTIFICIAL INTELLIGENCE (50%); STM STEM (Science, Technology, Engineering, Mathematics) (%); CPR Computer; Electronics Products (%)
Geographic: BEIJING, CHINA (79%); NORTH CENTRAL CHINA (79%); CHINA (94%); China
Load-Date: November 29, 2022",neutral,0.7660170793533325,balanced/neutral,['security'],[],"['governance', 'standards', 'should']",[],1,0,3,0
2021,Unknown Title,"Body
2022 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating from Krems, Austria, by NewsRx correspondents, research stated, ""AgeTech involves the use of emerging technologies to support the health, well-being and independent living of older adults. In this paper we focus on how AgeTech based on artificial intelligence (AI) may better support older adults to remain in their own living environment for longer, provide social connectedness, support wellbeing and mental health, and enable social participation."" 
 Financial support for this research came from Karl Landsteiner Privatuniversitat fur Gesundheitswissenschaften. 
 Our news editors obtained a quote from the research from the Karl Landsteiner University of Health Sciences, ""In order to assess and better understand the positive as well as negative outcomes of AI-based AgeTech, a critical analysis of ethical design, digital equity, and policy pathways is required. A crucial question is how AI-based AgeTech may drive practical, equitable, and inclusive multilevel solutions to support healthy, active ageing.In our paper, we aim to show that a focus on equity is key for AI-based AgeTech if it is to realize its full potential. We propose that equity should not just be an extra benefit or minimum requirement, but the explicit aim of designing AI-based health tech. This means that social determinants that affect the use of or access to these technologies have to be addressed. We will explore how complexity management as a crucial element of AI-based AgeTech may potentially create and exacerbate social inequities by marginalising or ignoring social determinants."" 
 According to the news editors, the research concluded: ""We identify bias, standardization, and access as main ethical issues in this context and subsequently, make recommendations as to how inequities that stem form AI-based AgeTech can be addressed."" 
 This research has been peer-reviewed. 
 For more information on this research see: Equity in AgeTech for Ageing Well in Technology-Driven Places: The Role of Social Determinants in Designing AI-based Assistive Technologies. Science and Engineering Ethics, 2022;28(6):49. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 The news editors report that additional information may be obtained by contacting Giovanni Rubeis, Dept. of General Health Studies, Division Biomedical and Public Health Ethics, Karl Landsteiner University of Health Sciences, Dr.-Karl-Dorrek-Straße 30, 3500, Krems, Austria. Additional authors for this research include Mei Lang Fang and Andrew Sixsmith. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-022-00397-y. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Publisher contact information for the journal Science and Engineering Ethics is: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Krems, Austria, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: AGING (90%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (90%); NEWS REPORTING (90%); ENGINEERING (89%); ETHICS (89%); MEDICAL TECHNOLOGY (79%); BIOMEDICINE (76%); INDEPENDENT LIVING PROGRAMS (76%); SENIOR CITIZENS (76%); NEGATIVE SOCIETAL NEWS (75%); EMERGING TECHNOLOGY (74%); WRITERS (73%); Krems;Austria;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); NEWS REPORTING (90%); ENGINEERING (89%); MEDICAL TECHNOLOGY (79%); BIOMEDICINE (76%); WRITERS (73%)
Geographic: EUROPE (73%); NETHERLANDS (58%)
Load-Date: November 4, 2022","2022 NOV 04 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating from Krems, Austria, by NewsRx correspondents, research stated, ""AgeTech involves the use of emerging technologies to support the health, well-being and independent living of older adults. In this paper we focus on how AgeTech based on artificial intelligence (AI) may better support older adults to remain in their own living environment for longer, provide social connectedness, support wellbeing and mental health, and enable social participation."" 
 Financial support for this research came from Karl Landsteiner Privatuniversitat fur Gesundheitswissenschaften. 
 Our news editors obtained a quote from the research from the Karl Landsteiner University of Health Sciences, ""In order to assess and better understand the positive as well as negative outcomes of AI-based AgeTech, a critical analysis of ethical design, digital equity, and policy pathways is required. A crucial question is how AI-based AgeTech may drive practical, equitable, and inclusive multilevel solutions to support healthy, active ageing.In our paper, we aim to show that a focus on equity is key for AI-based AgeTech if it is to realize its full potential. We propose that equity should not just be an extra benefit or minimum requirement, but the explicit aim of designing AI-based health tech. This means that social determinants that affect the use of or access to these technologies have to be addressed. We will explore how complexity management as a crucial element of AI-based AgeTech may potentially create and exacerbate social inequities by marginalising or ignoring social determinants."" 
 According to the news editors, the research concluded: ""We identify bias, standardization, and access as main ethical issues in this context and subsequently, make recommendations as to how inequities that stem form AI-based AgeTech can be addressed."" 
 This research has been peer-reviewed. 
 For more information on this research see: Equity in AgeTech for Ageing Well in Technology-Driven Places: The Role of Social Determinants in Designing AI-based Assistive Technologies. Science and Engineering Ethics, 2022;28(6):49. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 The news editors report that additional information may be obtained by contacting Giovanni Rubeis, Dept. of General Health Studies, Division Biomedical and Public Health Ethics, Karl Landsteiner University of Health Sciences, Dr.-Karl-Dorrek-Straße 30, 3500, Krems, Austria. Additional authors for this research include Mei Lang Fang and Andrew Sixsmith. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-022-00397-y. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Publisher contact information for the journal Science and Engineering Ethics is: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Krems, Austria, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: AGING (90%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MEDICAL SCIENCE (90%); MEDICINE & HEALTH (90%); NEWS REPORTING (90%); ENGINEERING (89%); ETHICS (89%); MEDICAL TECHNOLOGY (79%); BIOMEDICINE (76%); INDEPENDENT LIVING PROGRAMS (76%); SENIOR CITIZENS (76%); NEGATIVE SOCIETAL NEWS (75%); EMERGING TECHNOLOGY (74%); WRITERS (73%); Krems;Austria;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); NEWS REPORTING (90%); ENGINEERING (89%); MEDICAL TECHNOLOGY (79%); BIOMEDICINE (76%); WRITERS (73%)
Geographic: EUROPE (73%); NETHERLANDS (58%)
Load-Date: November 4, 2022",neutral,0.7984722256660461,balanced/neutral,"['bias', 'access']",['equity'],"['policy', 'should', 'propose']",[],2,1,3,0
2021,Unknown Title,"Dateline: STOCKHOLM, Jan. 26, 2022 
Body
PR Newswire
Against the rising tide of regulation,anch.AIhas released the first horizontally integrated ethical AI governance platform, a one-stop shop for businesses to accelerate responsible AI adoption across their organization. The B2B SaaS startup emerged from the AI Sustainability Center, a Swedish think tank, and has secured $2.1M in seed funding to further develop and launch their pioneering risk assessment platform. The round was led by Benhamou Global Ventures (BGV), with participation from Terrain Invest, Magnus Rausing, Kent Janér and Fredrik Andersson.
Demand for AI governance tools has surged as organizations that operate in the European Union anticipate implementing sweeping GDPR-caliber changes due to proposed regulation on the development and use of artificial intelligence. Noncompliant companies could face fines up to 6% of their global turnover or 30 million euros. Yet,McKinsey researchsuggests that companies lack the capacity to address the full range of AI risks they face, and many are unclear on the extent of their risk exposure or the harm their AI could cause society and individuals, such as unintended discrimination, privacy intrusion and social exclusion.
""AI solutions are often developed in a silo without integrated technical, legal, ethical and business related oversight, which opens the door to costly and damaging risk for the business,"" said Anna Felländer, anch.AI's Founder. ""We developed the anch.AI platform for enterprises' visibility and orchestration of AI, identify risks as well as their root causes, and remedy the areas of exposure.""
Enursing alignment with collective ethical values and compliance to existing and upcoming regulation, the anch.AI platform offers screening, assessment, mitigation and reporting on one coherent platform. The assessment methodology stems from multidisciplinary research to detect and remedy ethical risks in companies' AI solutions.
""anch.AI is pioneering an industry-first Ethical AI Governance Platform providing the best balance between speed, choice and development of ethical AI,"" said Anik Bose, general partner of BGV. ""We believe AI risk represents a sleeping giant in our industry, and the anch.ai platform can make a major impact in addressing these ethical challenges as a single source of truth.""
anch.AI invites organizations to complete its freeEthical AI Health Check,which uncovers their organization's exposure to ethical and legal breaches. This initial screening is an important first step to developing AI that humans can trust, regardless of their background.
The research team of the former AI Sustainability Center will continue to pursue world leading multidisciplinary research in the independent newly founded Research Institute for Sustainable AI, led by Ricardo Vinuesa, Ph.D. and AI researcher at the Royal Institute of Technology in Sweden.
""We are thrilled to continue our research on Sustainable AI to ensure human values are kept at the core, while the anch.AI platform focuses on scaling their offering to businesses,"" says Vinuesa, Director of the Research Institute for Sustainable AI.
More information about anch.AI and its Ethical AI Governance Platform is available athttps://anch.ai/the-offering/.
ABOUT ANCH.AIanch.AI was founded in 2018 by Anna Felländer—a leading expert on the effects of digitalization on organizations, society, and the economy—to determine the ethical and societal risks of AI. Originally formed as a multidisciplinary research and consulting think tank, anch.AI pivoted in 2021 to developing a risk assessment platform for businesses to ensure their use of AI is ethical and compliant with forthcoming regulation in the European Union. The customer base of over 20 customers using the products leading up to the platform, is ranging from global biopharmaceutical, retail and telecommunication companies to national agencies across the Nordic region. The company has secured $2.1M in seed funding, led by Benhamou Global Ventures, with additional participation from Terrain Invest, Magnus Rausing, Kent Janér and Fredrik Andersson. anch.AI is headquartered in Stockholm, Sweden. Visithttps://anch.aito learn more.
 View original content to download multimedia:https://www.prnewswire.com/news-releases/anchai-former-ai-sustainability-center-secures-2-1m-in-seed-funding-to-launch-ethical-ai-governance-platform-301467656.html
SOURCE anch.AI
CONTACT: US: BAM, anchai@bamtheagency.com  ; EUROPE: Miltton Labs, fredrik.andersson@miltton.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); NEGATIVE SOCIETAL NEWS (90%); SUSTAINABLE DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RESEARCH INSTITUTES (89%); PRESS RELEASES (79%); BUSINESS ETHICS (78%); FINES & PENALTIES (78%); RISK MANAGEMENT (78%); EU DATA PROTECTION REGULATION (75%); INTERNATIONAL ECONOMIC ORGANIZATIONS (75%); EUROPEAN UNION (73%); PLATFORMS & ISSUES (73%); DISCRIMINATION (71%); ANCH.AI-sec-seed-fund (%); PDT New Products and Services (%); VEN Venture Capital (%)
Company: anch.AI
Organization:  EUROPEAN UNION (57%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); RISK MANAGEMENT (78%); MOVIE RELEASE DATES (77%); EU DATA PROTECTION REGULATION (75%); FIN Banking; Financial Services (%); CPR Computer; Electronics Products (%)
Geographic: STOCKHOLM, SWEDEN (59%); SWEDEN (90%); EUROPEAN UNION MEMBER STATES (73%); EUROPE (58%); Sweden
Load-Date: January 26, 2022","PR Newswire
Against the rising tide of regulation,anch.AIhas released the first horizontally integrated ethical AI governance platform, a one-stop shop for businesses to accelerate responsible AI adoption across their organization. The B2B SaaS startup emerged from the AI Sustainability Center, a Swedish think tank, and has secured $2.1M in seed funding to further develop and launch their pioneering risk assessment platform. The round was led by Benhamou Global Ventures (BGV), with participation from Terrain Invest, Magnus Rausing, Kent Janér and Fredrik Andersson.
Demand for AI governance tools has surged as organizations that operate in the European Union anticipate implementing sweeping GDPR-caliber changes due to proposed regulation on the development and use of artificial intelligence. Noncompliant companies could face fines up to 6% of their global turnover or 30 million euros. Yet,McKinsey researchsuggests that companies lack the capacity to address the full range of AI risks they face, and many are unclear on the extent of their risk exposure or the harm their AI could cause society and individuals, such as unintended discrimination, privacy intrusion and social exclusion.
""AI solutions are often developed in a silo without integrated technical, legal, ethical and business related oversight, which opens the door to costly and damaging risk for the business,"" said Anna Felländer, anch.AI's Founder. ""We developed the anch.AI platform for enterprises' visibility and orchestration of AI, identify risks as well as their root causes, and remedy the areas of exposure.""
Enursing alignment with collective ethical values and compliance to existing and upcoming regulation, the anch.AI platform offers screening, assessment, mitigation and reporting on one coherent platform. The assessment methodology stems from multidisciplinary research to detect and remedy ethical risks in companies' AI solutions.
""anch.AI is pioneering an industry-first Ethical AI Governance Platform providing the best balance between speed, choice and development of ethical AI,"" said Anik Bose, general partner of BGV. ""We believe AI risk represents a sleeping giant in our industry, and the anch.ai platform can make a major impact in addressing these ethical challenges as a single source of truth.""
anch.AI invites organizations to complete its freeEthical AI Health Check,which uncovers their organization's exposure to ethical and legal breaches. This initial screening is an important first step to developing AI that humans can trust, regardless of their background.
The research team of the former AI Sustainability Center will continue to pursue world leading multidisciplinary research in the independent newly founded Research Institute for Sustainable AI, led by Ricardo Vinuesa, Ph.D. and AI researcher at the Royal Institute of Technology in Sweden.
""We are thrilled to continue our research on Sustainable AI to ensure human values are kept at the core, while the anch.AI platform focuses on scaling their offering to businesses,"" says Vinuesa, Director of the Research Institute for Sustainable AI.
More information about anch.AI and its Ethical AI Governance Platform is available athttps://anch.ai/the-offering/.
ABOUT ANCH.AIanch.AI was founded in 2018 by Anna Felländer—a leading expert on the effects of digitalization on organizations, society, and the economy—to determine the ethical and societal risks of AI. Originally formed as a multidisciplinary research and consulting think tank, anch.AI pivoted in 2021 to developing a risk assessment platform for businesses to ensure their use of AI is ethical and compliant with forthcoming regulation in the European Union. The customer base of over 20 customers using the products leading up to the platform, is ranging from global biopharmaceutical, retail and telecommunication companies to national agencies across the Nordic region. The company has secured $2.1M in seed funding, led by Benhamou Global Ventures, with additional participation from Terrain Invest, Magnus Rausing, Kent Janér and Fredrik Andersson. anch.AI is headquartered in Stockholm, Sweden. Visithttps://anch.aito learn more.
 View original content to download multimedia:https://www.prnewswire.com/news-releases/anchai-former-ai-sustainability-center-secures-2-1m-in-seed-funding-to-launch-ethical-ai-governance-platform-301467656.html
SOURCE anch.AI
CONTACT: US: BAM, anchai@bamtheagency.com  ; EUROPE: Miltton Labs, fredrik.andersson@miltton.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); NEGATIVE SOCIETAL NEWS (90%); SUSTAINABLE DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (89%); RESEARCH INSTITUTES (89%); PRESS RELEASES (79%); BUSINESS ETHICS (78%); FINES & PENALTIES (78%); RISK MANAGEMENT (78%); EU DATA PROTECTION REGULATION (75%); INTERNATIONAL ECONOMIC ORGANIZATIONS (75%); EUROPEAN UNION (73%); PLATFORMS & ISSUES (73%); DISCRIMINATION (71%); ANCH.AI-sec-seed-fund (%); PDT New Products and Services (%); VEN Venture Capital (%)
Company: anch.AI
Organization:  EUROPEAN UNION (57%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (90%); RISK MANAGEMENT (78%); MOVIE RELEASE DATES (77%); EU DATA PROTECTION REGULATION (75%); FIN Banking; Financial Services (%); CPR Computer; Electronics Products (%)
Geographic: STOCKHOLM, SWEDEN (59%); SWEDEN (90%); EUROPEAN UNION MEMBER STATES (73%); EUROPE (58%); Sweden
Load-Date: January 26, 2022",neutral,0.7053809762001038,balanced/neutral,"['privacy', 'discrimination']",[],"['regulation', 'governance', 'oversight', 'compliance']",[],2,0,4,0
2021,Unknown Title,"Body
Link to Story
New Delhi, April 25 (IANS) The controversies through business ethics usually stem from violations of insider trading rules and non-compliance with SEBI LODR guidelines.
Business Ethics has emerged to occupy a major portion of controversies both in service and manufacturing sector with as much as 72.6 per cent, as per the research and analysis carried out by ESGRisk.ai with NSE 600 companies in the financial year 2020-21. This is despite the fact that corporations are taking measures for sustainable business practices.
The controversies in the key issue of business ethics grew significantly between FY2020 and FY2021.
Sankar Chakraborti, Chairman, ESGRisk.ai & Group CEO, Acuite, said that 'several of the controversies are predominantly with respect to business ethics and stem from violations of insider trading rules, money laundering and non-compliance with SEBI LODR guidelines. BSFI sector is at the heart of ESG integration, the industry should set up policies, undertake initiatives and curate training programs apart from just following the regulations'.
Among the industries that have experienced the most controversies after Banking & Financial Services, are Pharmaceuticals and Metals.
ESGRisk.ai has also recognised a rise in contentions over environmental management issues in FY2021.
In several cases, pollution control boards' regulations with respect to emissions, water pollution and environmental management were violated. In the social category, a rise in controversies related to employee safety has been observed. Occupational health and safety hazards are largely attributed to plant fires and explosions, inadequate maintenance of machinery, and poor handling by workers.
Corporate frauds in India are frequent whistle blower complaints, corrupt audit practices and compliance fines are typical corporate governance controversies.
According to ESGRisk.ai's research, the controversies in the key issue of business ethics grew significantly between FY2020 and FY2021. Several of the controversies stem from violations of insider trading rules and non-compliance with SEBI LODR guidelines.
--IANS
san/ksk/
MENAFN25042022000231011071ID1104087791
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (93%); NEGATIVE PERSONAL NEWS (91%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); INSIDER TRADING (90%); NEGATIVE BUSINESS NEWS (90%); NEGATIVE ENVIRONMENTAL NEWS (90%); POLLUTION (90%); POLLUTION & ENVIRONMENTAL IMPACTS (90%); SAFETY (90%); NEGATIVE NEWS (89%); OCCUPATIONAL HEALTH & SAFETY LAW (87%); COMPANY ACTIVITIES & MANAGEMENT (78%); CORPORATE GOVERNANCE (78%); CORPORATE SUSTAINABILITY (78%); CORPORATE WRONGDOING (78%); ENVIRONMENTAL REGULATION & POLICY (78%); ESG FACTORS (78%); OCCUPATIONAL HEALTH & SAFETY AGENCIES (78%); SUSTAINABLE DEVELOPMENT (77%); ESG FACTORS - GOVERNANCE (75%); CORRUPTION (73%); WHISTLEBLOWERS (73%); MANUFACTURING OUTPUT (72%); ENVIRONMENT & NATURAL RESOURCES (71%); WATER POLLUTION (71%); SUSTAINABILITY (70%); WORKPLACE HEALTH & SAFETY (69%); MONEY LAUNDERING (68%); POLLUTION MONITORING, PREVENTION & REMEDIATION (66%); SAFETY, ACCIDENTS & DISASTERS (64%)
Industry: BANKING & FINANCE (90%); INSIDER TRADING (90%); MANUFACTURING (78%); SUSTAINABLE DEVELOPMENT (77%); PHARMACEUTICALS & BIOTECHNOLOGY (73%); MANUFACTURING OUTPUT (72%)
Geographic: NEW DELHI, INDIA (73%); INDIA (91%)
Load-Date: September 2, 2022","Link to Story
New Delhi, April 25 (IANS) The controversies through business ethics usually stem from violations of insider trading rules and non-compliance with SEBI LODR guidelines.
Business Ethics has emerged to occupy a major portion of controversies both in service and manufacturing sector with as much as 72.6 per cent, as per the research and analysis carried out by ESGRisk.ai with NSE 600 companies in the financial year 2020-21. This is despite the fact that corporations are taking measures for sustainable business practices.
The controversies in the key issue of business ethics grew significantly between FY2020 and FY2021.
Sankar Chakraborti, Chairman, ESGRisk.ai & Group CEO, Acuite, said that 'several of the controversies are predominantly with respect to business ethics and stem from violations of insider trading rules, money laundering and non-compliance with SEBI LODR guidelines. BSFI sector is at the heart of ESG integration, the industry should set up policies, undertake initiatives and curate training programs apart from just following the regulations'.
Among the industries that have experienced the most controversies after Banking & Financial Services, are Pharmaceuticals and Metals.
ESGRisk.ai has also recognised a rise in contentions over environmental management issues in FY2021.
In several cases, pollution control boards' regulations with respect to emissions, water pollution and environmental management were violated. In the social category, a rise in controversies related to employee safety has been observed. Occupational health and safety hazards are largely attributed to plant fires and explosions, inadequate maintenance of machinery, and poor handling by workers.
Corporate frauds in India are frequent whistle blower complaints, corrupt audit practices and compliance fines are typical corporate governance controversies.
According to ESGRisk.ai's research, the controversies in the key issue of business ethics grew significantly between FY2020 and FY2021. Several of the controversies stem from violations of insider trading rules and non-compliance with SEBI LODR guidelines.
--IANS
san/ksk/
MENAFN25042022000231011071ID1104087791
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (93%); NEGATIVE PERSONAL NEWS (91%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); INSIDER TRADING (90%); NEGATIVE BUSINESS NEWS (90%); NEGATIVE ENVIRONMENTAL NEWS (90%); POLLUTION (90%); POLLUTION & ENVIRONMENTAL IMPACTS (90%); SAFETY (90%); NEGATIVE NEWS (89%); OCCUPATIONAL HEALTH & SAFETY LAW (87%); COMPANY ACTIVITIES & MANAGEMENT (78%); CORPORATE GOVERNANCE (78%); CORPORATE SUSTAINABILITY (78%); CORPORATE WRONGDOING (78%); ENVIRONMENTAL REGULATION & POLICY (78%); ESG FACTORS (78%); OCCUPATIONAL HEALTH & SAFETY AGENCIES (78%); SUSTAINABLE DEVELOPMENT (77%); ESG FACTORS - GOVERNANCE (75%); CORRUPTION (73%); WHISTLEBLOWERS (73%); MANUFACTURING OUTPUT (72%); ENVIRONMENT & NATURAL RESOURCES (71%); WATER POLLUTION (71%); SUSTAINABILITY (70%); WORKPLACE HEALTH & SAFETY (69%); MONEY LAUNDERING (68%); POLLUTION MONITORING, PREVENTION & REMEDIATION (66%); SAFETY, ACCIDENTS & DISASTERS (64%)
Industry: BANKING & FINANCE (90%); INSIDER TRADING (90%); MANUFACTURING (78%); SUSTAINABLE DEVELOPMENT (77%); PHARMACEUTICALS & BIOTECHNOLOGY (73%); MANUFACTURING OUTPUT (72%)
Geographic: NEW DELHI, INDIA (73%); INDIA (91%)
Load-Date: September 2, 2022",neutral,0.6851998567581177,balanced/neutral,['safety'],[],"['regulation', 'policy', 'governance', 'guidelines', 'law', 'compliance', 'audit', 'should']",[],1,0,8,0
2021,Unknown Title,"Body
ATHENS, Ga., Oct. 14 -- The University of Georgia issued the following news release:
The University of Georgia will participate in the University System of Georgia's Ethics Awareness Week, scheduled for Nov. 7-13.
This year's theme is ""It's Up To All Of Us To Create A More Ethical Culture,"" and several upcoming events for faculty, staff and students aim to build that culture.
The Department of Philosophy will host a talk by Mary Beth Willard, professor of philosophy at Weber State University, on ""Why Artists Won't Stay #Canceled"" on Oct. 20 at 4 p.m. in Room 115 of Peabody Hall. Her talk explores why some artists who were canceled are now returning and embracing their counterculture status.
On Oct. 22, the philosophy department is hosting a Mini Ethics Bowl. Teams of up to four will debate ethical dilemmas for a chance at prizes. This tournament-style competition will take place over several rounds in Peabody Hall, with a final showdown between the top teams taking place in Room 115. Coffee and lunch will be provided for participants. Registration is available here.
Additionally, UGA is fielding an intercollegiate ethics bowl team for the first time. The team's practice includes a scrimmage with the United States Military Academy at West Point, and they will compete in a regional competition at the University of North Georgia on Nov. 12.
The Ethics Film Festival kicks off Nov. 3. Throughout the month, films that raise ethical issues about AI and technology will be shown from 7-10 p.m. in Room 400 of the Fine Arts Building. Showings are free and open to all, and UGA faculty will introduce the films and facilitate a brief discussion afterward.
The films include the following:
* 3: ""Alphaville"" facilitated by Richard Neupert (Department of Theater and Film) and Aaron Meskin (Department of Philosophy)
* 9: ""Minority Report"" facilitated by Jeremy Davis (Department of Philosophy)
* 16: ""Her"" facilitated by Vivian Appler (Department of Theater and Film)
* 30: ""Limitless"" facilitated by Sarah Wright (Department of Philosophy)
Ethics Awareness Week begins with ""Chancellor's Chat: Promoting a Culture of Excellence,"" a virtual discussion with USG Chancellor Sonny Perdue and Dan Cathy, chairman of Chick-fil-A, Inc., from 11 a.m. to noon on Nov. 7. USG will also host a virtual best practices panel discussion on ""Steering an Ethical Culture through Rapid Change and the Great Resignation"" from 11 a.m. to noon on Nov. 10.
Tristan Leavitt, attorney and member of the Merit Systems Protection Board, will deliver the Getzen Lecture on Government Accountability on Nov. 9 at 2 p.m. in the Special Collections Library auditorium. The event is a fall 2022 Signature Lecture and is sponsored by the School of Public and International Affairs' Department of Public Administration and Policy. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); ARTS & HUMANITIES EDUCATION (90%); PHILOSOPHY (90%); SOCIAL SCIENCE EDUCATION (90%); ARTISTS & PERFORMERS (89%); FILM (89%); FILM SCHOOLS (89%); BEST PRACTICES (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); FESTIVALS (78%); HUMANITIES & SOCIAL SCIENCE (78%); MILITARY SCHOOLS & ACADEMIES (78%); TRENDS & EVENTS (78%); RESIGNATIONS (76%); ARTIFICIAL INTELLIGENCE ETHICS (73%); EDUCATIONAL INSTITUTION EMPLOYEES (73%); EMPLOYMENT TRENDS (71%); ARTS FESTIVALS & EXHIBITIONS (70%); TOURNAMENTS (67%); FILM FESTIVALS (64%); LIBRARIES (64%)
Company:  CHICK-FIL-A INC (62%)
Organization: UNIVERSITY OF GEORGIA (93%); UNITED STATES MILITARY ACADEMY (72%); WEBER STATE UNIVERSITY (57%)
Industry: SIC5812 EATING PLACES (62%); ARTISTS & PERFORMERS (89%); FILM (89%); FILM SCHOOLS (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); FESTIVALS (78%); MILITARY SCHOOLS & ACADEMIES (78%); SPONSORSHIP (78%); ARTIFICIAL INTELLIGENCE ETHICS (73%); MEETING FACILITATION (73%); ARTS FESTIVALS & EXHIBITIONS (70%); FILM FESTIVALS (64%); LIBRARIES (64%)
Person: SONNY PERDUE (58%); DAN CATHY (51%)
Geographic: ATHENS, GA, USA (79%); GEORGIA, USA (94%); UNITED STATES (79%)
Load-Date: October 15, 2022","ATHENS, Ga., Oct. 14 -- The University of Georgia issued the following news release:
The University of Georgia will participate in the University System of Georgia's Ethics Awareness Week, scheduled for Nov. 7-13.
This year's theme is ""It's Up To All Of Us To Create A More Ethical Culture,"" and several upcoming events for faculty, staff and students aim to build that culture.
The Department of Philosophy will host a talk by Mary Beth Willard, professor of philosophy at Weber State University, on ""Why Artists Won't Stay #Canceled"" on Oct. 20 at 4 p.m. in Room 115 of Peabody Hall. Her talk explores why some artists who were canceled are now returning and embracing their counterculture status.
On Oct. 22, the philosophy department is hosting a Mini Ethics Bowl. Teams of up to four will debate ethical dilemmas for a chance at prizes. This tournament-style competition will take place over several rounds in Peabody Hall, with a final showdown between the top teams taking place in Room 115. Coffee and lunch will be provided for participants. Registration is available here.
Additionally, UGA is fielding an intercollegiate ethics bowl team for the first time. The team's practice includes a scrimmage with the United States Military Academy at West Point, and they will compete in a regional competition at the University of North Georgia on Nov. 12.
The Ethics Film Festival kicks off Nov. 3. Throughout the month, films that raise ethical issues about AI and technology will be shown from 7-10 p.m. in Room 400 of the Fine Arts Building. Showings are free and open to all, and UGA faculty will introduce the films and facilitate a brief discussion afterward.
The films include the following:
* 3: ""Alphaville"" facilitated by Richard Neupert (Department of Theater and Film) and Aaron Meskin (Department of Philosophy)
* 9: ""Minority Report"" facilitated by Jeremy Davis (Department of Philosophy)
* 16: ""Her"" facilitated by Vivian Appler (Department of Theater and Film)
* 30: ""Limitless"" facilitated by Sarah Wright (Department of Philosophy)
Ethics Awareness Week begins with ""Chancellor's Chat: Promoting a Culture of Excellence,"" a virtual discussion with USG Chancellor Sonny Perdue and Dan Cathy, chairman of Chick-fil-A, Inc., from 11 a.m. to noon on Nov. 7. USG will also host a virtual best practices panel discussion on ""Steering an Ethical Culture through Rapid Change and the Great Resignation"" from 11 a.m. to noon on Nov. 10.
Tristan Leavitt, attorney and member of the Merit Systems Protection Board, will deliver the Getzen Lecture on Government Accountability on Nov. 9 at 2 p.m. in the Special Collections Library auditorium. The event is a fall 2022 Signature Lecture and is sponsored by the School of Public and International Affairs' Department of Public Administration and Policy. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); ARTS & HUMANITIES EDUCATION (90%); PHILOSOPHY (90%); SOCIAL SCIENCE EDUCATION (90%); ARTISTS & PERFORMERS (89%); FILM (89%); FILM SCHOOLS (89%); BEST PRACTICES (78%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); FESTIVALS (78%); HUMANITIES & SOCIAL SCIENCE (78%); MILITARY SCHOOLS & ACADEMIES (78%); TRENDS & EVENTS (78%); RESIGNATIONS (76%); ARTIFICIAL INTELLIGENCE ETHICS (73%); EDUCATIONAL INSTITUTION EMPLOYEES (73%); EMPLOYMENT TRENDS (71%); ARTS FESTIVALS & EXHIBITIONS (70%); TOURNAMENTS (67%); FILM FESTIVALS (64%); LIBRARIES (64%)
Company:  CHICK-FIL-A INC (62%)
Organization: UNIVERSITY OF GEORGIA (93%); UNITED STATES MILITARY ACADEMY (72%); WEBER STATE UNIVERSITY (57%)
Industry: SIC5812 EATING PLACES (62%); ARTISTS & PERFORMERS (89%); FILM (89%); FILM SCHOOLS (89%); COLLEGE & UNIVERSITY PROFESSORS (78%); COLLEGES & UNIVERSITIES (78%); FESTIVALS (78%); MILITARY SCHOOLS & ACADEMIES (78%); SPONSORSHIP (78%); ARTIFICIAL INTELLIGENCE ETHICS (73%); MEETING FACILITATION (73%); ARTS FESTIVALS & EXHIBITIONS (70%); FILM FESTIVALS (64%); LIBRARIES (64%)
Person: SONNY PERDUE (58%); DAN CATHY (51%)
Geographic: ATHENS, GA, USA (79%); GEORGIA, USA (94%); UNITED STATES (79%)
Load-Date: October 15, 2022",neutral,0.88420170545578,balanced/neutral,['accountability'],[],['policy'],[],1,0,1,0
2021,Unknown Title,"Body
2022 DEC 05 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Artificial Intelligence and Ethics is the subject of a report. According to news reporting originating from Swansea, United Kingdom, by NewsRx correspondents, research stated, ""Ethics of technology systems have become an area of interest in academic research as well as international policy in recent years. Several organisation have consequently published principles of ethical artificial intelligence (AI) in line with this trend."" 
 Financial support for this research came from Engineering and Physical Sciences Research Council. 
 Our news editors obtained a quote from the research from Swansea University, ""The documents identify principles, values, and other abstract requirements for AI development and deployment. Critics raise concerns about whether these documents are in fact constructive, or if they are produced as a higher form of virtue signalling. A theme that is beginning to become apparent in the academic literature regarding these documents is the inherent lack of effective and practical methods and processes for producing ethical AI. This article attempts a critical analysis which draws upon ethical AI documents from a range of contexts including company, organisational, governmental, and academic perspectives. Both the theoretical and practical components of AI guidelines are explored and analysed, consequently bringing to light the necessity of introducing a measurable component to such documents for the purpose of ensuring a positive outcome of deploying AI systems based on ethical principles."" 
 According to the news editors, the research concluded: ""We propose a minimal framework for stakeholders to develop AI in an ethical and human-centred manner."" 
 This research has been peer-reviewed. 
 For more information on this research see: All that glitters is not gold: trustworthy and ethical AI principles. AI and Ethics, 2022:1-14. 
 The news editors report that additional information may be obtained by contacting Berndt Muller, Dept. of Computer Science, Swansea University, Swansea, UK. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00232-x. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Swansea, United Kingdom, Europe, Artificial Intelligence and Ethics. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); LITERATURE (89%); COMPUTER SCIENCE (79%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); JOURNALISM (78%); NEWS REPORTING (78%); COLLEGES & UNIVERSITIES (77%); ENGINEERING (77%); TRENDS (77%); Swansea;United Kingdom;Europe;Artificial Intelligence and Ethics (%)
Company:  AI SYSTEMS (54%)
Organization: ENGINEERING & PHYSICAL SCIENCES RESEARCH COUNCIL (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INDUSTRIAL AUTOMATION (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); NEWS REPORTING (78%); COLLEGES & UNIVERSITIES (77%); ENGINEERING (77%)
Geographic: SWANSEA, WALES (91%); UNITED KINGDOM (90%); EUROPE (73%)
Load-Date: December 5, 2022","2022 DEC 05 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Artificial Intelligence and Ethics is the subject of a report. According to news reporting originating from Swansea, United Kingdom, by NewsRx correspondents, research stated, ""Ethics of technology systems have become an area of interest in academic research as well as international policy in recent years. Several organisation have consequently published principles of ethical artificial intelligence (AI) in line with this trend."" 
 Financial support for this research came from Engineering and Physical Sciences Research Council. 
 Our news editors obtained a quote from the research from Swansea University, ""The documents identify principles, values, and other abstract requirements for AI development and deployment. Critics raise concerns about whether these documents are in fact constructive, or if they are produced as a higher form of virtue signalling. A theme that is beginning to become apparent in the academic literature regarding these documents is the inherent lack of effective and practical methods and processes for producing ethical AI. This article attempts a critical analysis which draws upon ethical AI documents from a range of contexts including company, organisational, governmental, and academic perspectives. Both the theoretical and practical components of AI guidelines are explored and analysed, consequently bringing to light the necessity of introducing a measurable component to such documents for the purpose of ensuring a positive outcome of deploying AI systems based on ethical principles."" 
 According to the news editors, the research concluded: ""We propose a minimal framework for stakeholders to develop AI in an ethical and human-centred manner."" 
 This research has been peer-reviewed. 
 For more information on this research see: All that glitters is not gold: trustworthy and ethical AI principles. AI and Ethics, 2022:1-14. 
 The news editors report that additional information may be obtained by contacting Berndt Muller, Dept. of Computer Science, Swansea University, Swansea, UK. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00232-x. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Swansea, United Kingdom, Europe, Artificial Intelligence and Ethics. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); LITERATURE (89%); COMPUTER SCIENCE (79%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); JOURNALISM (78%); NEWS REPORTING (78%); COLLEGES & UNIVERSITIES (77%); ENGINEERING (77%); TRENDS (77%); Swansea;United Kingdom;Europe;Artificial Intelligence and Ethics (%)
Company:  AI SYSTEMS (54%)
Organization: ENGINEERING & PHYSICAL SCIENCES RESEARCH COUNCIL (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (54%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INDUSTRIAL AUTOMATION (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPUTER SCIENCE (79%); NEWS REPORTING (78%); COLLEGES & UNIVERSITIES (77%); ENGINEERING (77%)
Geographic: SWANSEA, WALES (91%); UNITED KINGDOM (90%); EUROPE (73%)
Load-Date: December 5, 2022",neutral,0.8545583486557007,balanced/neutral,['security'],[],"['policy', 'guidelines', 'framework', 'propose']","['machine learning', 'robotics']",1,0,4,2
2021,Unknown Title,"Byline: Eurasia Review
Body
With the accelerating evolution of technology, artificial intelligence (AI) plays a growing role in decision-making processes. Humans are becoming increasingly dependent on algorithms to process information, recommend certain behaviors, and even take actions of their behalf. A research team has studied how humans react to the introduction of AI decision making. Specifically, they explored the question, ""is society ready for AI ethical decision making?"" by studying human interaction with autonomous cars.
The team published their findings in the Journal of Behavioral and Experimental Economics.
In the first of two experiments, the researchers presented 529 human subjects with an ethical dilemma a driver might face. In the scenario the researchers created, the car driver had to decide whether to crash the car into one group of people or another - the collision was unavoidable. The crash would cause severe harm to one group of people, but would save the lives of the other group. The subjects in the study had to rate the car driver's decision, when the driver was a human and also when the driver was AI. This first experiment was designed to measure the bias people might have against AI ethical decision making.
In their second experiment, 563 human subjects responded to the researchers' questions. The researchers determined how people react to the debate over AI ethical decisions once they become part of social and political discussions. In this experiment, there were two scenarios. One involved a hypothetical government that had already decided to allow autonomous cars to make ethical decisions. Their other scenario allowed the subjects to ""vote"" whether to allow the autonomous cars to make ethical decisions. In both cases, the subjects could choose to be in favor of or against the decisions made by the technology. This second experiment was designed to test the effect of two alternative ways of introducing AI into society.
The researchers observed that when the subjects were asked to evaluate the ethical decisions of either a human or AI driver, they did not have a definitive preference for either. However, when the subjects were asked their explicit opinion on whether a driver should be allowed to make ethical decisions on the road, the subjects had a stronger opinion against AI-operated cars. The researchers believe that the discrepancy between the two results is caused by a combination of two elements.
The first element is that individual people believe society as a whole does not want AI ethical decision making, and so they assign a positive weight to their beliefs when asked for their opinion on the matter. ""Indeed, when participants are asked explicitly to separate their answers from those of society, the difference between the permissibility for AI and human drivers vanishes,"" said Johann Caro-Burnett, an assistant professor in the Graduate School of Humanities and Social Sciences, Hiroshima University.
The second element is that when introducing this new technology into society, allowing discussion of the topic has mixed results depending on the country. ""In regions where people trust their government and have strong political institutions, information and decision-making power improve how subjects evaluate the ethical decisions of AI. In contrast, in regions where people do not trust their government and have weak political institutions, decision-making capability deteriorates how subjects evaluate the ethical decisions of AI,"" said Caro-Burnett.
""We find that there is a social fear of AI ethical decision-making. However, the source of this fear is not intrinsic to individuals. Indeed, this rejection of AI comes from what individuals believe is the society's opinion,"" said Shinji Kaneko, a professor in the Graduate School of Humanities and Social Sciences, Hiroshima University, and the Network for Education and Research on Peace and Sustainability. So when not being asked explicitly, people do not show any signs of bias against AI ethical decision-making. However, when asked explicitly, people show an aversion to AI. Furthermore, where there is added discussion and information on the topic, the acceptance of AI improves in developed countries and worsens in developing countries.
The researchers believe this rejection of a new technology, that is mostly due to incorporating individuals' beliefs about society's opinion, is likely to apply in other machines and robots. ""Therefore, it will be important to determine how to aggregate individual preferences into one social preference. Moreover, this task will also have to be different across countries, as our results suggest,"" said Kaneko.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1556
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HUMANITIES & SOCIAL SCIENCE (78%); RESEARCH REPORTS (78%); SOCIAL SCIENCE EDUCATION (75%); ARTS & HUMANITIES EDUCATION (60%); COLLEGE & UNIVERSITY PROFESSORS (60%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); AUTONOMOUS MOTOR VEHICLES (89%); COLLEGE & UNIVERSITY PROFESSORS (60%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Load-Date: June 6, 2022","With the accelerating evolution of technology, artificial intelligence (AI) plays a growing role in decision-making processes. Humans are becoming increasingly dependent on algorithms to process information, recommend certain behaviors, and even take actions of their behalf. A research team has studied how humans react to the introduction of AI decision making. Specifically, they explored the question, ""is society ready for AI ethical decision making?"" by studying human interaction with autonomous cars.
The team published their findings in the Journal of Behavioral and Experimental Economics.
In the first of two experiments, the researchers presented 529 human subjects with an ethical dilemma a driver might face. In the scenario the researchers created, the car driver had to decide whether to crash the car into one group of people or another - the collision was unavoidable. The crash would cause severe harm to one group of people, but would save the lives of the other group. The subjects in the study had to rate the car driver's decision, when the driver was a human and also when the driver was AI. This first experiment was designed to measure the bias people might have against AI ethical decision making.
In their second experiment, 563 human subjects responded to the researchers' questions. The researchers determined how people react to the debate over AI ethical decisions once they become part of social and political discussions. In this experiment, there were two scenarios. One involved a hypothetical government that had already decided to allow autonomous cars to make ethical decisions. Their other scenario allowed the subjects to ""vote"" whether to allow the autonomous cars to make ethical decisions. In both cases, the subjects could choose to be in favor of or against the decisions made by the technology. This second experiment was designed to test the effect of two alternative ways of introducing AI into society.
The researchers observed that when the subjects were asked to evaluate the ethical decisions of either a human or AI driver, they did not have a definitive preference for either. However, when the subjects were asked their explicit opinion on whether a driver should be allowed to make ethical decisions on the road, the subjects had a stronger opinion against AI-operated cars. The researchers believe that the discrepancy between the two results is caused by a combination of two elements.
The first element is that individual people believe society as a whole does not want AI ethical decision making, and so they assign a positive weight to their beliefs when asked for their opinion on the matter. ""Indeed, when participants are asked explicitly to separate their answers from those of society, the difference between the permissibility for AI and human drivers vanishes,"" said Johann Caro-Burnett, an assistant professor in the Graduate School of Humanities and Social Sciences, Hiroshima University.
The second element is that when introducing this new technology into society, allowing discussion of the topic has mixed results depending on the country. ""In regions where people trust their government and have strong political institutions, information and decision-making power improve how subjects evaluate the ethical decisions of AI. In contrast, in regions where people do not trust their government and have weak political institutions, decision-making capability deteriorates how subjects evaluate the ethical decisions of AI,"" said Caro-Burnett.
""We find that there is a social fear of AI ethical decision-making. However, the source of this fear is not intrinsic to individuals. Indeed, this rejection of AI comes from what individuals believe is the society's opinion,"" said Shinji Kaneko, a professor in the Graduate School of Humanities and Social Sciences, Hiroshima University, and the Network for Education and Research on Peace and Sustainability. So when not being asked explicitly, people do not show any signs of bias against AI ethical decision-making. However, when asked explicitly, people show an aversion to AI. Furthermore, where there is added discussion and information on the topic, the acceptance of AI improves in developed countries and worsens in developing countries.
The researchers believe this rejection of a new technology, that is mostly due to incorporating individuals' beliefs about society's opinion, is likely to apply in other machines and robots. ""Therefore, it will be important to determine how to aggregate individual preferences into one social preference. Moreover, this task will also have to be different across countries, as our results suggest,"" said Kaneko.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1556
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); HUMANITIES & SOCIAL SCIENCE (78%); RESEARCH REPORTS (78%); SOCIAL SCIENCE EDUCATION (75%); ARTS & HUMANITIES EDUCATION (60%); COLLEGE & UNIVERSITY PROFESSORS (60%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); AUTONOMOUS MOTOR VEHICLES (89%); COLLEGE & UNIVERSITY PROFESSORS (60%); GRADUATE & PROFESSIONAL SCHOOLS (60%)
Load-Date: June 6, 2022",neutral,0.8400459289550781,balanced/neutral,['bias'],[],"['should', 'recommend', 'suggest']",[],1,0,3,0
2021,Unknown Title,"Body
Link to Story
Magnus Diagnostics Continues to Bridge the Gap for Underserved Communities by Making Clinical Diagnostics and Testing Facilities Accessible and AffordableBethesda, Maryland--(Newsfile Corp. - August 26, 2022) - US-based independent high complexity clinical reference laboratory, Magnus Diagnostics , continues its efforts to provide equitable laboratory services across the US and beyond. It thrives to bridge the gap between well-served and underserved communities in accessing clinical diagnostics and testing facilities. It aims to provide people with world-class diagnostic testing to lead healthy and happy life irrespective of their wealth and status. It focuses on democratizing access to disease diagnostic procedures and facilities by providing affordable yet excellent service to well-served and underserved communities alike.
Magnus Diagnostics also focuses on ethical testing practices utilizing an ethical algorithm. Their commitment to ethics is evident from their focus on sustainable, interoperable and futureproof testing practices and procedures. The firm's co-founder, Christopher McNair, is proud that the company passed the inspections by both the federal and state authorities. In his view, it encourages the company to further maintain a clean license and ethical laboratory practice.
'We essentially focus on the social impact that we are committed to providing for the community and are determined to serve the well-served and underserved communities. Ensuring that commitment at scale is our aim. We are moral and ethical practitioners in the industry. We always prefer to uphold ethics over profitability,' says Christopher McNair, Co-founder and CEO of Magnus Diagnostics .
The company's new operating model intends to leverage the possibilities of artificial intelligence and machine learning to ensure accuracy and precision in test results. It is also keen to adopt advanced technologies and state-of-the-art facilities to provide patients with convenience and laboratory excellence. In addition, it helps the company to offer a patient-centric testing experience ensuring personalized care for patients from different demographics.
It facilitates testing for neurodegenerative illnesses like Alzheimer's and rare diseases and disorders. As part of its research and development endeavors, Magnus Diagnostic utilizes CRISPR-Cas9, the most advanced genome editing tool, to study neurodegenerative diseases and their effects on patients in detail. Magnus Diagnostics ' future plans include expanding its services in specific areas like Neurology, Gastroenterology, Hematology, Oncology, Infectious Diseases and many more.
Christopher McNair, Co-founder and CEO of Magnus Diagnostics, commented on the new initiatives and commitments, 'We are on a mission to democratize access to the clinical diagnostics and testing facilities by making it accessible and affordable to everyone. We are determined to bridge the gap between well-served and underserved communities in accessing these facilities. We believe that our efforts will help underserved communities to be proactive rather than reactive when it comes to maintaining their optimal health. Ultimately, we strive to put the theory of 'prevention is better than cure' into practice.'
Media contact:
Name: Christopher McNair
Email:
To view the source version of this press release, please visit
MENAFN26082022004218003983ID1104763813
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: DISABLED ACCESS (90%); ETHICS (90%); DISEASES & DISORDERS (89%); MEDICALLY UNDERSERVED AREAS (89%); NEUROLOGICAL DISORDERS & INJURIES (89%); ALZHEIMER'S DISEASE (78%); MEDICAL DIAGNOSTICS, SCREENING & TESTING (78%); PATHOLOGY (78%); RESEARCH & DEVELOPMENT (78%); INFECTIOUS DISEASE (75%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (75%); NEUROSCIENCE (74%); ARTIFICIAL INTELLIGENCE (73%); ONCOLOGY (73%); ORPHAN & RARE DISEASES (73%); GASTROENTEROLOGY (70%); MACHINE LEARNING (68%); EXECUTIVES (64%); GENE EDITING (60%); GENETIC ENGINEERING (60%)
Industry: DISABLED ACCESS (90%); MEDICALLY UNDERSERVED AREAS (89%); PATHOLOGY (78%); TEST LABORATORIES (78%); MEDICAL & DIAGNOSTIC LABORATORIES (77%); ARTIFICIAL INTELLIGENCE (73%); ONCOLOGY (73%); GASTROENTEROLOGY (70%); MACHINE LEARNING (68%)
Geographic: UNITED STATES (79%)
Load-Date: October 27, 2022","Link to Story
Magnus Diagnostics Continues to Bridge the Gap for Underserved Communities by Making Clinical Diagnostics and Testing Facilities Accessible and AffordableBethesda, Maryland--(Newsfile Corp. - August 26, 2022) - US-based independent high complexity clinical reference laboratory, Magnus Diagnostics , continues its efforts to provide equitable laboratory services across the US and beyond. It thrives to bridge the gap between well-served and underserved communities in accessing clinical diagnostics and testing facilities. It aims to provide people with world-class diagnostic testing to lead healthy and happy life irrespective of their wealth and status. It focuses on democratizing access to disease diagnostic procedures and facilities by providing affordable yet excellent service to well-served and underserved communities alike.
Magnus Diagnostics also focuses on ethical testing practices utilizing an ethical algorithm. Their commitment to ethics is evident from their focus on sustainable, interoperable and futureproof testing practices and procedures. The firm's co-founder, Christopher McNair, is proud that the company passed the inspections by both the federal and state authorities. In his view, it encourages the company to further maintain a clean license and ethical laboratory practice.
'We essentially focus on the social impact that we are committed to providing for the community and are determined to serve the well-served and underserved communities. Ensuring that commitment at scale is our aim. We are moral and ethical practitioners in the industry. We always prefer to uphold ethics over profitability,' says Christopher McNair, Co-founder and CEO of Magnus Diagnostics .
The company's new operating model intends to leverage the possibilities of artificial intelligence and machine learning to ensure accuracy and precision in test results. It is also keen to adopt advanced technologies and state-of-the-art facilities to provide patients with convenience and laboratory excellence. In addition, it helps the company to offer a patient-centric testing experience ensuring personalized care for patients from different demographics.
It facilitates testing for neurodegenerative illnesses like Alzheimer's and rare diseases and disorders. As part of its research and development endeavors, Magnus Diagnostic utilizes CRISPR-Cas9, the most advanced genome editing tool, to study neurodegenerative diseases and their effects on patients in detail. Magnus Diagnostics ' future plans include expanding its services in specific areas like Neurology, Gastroenterology, Hematology, Oncology, Infectious Diseases and many more.
Christopher McNair, Co-founder and CEO of Magnus Diagnostics, commented on the new initiatives and commitments, 'We are on a mission to democratize access to the clinical diagnostics and testing facilities by making it accessible and affordable to everyone. We are determined to bridge the gap between well-served and underserved communities in accessing these facilities. We believe that our efforts will help underserved communities to be proactive rather than reactive when it comes to maintaining their optimal health. Ultimately, we strive to put the theory of 'prevention is better than cure' into practice.'
Media contact:
Name: Christopher McNair
Email:
To view the source version of this press release, please visit
MENAFN26082022004218003983ID1104763813
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: DISABLED ACCESS (90%); ETHICS (90%); DISEASES & DISORDERS (89%); MEDICALLY UNDERSERVED AREAS (89%); NEUROLOGICAL DISORDERS & INJURIES (89%); ALZHEIMER'S DISEASE (78%); MEDICAL DIAGNOSTICS, SCREENING & TESTING (78%); PATHOLOGY (78%); RESEARCH & DEVELOPMENT (78%); INFECTIOUS DISEASE (75%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (75%); NEUROSCIENCE (74%); ARTIFICIAL INTELLIGENCE (73%); ONCOLOGY (73%); ORPHAN & RARE DISEASES (73%); GASTROENTEROLOGY (70%); MACHINE LEARNING (68%); EXECUTIVES (64%); GENE EDITING (60%); GENETIC ENGINEERING (60%)
Industry: DISABLED ACCESS (90%); MEDICALLY UNDERSERVED AREAS (89%); PATHOLOGY (78%); TEST LABORATORIES (78%); MEDICAL & DIAGNOSTIC LABORATORIES (77%); ARTIFICIAL INTELLIGENCE (73%); ONCOLOGY (73%); GASTROENTEROLOGY (70%); MACHINE LEARNING (68%)
Geographic: UNITED STATES (79%)
Load-Date: October 27, 2022",positive,0.6349659562110901,balanced/neutral,['access'],[],[],"['machine learning', 'algorithm']",1,0,0,2
2021,Unknown Title,"Byline: By James Ang, Is ethical AI no longer important'
Body
AFTER a tumultuous acquisition process, Elon Musk has acquired Twitter. This kick-started a wave of lay-offs within the company, with its ethical artificial intelligence (AI) team not spared either. In essence, Twitter's team that was in charge of their machine learning (ML) ethics, transparency and accountability within the AI space is now gone. 
 With the company de-prioritising ethical AI, will other companies follow suit and perhaps more importantly, does this signal that ethics don't matter when it comes to AI'
 Well, in short, no.
 The world is undeniably in the middle of a digital revolution, with AI and ML among other technologies developing rapidly. These technologies have immense potential and are set to transform our lives through the way we live and work.
 AI -- which was once confined to academics or research and development, and therefore limited in terms of risk when deployed -- now has a much larger impact in terms of its practical applications. This inevitably raises the question of ethics, and it is something government bodies and businesses alike have to keep atop their priorities to ensure we steer clear of any unwanted repercussions.
 In Singapore, the emphasis is on a trusted ecosystem, where organisations can benefit from the innovations brought about by technology, and consumers can remain confident to adopt AI. We see this balanced approach in the launch of AI Verify -- the world's first AI governance testing framework and toolkit launched in May, that is set to be Singapore's first step to identifying and defining an objective and verifiable way to validate the performance of AI systems. The international pilot will facilitate the collation and development of industry benchmarks for AI ethics principles.
 Similarly, in the US, the White House released its AI Bill of Rights blueprint, which serves as a guide for the design, use, and deployment of AI while protecting the interests of the American public in the age of AI. 
 The idea of ethics itself is subjective, controversial and often up for debate. Naturally, it's unrealistic to expect a simple, straightforward path to navigate it. So, how can governments and businesses address the subject'
 Understand the challengesWhen it comes to AI, harm can take many forms. 
 One of the most common is the perception that AI is intrinsically objective, meaning that its recommendations, forecasts and output are not subject to individuals' biases. Such a misconception leads to the creation of a false sense of comfort, diluting both individual and collective responsibility when it concerns AI tools and models. Think of it as a snowball. When biases are ingrained in our society and original data sets are created with those biases as a foundation, ML can only magnify them in its process.
 We also have to acknowledge the biases that exist within algorithms, which can be complex and sometimes entirely black boxed, making it harder to determine how the models reach their unique decisions. For instance, if a system has an over-represented population within its data set, the algorithm will not be able to distinguish or recognise other sections of the population as a result. 
 At every step, right down to the choice of modelling techniques and validations, bias and drift can be induced.
 Another steep challenge comes in the form of AI governance. Across companies today, it is not uncommon to see several teams within a much larger group developing different AI systems, each using different technologies and data sets. Once deployed, these modes are monitored individually by their owners.
 Yet what is truly needed is governance at scale. That means working towards standardised rules, requirements, and processes in alignment with organisational priorities, which sets expectations for how teams design, build, and deploy AI systems. For this to be effective, AI governance practices should include monitoring all projects centrally and being able to see the data that is being used, as well as the performance of deployed models. Without this level of governance, ensuring that teams are empowered and accountable becomes an uphill battle, and there is no guarantee of responsible AI within the organisation's ecosystem.
 The ethical frameworkTo avoid these potential pitfalls, organisations must first lay down a solid foundation by determining a precise framework for their own ethical principles regarding the impacts of AI. Defining these values and taking into account the regulatory environment the organisation is in ensures that stakeholders can take a clear stance on their principles, and helps facilitate communication of these principles across all teams.
 Using these values for ethical AI, organisations can set actionable criteria and indicators into a well-defined ethical checklist. Adopting an ethical checklist will help guide practitioners through the identification of potential AI concerns for use cases. Some essential questions to consider include: What are the objectives and the purpose of the project, and what are the metrics to measure success? Who will be affected by the project (directly or indirectly), and how? What are potential biases included in the data used to train models? What measures have been implemented to address the ethical concerns of the project? And how will the potential ethical impacts of the AI system be monitored once in operation? 
 An ethical checklist encourages communication between project team members and stakeholders, and fosters both awareness and a healthy questioning attitude within teams. This gives organisations a head start, but it still is ultimately up to leaders and the organisation to draw the necessary conclusions from their checklists.
 More broadly, ethical checklists and ethical rules should be part of a cohesive responsible AI framework, which should include ethics guidelines, templates for algorithmic impact assessments, and audit frameworks. Additionally, all data sets and models should be documented using methods such as Datasheets for Datasets and Model Cards for Model Reporting. By making use of the variety of tools available to them, organisations can take a holistic and practical approach to implementing ethical AI. 
 Paving the way forward While the ethics of AI may be controversial, it is vital that governments and companies do not step back and ignore what is necessary -- the presence of a higher ethics authority or dedicated content that teams can rely on. Assessing potential ethical concerns of AI is crucial, given the significant risks of inadvertent harm. 
 The momentum of digitalisation and AI adoption is not slowing down, especially in South-east Asia. As with any form of widespread adoption, there are inevitable risks that come along and it is imperative that ethical systems are established, implemented and monitored. This will foster an AI ecosystem of trust and transparency that safeguards everyone.
 The writer is senior vice-president, Asia-Pacific, at Dataiku.
Graphic
AI has a much larger impact now in terms of its practical applications. This inevitably raises the question of ethics, and it is something government bodies and businesses alike have to keep atop their priorities to steer clear of any unwanted repercussions. photo: pixabay
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEGATIVE BUSINESS NEWS (90%); TECHNOLOGY (90%); BENCHMARKING (78%); HOLDING COMPANIES (78%); LAYOFFS (78%); MACHINE LEARNING (78%); RESEARCH & DEVELOPMENT (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); GOVERNMENT BODIES & OFFICES (66%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); MACHINE LEARNING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%)
Person: ELON MUSK (58%)
Geographic: SINGAPORE (92%); UNITED STATES (90%)
Load-Date: November 15, 2022","AFTER a tumultuous acquisition process, Elon Musk has acquired Twitter. This kick-started a wave of lay-offs within the company, with its ethical artificial intelligence (AI) team not spared either. In essence, Twitter's team that was in charge of their machine learning (ML) ethics, transparency and accountability within the AI space is now gone. 
 With the company de-prioritising ethical AI, will other companies follow suit and perhaps more importantly, does this signal that ethics don't matter when it comes to AI'
 Well, in short, no.
 The world is undeniably in the middle of a digital revolution, with AI and ML among other technologies developing rapidly. These technologies have immense potential and are set to transform our lives through the way we live and work.
 AI -- which was once confined to academics or research and development, and therefore limited in terms of risk when deployed -- now has a much larger impact in terms of its practical applications. This inevitably raises the question of ethics, and it is something government bodies and businesses alike have to keep atop their priorities to ensure we steer clear of any unwanted repercussions.
 In Singapore, the emphasis is on a trusted ecosystem, where organisations can benefit from the innovations brought about by technology, and consumers can remain confident to adopt AI. We see this balanced approach in the launch of AI Verify -- the world's first AI governance testing framework and toolkit launched in May, that is set to be Singapore's first step to identifying and defining an objective and verifiable way to validate the performance of AI systems. The international pilot will facilitate the collation and development of industry benchmarks for AI ethics principles.
 Similarly, in the US, the White House released its AI Bill of Rights blueprint, which serves as a guide for the design, use, and deployment of AI while protecting the interests of the American public in the age of AI. 
 The idea of ethics itself is subjective, controversial and often up for debate. Naturally, it's unrealistic to expect a simple, straightforward path to navigate it. So, how can governments and businesses address the subject'
 Understand the challengesWhen it comes to AI, harm can take many forms. 
 One of the most common is the perception that AI is intrinsically objective, meaning that its recommendations, forecasts and output are not subject to individuals' biases. Such a misconception leads to the creation of a false sense of comfort, diluting both individual and collective responsibility when it concerns AI tools and models. Think of it as a snowball. When biases are ingrained in our society and original data sets are created with those biases as a foundation, ML can only magnify them in its process.
 We also have to acknowledge the biases that exist within algorithms, which can be complex and sometimes entirely black boxed, making it harder to determine how the models reach their unique decisions. For instance, if a system has an over-represented population within its data set, the algorithm will not be able to distinguish or recognise other sections of the population as a result. 
 At every step, right down to the choice of modelling techniques and validations, bias and drift can be induced.
 Another steep challenge comes in the form of AI governance. Across companies today, it is not uncommon to see several teams within a much larger group developing different AI systems, each using different technologies and data sets. Once deployed, these modes are monitored individually by their owners.
 Yet what is truly needed is governance at scale. That means working towards standardised rules, requirements, and processes in alignment with organisational priorities, which sets expectations for how teams design, build, and deploy AI systems. For this to be effective, AI governance practices should include monitoring all projects centrally and being able to see the data that is being used, as well as the performance of deployed models. Without this level of governance, ensuring that teams are empowered and accountable becomes an uphill battle, and there is no guarantee of responsible AI within the organisation's ecosystem.
 The ethical frameworkTo avoid these potential pitfalls, organisations must first lay down a solid foundation by determining a precise framework for their own ethical principles regarding the impacts of AI. Defining these values and taking into account the regulatory environment the organisation is in ensures that stakeholders can take a clear stance on their principles, and helps facilitate communication of these principles across all teams.
 Using these values for ethical AI, organisations can set actionable criteria and indicators into a well-defined ethical checklist. Adopting an ethical checklist will help guide practitioners through the identification of potential AI concerns for use cases. Some essential questions to consider include: What are the objectives and the purpose of the project, and what are the metrics to measure success? Who will be affected by the project (directly or indirectly), and how? What are potential biases included in the data used to train models? What measures have been implemented to address the ethical concerns of the project? And how will the potential ethical impacts of the AI system be monitored once in operation? 
 An ethical checklist encourages communication between project team members and stakeholders, and fosters both awareness and a healthy questioning attitude within teams. This gives organisations a head start, but it still is ultimately up to leaders and the organisation to draw the necessary conclusions from their checklists.
 More broadly, ethical checklists and ethical rules should be part of a cohesive responsible AI framework, which should include ethics guidelines, templates for algorithmic impact assessments, and audit frameworks. Additionally, all data sets and models should be documented using methods such as Datasheets for Datasets and Model Cards for Model Reporting. By making use of the variety of tools available to them, organisations can take a holistic and practical approach to implementing ethical AI. 
 Paving the way forward While the ethics of AI may be controversial, it is vital that governments and companies do not step back and ignore what is necessary -- the presence of a higher ethics authority or dedicated content that teams can rely on. Assessing potential ethical concerns of AI is crucial, given the significant risks of inadvertent harm. 
 The momentum of digitalisation and AI adoption is not slowing down, especially in South-east Asia. As with any form of widespread adoption, there are inevitable risks that come along and it is imperative that ethical systems are established, implemented and monitored. This will foster an AI ecosystem of trust and transparency that safeguards everyone.
 The writer is senior vice-president, Asia-Pacific, at Dataiku.
Graphic
AI has a much larger impact now in terms of its practical applications. This inevitably raises the question of ethics, and it is something government bodies and businesses alike have to keep atop their priorities to steer clear of any unwanted repercussions. photo: pixabay
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); NEGATIVE BUSINESS NEWS (90%); TECHNOLOGY (90%); BENCHMARKING (78%); HOLDING COMPANIES (78%); LAYOFFS (78%); MACHINE LEARNING (78%); RESEARCH & DEVELOPMENT (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%); GOVERNMENT BODIES & OFFICES (66%); EDITORIALS & OPINIONS (59%); REPORTS, REVIEWS & SECTIONS (59%)
Company:  AI SYSTEMS (53%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); MACHINE LEARNING (78%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (73%)
Person: ELON MUSK (58%)
Geographic: SINGAPORE (92%); UNITED STATES (90%)
Load-Date: November 15, 2022",negative,0.5237275958061218,balanced/neutral,"['bias', 'transparency', 'accountability']",[],"['regulation', 'policy', 'governance', 'guidelines', 'framework', 'audit', 'should', 'must']","['machine learning', 'algorithm']",3,0,8,2
2021,Unknown Title,"Dateline: New Delhi, 2022-10-08 10:58:30 
Body
 DLA Piper is proud to announce its participation in the World Benchmarking Alliances (WBA) Collective Impact Coalition (CIC) for Digital Inclusion. DLA Piper recently participated in the WBAs roundtable launch of the CIC on the side-lines of the 77th session of the United Nations General Assembly.
  The CIC is a multi-stakeholder coalition on ethical AI and is focused on driving measurable progress on corporate commitment to ethical AI principles. The CIC aims to raise awareness of the importance of responsible and ethical AI, increase understanding of the state of play and leading best practices, and improve technology companies commitment to ethical AI.
  The launch of the Collective Impact Coalition for Digital Inclusion is an important and exciting step in the World Benchmarking Alliances mission, said Tony Samp, a DLA Piper senior policy advisor who attended the roundtable launch. As the proliferation and deployment of AI continues to accelerate around the globe, its increasingly necessary that best practices are shared, and meaningful dialogue occurs amongst a variety of stakeholders to advance ethical and responsible AI.
  Earlier this year, DLA Piper became the first law firm to join the WBA, which supports businesses in their commitment to the United Nations Sustainable Development Goals (SDGs) by developing publicly available benchmarks to measure progress against. As an ally, DLA Piper has pledged its commitment to the WBAs mission by working at the global, regional and local levels to shape and steer the contributions of the private sector and the legal industry toward achieving the SDGs.
  DLA Piper was among the first law firms to establish a formal AI practice in 2019. DLA Piper remains focused on assisting companies as they navigate the legal landscape of emerging and disruptive technologies, while helping them understand the legal and compliance risks arising from the creation and deployment of AI systems.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); BENCHMARKING (91%); BEST PRACTICES (90%); DIGITAL DIVIDE (90%); ETHICS (90%); MAJOR US LAW FIRMS (90%); UNITED NATIONS (90%); SUSTAINABLE DEVELOPMENT GOALS (89%); LAW & LEGAL SYSTEM (87%); LEGAL SERVICES (87%); UNITED NATIONS INSTITUTIONS (77%); ARTIFICIAL INTELLIGENCE (76%); RISK MANAGEMENT (76%); EMERGING TECHNOLOGY (71%); DISRUPTIVE INNOVATION (70%); SUSTAINABLE DEVELOPMENT (66%); SUSTAINABILITY (51%)
Company:  DLA PIPER LLP (92%);  AI SYSTEMS (50%)
Industry: NAICS541110 OFFICES OF LAWYERS (92%); SIC8111 LEGAL SERVICES (92%); SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); MAJOR US LAW FIRMS (90%); SUSTAINABLE DEVELOPMENT GOALS (89%); LEGAL SERVICES (87%); INFORMATION TECHNOLOGY INDUSTRY (78%); ARTIFICIAL INTELLIGENCE (76%); RISK MANAGEMENT (76%); SUSTAINABLE DEVELOPMENT (66%)
Geographic: NEW DELHI, INDIA (74%)
Load-Date: October 25, 2022","DLA Piper is proud to announce its participation in the World Benchmarking Alliances (WBA) Collective Impact Coalition (CIC) for Digital Inclusion. DLA Piper recently participated in the WBAs roundtable launch of the CIC on the side-lines of the 77th session of the United Nations General Assembly.
  The CIC is a multi-stakeholder coalition on ethical AI and is focused on driving measurable progress on corporate commitment to ethical AI principles. The CIC aims to raise awareness of the importance of responsible and ethical AI, increase understanding of the state of play and leading best practices, and improve technology companies commitment to ethical AI.
  The launch of the Collective Impact Coalition for Digital Inclusion is an important and exciting step in the World Benchmarking Alliances mission, said Tony Samp, a DLA Piper senior policy advisor who attended the roundtable launch. As the proliferation and deployment of AI continues to accelerate around the globe, its increasingly necessary that best practices are shared, and meaningful dialogue occurs amongst a variety of stakeholders to advance ethical and responsible AI.
  Earlier this year, DLA Piper became the first law firm to join the WBA, which supports businesses in their commitment to the United Nations Sustainable Development Goals (SDGs) by developing publicly available benchmarks to measure progress against. As an ally, DLA Piper has pledged its commitment to the WBAs mission by working at the global, regional and local levels to shape and steer the contributions of the private sector and the legal industry toward achieving the SDGs.
  DLA Piper was among the first law firms to establish a formal AI practice in 2019. DLA Piper remains focused on assisting companies as they navigate the legal landscape of emerging and disruptive technologies, while helping them understand the legal and compliance risks arising from the creation and deployment of AI systems.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); BENCHMARKING (91%); BEST PRACTICES (90%); DIGITAL DIVIDE (90%); ETHICS (90%); MAJOR US LAW FIRMS (90%); UNITED NATIONS (90%); SUSTAINABLE DEVELOPMENT GOALS (89%); LAW & LEGAL SYSTEM (87%); LEGAL SERVICES (87%); UNITED NATIONS INSTITUTIONS (77%); ARTIFICIAL INTELLIGENCE (76%); RISK MANAGEMENT (76%); EMERGING TECHNOLOGY (71%); DISRUPTIVE INNOVATION (70%); SUSTAINABLE DEVELOPMENT (66%); SUSTAINABILITY (51%)
Company:  DLA PIPER LLP (92%);  AI SYSTEMS (50%)
Industry: NAICS541110 OFFICES OF LAWYERS (92%); SIC8111 LEGAL SERVICES (92%); SIC7372 PREPACKAGED SOFTWARE (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); MAJOR US LAW FIRMS (90%); SUSTAINABLE DEVELOPMENT GOALS (89%); LEGAL SERVICES (87%); INFORMATION TECHNOLOGY INDUSTRY (78%); ARTIFICIAL INTELLIGENCE (76%); RISK MANAGEMENT (76%); SUSTAINABLE DEVELOPMENT (66%)
Geographic: NEW DELHI, INDIA (74%)
Load-Date: October 25, 2022",positive,0.8598688840866089,balanced/neutral,['digital divide'],[],"['policy', 'law', 'compliance']",[],1,0,3,0
2021,Unknown Title,"Body
University of Bonn : EU project focuses on research ethics; University of Bonn is conducting a pilot project with international partners. Funding in the amount of 4.5 million euros.
From the CRISPR Cas9 gene scissors to artificial intelligence and reprogrammed cells: New technologies are always associated with ethical questions for research and application, to which there are no easy answers. irecs, the new collaborative project funded by the European Union, aims to strengthen principles of research ethics in as many disciplines as possible.
Under the leadership of the University of Bonn, 17 partner organizations from Germany and abroad have joined forces to drive the project forward. The EU is funding the project with a total of 4.5 million euros over the next three years.
The impression in connection with the service is free, while the image specified author is mentioned.
'Issues of research ethics are already strongly anchored in the life sciences and medicine,' says Prof. Dr. Dirk Lanzerath, director of the German Reference Center for Ethics in the Life Sciences (DRZE) at the University of Bonn. 'But we need more discourse on research ethics and standards in other disciplines as well.' This gap is to be filled by irecs (Improving Research Ethics Expertise and Competencies to Ensure Reliability and Trust in Science), which is integrated into the Transdisciplinary Research Area 'Individuals, Institutions and Societies' at the University of Bonn. The EU project aims to show that ethically reflective research is the key to high-quality science and a prerequisite for earning the trust of the public.
'One important way to promote awareness of ethical requirements associated with new research fields and technologies is through innovative, state-of-the-art training programs for students, researchers and ethics committee members,' Lanzerath says. Such training programs can also demonstrate that ethical review processes create a trust-building connection between science and society.
Lisa Diependaele, European Commission research ethics and integrity officer, adds: 'Europe's green and digital transformation relies on a strong, dynamic and resilient research ecosystem.' The European Commission's main goal, she explains, is to ensure that ethics and research integrity are fully integrated into research. 'By strengthening ethics governance, irecs supports excellence and empowers researchers to do the right thing for our society.'
Ethical values in the humanities and social sciences
irecs is also significant because it thinks deeply about ethical values that apply to the humanities and social sciences. 'Because research with questionnaires and interviews, for example, can also be very invasive and hurtful. This is why research funding bodies are now increasingly requiring an ethics approval for these methods,' explains Prof. Dr. Laura Palazzani, a legal scholar at LUMSA University in Rome and a member of irecs' Stakeholder Advisory Board.
'By involving different disciplines, global partners and research ethics networks, as well as the members of the Stakeholder Advisory Board, irecs will develop a new awareness of research ethics,' says Prof. Dr. Andreas Zimmer, Vice Rector for Research and Early-Career Researchers at the University of Bonn.
Prof. Dr. Dirk Lanzerath coordinates the collaborative project irecs within the framework of the research funding program 'Horizon Europe' of the European Commission. He initiated the project together with Prof. Dr. Dr. Jochen Sautermeister from the Department of Catholic Moral Theology, Prof. Dr. Dr. Tade Spranger from the Department of Law and Nadine Kollmeyer from Research and Innovation Services (all University of Bonn) and in cooperation with 16 other European and international partner institutions. Among the project participants is the European Network of Research Ethics Committees, EUREC (eurecnet.org), which emerged from an EU project at the University of Bonn.
An international advisory board accompanies the irecs project. Medical ethicist Prof. David R. Curry, MD, of NYU Medical School, will chair the advisory board. 'This is a time of rapid advancement in many new technologies where conducting the underlying, enabling research presents unique ethical challenges,' Curry says.
Participating institutions:
In addition to the University of Bonn as coordinating institution, irecs involves the European Network of Research Ethics Committees (EUREC), the European University Association (EUA), the European Association of Research Managers and Administrators (EARMA), Maastricht University (UM), University of Split School of Medicine (MEFST), Trilateral Research (TRI), Karlsruhe Institute of Technology (KIT), University of Central Lancashire (UClan), VU Amsterdam Medical Centers (VUMC), National Technical University of Athens (NTUA), Radboud University (RU), University of Vilnius (VU), De Montfort University (DMU), the French Alternative Energies and Atomic Energy Commission (CEA), the Korea Advanced Institute of Science and Technology (KAIST), and Fudan University (FDU).
CONTACT
Dorothee Guth
German Reference Center for Ethics in the Life Sciences (DRZE)
University of Bonn
Phone +49 228 738110
E-mail: gueth@drze.de
www.drze.de
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (94%); EUROPEAN UNION (91%); ALLIANCES & PARTNERSHIPS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); EUROPEAN UNION INSTITUTIONS (89%); HUMANITIES & SOCIAL SCIENCE (89%); INTERNATIONAL ECONOMIC ORGANIZATIONS (89%); STUDENTS & STUDENT LIFE (79%); EXPERIMENTATION & RESEARCH (78%); GOVERNMENT RESEARCH FUNDING (78%); SCIENCE FUNDING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PRESS RELEASES (74%); APPROVALS (71%); ASSOCIATIONS & ORGANIZATIONS (70%); ARTIFICIAL INTELLIGENCE (57%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); DIGITALIZATION & DIGITAL TRANSFORMATION (77%); ARTIFICIAL INTELLIGENCE (57%)
Geographic: ROME, ITALY (50%); EUROPEAN UNION MEMBER STATES (94%); GERMANY (92%); EUROPE (90%)
Load-Date: November 18, 2022","University of Bonn : EU project focuses on research ethics; University of Bonn is conducting a pilot project with international partners. Funding in the amount of 4.5 million euros.
From the CRISPR Cas9 gene scissors to artificial intelligence and reprogrammed cells: New technologies are always associated with ethical questions for research and application, to which there are no easy answers. irecs, the new collaborative project funded by the European Union, aims to strengthen principles of research ethics in as many disciplines as possible.
Under the leadership of the University of Bonn, 17 partner organizations from Germany and abroad have joined forces to drive the project forward. The EU is funding the project with a total of 4.5 million euros over the next three years.
The impression in connection with the service is free, while the image specified author is mentioned.
'Issues of research ethics are already strongly anchored in the life sciences and medicine,' says Prof. Dr. Dirk Lanzerath, director of the German Reference Center for Ethics in the Life Sciences (DRZE) at the University of Bonn. 'But we need more discourse on research ethics and standards in other disciplines as well.' This gap is to be filled by irecs (Improving Research Ethics Expertise and Competencies to Ensure Reliability and Trust in Science), which is integrated into the Transdisciplinary Research Area 'Individuals, Institutions and Societies' at the University of Bonn. The EU project aims to show that ethically reflective research is the key to high-quality science and a prerequisite for earning the trust of the public.
'One important way to promote awareness of ethical requirements associated with new research fields and technologies is through innovative, state-of-the-art training programs for students, researchers and ethics committee members,' Lanzerath says. Such training programs can also demonstrate that ethical review processes create a trust-building connection between science and society.
Lisa Diependaele, European Commission research ethics and integrity officer, adds: 'Europe's green and digital transformation relies on a strong, dynamic and resilient research ecosystem.' The European Commission's main goal, she explains, is to ensure that ethics and research integrity are fully integrated into research. 'By strengthening ethics governance, irecs supports excellence and empowers researchers to do the right thing for our society.'
Ethical values in the humanities and social sciences
irecs is also significant because it thinks deeply about ethical values that apply to the humanities and social sciences. 'Because research with questionnaires and interviews, for example, can also be very invasive and hurtful. This is why research funding bodies are now increasingly requiring an ethics approval for these methods,' explains Prof. Dr. Laura Palazzani, a legal scholar at LUMSA University in Rome and a member of irecs' Stakeholder Advisory Board.
'By involving different disciplines, global partners and research ethics networks, as well as the members of the Stakeholder Advisory Board, irecs will develop a new awareness of research ethics,' says Prof. Dr. Andreas Zimmer, Vice Rector for Research and Early-Career Researchers at the University of Bonn.
Prof. Dr. Dirk Lanzerath coordinates the collaborative project irecs within the framework of the research funding program 'Horizon Europe' of the European Commission. He initiated the project together with Prof. Dr. Dr. Jochen Sautermeister from the Department of Catholic Moral Theology, Prof. Dr. Dr. Tade Spranger from the Department of Law and Nadine Kollmeyer from Research and Innovation Services (all University of Bonn) and in cooperation with 16 other European and international partner institutions. Among the project participants is the European Network of Research Ethics Committees, EUREC (eurecnet.org), which emerged from an EU project at the University of Bonn.
An international advisory board accompanies the irecs project. Medical ethicist Prof. David R. Curry, MD, of NYU Medical School, will chair the advisory board. 'This is a time of rapid advancement in many new technologies where conducting the underlying, enabling research presents unique ethical challenges,' Curry says.
Participating institutions:
In addition to the University of Bonn as coordinating institution, irecs involves the European Network of Research Ethics Committees (EUREC), the European University Association (EUA), the European Association of Research Managers and Administrators (EARMA), Maastricht University (UM), University of Split School of Medicine (MEFST), Trilateral Research (TRI), Karlsruhe Institute of Technology (KIT), University of Central Lancashire (UClan), VU Amsterdam Medical Centers (VUMC), National Technical University of Athens (NTUA), Radboud University (RU), University of Vilnius (VU), De Montfort University (DMU), the French Alternative Energies and Atomic Energy Commission (CEA), the Korea Advanced Institute of Science and Technology (KAIST), and Fudan University (FDU).
CONTACT
Dorothee Guth
German Reference Center for Ethics in the Life Sciences (DRZE)
University of Bonn
Phone +49 228 738110
E-mail: gueth@drze.de
www.drze.de
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ETHICS (94%); EUROPEAN UNION (91%); ALLIANCES & PARTNERSHIPS (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); EUROPEAN UNION INSTITUTIONS (89%); HUMANITIES & SOCIAL SCIENCE (89%); INTERNATIONAL ECONOMIC ORGANIZATIONS (89%); STUDENTS & STUDENT LIFE (79%); EXPERIMENTATION & RESEARCH (78%); GOVERNMENT RESEARCH FUNDING (78%); SCIENCE FUNDING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); PRESS RELEASES (74%); APPROVALS (71%); ASSOCIATIONS & ORGANIZATIONS (70%); ARTIFICIAL INTELLIGENCE (57%)
Industry: COLLEGE & UNIVERSITY PROFESSORS (89%); DIGITALIZATION & DIGITAL TRANSFORMATION (77%); ARTIFICIAL INTELLIGENCE (57%)
Geographic: ROME, ITALY (50%); EUROPEAN UNION MEMBER STATES (94%); GERMANY (92%); EUROPE (90%)
Load-Date: November 18, 2022",neutral,0.5663009285926819,balanced/neutral,[],[],"['governance', 'standards', 'framework', 'law', 'should']",[],0,0,5,0
2021,Unknown Title,"Body
SAN JOSE: Western Digital Corp., a leader in data infrastructure, announced its recognition as one of the world ’ s most ethical companies by Ethisphere. The organization defines and advances the standards of ethical business practices worldwide. Western Digital unlocks the potential of data and champions human potential, emphasizing the importance of high ethical standards in its business at every step. Western Digital fosters and thrives in an environment of ethical behavior through policies and practices that have led to this repeated recognition for integrity. As global leaders in data infrastructure, stakeholder trust is paramount.
“Rather than treat ethics as simply a topic for yearly compliance training, our leadership team actively behaves and promotes an ethical workplace culture for employees worldwide,” said Tiffany Scurry, SVP and Chief Compliance Officer at Western Digital. “We are proud to once again receive this recognition from Ethisphere, further underscoring the ethical responsibilities we have with our stakeholders, including employees, shareholders, and the broader market. ”
“Trust is paramount to any relationship with business partners, and DDN is pleased to see Western Digital recognized for their integrity and respected position in the industry,” said Kurt Kuckein, VP of Marketing at DDN. “As DDN continues to pursue new solutions for AI and other advance computing workloads, having strategic partners like Western Digital is key to accomplishing our mission. ”
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (95%); BUSINESS ETHICS (93%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); EXECUTIVES (90%); STRATEGIC PARTNERSHIPS (78%); CORPORATE CULTURE (77%); INTERPERSONAL RELATIONSHIPS (76%); ALLIANCES & PARTNERSHIPS (74%); LABOR & EMPLOYMENT (74%); SHAREHOLDERS (73%); REGULATORY COMPLIANCE (72%)
Company:  WESTERN DIGITAL CORP (94%)
Ticker: WDC (NASDAQ) (94%)
Industry: NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (94%); SIC3572 COMPUTER STORAGE DEVICES (94%)
Load-Date: March 16, 2022","SAN JOSE: Western Digital Corp., a leader in data infrastructure, announced its recognition as one of the world ’ s most ethical companies by Ethisphere. The organization defines and advances the standards of ethical business practices worldwide. Western Digital unlocks the potential of data and champions human potential, emphasizing the importance of high ethical standards in its business at every step. Western Digital fosters and thrives in an environment of ethical behavior through policies and practices that have led to this repeated recognition for integrity. As global leaders in data infrastructure, stakeholder trust is paramount.
“Rather than treat ethics as simply a topic for yearly compliance training, our leadership team actively behaves and promotes an ethical workplace culture for employees worldwide,” said Tiffany Scurry, SVP and Chief Compliance Officer at Western Digital. “We are proud to once again receive this recognition from Ethisphere, further underscoring the ethical responsibilities we have with our stakeholders, including employees, shareholders, and the broader market. ”
“Trust is paramount to any relationship with business partners, and DDN is pleased to see Western Digital recognized for their integrity and respected position in the industry,” said Kurt Kuckein, VP of Marketing at DDN. “As DDN continues to pursue new solutions for AI and other advance computing workloads, having strategic partners like Western Digital is key to accomplishing our mission. ”
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (95%); BUSINESS ETHICS (93%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); EXECUTIVES (90%); STRATEGIC PARTNERSHIPS (78%); CORPORATE CULTURE (77%); INTERPERSONAL RELATIONSHIPS (76%); ALLIANCES & PARTNERSHIPS (74%); LABOR & EMPLOYMENT (74%); SHAREHOLDERS (73%); REGULATORY COMPLIANCE (72%)
Company:  WESTERN DIGITAL CORP (94%)
Ticker: WDC (NASDAQ) (94%)
Industry: NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (94%); SIC3572 COMPUTER STORAGE DEVICES (94%)
Load-Date: March 16, 2022",positive,0.816936194896698,balanced/neutral,[],[],"['standards', 'compliance']",[],0,0,2,0
2021,Unknown Title,"Body
The first Global Forum on the Ethics of Artificial Intelligence (AI) took place on 13 December 2022, at Czernin Palace during the Czech Presidency of the Council of the European Union and under the patronage of UNESCO. Organizing the event is a major milestone in building a strong international coalition aimed at ensuring ethical developments and usage of AI worldwide.
The Forums program featured two ministerial sessions, as well as a series of expert roundtables aimed at exploring the state of AI from different angles such as addressing gender bias in AI, ensuring transparency and non-discrimination, promoting environmental protection, and engaging with the private sector. Ministers and representatives from different EU institutions and other regions of the world met at the Forum along with frontline experts in the field of AI ethics.
We welcome the UNESCO Recommendation on the Ethics of Artificial Intelligence. I consider it an effective instrument that seeks to regulate the use of AI in an ethical way, said the Czech Foreign Minister, Jan Lipavsk, as he opened the Forum.
Gabriela Ramos, Assistant Director General for Social and Human Sciences of UNESCO, highlighted in her speech: Holding the first Global Forum on the Ethics of AI in Prague under the Czech Presidency of the Council of the EU marks a major milestone. This represents a real convergence of the efforts of UNESCO and the European Union to build strong institutional and regulatory frameworks around the world, to ensure ethical and inclusive technological change.
I am happy that the Czech Republic continues promoting a human-centric approach to digital technologies. The ambition of UNESCO's Recommendation is to protect human rights and human dignity and its implementation should be our ethical guiding compass allowing us to build strong respect for the rule of law in the digital world, said Deputy Prime Minister for Digitalization Ivan Barto.
Furthermore, Deputy Minister for European Affairs Marek Havrda stated, among other things, that ""artificial intelligence has enormous potential for the development of our societies and solutions to global challenges such as climate change. However, we must be able to ensure that it is used in accordance with general ethical standards. Today's first global forum enabled the sharing of concrete practices between ministers and experts from several continents. It is such an important step on the road to trustworthy and ethical artificial intelligence.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 812
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EUROPEAN UNION (92%); ETHICS (91%); INTERNATIONAL ECONOMIC ORGANIZATIONS (91%); ARTIFICIAL INTELLIGENCE (90%); EU PRESIDENCY (90%); EUROPEAN UNION INSTITUTIONS (90%); TALKS & MEETINGS (90%); GOVERNMENT ADVISORS & MINISTERS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); RULE OF LAW (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CLIMATE CHANGE (75%); NEGATIVE SOCIETAL NEWS (75%); HEADS OF STATE & GOVERNMENT (73%); INTERNATIONAL RELATIONS (73%); STATE DEPARTMENTS & FOREIGN SERVICES (73%); ENVIRONMENT & NATURAL RESOURCES (70%); GENDER & SEX DISCRIMINATION (70%); PRIME MINISTERS (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%)
Geographic: PRAGUE, CZECH REPUBLIC (79%); CZECH REPUBLIC (94%); EUROPE (93%); EUROPEAN UNION MEMBER STATES (90%)
Load-Date: December 30, 2022","The first Global Forum on the Ethics of Artificial Intelligence (AI) took place on 13 December 2022, at Czernin Palace during the Czech Presidency of the Council of the European Union and under the patronage of UNESCO. Organizing the event is a major milestone in building a strong international coalition aimed at ensuring ethical developments and usage of AI worldwide.
The Forums program featured two ministerial sessions, as well as a series of expert roundtables aimed at exploring the state of AI from different angles such as addressing gender bias in AI, ensuring transparency and non-discrimination, promoting environmental protection, and engaging with the private sector. Ministers and representatives from different EU institutions and other regions of the world met at the Forum along with frontline experts in the field of AI ethics.
We welcome the UNESCO Recommendation on the Ethics of Artificial Intelligence. I consider it an effective instrument that seeks to regulate the use of AI in an ethical way, said the Czech Foreign Minister, Jan Lipavsk, as he opened the Forum.
Gabriela Ramos, Assistant Director General for Social and Human Sciences of UNESCO, highlighted in her speech: Holding the first Global Forum on the Ethics of AI in Prague under the Czech Presidency of the Council of the EU marks a major milestone. This represents a real convergence of the efforts of UNESCO and the European Union to build strong institutional and regulatory frameworks around the world, to ensure ethical and inclusive technological change.
I am happy that the Czech Republic continues promoting a human-centric approach to digital technologies. The ambition of UNESCO's Recommendation is to protect human rights and human dignity and its implementation should be our ethical guiding compass allowing us to build strong respect for the rule of law in the digital world, said Deputy Prime Minister for Digitalization Ivan Barto.
Furthermore, Deputy Minister for European Affairs Marek Havrda stated, among other things, that ""artificial intelligence has enormous potential for the development of our societies and solutions to global challenges such as climate change. However, we must be able to ensure that it is used in accordance with general ethical standards. Today's first global forum enabled the sharing of concrete practices between ministers and experts from several continents. It is such an important step on the road to trustworthy and ethical artificial intelligence.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 812
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EUROPEAN UNION (92%); ETHICS (91%); INTERNATIONAL ECONOMIC ORGANIZATIONS (91%); ARTIFICIAL INTELLIGENCE (90%); EU PRESIDENCY (90%); EUROPEAN UNION INSTITUTIONS (90%); TALKS & MEETINGS (90%); GOVERNMENT ADVISORS & MINISTERS (89%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (78%); RULE OF LAW (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CLIMATE CHANGE (75%); NEGATIVE SOCIETAL NEWS (75%); HEADS OF STATE & GOVERNMENT (73%); INTERNATIONAL RELATIONS (73%); STATE DEPARTMENTS & FOREIGN SERVICES (73%); ENVIRONMENT & NATURAL RESOURCES (70%); GENDER & SEX DISCRIMINATION (70%); PRIME MINISTERS (50%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%)
Geographic: PRAGUE, CZECH REPUBLIC (79%); CZECH REPUBLIC (94%); EUROPE (93%); EUROPEAN UNION MEMBER STATES (90%)
Load-Date: December 30, 2022",positive,0.654076874256134,balanced/neutral,"['bias', 'discrimination', 'transparency', 'security', 'human rights']",['dignity'],"['regulation', 'policy', 'standards', 'law', 'should', 'must']",[],5,1,6,0
2021,Unknown Title,"Body
2022 NOV 29 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Research findings on Artificial Intelligence are discussed in a new report. According to news reporting from Zigong, People's Republic of China, by NewsRx editors, the research stated, ""With the wide application of artificial intelligence, how to make ethical reasoning and moral decision-making by intelligent machines with high autonomy in the future has become one of the most urgent problems to be solved in the study of machine ethics. In order to solve the ethical dilemma of artificial intelligence, machine ethics put forward the theoretical presupposition of moral computation."" 
 The news correspondents obtained a quote from the research from Sichuan University, ""However, there are methodological challenges in the theoretical presupposition of moral computing in moral theory, background representation, moral phenomenon and subjective initiative. In addition, according to advocates, moral computation as a better moral explanation provides an epistemological basis for the ethical turn. However, this 'revolution of moral thinking' itself has many limitations."" 
 According to the news reporters, the research concluded: ""Therefore, to realize the integrated development of moral philosophy and intelligent machines, we can consider the status of machine ethics to crack the ethical dilemma of methodology and epistemology, and bring the behaviour of intelligent machines more in line with ethics and morality in the human sense."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethical Dilemmas and Solution Strategies In Creating Intelligent Moral Machines. Ethical Perspectives, 2021;28(4):473-497. Ethical Perspectives can be contacted at: Peeters, Bondgenotenlaan 153, B-3000 Leuven, Belgium. 
 Our news journalists report that additional information may be obtained by contacting Zichun Xu, Sichuan University, Zigong, People's Republic of China. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.2143/EP.28.4.3290397. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Zigong, People's Republic of China, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning, Sichuan University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); PHILOSOPHY (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); EMERGING TECHNOLOGY (74%); WRITERS (73%); Zigong;People's Republic of China;Asia;Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); WRITERS (73%)
Geographic: SOUTHWEST CHINA (91%); SICHUAN, CHINA (90%); ASIA (91%); CHINA (91%); BELGIUM (68%)
Load-Date: November 29, 2022","2022 NOV 29 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Research findings on Artificial Intelligence are discussed in a new report. According to news reporting from Zigong, People's Republic of China, by NewsRx editors, the research stated, ""With the wide application of artificial intelligence, how to make ethical reasoning and moral decision-making by intelligent machines with high autonomy in the future has become one of the most urgent problems to be solved in the study of machine ethics. In order to solve the ethical dilemma of artificial intelligence, machine ethics put forward the theoretical presupposition of moral computation."" 
 The news correspondents obtained a quote from the research from Sichuan University, ""However, there are methodological challenges in the theoretical presupposition of moral computing in moral theory, background representation, moral phenomenon and subjective initiative. In addition, according to advocates, moral computation as a better moral explanation provides an epistemological basis for the ethical turn. However, this 'revolution of moral thinking' itself has many limitations."" 
 According to the news reporters, the research concluded: ""Therefore, to realize the integrated development of moral philosophy and intelligent machines, we can consider the status of machine ethics to crack the ethical dilemma of methodology and epistemology, and bring the behaviour of intelligent machines more in line with ethics and morality in the human sense."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethical Dilemmas and Solution Strategies In Creating Intelligent Moral Machines. Ethical Perspectives, 2021;28(4):473-497. Ethical Perspectives can be contacted at: Peeters, Bondgenotenlaan 153, B-3000 Leuven, Belgium. 
 Our news journalists report that additional information may be obtained by contacting Zichun Xu, Sichuan University, Zigong, People's Republic of China. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.2143/EP.28.4.3290397. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Zigong, People's Republic of China, Asia, Artificial Intelligence, Emerging Technologies, Machine Learning, Sichuan University. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (97%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); INVESTIGATIONS (90%); JOURNALISM (90%); MACHINE LEARNING (90%); PHILOSOPHY (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); EMERGING TECHNOLOGY (74%); WRITERS (73%); Zigong;People's Republic of China;Asia;Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COLLEGES & UNIVERSITIES (89%); ARTIFICIAL INTELLIGENCE ETHICS (79%); NEWS REPORTING (78%); WRITERS (73%)
Geographic: SOUTHWEST CHINA (91%); SICHUAN, CHINA (90%); ASIA (91%); CHINA (91%); BELGIUM (68%)
Load-Date: November 29, 2022",neutral,0.9082975387573242,balanced/neutral,['autonomy'],['autonomy'],[],"['machine learning', 'robotics']",1,1,0,2
2021,Unknown Title,"Body
2022 JUN 09 (NewsRx) -- By a News Reporter-Staff News Editor at Politics, Law & Government Daily -- New research on religion is the subject of a new report. According to news reporting originating from Kingston, Canada, by NewsRx correspondents, research stated, ""Potential spiritual impacts of Artificial Intelligence (AI) driven Assistive Technologies (AT) for older adults are absent in most ethics conversations.""
 The news reporters obtained a quote from the research from Queen's University: ""Intelligent Assistive Technology (IAT) is the term used to describe the spectrum of Assistive Technologies that use AI. In this theoretical essay, I begin by introducing examples of AT and IAT for older adults with age-related disabilities. I argue that spirituality is a marginalized value in ethics that must be considered if IAT ethics is to address the whole person. Some of the potential spiritual impacts of IATs will be suggested through engagement with three core spiritual needs. I ask how IAT might impact these three core spiritual needs. This is not meant to be an exhaustive study of the spiritual impacts of AT.""
 According to the news editors, the research concluded: ""Through the engagement of one approach to spiritual needs, this article proposes that IAT ethics issues intersect with the spiritual needs of aging adults and, therefore, that potential spiritual impacts ought to be addressed as part of IAT ethics for older adults.""
 For more information on this research see: Intelligent Assistive Technology Ethics for Aging Adults: Spiritual Impacts as a Necessary Consideration. Religions, 2022,13(452):452. (Religions - http://www.mdpi.com/journal/religions/). The publisher for Religions is MDPI AG.
 A free version of this journal article is available at https://doi.org/10.3390/rel13050452.
 Our news journalists report that more information may be obtained by contacting Tracy J. Trothen, School of Religion and School of Rehabilitation Therapy, Queen's University, Kingston, ON K7L 3N6, Canada.
 Keywords for this news article include: Queen's University, Kingston, Canada, North and Central America, Assistive Technology, Global Views, Religion, Technology.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ADULTS (91%); AGING (90%); ARTIFICIAL INTELLIGENCE (90%); ELECTIONS & POLITICS (90%); ETHICS (90%); GOVERNMENT & PUBLIC ADMINISTRATION (90%); JOURNALISM (90%); PROSTHETIC & ASSISTIVE DEVICES (90%); RELIGION (90%); RESEARCH REPORTS (90%); SENIOR CITIZENS (90%); NEWS REPORTING (78%); RELIGION IN SCHOOLS (78%); WRITERS (73%); WEDDINGS & ENGAGEMENTS (72%); Assistive Technology;Global Views;Religion;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); PROSTHETIC & ASSISTIVE DEVICES (90%); NEWS REPORTING (78%); WRITERS (73%)
Geographic: CANADA (93%); CENTRAL AMERICA (79%)
Load-Date: July 28, 2022","2022 JUN 09 (NewsRx) -- By a News Reporter-Staff News Editor at Politics, Law & Government Daily -- New research on religion is the subject of a new report. According to news reporting originating from Kingston, Canada, by NewsRx correspondents, research stated, ""Potential spiritual impacts of Artificial Intelligence (AI) driven Assistive Technologies (AT) for older adults are absent in most ethics conversations.""
 The news reporters obtained a quote from the research from Queen's University: ""Intelligent Assistive Technology (IAT) is the term used to describe the spectrum of Assistive Technologies that use AI. In this theoretical essay, I begin by introducing examples of AT and IAT for older adults with age-related disabilities. I argue that spirituality is a marginalized value in ethics that must be considered if IAT ethics is to address the whole person. Some of the potential spiritual impacts of IATs will be suggested through engagement with three core spiritual needs. I ask how IAT might impact these three core spiritual needs. This is not meant to be an exhaustive study of the spiritual impacts of AT.""
 According to the news editors, the research concluded: ""Through the engagement of one approach to spiritual needs, this article proposes that IAT ethics issues intersect with the spiritual needs of aging adults and, therefore, that potential spiritual impacts ought to be addressed as part of IAT ethics for older adults.""
 For more information on this research see: Intelligent Assistive Technology Ethics for Aging Adults: Spiritual Impacts as a Necessary Consideration. Religions, 2022,13(452):452. (Religions - http://www.mdpi.com/journal/religions/). The publisher for Religions is MDPI AG.
 A free version of this journal article is available at https://doi.org/10.3390/rel13050452.
 Our news journalists report that more information may be obtained by contacting Tracy J. Trothen, School of Religion and School of Rehabilitation Therapy, Queen's University, Kingston, ON K7L 3N6, Canada.
 Keywords for this news article include: Queen's University, Kingston, Canada, North and Central America, Assistive Technology, Global Views, Religion, Technology.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ADULTS (91%); AGING (90%); ARTIFICIAL INTELLIGENCE (90%); ELECTIONS & POLITICS (90%); ETHICS (90%); GOVERNMENT & PUBLIC ADMINISTRATION (90%); JOURNALISM (90%); PROSTHETIC & ASSISTIVE DEVICES (90%); RELIGION (90%); RESEARCH REPORTS (90%); SENIOR CITIZENS (90%); NEWS REPORTING (78%); RELIGION IN SCHOOLS (78%); WRITERS (73%); WEDDINGS & ENGAGEMENTS (72%); Assistive Technology;Global Views;Religion;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); PROSTHETIC & ASSISTIVE DEVICES (90%); NEWS REPORTING (78%); WRITERS (73%)
Geographic: CANADA (93%); CENTRAL AMERICA (79%)
Load-Date: July 28, 2022",neutral,0.9361149072647095,balanced/neutral,[],[],"['law', 'must']",[],0,0,2,0
2021,Unknown Title,"Byline: Targeted News Service
Dateline: WASHINGTON 
Body
WASHINGTON, May 25 (TNSrep) -- The Europol Innovation Lab and the Centre of Excellence in Terrorism, Resilience, Intelligence and Organized Crime Research issued a 124-page report in March 2022 entitled ""Accountability Principles for Artificial Intelligence (AP4AI) in the Internal Security Domain.""
Supporting partners included Eurojust, the European Union Agency for Asylum and the European Union Agency for Law Enforcement Training.
The report was written by B. Akhgar, P.S. Bayerl, K. Bailey, R. Dennis, H. Gibson, S. Heyes, A. Lyle, A. Raven, F. Sampson.
(Continued from Part 1 of 2)
Here are excerpts:
* * *
ENDNOTES
a/ In defining 'internal security' we follow the Internal Security Strategy 2010-2014 which was endorsed by the European Council: ""The concept of internal security must be understood as a wide and comprehensive concept which straddles multiple sectors in order to address these major threats and others which have a direct impact on the lives, safety and well-being of citizens, including natural and man-made disasters such as forest fires, earthquakes, floods and storms."" Internal Security Strategy 2010-2014. https://www.europarl. europa.eu/thinktank/en/document/EPRS_ATA(2014)542180
b/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
1/ Europol. (2021). Internet Organised Crime Threat Assessment 2021. https://www.europol.europa.eu/cms/ sites/default/files/documents/internet_organised_crime_threat_assessment_iocta_2021.pdf
2/ Trend Micro Research. (2020). Malicious Uses and Abuses of Artificial Intelligence. https://www.europol. europa.eu/cms/sites/default/files/documents/malicious_uses_and_abuses_of_artificial_intelligence_ europol.pdf
3/ Whilst AI is a broad term which has proven difficult to define, for the purpose of this project we have adopted the European Commission High-Level Expert Group definition of AI (2018): ""Artificial intelligence (AI) refers to systems that display intelligent behaviour by analysing their environment and taking actions - with some degree of autonomy - to achieve specific goals. AI-based systems can be purely software based, acting in the virtual world (e.g., voice assistants, image analysis software, search engines, speech and face recognition systems) or AI can be embedded in hardware devices (e.g., advanced robots, autonomous cars, drones or Internet of Things applications)."" Communication from the Commission to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions on Artificial Intelligence for Europe, Brussels, 25.4.2018 COM(2018) 237 final.
4/ For example, see proposed EU AI Act, Art 3,17 and 38; https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
5/ Interpol and UNICRI. (2020). Towards Responsible Artificial Intelligence Innovation. http://www.unicri.it/ towards-responsible-artificial-intelligence-innovation
6/ E.g., Lutz, C. (2019). Digital inequalities in the age of artificial intelligence and big data. Human Behaviour and Emerging Technologies, 1(2), 141-148.
7/ See for example PT I of the Police Reform and Social Responsibility Act 2011 in England and Wales. https:// www.legislation.gov.uk/ukpga/2011/13/contents/enacted
8/ See Akhgar et al. (2022). AP4AI Summary Report on Expert Consultation. https://www.ap4ai.eu/node/6
9/ The AP4AI Principles are defined in the AP4AI Summary Report on Expert Consultations. (https://www. ap4ai.eu/node/6). This report also outlines the overall project methodology and the activities leading to the creation of the AP4AI Principles.
10/ This is in line with Art 38, Laying Down Harmonised Rules on Artificial Intelligence (AI ACT) and Amending Certain Union Legislative Acts. https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
11/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
12/ Schedler, A. (1999). Conceptualizing Accountability, in: A. Schedler et al. (eds), The Self-restraining State: Power and Accountability in New Democracies (pp. 13-28).
13/ Ibid.
14/ Thomas Reuters Practical Law. (2021) Accountability Principles. https://uk.practicallaw.thomsonreuters. com/w-014-8164
15/ E.g., Duff, R. A. (2017). Moral and Criminal Responsibility: Answering and Refusing to Answer. https://ssrn. com/abstract=3087771
16/ https://www.hrw.org/world-report/2022/autocrats-on-defensive-can-democrats-rise-to-occasion
17/ The decision of the Court of Appeal for England & Wales on 11 August 2020 serves to underscore the importance of this project. In R (on the application of Bridges) v Chief Constable of South Wales Police and Ors [2020] EWCA Civ 1058 the court identified the key legal risks and attendant community/citizen considerations in the police use of Automated Facial Recognition (AFR) technology during December 2017 and March 2018 and whether those deployments constituted a proportionate interference with Convention rights within Article 8(2) ECHR. The judgment emphasises the critical importance of LEAs having an ""appropriate policy document"" in place in order to be able to demonstrate lawful and fair processing of personal AFR data. Further, it emphasised that having ""a sufficient legal framework"" for the use of the AI system includes a legal basis that must be 'accessible' to the person concerned, meaning that it must be published and comprehensible, and it must be possible to discover what its provisions are. The measure must also be 'foreseeable' meaning that it must be possible for a person to foresee its consequences for them (R (on the Application of Catt) v Association of Chief Police Officers [2015] UKSC 9. Each of these elements is covered within this project.
18/ The overall project approach, together with a description of Cycle 1 activities can be found in Appendix A. The text is replicated from Akhgar et al., (2022). AP4AI Report on Expert Consultations. https://www.ap4ai. eu/node/6 for easier reference.
19/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
20/ The full details of the activities in Cycle 1 are described in AP4AI Summary Report on Expert Consultation (https://www.ap4ai.eu/node/6) and can also be found in Appendix A.
21/ E.g., Deloitte Insights. (2020) Government Trends 2020. What are the most transformative trends in government today? Deloitte Center for Government Insights. https://www2.deloitte.com/content/dam/ insights/us/articles/government-trends-2020/DI_Government-Trends-2020.pdf
22/ Vaio, A.D., Hassan, R., & Alavoine, C., (2021). Data intelligence and analytics: A bibliometric analysis of human-Artificial intelligence in public sector decision-making effectiveness. Technological Forecasting and Social Change. 174, 1-17.
23/ European Commission. (2018). Communication from the Commission to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions. https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2018%3A237%3AFIN
24/ House of Lords. (2020). AI in the UK, no place for complacency. https://committees.parliament.uk/ committee/187/liaison-committee-lords/news/138009/no-room-for-government-complacency-onartificial-intelligence/
25/ Interpol World. (2019). Engaging co-creation for future security threats. https://ecuritydelta.nl/images/ INTERPOL_World_2019_Brochure.pdf
26/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
27/ Information Commissioners Office. https://ico.org.uk/
28/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection; https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-dataprotection.pdf
29/ Law Council of Australia., (2019). Artificial Intelligence: Australia's ethics framework. Department of Industry, Innovation and Science.
30/ UK Government., (2020, September 16). Data Ethics Framework. Central Digital and Data Office. https:// www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework-2020
31/ European Commission., (2018). Artificial Intelligence for Europe. https://eur-lex.europa.eu/legal-content/ EN/TXT/?uri=COM%3A2018%3A237%3AFIN
32/ Evas, T. (2020). European framework on ethical aspects of artificial intelligence, robotics and related technologies. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/654179/EPRS_ STU(2020)654179_EN.pdf
33/ Government of Canada. (2022). Responsible use of artificial intelligence (AI). https://www.canada.ca/en/ government/system/digital-government/digital-government-innovations/responsible-use-ai.html#toc1
34/ European Union., and OEDC. (2021). National strategies on artificial intelligence. AI Watch. H
35/ National Institute of Standards and Technology. (2021). Building Trust in AI and ML. https://www.nist.gov/ system/files/documents/2021/08/18/ai-rmf-rfi-0014-attachment2.pdf
36/ European Commission High-Level Expert Group on Artificial Intelligence., (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelinestrustworthy-ai
37/ Ibid.
38/ European Commission. (2018). Artificial Intelligence for Europe. https://eur-lex.europa.eu/legal-content/ EN/TXT/?uri=COM%3A2018%3A237%3AFIN
39/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
40/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
41/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
42/ Akhgar et al., (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6 for easier Reference
43/ Council of Europe. CEPEJ European Ethical Charter on the use of artificial intelligence (AI) in judicial systems and their environment. https://www.coe.int/en/web/cepej/cepej-european-ethical-charter-on-the-use-ofartificial-intelligence-ai-in-judicial-systems-and-their-environment
44/ Law Commission of Ontario., AI, ADM and the Justice System. https://www.lco-cdo.org/en/our-currentprojects/ai-adm-and-the-justice-system/
45/ Law Council of Australia. (2019). Artificial Intelligence: Australia's ethics framework. Department of Industry, Innovation and Science.
46/ US Department of Homeland Security (DHS). (2021). S&T artificial intelligence and machine learning strategic plan. https://www.dhs.gov/sites/default/files/publications/21_0730_st_ai_ml_strategic_plan_2021.pdf
47/ The Alan Turing Institute & UK AI Council. (2021). AI Ecosystem Survey: Informing the National AI Strategy. Summary Report. https://www.turing.ac.uk/sites/default/files/2021-09/ai-strategy-survey_results_020921. Pdf
48/ Centre for Data Ethics and Innovation. (2020). CDEI AI Barometer. https://assets.publishing.service.gov.uk/ government/uploads/system/uploads/attachment_data/file/894170/CDEI_AI_Barometer.pdf
49/ Europol. Eurojust (June 2019). Common Challenges in Combating Cybercrime. https://www.europol. europa.eu/publications-events/publications/common-challenges-in-combating-cybercrime
50/ Committee on standards in public life., (2020). Artificial Intelligence and Public Standards. https://assets. publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/868284/Web_ Version_AI_and_Public_Standards.PDF
51/ Fuster, G.G., (2020). Artificial intelligence and law enforcement. Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
52/ Committee on standards in public life., (2020). Artificial Intelligence and Public Standards. https://assets. publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/868284/Web_ Version_AI_and_Public_Standards.PDF
53/ Stix, C., (2021). Actionable principles for artificial intelligence policy: Three pathways. Science and Engineering Ethics. 27(15), 1-15.
54/ Mantelero, A. (2020). Elaboration of the feasibility study. Council of Europe.
55/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI ethics for law enforcement: A study into requirements for responsible use of AI at the Dutch police. Delphi, 2, 179.
56/ Parliamentary Secretariat for Financial Services. (2019). Malta Towards Trustworthy AI. Office of the Prime Minister. https://malta.ai/wp-content/uploads/2019/10/Malta_Towards_Ethical_and_Trustworthy_AI_ vFINAL.pdf
57/ College of Policing. (2020). Policing in England and Wales: Future Operating Environment 2040. https:// paas-s3-broker-prod-lon-6453d964-1d1a-432a-9260-5e0ba7d2fc51.s3.eu-west-2.amazonaws.com/s3fspublic/2020-08/Future-Operating-Environment-2040_0.pdf
58/ Europol. (2019). Trustworthy AI Requires Solid Cybersecurity. https://www.europol.europa.eu/media-press/ newsroom/news/trustworthy-ai-requires-solid-cybersecurity
59/ UNODC. (2011). Handbook on police accountability, oversight and integrity. https://www.unodc.org/pdf/ criminal_justice/Handbook_on_police_Accountability_Oversight_and_Integrity.pdf
60/ Police Scotland. (2017). Policing 2026: Our 10 year strategy for policing in Scotland. https://www.scotland. police.uk/spa-media/jjkpn4et/policing-2026-strategy.pdf?view=Standard
61/ Kearns, I., and Muir, R. (2019). Data-driven Policing and Public Value. The Police Foundation. https://www. police-foundation.org.uk/2017/wp-content/uploads/2010/10/data_driven_policing_final.pdf
62/ Police Professional. (2017). Harnessing potential of AI on front line. https://www.policeprofessional.com/ news/harnessing-potential-of-ai-on-front-line-2/
63/ National Security Commission on Artificial Intelligence. (2021). Final Report. https://www.nscai.gov/wpcontent/uploads/2021/03/Full-Report-Digital-1.pdf
64/ Fair Trials. Regulating Artificial Intelligence for Use in Criminal Justice Systems in the EU. https://www. fairtrials.org/app/uploads/2022/01/Regulating-Artificial-Intelligence-for-Use-in-Criminal-Justice-SystemsFair-Trials.pdf
65/ Laat, P.B. (2021). Companies Committed to Responsible AI: From Principles towards Implementation and Regulation? Philosophy and Technology, 34, 1135-1193.
66/ Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., & Barnes, P. (2020). Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 33-44).
67/ Partnership on AI. (n.d.). Explainable AI in Practice. https://partnershiponai.org/workstream/explainable-aiin-practice/
68/ Partnership on AI. (2021). About ML. https://partnershiponai.org/workstream/about-ml/ 69 Cutler, A., Pribic, M., & Humphrey, L., (2019). Everyday Ethics for Artificial Intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
70/ Samsung. (2022). AI Ethics: To develop the best products and services with human resources and technology. https://www.samsung.com/uk/sustainability/digital-responsibility/ai-ethics/
71/ Microsoft. (2022). Responsible AI: We are committed to the advancement of AI driven by ethical principles that put people first. https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6
72/ Accenture. (2022). Artificial Intelligence: AI Ethics and Governance. https://www.accenture.com/gb-en/ services/applied-intelligence/ai-ethics-governance
73/ Wagner, B. (2018) Ethics as an escape from regulation. From ""ethics-washing"" to ethics-shopping? In: E. Bayamlioglu, I. Baraliuc, L. Janssens et al. (eds.) Being Profiled: Cogitas Ergo Sum 10 Years of 'Profiling the European Citizen (p. 84-88). Amsterdam: Amsterdam University Press.
74/ Cutler, A., Pribic, M., & Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
75/ Laat, P.B. (2021). Companies Committed to Responsible AI: From Principles towards Implementation and Regulation? Philosophy and Technology, 34, 1135-1193.
76/ Edelman. (2019). Edelman AI Survey. https://www.edelman.com/sites/g/files/aatuss191/ files/2019-03/2019_Edelman_AI_Survey_Whitepaper.pdf
77/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
78/ Reisman, D., Schultz, J., Crawford, K., & Whittaker, M. (2018). Algorithmic impact assessments. AI Now. https://ainowinstitute.org/aiareport2018.pdf
79/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life. https://www.gov.uk/government/publications/artificialintelligence-and-public-standards-report
80/ Cutler, A., Pribic, M., and Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www. ibm.com/watson/assets/duo/pdf/everydayethics.pdf
81/ Jordan, S., Fazelpour, S., Koshiyama, A., Kueper, J., DeChant, C., Leong, B., Marchant, G., & Shank, C. (2019). Creating a Tool to Reproducibly Estimate the Ethical Impact of Artificial Intelligence. Pulse. https://aipulse. org/creating-a-tool-to-reproducibly-estimate-the-ethical-impact-of-artificial-intelligence/
82/ De Almeida, P.G.R., dos Santos, C.D., and Farias, J.S., (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
83/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
84/ UK.GOV. (2019). Understanding artificial intelligence ethics and safety. https://www.gov.uk/guidance/ understanding-artificial-intelligence-ethics-and-safety 85 OEDC. (2022). Recommendation of the Council on Artificial Intelligence. https://oecd.ai/en/ai-principles
86/ European Commission. (2019). High-Level Expert Group on Artificial Intelligence. https://www.aepd.es/ sites/default/files/2019-12/ai-ethics-guidelines.pdf
87/ Standards Australia., (2019). An artificial intelligence standards roadmap. https://www.standards.org. au/getmedia/ede81912-55a2-4d8e-849f-9844993c3b9d/1515-An-Artificial-Intelligence-StandardsRoadmap12-02-2020.pdf.aspx requirements for responsible use of AI at the Dutch police. Delphi, 2, 179.
88/ OEDC. (2022). Recommendation of the Council on Artificial Intelligence. https://oecd.ai/en/ai-principles, p. 3
89/ IEEE., (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead_v2.pdf
90/ IEEE., (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead_v2.pdf, p. 99
91/ Center for Democracy and Technology. So, you want to build an algorithm. https://www.cdt.info/ddtool/
92/ Neudert, L.M., & Howard, P.N. (2020). Four principles for integrating AI and good governance. Oxford Commission on AI and Good Governance.
93/ Standards Australia. (2019). An artificial intelligence standards roadmap. https://www.standards.org. au/getmedia/ede81912-55a2-4d8e-849f-9844993c3b9d/1515-An-Artificial-Intelligence-StandardsRoadmap12-02-2020.pdf.aspx
94/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
95/ Jobin, A., Ienca, M., & Vayena, E. (2019). The Global Landscape of AI Ethics Guidelines. Nature Machine Intelligence, 1, 389-399.
96/ Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. 30 Minds and Machines, 99(102), 99-120.
97/ Beckley, A., & Kennedy, M. (2020). Ethics and police practice. In: P. Birch, M. Kennedy, and E. Kruger. (eds). Australian Policing: Critical Issues in 21st Century Police Practice. London: Routledge.
98/ Hagendorff, T., (2020). The ethics of AI ethics: An evaluation of guidelines. 30 Minds and Machines, 99(102), 99-120; p. 112
99/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
100/ Kroll, J.A., Huey, J., Barocas, S., Felten, E.W., Reidenberg, J.R., Robinson, D.G., & Yu, H. (2015). Accountable Algorithms. University of Pennsylvania Law Review, 3(165), 633-707.
101/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper. https://dash.harvard.edu/bitstream/ handle/1/34372584/2017-11_aiexplainability-1.pdf?sequence=3
102/ Stix, C. (2021). Actionable principles for artificial intelligence policy: Three pathways. Science and Engineering Ethics, 27(15), 1-15.
103/ Coeckelbergh, M. (2020). Artificial intelligence, responsibility attribution, and a relational justification of Explainability. Science and Engineering Ethics, 26(4), 2051-2068.
104/ De Almeida, P.G.R., dos Santos, C.D., & Farias, J.S. (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
105/ Coeckelbergh, M. (2020). Artificial intelligence, responsibility attribution, and a relational justification of Explainability. Science and Engineering Ethics, 26(4), 2051-2068.
106/ Wilson, C., Dalins, J., & Rolan, G. (2020). Effective, explainable and ethical: AI for law enforcement and community safety. International Conference on Artificial Intelligence for Good (AI4G).
107/ Schrader, D., & Ghosh, D. (2018). Proactively protecting against the singularity: Ethical decision making AI. IEEE Computer and Reliability Societies Review, 16(3), 56-63
108/ De Almeida, P.G.R., dos Santos, C.D., & Farias, J.S., (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
109/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
110/ Engstrom, D. F., Ho, D. E., Sharkey, C. M., & Cuellar, M. F. (2020). Government by algorithm: Artificial intelligence in federal administrative agencies. NYU School of Law, Public Law Research Paper, (20-54).
111/ European Parliament. (2020). Artificial Intelligence and Law Enforcement. Impact on Fundamental Rights. European Parliament. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_ STU(2020)656295(SUM01)_EN.pdf
112/ European Commission High-Level Expert Group on Artificial Intelligence. (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelinestrustworthy-ai
113/ The Committee on Standards in Public Life., (2020). AI and Public Standards. A Review by the Committee on Standards in Public Life. https://www.gov.uk/government/publications/artificial-intelligence-and-publicstandards-report
114/ Australian Government, (2019). Australia's Ethics Framework. A Discussion Paper. Department of Industry, Innovation and Science. https://www.csiro.au/-/media/D61/Reports/Artificial-Intelligence-ethicsframework.pdf
115/ National Security Commission on Artificial Intelligence. (2021). Final Report. https://www.nscai.gov/2021- final-report/
116/ European Parliament. (2020). European framework on ethical aspects of artificial intelligence, robotics and related technologies. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/654179/EPRS_ STU(2020)654179_EN.pdf ; European Parliamentary Research Service & European Parliament. (2019). EU guidelines on ethics in artificial intelligence: Context and implementation. European Parliamentary Research Service. https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/640163/EPRS_BRI(2019)640163_ EN.pdf
117/ Cutler, A., Pribic, M., & Humphrey, L. (2019). Everyday Ethics for Artificial Intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
118/ FRA. (2020). Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_ uploads/fra-2020-artificial-intelligence_en.pdf
119/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic accountability for the public sector. https://www.opengovpartnership.org/documents/algorithmic- 116 accountability-public-sector
120/ Leslie, D. (2019). Understanding AI Ethics and Safety: A guide for the responsible implementation of AI systems in the public sector. https://www.turing.ac.uk/research/publications/understanding-artificialintelligence-ethics-and-safety
121/ Amnesty International. (2019). PHRP Expert Meeting on Predictive Policing - Executive Summary. https:// www.amnesty.nl/content/uploads/2019/08/Expert-meeting-predictive-policing-executive-summary. pdf?x96671
122/ Neudert, N. D., & Howard, P. (2020). Four Principles for Integrating AI and Good Governance. Working paper 2020.1 Oxford, UK: Oxford Commission on AI & Good Governance
123/ European Parliament. (2019). EU guidelines on ethics in artificial intelligence: Context and implementation. European Parliamentary. https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/640163/EPRS_ BRI(2019)640163_EN.pdf ; Research Service & Council of Europe. (2020). AD Hoc Committee on Artificial Intelligence (CAHAI): Feasibility Study. https://rm.coe.int/cahai-2020-23-final-eng-feasibility-study- /1680a0c6da
124/ UK Government. (2020, September 16). Data Ethics Framework. https://www.gov.uk/government/ publications/data-ethics-framework ; Government Digital Service & European Commission. (2021). Regulation of the European Parliament and of the Council: Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts & Privacy International, Article 19., (2018). Privacy and Freedom of Expression in the Age of AI. https://eur-lex.europa.eu/legalcontent/EN/TXT/?uri=CELEX:52021PC0206
125/ Interpol/UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement. https://ai-regulation.com/towards-responsible-ai-innovation-second-interpol-unicri-reporton-artificial-intelligence-for-law-enforcement ; Second Interpol-UNICRI Report on Artificial Intelligence for Law Enforcement & Interpol/UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement. http:// www.unicri.it/artificial-intelligence-and-robotics-law-enforcement
126/ European Parliament. (2020). The Ethics of AI: Issues and Initiatives. European Parliamentary Research Service. https://www.europarl.europa.eu/stoa/en/document/EPRS_STU(2020)634452
127/ Cutler, A., Pribic, M., and Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www. ibm.com/watson/assets/duo/pdf/everydayethics.pdf
128/ Neudert, N. D., & Howard, P., (2020). Four Principles for Integrating AI and Good Governance. Working paper 2020.1 Oxford, UK: Oxford Commission on AI & Good Governance. https://oxcaigg.oii.ox.ac.uk/wp-content/ uploads/sites/124/2020/12/OxCAIGG-Report-Clibre-3.pdf
129/ Centre for Data Ethics and Innovation., (2020). Review into bias in algorithmic decision-making & OECD., (2021). Tools for Trustworthy AI. OECD Digital Economy Papers. OECD Publishing & European Union., (2019). Report with recommendations to the Commission on Civil Law Rules on Robotics. Committee on Legal Affairs.
130/ Interpol., UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement. Second Interpol-UNICRI Report on Artificial Intelligence For Law Enforcement & Interpol., UNICRI., (2019). Artificial Intelligence and Robotics for Law Enforcement
131/ Gemeente Amsterdam, Helsinki, Saidot., (2020). Public AI Registers: Realising AI transparency and civic participation in government use of AI. https://openresearch.amsterdam/nl/page/73074/public-ai-registers
132/ Council of Europe. (2020). Possible introduction of a mechanism for certifying artificial intelligence tools and services in the sphere of justice and the judiciary: Feasibility Study. European Commission for the Efficiency of Justice (CEPEJ). https://rm.coe.int/feasability-study-en-cepej-2020-15/1680a0adf4 133 Interpol., UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement and Interpol & UNICRI, 2019, Second Interpol-UNICRI Report on Artificial Intelligence for Law Enforcement. http://www.unicri.nu/in_focus/files/UNICRI-INTERPOL_Report_Towards_Responsible_AI_ Innovation_small.pdf
134/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
135/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
136/ Cavoukian, A., Taylor, S., & Abrams, M. E. (2010). Privacy by Design: essential for organizational accountability and strong business practices. Identity in the Information Society, 3(2), 405-413.
137/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/algorithmicaccountability-public-sector/
138/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aliged Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
139/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
140/ Centre for Data Ethics and Innovation. (2020). Review into Bias in Algorithmic Decision-Making.
141/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
142/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
143/ European Commission. (2021). Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts. European Commission. https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX:52021PC0206
144/ Central Digital and Data Office & the Office for Artificial Intelligence. (2021). Ethics, Transparency and Accountability Framework for Automated Decision-Making. GOV.UK. https://www.gov.uk/government/ publications/ethics-transparency-and-accountability-framework-for-automated-decision-making/ethicstransparency-and-accountability-framework-for-automated-decision-making#ensure-that-you-arecompliant-with-the-law
145/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. Available at: https:// www.opengovpartnership.org/documents/ algorithmic-accountability-public-sector/
146/ European Parliament. (2017). Report with Recommendations to the Commission on Civil Law Rules on Robotics. 2015/2103(INL).
147/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection. UK. https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-dataprotection.pdf
148/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
149/ High-Level Expert Group on Artificial Intelligence. (2019). Policy and Investment Recommendations for Trustworthy AI. European Commission.
150/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
151/ AI Now. (2018). Algorithmic Accountability Policy Toolkit. https://ainowinstitute.org/aap-toolkit.pdf
152/ Babuta, A. and Oswald, M. (2020). Data Analytics and Algorithms in Policing in England and Wales: Towards a New Policy Framework. RUSI.
153/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
154/ Haataja, M., van de Fliert, L., & Rautio, P. (2020). Public AI Registers: Realising AI Transparency and Civic Participation in Government Use of AI.
155/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
156/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
157/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
158/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
159/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
160/ Reed, C. (2018). How Should We Regulate Artificial Intelligence? https://doi.org/10.1098/rsta.2017.0360
161/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
162/ Holder, C., Khurana, V., & Mark, W. (2018). Artificial Intelligence: Public Perception Attitude and Trust. Technical Report, Bristow, 1-23.
163/ Center for Democracy & Technology. (n.d.). AI & Machine Learning. https://cdt.org/ai-machine-learning/
164/ Janssen, M., & Kuk, G. (2016). The challenges and limits of big data algorithms in technocratic governance. Government Information Quarterly, 33(3), 371-377.
165/ Malgieri, G., & Comande, G. (2017). Why a right to legibility of automated decision-making exists in the general data protection regulation. International Data Privacy Law.
166/ Holder, C., Khurana, V., & Mark, W. (2018). Artificial Intelligence: Public Perception Attitude and Trust. Technical Report, Bristow, 1-23.
167/ Select Committee on Artificial Intelligence. (2020). AI in the UK: No Room for Complaceny. Report HL196, 2019-21. By the authority of the House of Lords.
168/ NPCC. & Association of Police and Crime Commissioners. (2020). National Policing Digital Strategy: Digital, Data and Technology Strategy 2020-2030. https://www.apccs.police.uk/media/4886/national-policingdigital-strategy-2020-2030.pdf
169/ European Commission. (2018). Communication from the Commission to the European Parliament, The European Council, The Council, The European Economic and Social Committee and The Committee of The Regions. Artificial Intelligence for Europe. Brussels, 25.4.2018 COM(2018) 237 final.
170/ Engstrom, D. F., Ho, D. E., Sharkey, C. M., & Cuellar, M. F. (2020). Government by algorithm: Artificial intelligence in federal administrative agencies. NYU School of Law, Public Law Research Paper, (20-54).
171/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection. UK.
172/ Select Committee on Artificial Intelligence. (2018). AI in the UK: Ready, Willing and Able? Report HL100, 2017-19. By the authority of the House of Lords.
173/ Caplan, R., Donovan, J., Hanson, L., & Matthews, J. (18 April 2018). Algorithmic Accountability: A Primer. Data & Society. https://datasociety.net/library/algorithmic-accountability-a-primer/
174/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework.
175/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
176 BritainThinks. (2021). Complete Transparency, Complete Simplicity. Centre for Data Ethics and Innovation, and Central Digital and Data Office. GOV.UK. https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/file/995014/Complete_transparency__complete_simplicity_-_ Accessible.pdf
177/ Ibid
178/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
179/ Ibid
180/ Interpol & UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement.
181/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
182/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
183/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
184/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
185/ Ibid
186/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi.
187/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
188/ Ibid
189/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework.
190/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
191/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
192/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
193/ High-Level Expert Group on Artificial Intelligence. (2019). Policy and Investment Recommendations for Trustworthy AI. European Commission.
194/ Binns, R. (2018). Algorithmic accountability and public reason. Philosophy & technology, 31(4), 543-556.
195/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
196/ The Alan Turing Institute & UK AI Council. (2021). AI Ecosystem Survey: Informing the National AI Strategy. Summary Report.
197/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
198/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
199/ Deloitte. (2021). Urban Future with a Purpose: 12 trends shaping the future of cities by 2030. Deloitte. https:// www2.deloitte.com/global/en/pages/public-sector/articles/urban-future-with-a-purpose/surveillanceand-predictive-policing-through-ai.html
200/ AI Now. (2018). Algorithmic Accountability Policy Toolkit. https://ainowinstitute.org/aap-toolkit.pdf
201/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
202/ European Commission. (2018). Communication from the Commission to the European Parliament, The European Council, The Council, The European Economic and Social Committee and The Committee of The Regions. Artificial Intelligence for Europe. Brussels, 25.4.2018 COM(2018) 237 final.
203/ Center for Democracy & Technology. (n.d.). AI & Machine Learning. https://cdt.org/ai-machine-learning/
204/ Diakopoulos, N., Friedler, S., Arenas, M., Barocas, S., Hay, M., Howe, B., Jagadish, H. V., Unsworth, K., Sahuguet, A., Venkatasubramanian, S., Wilson, C., Yu, C., & Zevenbergen, B. (n.d.). Principles for Accountable Algorithms and a Social Impact Statement for Algorithms. Fairness, Accountability, and Transparency. in Machine Learning (FAT/ML). https://www.fatml.org/resources/principles-for-accountable-algorithms
205/ Association for Computing Machinery US Public Policy Council (USACM). (2017). Statement on Algorithmic Transparency and Accountability. https://www.acm.org/binaries/content/assets/public-policy/2017_ usacm_statement_algorithms.pdf
206/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
207/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
208/ Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., & Barnes, P. (2020). Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 conference on fairness, accountability, and transparency (pp. 33-44).
209/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
210/ Binns, R. (2018). Algorithmic accountability and public reason. Philosophy & technology, 31(4), 543-556.
211/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
212/ Partnership on AI. (n.d.). Explainable AI in Practice. https://partnershiponai.org/workstream/explainable-aiin-practice/
213/ Dawson, D., Schleiger, E., Horton, J., McLaughlin, J., Robinson, C., Quezada, G., & Hajkowicz, S. (2019). Artificial intelligence: Australia's ethics framework-a discussion paper.
214/ Pichai, S. (2018). AI at Google: our principles. The Keyword, 7, 1-3.
215/ GCHQ. (2021). Pioneering a New National Security: The Ethics of Artificial Intelligence.
216/ Council of Europe. (2001). Recommendation Rec (2001)10 adopted by the Committee of Ministers of the Council of Europe on 19 September 2001, p. 18.
217/ European Parliament. (2020). Artificial Intelligence and Law Enforcement. Impact on Fundamental Rights. European Parliament.
218/ Select Committee on Artificial Intelligence. (2018). AI in the UK: Ready, Willing and Able? Report HL100, 2017-19. By the authority of the House of Lords.
219/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
220/ Interpol & UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement.
221/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
222/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
223/ Centre for Data Ethics and Innovation. (2020). Review into Bias in Algorithmic Decision-Making.
224/ OECD. (2021). Tools for Trustworthy AI: A Framework to Compare Implementation Tools for Trustworthy AI Systems. OECD Digital Economy Papers, No. 312. OECD Publishing.
225/ Ibid
226/ Regulation 2016/679 ""General Data Protection Data Regulation"" Article 14(2)(g) https://digital-strategy. ec.europa.eu/en/policies/digital-services-act-package
227/ Automated Decision Systems Accountability Act of 2021 CA A 13
228/ Algorithmic Accountability Act of 2019
229/ European Union (2021) Regulation on the European Parliament and of the Council - Laying Down Harmonised Rules on Artifical Intelligence (Artifical Intellgience Act) and Amemending Certain Union Legilsative Acts. Brussels, European Commission. https://eur-lex.europa.eu/LexUriServ/LexUriServ. do?uri=SWD:2021:0085:FIN:EN:PDF
230/ Council of the European Union. (2020). Presidency Conclusions on the Charter of Fundamental Rights in the context of Artificial Intelligence and Digital Change. https://www.consilium.europa.eu/media/46496/ st11481-en20.pdf
231/ The Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA mirroring the GDPR in the law enforcement context.
232/ Regulation 2016/679 ""General Data Protection Data Regulation"" Article 14(2)(g) 233 Automated Decision Systems Accountability Act of 2021 CA A 13
234/ Algorithmic Accountability Act of 2019.
235/ Kristen, K (2021) AI and Tort Law, In: F. Martin-Bariteau, T. Scassa (eds.), Artificial Intelligence and the Law in Canada (Toronto: LexisNexis Canada). https://ssrn.com/abstract=373465
236/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework' Department of Innovation and Science. https://www.industry.gov.au/data-and-publications/australias-artificialintelligence-ethics-framework
237/ HM Government. (2021). National AI Strategy. https://www.gov.uk/government/publications/national-aistrategy
238/ HM Government. (2021). National AI Strategy. https://www.gov.uk/government/publications/national-aistrategy
239/ HM Government. (2021). Algorithmic Transparency Standard. https://www.gov.uk/government/collections/ algorithmic-transparency-standard
240/ Ibid
241/ HM Government. (2019). Artificial Intelligence and Public Standards - Written Evidence. https://www.gov. uk/government/publications/artificial-intelligence-and-public-standards-written-evidence
242/ Hacker, P., Krestel, R., Grundmann, S. et al. (2020). Explainable AI under contract and tort law. Legal incentives and Technical Challenges. Artificial Intelligence Law, 28, 415-439.
243/ Council of Bars and Law Societies of Europe. (2020). CCBE Response to the consultation on the European Commission's White Paper on Artificial Intelligence. https://www.ccbe.eu/fileadmin/speciality_distribution/ public/documents/IT_LAW/ITL_Position_papers/EN_ITL_20200605_CCBE-Response-to-the-consultationregarding-the-European-Commission-s-White-Paper-on-AI.pdf
244/ EDPB-EDPS Joint Opinion 5/2021 on the proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) 22. https://edpb. europa.eu/our-work-tools/our-documents/edpbedps-joint-opinion/edpb-edps-joint-opinion-52021- proposal_en
245/ For example, under Article 3 ECHR
246/ Fundamental Rights Agency. (2019). Facial recognition technology: fundamental rights considerations in the context of law enforcement. https://fra.europa.eu/en/publication/2019/facial-recognition-technologyfundamental-rights-considerations-context-law
247/ Fundamental Rights Agency. (2019). Data quality and artificial intelligence - mitigating bias and error to protect fundamental rights. https://fra.europa.eu/en/publication/2019/data-quality-and-artificialintelligence-mitigating-bias-and-error-protect
248/ Fundamental Rights Agency. (2018). #BigData: Discrimination in data-supported decision making. https:// fra.europa.eu/en/publication/2018/bigdata-discrimination-data-supported-decision-making
249/ Fundamental Rights Agency. (2018). Preventing unlawful profiling today and in the future: A guide. https:// fra.europa.eu/en/publication/2018/preventing-unlawful-profiling-today-and-future-guide
250/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
251/ Ibid
252/ Ibid
253/ Flexer, A., Dorer, M., Schluter, J., Grill, T. (2018). Hubness as a case of technical algorithmic bias in music recommendation. In: 2018 IEEE International Conference on Data Mining Workshops (ICDMW), pp. 1062- 1069.
254/ Proposal for a Regulation o the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts, COM/2021/206 final
255/ Access Now. (2021). An EU Artificial Intelligence Act for Fundamental Rights - A Civil Society Statement. https://www.accessnow.org/cms/assets/uploads/2021/11/joint-statement-EU-AIA.pdf
256/ See also the concept of Materiality Threshold cp. section on AP4AI Framework Blueprint
257/ Access Now. (2021). Here's how to fix the EU's Artificial Intelligence Act. https://www.accessnow.org/howto-fix-eu-artificial-intelligence-act
258/ European Digital Rights & Others (2021). European Digital Rights to Margrethe Vestager & Others
259/ Access Now. (2021). Here's how to fix the EU's Artificial Intelligence Act. https://www.accessnow.org/howto-fix-eu-artificial-intelligence-act
260/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
261/ Ibid
262/ Ibid
263/ Council of Europe. (2020). Ad hoc Committee on Artificial Intelligence, 'Feasibility Study', Strasbourg, 17 December 2020 44, 50; Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificialintelligence_en.pdf, p. 87-98.
264/ United Nations. (2011). Guiding Principles on Business and Human Rights. https://www.ohchr.org/ documents/publications/guidingprinciplesbusinesshr_en.pdf
265/ United Nations. (2011). Guiding Principles on Business and Human Rights. https://www.ohchr.org/ documents/publications/guidingprinciplesbusinesshr_en.pdf
266/ Data & Society. (2021). Mandating Human Rights Impacts Assessments in the AI Act. https://ecnl.org/sites/ default/files/2021-11/HRIA%20paper%20ECNL%20and%20Data%20Society.pdf
267/ Mantelero, A. (2020). Regulating AI within the Human Rights Framework: A Roadmapping Methodology, in: Philip Czech et al. (eds), European Yearbook on Human Rights (p. 477-502). Cambridge University Press.
268/ There is also a developing argument that Human Rights (like Data Protection) only cover the living whereas issues such as dignity and respect for the bodies of the dead and also genealogical considerations in DNA processing are a legitimate consideration in the LEA application of AI; see Response of the Biometrics & Surveillance Camera Commissioner to the consultation on data reform 2021 https://www.gov.uk/ government/publications/data-a-new-direction-commissioners-response/dcms-consultation-data-anew-direction-response-by-the-biometrics-and-surveillance-camera-commissioner-accessible-version
269/ IEEE. (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead1e.pdf
270/ Alan Turing Institute. (2021). AI strategy survey results. https://www.turing.ac.uk/sites/default/files/2021-09/ ai-strategy-survey_results_020921.pdf
271/ Committee of Standards in Public Life. (2020). Artificial Intelligence and Public Standards. A Review by the Committee on Standards in Public Life. https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/file/868284/Web_Version_AI_and_Public_Standards.PDF
272/ OECD. (2021). State of implementation of the OECD AI Principles: Insights from national AI policies. OECD Digital Economy Papers, No. 311, OECD Publishing, Paris. https://www.oecd.org/innovation/state-ofimplementation-of-the-oecd-ai-principles-1cd40c44-en.htm
273/ Ibid
274/ High-Level Expert Group on Artificial Intelligence. (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai
275/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
276/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic accountability for the public sector. https://www.opengovpartnership.org/documents/algorithmicaccountability-public-sector
277/ Gemeente Amsterdam, Helsinki, Saidot., (2020). Public AI Registers: Realising AI transparency and civic participation in government use of AI. https://openresearch.amsterdam/nl/page/73074/public-ai-registers
278/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
279/ The recruitment across all countries was conducted by panel provider Qualtrics.
280/ People, who failed to agree to one or more questions, were not allowed to proceed to ensure that all participants included in the consultation had given their full consent.
281/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
282/ Akhgar, B. (2003). Development of a methodology for design and implementation of SIS. SG publication, PEGAH 2003.
283/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
284/ This is in line with Art 38, Laying Down Harmonised Rules on Artificial Intelligence (AI ACT) and Amending Certain Union Legislative Acts; https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
285/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
286/ A reference architecture often refer to a document or set of documents that provide overall structure of 'an implementation' for a particular domain, it contain template solution which its instantiation can be utilised for customisation / re-use by maintaining consistency and applicability
287/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6 121
288/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
289/ Materiality is an assessment of the relative impact that something may have on accountability within the AI programme and in the context of Legality mirrors both the de minimis principle and the concept of proportionality.
290/ Following the MoSCoW prioritisation approach, Must Have, Should Have, Could Have, Won't Have this time. It addresses the problems associated with simpler prioritisation approaches which are based on relative priorities such as risk. ""The use of a simple high, medium or low classification is weaker because definitions of these priorities are missing or need to be defined. Nor does this categorization provide the business with a clear promise of what to expect. A categorisation with a single middle option, such as medium, also allows for indecision"". The latter is particularly problematic in context of accountability towards AI deployment. The specific use of Must Have, Should Have, Could Have or Won't Have this time provides a clear indication of the weight of applicability of specific accountability principle for AI utilisation. See https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation
291/ RACI is an acronym that stands for responsible, accountable, consulted and informed
292/ In the next iterations of this report, we will develop and validate a guide and companion software tool to support organisations to create an AAA, rooted in applications of AI in the internal security domain. The guide will contain use cases and reference models for the application of different AI functions and domains based on the AP4AI principles.
293/ For example, if an LEA adapt the MLOps model it involves the following steps: (a) Framing the business objectives (CONTEX), (b) Searching for the relevant data (SCOPE), (c) Preparing and processing the data (Data Engineering), (d) Developing and training the Machine Learning model, (e) Building and automating a machine learning pipeline (METHODOLOGY), (f) Deploy the model via static or dynamic deployment (METHODOLOGY) and Governance, compliance and security (GOVERNANCE). The mapping exercise should be carried out by the organisation to ensure the 12 Accountability Principles are applied in each stage of development life cycle.
294/ A RACI chart or a responsibility assignment matrix-- provide roles and responsibilities used in project management. A RACI chart defines whether the people involved in a project activity will be Responsible, 'Accountable' (at a tactical, task level), Consulted, or Informed for the corresponding task, milestone, or decision. https://www.teamgantt.com/blog/raci-chart-definition-tips-and-example.
295/ Google has used the term ""MLOps"" where constantly monitoring the dataset and model are done all the way through design to deployment: https://cloud.google.com/architecture/mlops-continuous-deliveryand-automation-pipelines-in-machine-learning
296/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
297/ These are examples of applicable laws, directives, procedures and rules; in the forthcoming report we will provide an extensive set of applicable laws for each principle.
298/ For example, public procurement guidance
299/ See e.g., The Danish Institute for Human Rights (2020) Guidance and Toolbox. https://www.humanrights.dk/ sites/humanrights.dk/files/media/dokumenter/udgivelser/hria_toolbox_2020/eng/dihr_hria_guidance_ and_toolbox_2020_eng.pdf.
300/ Mantelero, A., & Esposito, M.S. (2021). An Evidence-Based Methodology for Human Rights Impact Assessment (HRIA) in the Development of AI Data-Intensive Systems. Computer Law & Security Review, 41, doi:10.1016/j.clsr.2021.105561, https://www.sciencedirect.com/science/article/pii/S0267364921000340.
301/ United Nations. (2011). Guiding Principles on Business and Human Rights https://www.ohchr.org/ Documents/Publications/GuidingPrinciplesBusinessHR_EN.pdf.
302/ See e.g., IEEE. (2019). Ethically Aligned Design, First Edition. https://standards.ieee.org/wp-content/ uploads/import/documents/other/ead1e.pdf?utm_medium=undefined&utm_source=undefined&utm_ campaign=undefined&utm_content=undefined&utm_term=undefined; Independent High-Level Expert Group on Artificial Intelligence set up by the European Commission. (2019). Ethics Guidelines for Trustworthy AI. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai
303/ See e.g. the tools provided by the French, Spanish and Italian data protection authorities respectively. https://www.cnil.fr/en/privacy-impact-assessment-pia; https://www.aepd.es/es/derechos-y-deberes/ cumple-tus-deberes/medidas-de-cumplimiento/evaluaciones-de-impacto; https://www.garanteprivacy. it/regolamentoue/DPIA. As regards the EU context, see also Article 29 Data Protection Working Party (2017). Guidelines on Data Protection Impact Assessment (DPIA) and determining whether processing is ""likely to result in a high risk"" for the purposes of Regulation 2016/679. wp248rev.01.
304/ See EDPB (2020) Guidelines 4/2019 on Article 25 Data Protection by Design and by Default, https:// edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_201904_dataprotection_by_design_ and_by_default_v2.0_en.pdf. See also, ICO. Data protection by design and default. https://ico.org.uk/ for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/ accountability-and-governance/data-protection-by-design-and-default/.
305/ In the subsequent iteration of this report, the notion of meaningful participation of public affairs as discussed in A/HRC/39/28 - E - A/HRC/39/28 -Desktop (https://undocs.org/A/HRC/39/28) will be elaborated.
306/ See e.g., Data Justice Lab. (2021). Advancing Civic Participation in Algorithmic Decision-Making: A Guidebook for the Public Sector. https://datajusticelab.org/wp-content/uploads/2021/06/PublicSectorToolkit_english. pdf
307/ See Article 35.9 GDPR (""Where appropriate, the controller shall seek the views of data subjects or their representatives on the intended processing, without prejudice to the protection of commercial or public interests or the security of processing operations"").
308/ See article 27, Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA.
309/ Consideration for Application of ""A Risk based approach"" see https://digital-strategy.ec.europa.eu/en/ policies/regulatory-framework-ai in line with EC proposal on AI will be taken to account during the next version of this report. 122
310/ See Council of Europe (2017) Guidelines on the protection of individuals with regard to the processing of personal data in a world of Big Data, il of Europe 2017, Section IV, para 3.3. https://rm.coe.int/ CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=09000016806ebe7a
311/ See e.g., Council of Europe, Consultative Committee of the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data (Convention 108) (2019) Guidelines on Artificial Intelligence and Data Protection, T-PD(2019)01. https://unesdoc.unesco.org/ark:/48223/pf0000377881. (""AI developers, manufacturers and service providers are encouraged to set up and consult independent committees of experts from a range of fields, as well as engage with independent academic institutions, which can contribute to designing human rights-based and ethically and socially-oriented AI applications, and to detecting potential bias. Such committees may play an especially important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights, such as in the fields of predictive justice, crime prevention and detection"").
312/ Independence is a requirement of national supervisory authorities, but not of the HRIA or DPIA, which in many cases are forms of self-assessment
313/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
314/ Cp. article 47 of the Charter of Fundamental Rights: https://eur-lex.europa.eu/legal-content/EN/TXT/ HTML/?uri=CELEX:12016P047&from=EN
315/ It should be noted that enforcement relates to the activity of DPAs and is not part of the DPIA; on the other hand, the HRIA is not necessarily enforceable.
316/ This is a general principle relating to the functioning of an organisation that is also reflected in its HRIA and DPIA practices, but not specifically addressed by them. The potential link relates to the required expertise and competence of those making the assessment.
317/ Justice and Home Affaires
318/ Europol's EU Terrorism Situation and Trend report (TE-SAT), published 23 June 2020
319/ We refer to 2019 figures here as explained in Europol's 2021 Terrorism Situation and Trend Report (TESAT) it is not yet clear whether changes in 2020 are simply an artefact of the pandemic and the impact of the United Kingdom leaving the European Union. https://www.europol.europa.eu/cms/sites/default/files/ documents/tesat_2021_0.pdf
320/ Europol's Exploiting Isolation: Offenders and victims of online child sexual abuse during the COVID-19 pandemic, published 19 June 2020.
321/ See e.g., Leclerc, B., Cale, J., Holt, T., and Drew, J. (2022). Child sexual abuse material online: The perspective of online investigators on training and support. Po
TARGETED NEWS SERVICE (founded 2004) features non-partisan 'edited journalism' news briefs and information for news organizations, public policy groups and individuals; as well as 'gathered' public policy information, including news releases, reports, speeches. For more information contact MYRON STRUCK, editor, editor@targetednews.com, Springfield, Virginia; 703/304-1897; https://targetednews.com
-1606679
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (98%); NEGATIVE NEWS (92%); ORGANIZED CRIME (91%); EUROPEAN UNION (90%); TERRORISM (90%); TERRORISM & COUNTERTERRORISM (90%); CYBERCRIME (89%); EUROPEAN UNION INSTITUTIONS (89%); INTERNATIONAL ECONOMIC ORGANIZATIONS (89%); CRIME, LAW ENFORCEMENT & CORRECTIONS (78%); LAW ENFORCEMENT (78%); RESEARCH INSTITUTES (78%); BIOMETRICS (77%); IDENTIFICATION TECHNOLOGIES (77%); SAFETY (77%); SCIENTIFIC SOFTWARE (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); EUROPEAN UNION LAW (71%); LAW ENFORCEMENT TRAINING (71%); LEGISLATIVE BODIES (69%); WILDFIRES (67%); FOREST FIRES (52%)
Company:  ATA CREATIVITY GLOBAL (67%)
Organization: EUROPEAN POLICE OFFICE (94%);  EUROPEAN UNION (84%); EUROJUST (58%); EUROPEAN PARLIAMENT (55%)
Ticker: AACG (NASDAQ) (67%)
Industry: NAICS611710 EDUCATIONAL SUPPORT SERVICES (67%); NAICS611420 COMPUTER TRAINING (67%); SIC8748 BUSINESS CONSULTING SERVICES, NEC (67%); SIC8299 SCHOOLS & EDUCATIONAL SERVICES, NEC (67%); ARTIFICIAL INTELLIGENCE (98%); CYBERCRIME (89%); COMPUTER SOFTWARE (86%); PATTERN RECOGNITION (77%); SCIENTIFIC SOFTWARE (73%); SEARCH ENGINES (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); IMAGE PROCESSING & COMPUTER VISION (72%); LAW ENFORCEMENT TRAINING (71%); VIRTUAL REALITY (71%); INTERNET OF THINGS (64%); AUTONOMOUS VEHICLES (62%); AUTONOMOUS MOTOR VEHICLES (60%)
Geographic: BRUSSELS, BELGIUM (79%); EUROPEAN UNION MEMBER STATES (94%); EUROPE (93%); BELGIUM (79%)
Load-Date: May 25, 2022","WASHINGTON, May 25 (TNSrep) -- The Europol Innovation Lab and the Centre of Excellence in Terrorism, Resilience, Intelligence and Organized Crime Research issued a 124-page report in March 2022 entitled ""Accountability Principles for Artificial Intelligence (AP4AI) in the Internal Security Domain.""
Supporting partners included Eurojust, the European Union Agency for Asylum and the European Union Agency for Law Enforcement Training.
The report was written by B. Akhgar, P.S. Bayerl, K. Bailey, R. Dennis, H. Gibson, S. Heyes, A. Lyle, A. Raven, F. Sampson.
(Continued from Part 1 of 2)
Here are excerpts:
* * *
ENDNOTES
a/ In defining 'internal security' we follow the Internal Security Strategy 2010-2014 which was endorsed by the European Council: ""The concept of internal security must be understood as a wide and comprehensive concept which straddles multiple sectors in order to address these major threats and others which have a direct impact on the lives, safety and well-being of citizens, including natural and man-made disasters such as forest fires, earthquakes, floods and storms."" Internal Security Strategy 2010-2014. https://www.europarl. europa.eu/thinktank/en/document/EPRS_ATA(2014)542180
b/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
1/ Europol. (2021). Internet Organised Crime Threat Assessment 2021. https://www.europol.europa.eu/cms/ sites/default/files/documents/internet_organised_crime_threat_assessment_iocta_2021.pdf
2/ Trend Micro Research. (2020). Malicious Uses and Abuses of Artificial Intelligence. https://www.europol. europa.eu/cms/sites/default/files/documents/malicious_uses_and_abuses_of_artificial_intelligence_ europol.pdf
3/ Whilst AI is a broad term which has proven difficult to define, for the purpose of this project we have adopted the European Commission High-Level Expert Group definition of AI (2018): ""Artificial intelligence (AI) refers to systems that display intelligent behaviour by analysing their environment and taking actions - with some degree of autonomy - to achieve specific goals. AI-based systems can be purely software based, acting in the virtual world (e.g., voice assistants, image analysis software, search engines, speech and face recognition systems) or AI can be embedded in hardware devices (e.g., advanced robots, autonomous cars, drones or Internet of Things applications)."" Communication from the Commission to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions on Artificial Intelligence for Europe, Brussels, 25.4.2018 COM(2018) 237 final.
4/ For example, see proposed EU AI Act, Art 3,17 and 38; https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
5/ Interpol and UNICRI. (2020). Towards Responsible Artificial Intelligence Innovation. http://www.unicri.it/ towards-responsible-artificial-intelligence-innovation
6/ E.g., Lutz, C. (2019). Digital inequalities in the age of artificial intelligence and big data. Human Behaviour and Emerging Technologies, 1(2), 141-148.
7/ See for example PT I of the Police Reform and Social Responsibility Act 2011 in England and Wales. https:// www.legislation.gov.uk/ukpga/2011/13/contents/enacted
8/ See Akhgar et al. (2022). AP4AI Summary Report on Expert Consultation. https://www.ap4ai.eu/node/6
9/ The AP4AI Principles are defined in the AP4AI Summary Report on Expert Consultations. (https://www. ap4ai.eu/node/6). This report also outlines the overall project methodology and the activities leading to the creation of the AP4AI Principles.
10/ This is in line with Art 38, Laying Down Harmonised Rules on Artificial Intelligence (AI ACT) and Amending Certain Union Legislative Acts. https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
11/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
12/ Schedler, A. (1999). Conceptualizing Accountability, in: A. Schedler et al. (eds), The Self-restraining State: Power and Accountability in New Democracies (pp. 13-28).
13/ Ibid.
14/ Thomas Reuters Practical Law. (2021) Accountability Principles. https://uk.practicallaw.thomsonreuters. com/w-014-8164
15/ E.g., Duff, R. A. (2017). Moral and Criminal Responsibility: Answering and Refusing to Answer. https://ssrn. com/abstract=3087771
16/ https://www.hrw.org/world-report/2022/autocrats-on-defensive-can-democrats-rise-to-occasion
17/ The decision of the Court of Appeal for England & Wales on 11 August 2020 serves to underscore the importance of this project. In R (on the application of Bridges) v Chief Constable of South Wales Police and Ors [2020] EWCA Civ 1058 the court identified the key legal risks and attendant community/citizen considerations in the police use of Automated Facial Recognition (AFR) technology during December 2017 and March 2018 and whether those deployments constituted a proportionate interference with Convention rights within Article 8(2) ECHR. The judgment emphasises the critical importance of LEAs having an ""appropriate policy document"" in place in order to be able to demonstrate lawful and fair processing of personal AFR data. Further, it emphasised that having ""a sufficient legal framework"" for the use of the AI system includes a legal basis that must be 'accessible' to the person concerned, meaning that it must be published and comprehensible, and it must be possible to discover what its provisions are. The measure must also be 'foreseeable' meaning that it must be possible for a person to foresee its consequences for them (R (on the Application of Catt) v Association of Chief Police Officers [2015] UKSC 9. Each of these elements is covered within this project.
18/ The overall project approach, together with a description of Cycle 1 activities can be found in Appendix A. The text is replicated from Akhgar et al., (2022). AP4AI Report on Expert Consultations. https://www.ap4ai. eu/node/6 for easier reference.
19/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
20/ The full details of the activities in Cycle 1 are described in AP4AI Summary Report on Expert Consultation (https://www.ap4ai.eu/node/6) and can also be found in Appendix A.
21/ E.g., Deloitte Insights. (2020) Government Trends 2020. What are the most transformative trends in government today? Deloitte Center for Government Insights. https://www2.deloitte.com/content/dam/ insights/us/articles/government-trends-2020/DI_Government-Trends-2020.pdf
22/ Vaio, A.D., Hassan, R., & Alavoine, C., (2021). Data intelligence and analytics: A bibliometric analysis of human-Artificial intelligence in public sector decision-making effectiveness. Technological Forecasting and Social Change. 174, 1-17.
23/ European Commission. (2018). Communication from the Commission to the European Parliament, the European Council, the Council, the European Economic and Social Committee and the Committee of the Regions. https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2018%3A237%3AFIN
24/ House of Lords. (2020). AI in the UK, no place for complacency. https://committees.parliament.uk/ committee/187/liaison-committee-lords/news/138009/no-room-for-government-complacency-onartificial-intelligence/
25/ Interpol World. (2019). Engaging co-creation for future security threats. https://ecuritydelta.nl/images/ INTERPOL_World_2019_Brochure.pdf
26/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
27/ Information Commissioners Office. https://ico.org.uk/
28/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection; https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-dataprotection.pdf
29/ Law Council of Australia., (2019). Artificial Intelligence: Australia's ethics framework. Department of Industry, Innovation and Science.
30/ UK Government., (2020, September 16). Data Ethics Framework. Central Digital and Data Office. https:// www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework-2020
31/ European Commission., (2018). Artificial Intelligence for Europe. https://eur-lex.europa.eu/legal-content/ EN/TXT/?uri=COM%3A2018%3A237%3AFIN
32/ Evas, T. (2020). European framework on ethical aspects of artificial intelligence, robotics and related technologies. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/654179/EPRS_ STU(2020)654179_EN.pdf
33/ Government of Canada. (2022). Responsible use of artificial intelligence (AI). https://www.canada.ca/en/ government/system/digital-government/digital-government-innovations/responsible-use-ai.html#toc1
34/ European Union., and OEDC. (2021). National strategies on artificial intelligence. AI Watch. H
35/ National Institute of Standards and Technology. (2021). Building Trust in AI and ML. https://www.nist.gov/ system/files/documents/2021/08/18/ai-rmf-rfi-0014-attachment2.pdf
36/ European Commission High-Level Expert Group on Artificial Intelligence., (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelinestrustworthy-ai
37/ Ibid.
38/ European Commission. (2018). Artificial Intelligence for Europe. https://eur-lex.europa.eu/legal-content/ EN/TXT/?uri=COM%3A2018%3A237%3AFIN
39/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
40/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
41/ Fuster, G.G., (2020). Artificial intelligence and law enforcement, Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
42/ Akhgar et al., (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6 for easier Reference
43/ Council of Europe. CEPEJ European Ethical Charter on the use of artificial intelligence (AI) in judicial systems and their environment. https://www.coe.int/en/web/cepej/cepej-european-ethical-charter-on-the-use-ofartificial-intelligence-ai-in-judicial-systems-and-their-environment
44/ Law Commission of Ontario., AI, ADM and the Justice System. https://www.lco-cdo.org/en/our-currentprojects/ai-adm-and-the-justice-system/
45/ Law Council of Australia. (2019). Artificial Intelligence: Australia's ethics framework. Department of Industry, Innovation and Science.
46/ US Department of Homeland Security (DHS). (2021). S&T artificial intelligence and machine learning strategic plan. https://www.dhs.gov/sites/default/files/publications/21_0730_st_ai_ml_strategic_plan_2021.pdf
47/ The Alan Turing Institute & UK AI Council. (2021). AI Ecosystem Survey: Informing the National AI Strategy. Summary Report. https://www.turing.ac.uk/sites/default/files/2021-09/ai-strategy-survey_results_020921. Pdf
48/ Centre for Data Ethics and Innovation. (2020). CDEI AI Barometer. https://assets.publishing.service.gov.uk/ government/uploads/system/uploads/attachment_data/file/894170/CDEI_AI_Barometer.pdf
49/ Europol. Eurojust (June 2019). Common Challenges in Combating Cybercrime. https://www.europol. europa.eu/publications-events/publications/common-challenges-in-combating-cybercrime
50/ Committee on standards in public life., (2020). Artificial Intelligence and Public Standards. https://assets. publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/868284/Web_ Version_AI_and_Public_Standards.PDF
51/ Fuster, G.G., (2020). Artificial intelligence and law enforcement. Impact on fundamental rights. https://www. europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_STU(2020)656295_EN.pdf
52/ Committee on standards in public life., (2020). Artificial Intelligence and Public Standards. https://assets. publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/868284/Web_ Version_AI_and_Public_Standards.PDF
53/ Stix, C., (2021). Actionable principles for artificial intelligence policy: Three pathways. Science and Engineering Ethics. 27(15), 1-15.
54/ Mantelero, A. (2020). Elaboration of the feasibility study. Council of Europe.
55/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI ethics for law enforcement: A study into requirements for responsible use of AI at the Dutch police. Delphi, 2, 179.
56/ Parliamentary Secretariat for Financial Services. (2019). Malta Towards Trustworthy AI. Office of the Prime Minister. https://malta.ai/wp-content/uploads/2019/10/Malta_Towards_Ethical_and_Trustworthy_AI_ vFINAL.pdf
57/ College of Policing. (2020). Policing in England and Wales: Future Operating Environment 2040. https:// paas-s3-broker-prod-lon-6453d964-1d1a-432a-9260-5e0ba7d2fc51.s3.eu-west-2.amazonaws.com/s3fspublic/2020-08/Future-Operating-Environment-2040_0.pdf
58/ Europol. (2019). Trustworthy AI Requires Solid Cybersecurity. https://www.europol.europa.eu/media-press/ newsroom/news/trustworthy-ai-requires-solid-cybersecurity
59/ UNODC. (2011). Handbook on police accountability, oversight and integrity. https://www.unodc.org/pdf/ criminal_justice/Handbook_on_police_Accountability_Oversight_and_Integrity.pdf
60/ Police Scotland. (2017). Policing 2026: Our 10 year strategy for policing in Scotland. https://www.scotland. police.uk/spa-media/jjkpn4et/policing-2026-strategy.pdf?view=Standard
61/ Kearns, I., and Muir, R. (2019). Data-driven Policing and Public Value. The Police Foundation. https://www. police-foundation.org.uk/2017/wp-content/uploads/2010/10/data_driven_policing_final.pdf
62/ Police Professional. (2017). Harnessing potential of AI on front line. https://www.policeprofessional.com/ news/harnessing-potential-of-ai-on-front-line-2/
63/ National Security Commission on Artificial Intelligence. (2021). Final Report. https://www.nscai.gov/wpcontent/uploads/2021/03/Full-Report-Digital-1.pdf
64/ Fair Trials. Regulating Artificial Intelligence for Use in Criminal Justice Systems in the EU. https://www. fairtrials.org/app/uploads/2022/01/Regulating-Artificial-Intelligence-for-Use-in-Criminal-Justice-SystemsFair-Trials.pdf
65/ Laat, P.B. (2021). Companies Committed to Responsible AI: From Principles towards Implementation and Regulation? Philosophy and Technology, 34, 1135-1193.
66/ Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., & Barnes, P. (2020). Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 33-44).
67/ Partnership on AI. (n.d.). Explainable AI in Practice. https://partnershiponai.org/workstream/explainable-aiin-practice/
68/ Partnership on AI. (2021). About ML. https://partnershiponai.org/workstream/about-ml/ 69 Cutler, A., Pribic, M., & Humphrey, L., (2019). Everyday Ethics for Artificial Intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
70/ Samsung. (2022). AI Ethics: To develop the best products and services with human resources and technology. https://www.samsung.com/uk/sustainability/digital-responsibility/ai-ethics/
71/ Microsoft. (2022). Responsible AI: We are committed to the advancement of AI driven by ethical principles that put people first. https://www.microsoft.com/en-us/ai/responsible-ai?activetab=pivot1%3aprimaryr6
72/ Accenture. (2022). Artificial Intelligence: AI Ethics and Governance. https://www.accenture.com/gb-en/ services/applied-intelligence/ai-ethics-governance
73/ Wagner, B. (2018) Ethics as an escape from regulation. From ""ethics-washing"" to ethics-shopping? In: E. Bayamlioglu, I. Baraliuc, L. Janssens et al. (eds.) Being Profiled: Cogitas Ergo Sum 10 Years of 'Profiling the European Citizen (p. 84-88). Amsterdam: Amsterdam University Press.
74/ Cutler, A., Pribic, M., & Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
75/ Laat, P.B. (2021). Companies Committed to Responsible AI: From Principles towards Implementation and Regulation? Philosophy and Technology, 34, 1135-1193.
76/ Edelman. (2019). Edelman AI Survey. https://www.edelman.com/sites/g/files/aatuss191/ files/2019-03/2019_Edelman_AI_Survey_Whitepaper.pdf
77/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
78/ Reisman, D., Schultz, J., Crawford, K., & Whittaker, M. (2018). Algorithmic impact assessments. AI Now. https://ainowinstitute.org/aiareport2018.pdf
79/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life. https://www.gov.uk/government/publications/artificialintelligence-and-public-standards-report
80/ Cutler, A., Pribic, M., and Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www. ibm.com/watson/assets/duo/pdf/everydayethics.pdf
81/ Jordan, S., Fazelpour, S., Koshiyama, A., Kueper, J., DeChant, C., Leong, B., Marchant, G., & Shank, C. (2019). Creating a Tool to Reproducibly Estimate the Ethical Impact of Artificial Intelligence. Pulse. https://aipulse. org/creating-a-tool-to-reproducibly-estimate-the-ethical-impact-of-artificial-intelligence/
82/ De Almeida, P.G.R., dos Santos, C.D., and Farias, J.S., (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
83/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
84/ UK.GOV. (2019). Understanding artificial intelligence ethics and safety. https://www.gov.uk/guidance/ understanding-artificial-intelligence-ethics-and-safety 85 OEDC. (2022). Recommendation of the Council on Artificial Intelligence. https://oecd.ai/en/ai-principles
86/ European Commission. (2019). High-Level Expert Group on Artificial Intelligence. https://www.aepd.es/ sites/default/files/2019-12/ai-ethics-guidelines.pdf
87/ Standards Australia., (2019). An artificial intelligence standards roadmap. https://www.standards.org. au/getmedia/ede81912-55a2-4d8e-849f-9844993c3b9d/1515-An-Artificial-Intelligence-StandardsRoadmap12-02-2020.pdf.aspx requirements for responsible use of AI at the Dutch police. Delphi, 2, 179.
88/ OEDC. (2022). Recommendation of the Council on Artificial Intelligence. https://oecd.ai/en/ai-principles, p. 3
89/ IEEE., (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead_v2.pdf
90/ IEEE., (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead_v2.pdf, p. 99
91/ Center for Democracy and Technology. So, you want to build an algorithm. https://www.cdt.info/ddtool/
92/ Neudert, L.M., & Howard, P.N. (2020). Four principles for integrating AI and good governance. Oxford Commission on AI and Good Governance.
93/ Standards Australia. (2019). An artificial intelligence standards roadmap. https://www.standards.org. au/getmedia/ede81912-55a2-4d8e-849f-9844993c3b9d/1515-An-Artificial-Intelligence-StandardsRoadmap12-02-2020.pdf.aspx
94/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
95/ Jobin, A., Ienca, M., & Vayena, E. (2019). The Global Landscape of AI Ethics Guidelines. Nature Machine Intelligence, 1, 389-399.
96/ Hagendorff, T. (2020). The ethics of AI ethics: An evaluation of guidelines. 30 Minds and Machines, 99(102), 99-120.
97/ Beckley, A., & Kennedy, M. (2020). Ethics and police practice. In: P. Birch, M. Kennedy, and E. Kruger. (eds). Australian Policing: Critical Issues in 21st Century Police Practice. London: Routledge.
98/ Hagendorff, T., (2020). The ethics of AI ethics: An evaluation of guidelines. 30 Minds and Machines, 99(102), 99-120; p. 112
99/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
100/ Kroll, J.A., Huey, J., Barocas, S., Felten, E.W., Reidenberg, J.R., Robinson, D.G., & Yu, H. (2015). Accountable Algorithms. University of Pennsylvania Law Review, 3(165), 633-707.
101/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper. https://dash.harvard.edu/bitstream/ handle/1/34372584/2017-11_aiexplainability-1.pdf?sequence=3
102/ Stix, C. (2021). Actionable principles for artificial intelligence policy: Three pathways. Science and Engineering Ethics, 27(15), 1-15.
103/ Coeckelbergh, M. (2020). Artificial intelligence, responsibility attribution, and a relational justification of Explainability. Science and Engineering Ethics, 26(4), 2051-2068.
104/ De Almeida, P.G.R., dos Santos, C.D., & Farias, J.S. (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
105/ Coeckelbergh, M. (2020). Artificial intelligence, responsibility attribution, and a relational justification of Explainability. Science and Engineering Ethics, 26(4), 2051-2068.
106/ Wilson, C., Dalins, J., & Rolan, G. (2020). Effective, explainable and ethical: AI for law enforcement and community safety. International Conference on Artificial Intelligence for Good (AI4G).
107/ Schrader, D., & Ghosh, D. (2018). Proactively protecting against the singularity: Ethical decision making AI. IEEE Computer and Reliability Societies Review, 16(3), 56-63
108/ De Almeida, P.G.R., dos Santos, C.D., & Farias, J.S., (2021). Artificial intelligence regulation: A framework for governance. Ethics and Information Technology, 23(3), 505-525.
109/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
110/ Engstrom, D. F., Ho, D. E., Sharkey, C. M., & Cuellar, M. F. (2020). Government by algorithm: Artificial intelligence in federal administrative agencies. NYU School of Law, Public Law Research Paper, (20-54).
111/ European Parliament. (2020). Artificial Intelligence and Law Enforcement. Impact on Fundamental Rights. European Parliament. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/656295/IPOL_ STU(2020)656295(SUM01)_EN.pdf
112/ European Commission High-Level Expert Group on Artificial Intelligence. (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelinestrustworthy-ai
113/ The Committee on Standards in Public Life., (2020). AI and Public Standards. A Review by the Committee on Standards in Public Life. https://www.gov.uk/government/publications/artificial-intelligence-and-publicstandards-report
114/ Australian Government, (2019). Australia's Ethics Framework. A Discussion Paper. Department of Industry, Innovation and Science. https://www.csiro.au/-/media/D61/Reports/Artificial-Intelligence-ethicsframework.pdf
115/ National Security Commission on Artificial Intelligence. (2021). Final Report. https://www.nscai.gov/2021- final-report/
116/ European Parliament. (2020). European framework on ethical aspects of artificial intelligence, robotics and related technologies. https://www.europarl.europa.eu/RegData/etudes/STUD/2020/654179/EPRS_ STU(2020)654179_EN.pdf ; European Parliamentary Research Service & European Parliament. (2019). EU guidelines on ethics in artificial intelligence: Context and implementation. European Parliamentary Research Service. https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/640163/EPRS_BRI(2019)640163_ EN.pdf
117/ Cutler, A., Pribic, M., & Humphrey, L. (2019). Everyday Ethics for Artificial Intelligence. IBM. https://www.ibm. com/watson/assets/duo/pdf/everydayethics.pdf
118/ FRA. (2020). Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_ uploads/fra-2020-artificial-intelligence_en.pdf
119/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic accountability for the public sector. https://www.opengovpartnership.org/documents/algorithmic- 116 accountability-public-sector
120/ Leslie, D. (2019). Understanding AI Ethics and Safety: A guide for the responsible implementation of AI systems in the public sector. https://www.turing.ac.uk/research/publications/understanding-artificialintelligence-ethics-and-safety
121/ Amnesty International. (2019). PHRP Expert Meeting on Predictive Policing - Executive Summary. https:// www.amnesty.nl/content/uploads/2019/08/Expert-meeting-predictive-policing-executive-summary. pdf?x96671
122/ Neudert, N. D., & Howard, P. (2020). Four Principles for Integrating AI and Good Governance. Working paper 2020.1 Oxford, UK: Oxford Commission on AI & Good Governance
123/ European Parliament. (2019). EU guidelines on ethics in artificial intelligence: Context and implementation. European Parliamentary. https://www.europarl.europa.eu/RegData/etudes/BRIE/2019/640163/EPRS_ BRI(2019)640163_EN.pdf ; Research Service & Council of Europe. (2020). AD Hoc Committee on Artificial Intelligence (CAHAI): Feasibility Study. https://rm.coe.int/cahai-2020-23-final-eng-feasibility-study- /1680a0c6da
124/ UK Government. (2020, September 16). Data Ethics Framework. https://www.gov.uk/government/ publications/data-ethics-framework ; Government Digital Service & European Commission. (2021). Regulation of the European Parliament and of the Council: Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts & Privacy International, Article 19., (2018). Privacy and Freedom of Expression in the Age of AI. https://eur-lex.europa.eu/legalcontent/EN/TXT/?uri=CELEX:52021PC0206
125/ Interpol/UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement. https://ai-regulation.com/towards-responsible-ai-innovation-second-interpol-unicri-reporton-artificial-intelligence-for-law-enforcement ; Second Interpol-UNICRI Report on Artificial Intelligence for Law Enforcement & Interpol/UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement. http:// www.unicri.it/artificial-intelligence-and-robotics-law-enforcement
126/ European Parliament. (2020). The Ethics of AI: Issues and Initiatives. European Parliamentary Research Service. https://www.europarl.europa.eu/stoa/en/document/EPRS_STU(2020)634452
127/ Cutler, A., Pribic, M., and Humphrey, L., (2019). Everyday ethics for artificial intelligence. IBM. https://www. ibm.com/watson/assets/duo/pdf/everydayethics.pdf
128/ Neudert, N. D., & Howard, P., (2020). Four Principles for Integrating AI and Good Governance. Working paper 2020.1 Oxford, UK: Oxford Commission on AI & Good Governance. https://oxcaigg.oii.ox.ac.uk/wp-content/ uploads/sites/124/2020/12/OxCAIGG-Report-Clibre-3.pdf
129/ Centre for Data Ethics and Innovation., (2020). Review into bias in algorithmic decision-making & OECD., (2021). Tools for Trustworthy AI. OECD Digital Economy Papers. OECD Publishing & European Union., (2019). Report with recommendations to the Commission on Civil Law Rules on Robotics. Committee on Legal Affairs.
130/ Interpol., UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement. Second Interpol-UNICRI Report on Artificial Intelligence For Law Enforcement & Interpol., UNICRI., (2019). Artificial Intelligence and Robotics for Law Enforcement
131/ Gemeente Amsterdam, Helsinki, Saidot., (2020). Public AI Registers: Realising AI transparency and civic participation in government use of AI. https://openresearch.amsterdam/nl/page/73074/public-ai-registers
132/ Council of Europe. (2020). Possible introduction of a mechanism for certifying artificial intelligence tools and services in the sphere of justice and the judiciary: Feasibility Study. European Commission for the Efficiency of Justice (CEPEJ). https://rm.coe.int/feasability-study-en-cepej-2020-15/1680a0adf4 133 Interpol., UNICRI. (2020). Towards Responsible AI Innovation, Report on Artificial Intelligence for Law Enforcement and Interpol & UNICRI, 2019, Second Interpol-UNICRI Report on Artificial Intelligence for Law Enforcement. http://www.unicri.nu/in_focus/files/UNICRI-INTERPOL_Report_Towards_Responsible_AI_ Innovation_small.pdf
134/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
135/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
136/ Cavoukian, A., Taylor, S., & Abrams, M. E. (2010). Privacy by Design: essential for organizational accountability and strong business practices. Identity in the Information Society, 3(2), 405-413.
137/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/algorithmicaccountability-public-sector/
138/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aliged Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
139/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
140/ Centre for Data Ethics and Innovation. (2020). Review into Bias in Algorithmic Decision-Making.
141/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
142/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
143/ European Commission. (2021). Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts. European Commission. https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX:52021PC0206
144/ Central Digital and Data Office & the Office for Artificial Intelligence. (2021). Ethics, Transparency and Accountability Framework for Automated Decision-Making. GOV.UK. https://www.gov.uk/government/ publications/ethics-transparency-and-accountability-framework-for-automated-decision-making/ethicstransparency-and-accountability-framework-for-automated-decision-making#ensure-that-you-arecompliant-with-the-law
145/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. Available at: https:// www.opengovpartnership.org/documents/ algorithmic-accountability-public-sector/
146/ European Parliament. (2017). Report with Recommendations to the Commission on Civil Law Rules on Robotics. 2015/2103(INL).
147/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection. UK. https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-dataprotection.pdf
148/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
149/ High-Level Expert Group on Artificial Intelligence. (2019). Policy and Investment Recommendations for Trustworthy AI. European Commission.
150/ Leslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. https://www.gov.uk/guidance/understandingartificial-intelligence-ethics-and-safety
151/ AI Now. (2018). Algorithmic Accountability Policy Toolkit. https://ainowinstitute.org/aap-toolkit.pdf
152/ Babuta, A. and Oswald, M. (2020). Data Analytics and Algorithms in Policing in England and Wales: Towards a New Policy Framework. RUSI.
153/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
154/ Haataja, M., van de Fliert, L., & Rautio, P. (2020). Public AI Registers: Realising AI Transparency and Civic Participation in Government Use of AI.
155/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
156/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
157/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
158/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
159/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
160/ Reed, C. (2018). How Should We Regulate Artificial Intelligence? https://doi.org/10.1098/rsta.2017.0360
161/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
162/ Holder, C., Khurana, V., & Mark, W. (2018). Artificial Intelligence: Public Perception Attitude and Trust. Technical Report, Bristow, 1-23.
163/ Center for Democracy & Technology. (n.d.). AI & Machine Learning. https://cdt.org/ai-machine-learning/
164/ Janssen, M., & Kuk, G. (2016). The challenges and limits of big data algorithms in technocratic governance. Government Information Quarterly, 33(3), 371-377.
165/ Malgieri, G., & Comande, G. (2017). Why a right to legibility of automated decision-making exists in the general data protection regulation. International Data Privacy Law.
166/ Holder, C., Khurana, V., & Mark, W. (2018). Artificial Intelligence: Public Perception Attitude and Trust. Technical Report, Bristow, 1-23.
167/ Select Committee on Artificial Intelligence. (2020). AI in the UK: No Room for Complaceny. Report HL196, 2019-21. By the authority of the House of Lords.
168/ NPCC. & Association of Police and Crime Commissioners. (2020). National Policing Digital Strategy: Digital, Data and Technology Strategy 2020-2030. https://www.apccs.police.uk/media/4886/national-policingdigital-strategy-2020-2030.pdf
169/ European Commission. (2018). Communication from the Commission to the European Parliament, The European Council, The Council, The European Economic and Social Committee and The Committee of The Regions. Artificial Intelligence for Europe. Brussels, 25.4.2018 COM(2018) 237 final.
170/ Engstrom, D. F., Ho, D. E., Sharkey, C. M., & Cuellar, M. F. (2020). Government by algorithm: Artificial intelligence in federal administrative agencies. NYU School of Law, Public Law Research Paper, (20-54).
171/ Information Commissioner's Office. (2017). Big data, artificial intelligence, machine learning and data protection. UK.
172/ Select Committee on Artificial Intelligence. (2018). AI in the UK: Ready, Willing and Able? Report HL100, 2017-19. By the authority of the House of Lords.
173/ Caplan, R., Donovan, J., Hanson, L., & Matthews, J. (18 April 2018). Algorithmic Accountability: A Primer. Data & Society. https://datasociety.net/library/algorithmic-accountability-a-primer/
174/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework.
175/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi, 2, 179.
176 BritainThinks. (2021). Complete Transparency, Complete Simplicity. Centre for Data Ethics and Innovation, and Central Digital and Data Office. GOV.UK. https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/file/995014/Complete_transparency__complete_simplicity_-_ Accessible.pdf
177/ Ibid
178/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
179/ Ibid
180/ Interpol & UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement.
181/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
182/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
183/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
184/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
185/ Ibid
186/ Zardiashvili, L., Bieger, J., Dechesne, F., & Dignum, V. (2019). AI Ethics for Law Enforcement: A Study into Requirements for Responsible Use of AI at the Dutch Police. Delphi.
187/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
188/ Ibid
189/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework.
190/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
191/ Council of Europe. (2020). Ad Hoc Committee on Artificial Intelligence (CAHAI). Feasibility Study. CAHAI(2020)23.
192/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
193/ High-Level Expert Group on Artificial Intelligence. (2019). Policy and Investment Recommendations for Trustworthy AI. European Commission.
194/ Binns, R. (2018). Algorithmic accountability and public reason. Philosophy & technology, 31(4), 543-556.
195/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
196/ The Alan Turing Institute & UK AI Council. (2021). AI Ecosystem Survey: Informing the National AI Strategy. Summary Report.
197/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
198/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
199/ Deloitte. (2021). Urban Future with a Purpose: 12 trends shaping the future of cities by 2030. Deloitte. https:// www2.deloitte.com/global/en/pages/public-sector/articles/urban-future-with-a-purpose/surveillanceand-predictive-policing-through-ai.html
200/ AI Now. (2018). Algorithmic Accountability Policy Toolkit. https://ainowinstitute.org/aap-toolkit.pdf
201/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
202/ European Commission. (2018). Communication from the Commission to the European Parliament, The European Council, The Council, The European Economic and Social Committee and The Committee of The Regions. Artificial Intelligence for Europe. Brussels, 25.4.2018 COM(2018) 237 final.
203/ Center for Democracy & Technology. (n.d.). AI & Machine Learning. https://cdt.org/ai-machine-learning/
204/ Diakopoulos, N., Friedler, S., Arenas, M., Barocas, S., Hay, M., Howe, B., Jagadish, H. V., Unsworth, K., Sahuguet, A., Venkatasubramanian, S., Wilson, C., Yu, C., & Zevenbergen, B. (n.d.). Principles for Accountable Algorithms and a Social Impact Statement for Algorithms. Fairness, Accountability, and Transparency. in Machine Learning (FAT/ML). https://www.fatml.org/resources/principles-for-accountable-algorithms
205/ Association for Computing Machinery US Public Policy Council (USACM). (2017). Statement on Algorithmic Transparency and Accountability. https://www.acm.org/binaries/content/assets/public-policy/2017_ usacm_statement_algorithms.pdf
206/ Phillips, P. J., Hahn, C. A., Fontana, P. C., Broniatowski, D. A., & Przybocki, M. A. (2020). Four principles of explainable artificial intelligence. Gaithersburg, Maryland.
207/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
208/ Raji, I. D., Smart, A., White, R. N., Mitchell, M., Gebru, T., Hutchinson, B., & Barnes, P. (2020). Closing the AI accountability gap: Defining an end-to-end framework for internal algorithmic auditing. In Proceedings of the 2020 conference on fairness, accountability, and transparency (pp. 33-44).
209/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
210/ Binns, R. (2018). Algorithmic accountability and public reason. Philosophy & technology, 31(4), 543-556.
211/ Doshi-Velez, F., Kortz, M., Budish, R., Bavitz, C., Gershman, S., O'Brien, D., & Wood, A. (2017). Accountability of AI under the law: The role of explanation. Berkman Klein Center Working Group on Explanation and the Law, Berkman Klein Center for Internet & Society working paper.
212/ Partnership on AI. (n.d.). Explainable AI in Practice. https://partnershiponai.org/workstream/explainable-aiin-practice/
213/ Dawson, D., Schleiger, E., Horton, J., McLaughlin, J., Robinson, C., Quezada, G., & Hajkowicz, S. (2019). Artificial intelligence: Australia's ethics framework-a discussion paper.
214/ Pichai, S. (2018). AI at Google: our principles. The Keyword, 7, 1-3.
215/ GCHQ. (2021). Pioneering a New National Security: The Ethics of Artificial Intelligence.
216/ Council of Europe. (2001). Recommendation Rec (2001)10 adopted by the Committee of Ministers of the Council of Europe on 19 September 2001, p. 18.
217/ European Parliament. (2020). Artificial Intelligence and Law Enforcement. Impact on Fundamental Rights. European Parliament.
218/ Select Committee on Artificial Intelligence. (2018). AI in the UK: Ready, Willing and Able? Report HL100, 2017-19. By the authority of the House of Lords.
219/ The Committee on Standards in Public Life. (2020). Artificial Intelligence and Public Standards: A Review by the Committee on Standards in Public Life.
220/ Interpol & UNICRI. (2019). Artificial Intelligence and Robotics for Law Enforcement.
221/ The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. (2017). Ethically Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and Intelligent Systems, Version 2. IEEE.
222/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic Accountability for the Public Sector. https://www.opengovpartnership.org/documents/
223/ Centre for Data Ethics and Innovation. (2020). Review into Bias in Algorithmic Decision-Making.
224/ OECD. (2021). Tools for Trustworthy AI: A Framework to Compare Implementation Tools for Trustworthy AI Systems. OECD Digital Economy Papers, No. 312. OECD Publishing.
225/ Ibid
226/ Regulation 2016/679 ""General Data Protection Data Regulation"" Article 14(2)(g) https://digital-strategy. ec.europa.eu/en/policies/digital-services-act-package
227/ Automated Decision Systems Accountability Act of 2021 CA A 13
228/ Algorithmic Accountability Act of 2019
229/ European Union (2021) Regulation on the European Parliament and of the Council - Laying Down Harmonised Rules on Artifical Intelligence (Artifical Intellgience Act) and Amemending Certain Union Legilsative Acts. Brussels, European Commission. https://eur-lex.europa.eu/LexUriServ/LexUriServ. do?uri=SWD:2021:0085:FIN:EN:PDF
230/ Council of the European Union. (2020). Presidency Conclusions on the Charter of Fundamental Rights in the context of Artificial Intelligence and Digital Change. https://www.consilium.europa.eu/media/46496/ st11481-en20.pdf
231/ The Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA mirroring the GDPR in the law enforcement context.
232/ Regulation 2016/679 ""General Data Protection Data Regulation"" Article 14(2)(g) 233 Automated Decision Systems Accountability Act of 2021 CA A 13
234/ Algorithmic Accountability Act of 2019.
235/ Kristen, K (2021) AI and Tort Law, In: F. Martin-Bariteau, T. Scassa (eds.), Artificial Intelligence and the Law in Canada (Toronto: LexisNexis Canada). https://ssrn.com/abstract=373465
236/ Law Council of Australia. (2019). Artificial Intelligence: Australia's Ethics Framework' Department of Innovation and Science. https://www.industry.gov.au/data-and-publications/australias-artificialintelligence-ethics-framework
237/ HM Government. (2021). National AI Strategy. https://www.gov.uk/government/publications/national-aistrategy
238/ HM Government. (2021). National AI Strategy. https://www.gov.uk/government/publications/national-aistrategy
239/ HM Government. (2021). Algorithmic Transparency Standard. https://www.gov.uk/government/collections/ algorithmic-transparency-standard
240/ Ibid
241/ HM Government. (2019). Artificial Intelligence and Public Standards - Written Evidence. https://www.gov. uk/government/publications/artificial-intelligence-and-public-standards-written-evidence
242/ Hacker, P., Krestel, R., Grundmann, S. et al. (2020). Explainable AI under contract and tort law. Legal incentives and Technical Challenges. Artificial Intelligence Law, 28, 415-439.
243/ Council of Bars and Law Societies of Europe. (2020). CCBE Response to the consultation on the European Commission's White Paper on Artificial Intelligence. https://www.ccbe.eu/fileadmin/speciality_distribution/ public/documents/IT_LAW/ITL_Position_papers/EN_ITL_20200605_CCBE-Response-to-the-consultationregarding-the-European-Commission-s-White-Paper-on-AI.pdf
244/ EDPB-EDPS Joint Opinion 5/2021 on the proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) 22. https://edpb. europa.eu/our-work-tools/our-documents/edpbedps-joint-opinion/edpb-edps-joint-opinion-52021- proposal_en
245/ For example, under Article 3 ECHR
246/ Fundamental Rights Agency. (2019). Facial recognition technology: fundamental rights considerations in the context of law enforcement. https://fra.europa.eu/en/publication/2019/facial-recognition-technologyfundamental-rights-considerations-context-law
247/ Fundamental Rights Agency. (2019). Data quality and artificial intelligence - mitigating bias and error to protect fundamental rights. https://fra.europa.eu/en/publication/2019/data-quality-and-artificialintelligence-mitigating-bias-and-error-protect
248/ Fundamental Rights Agency. (2018). #BigData: Discrimination in data-supported decision making. https:// fra.europa.eu/en/publication/2018/bigdata-discrimination-data-supported-decision-making
249/ Fundamental Rights Agency. (2018). Preventing unlawful profiling today and in the future: A guide. https:// fra.europa.eu/en/publication/2018/preventing-unlawful-profiling-today-and-future-guide
250/ Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificial-intelligence_en.pdf
251/ Ibid
252/ Ibid
253/ Flexer, A., Dorer, M., Schluter, J., Grill, T. (2018). Hubness as a case of technical algorithmic bias in music recommendation. In: 2018 IEEE International Conference on Data Mining Workshops (ICDMW), pp. 1062- 1069.
254/ Proposal for a Regulation o the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts, COM/2021/206 final
255/ Access Now. (2021). An EU Artificial Intelligence Act for Fundamental Rights - A Civil Society Statement. https://www.accessnow.org/cms/assets/uploads/2021/11/joint-statement-EU-AIA.pdf
256/ See also the concept of Materiality Threshold cp. section on AP4AI Framework Blueprint
257/ Access Now. (2021). Here's how to fix the EU's Artificial Intelligence Act. https://www.accessnow.org/howto-fix-eu-artificial-intelligence-act
258/ European Digital Rights & Others (2021). European Digital Rights to Margrethe Vestager & Others
259/ Access Now. (2021). Here's how to fix the EU's Artificial Intelligence Act. https://www.accessnow.org/howto-fix-eu-artificial-intelligence-act
260/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
261/ Ibid
262/ Ibid
263/ Council of Europe. (2020). Ad hoc Committee on Artificial Intelligence, 'Feasibility Study', Strasbourg, 17 December 2020 44, 50; Fundamental Rights Agency. (2020). Getting the Future Right - Artificial Intelligence and Fundamental Rights. https://fra.europa.eu/sites/default/files/fra_uploads/fra-2020-artificialintelligence_en.pdf, p. 87-98.
264/ United Nations. (2011). Guiding Principles on Business and Human Rights. https://www.ohchr.org/ documents/publications/guidingprinciplesbusinesshr_en.pdf
265/ United Nations. (2011). Guiding Principles on Business and Human Rights. https://www.ohchr.org/ documents/publications/guidingprinciplesbusinesshr_en.pdf
266/ Data & Society. (2021). Mandating Human Rights Impacts Assessments in the AI Act. https://ecnl.org/sites/ default/files/2021-11/HRIA%20paper%20ECNL%20and%20Data%20Society.pdf
267/ Mantelero, A. (2020). Regulating AI within the Human Rights Framework: A Roadmapping Methodology, in: Philip Czech et al. (eds), European Yearbook on Human Rights (p. 477-502). Cambridge University Press.
268/ There is also a developing argument that Human Rights (like Data Protection) only cover the living whereas issues such as dignity and respect for the bodies of the dead and also genealogical considerations in DNA processing are a legitimate consideration in the LEA application of AI; see Response of the Biometrics & Surveillance Camera Commissioner to the consultation on data reform 2021 https://www.gov.uk/ government/publications/data-a-new-direction-commissioners-response/dcms-consultation-data-anew-direction-response-by-the-biometrics-and-surveillance-camera-commissioner-accessible-version
269/ IEEE. (2019). Ethically aligned design. https://standards.ieee.org/wp-content/uploads/import/documents/ other/ead1e.pdf
270/ Alan Turing Institute. (2021). AI strategy survey results. https://www.turing.ac.uk/sites/default/files/2021-09/ ai-strategy-survey_results_020921.pdf
271/ Committee of Standards in Public Life. (2020). Artificial Intelligence and Public Standards. A Review by the Committee on Standards in Public Life. https://assets.publishing.service.gov.uk/government/uploads/ system/uploads/attachment_data/file/868284/Web_Version_AI_and_Public_Standards.PDF
272/ OECD. (2021). State of implementation of the OECD AI Principles: Insights from national AI policies. OECD Digital Economy Papers, No. 311, OECD Publishing, Paris. https://www.oecd.org/innovation/state-ofimplementation-of-the-oecd-ai-principles-1cd40c44-en.htm
273/ Ibid
274/ High-Level Expert Group on Artificial Intelligence. (2019). Ethics Guidelines for Trustworthy AI. European Commission. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai
275/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
276/ Ada Lovelace Institute, AI Now Institute and Open Government Partnership. (2021). Algorithmic accountability for the public sector. https://www.opengovpartnership.org/documents/algorithmicaccountability-public-sector
277/ Gemeente Amsterdam, Helsinki, Saidot., (2020). Public AI Registers: Realising AI transparency and civic participation in government use of AI. https://openresearch.amsterdam/nl/page/73074/public-ai-registers
278/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
279/ The recruitment across all countries was conducted by panel provider Qualtrics.
280/ People, who failed to agree to one or more questions, were not allowed to proceed to ensure that all participants included in the consultation had given their full consent.
281/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
282/ Akhgar, B. (2003). Development of a methodology for design and implementation of SIS. SG publication, PEGAH 2003.
283/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
284/ This is in line with Art 38, Laying Down Harmonised Rules on Artificial Intelligence (AI ACT) and Amending Certain Union Legislative Acts; https://eur-lex.europa.eu/legal-content/EN/ TXT/?uri=CELEX%3A52021PC0206
285/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
286/ A reference architecture often refer to a document or set of documents that provide overall structure of 'an implementation' for a particular domain, it contain template solution which its instantiation can be utilised for customisation / re-use by maintaining consistency and applicability
287/ See Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6 121
288/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
289/ Materiality is an assessment of the relative impact that something may have on accountability within the AI programme and in the context of Legality mirrors both the de minimis principle and the concept of proportionality.
290/ Following the MoSCoW prioritisation approach, Must Have, Should Have, Could Have, Won't Have this time. It addresses the problems associated with simpler prioritisation approaches which are based on relative priorities such as risk. ""The use of a simple high, medium or low classification is weaker because definitions of these priorities are missing or need to be defined. Nor does this categorization provide the business with a clear promise of what to expect. A categorisation with a single middle option, such as medium, also allows for indecision"". The latter is particularly problematic in context of accountability towards AI deployment. The specific use of Must Have, Should Have, Could Have or Won't Have this time provides a clear indication of the weight of applicability of specific accountability principle for AI utilisation. See https://www.agilebusiness.org/page/ProjectFramework_10_MoSCoWPrioritisation
291/ RACI is an acronym that stands for responsible, accountable, consulted and informed
292/ In the next iterations of this report, we will develop and validate a guide and companion software tool to support organisations to create an AAA, rooted in applications of AI in the internal security domain. The guide will contain use cases and reference models for the application of different AI functions and domains based on the AP4AI principles.
293/ For example, if an LEA adapt the MLOps model it involves the following steps: (a) Framing the business objectives (CONTEX), (b) Searching for the relevant data (SCOPE), (c) Preparing and processing the data (Data Engineering), (d) Developing and training the Machine Learning model, (e) Building and automating a machine learning pipeline (METHODOLOGY), (f) Deploy the model via static or dynamic deployment (METHODOLOGY) and Governance, compliance and security (GOVERNANCE). The mapping exercise should be carried out by the organisation to ensure the 12 Accountability Principles are applied in each stage of development life cycle.
294/ A RACI chart or a responsibility assignment matrix-- provide roles and responsibilities used in project management. A RACI chart defines whether the people involved in a project activity will be Responsible, 'Accountable' (at a tactical, task level), Consulted, or Informed for the corresponding task, milestone, or decision. https://www.teamgantt.com/blog/raci-chart-definition-tips-and-example.
295/ Google has used the term ""MLOps"" where constantly monitoring the dataset and model are done all the way through design to deployment: https://cloud.google.com/architecture/mlops-continuous-deliveryand-automation-pipelines-in-machine-learning
296/ Akhgar et al. (2022). AP4AI Report on Expert Consultations. https://www.ap4ai.eu/node/6
297/ These are examples of applicable laws, directives, procedures and rules; in the forthcoming report we will provide an extensive set of applicable laws for each principle.
298/ For example, public procurement guidance
299/ See e.g., The Danish Institute for Human Rights (2020) Guidance and Toolbox. https://www.humanrights.dk/ sites/humanrights.dk/files/media/dokumenter/udgivelser/hria_toolbox_2020/eng/dihr_hria_guidance_ and_toolbox_2020_eng.pdf.
300/ Mantelero, A., & Esposito, M.S. (2021). An Evidence-Based Methodology for Human Rights Impact Assessment (HRIA) in the Development of AI Data-Intensive Systems. Computer Law & Security Review, 41, doi:10.1016/j.clsr.2021.105561, https://www.sciencedirect.com/science/article/pii/S0267364921000340.
301/ United Nations. (2011). Guiding Principles on Business and Human Rights https://www.ohchr.org/ Documents/Publications/GuidingPrinciplesBusinessHR_EN.pdf.
302/ See e.g., IEEE. (2019). Ethically Aligned Design, First Edition. https://standards.ieee.org/wp-content/ uploads/import/documents/other/ead1e.pdf?utm_medium=undefined&utm_source=undefined&utm_ campaign=undefined&utm_content=undefined&utm_term=undefined; Independent High-Level Expert Group on Artificial Intelligence set up by the European Commission. (2019). Ethics Guidelines for Trustworthy AI. https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai
303/ See e.g. the tools provided by the French, Spanish and Italian data protection authorities respectively. https://www.cnil.fr/en/privacy-impact-assessment-pia; https://www.aepd.es/es/derechos-y-deberes/ cumple-tus-deberes/medidas-de-cumplimiento/evaluaciones-de-impacto; https://www.garanteprivacy. it/regolamentoue/DPIA. As regards the EU context, see also Article 29 Data Protection Working Party (2017). Guidelines on Data Protection Impact Assessment (DPIA) and determining whether processing is ""likely to result in a high risk"" for the purposes of Regulation 2016/679. wp248rev.01.
304/ See EDPB (2020) Guidelines 4/2019 on Article 25 Data Protection by Design and by Default, https:// edpb.europa.eu/sites/default/files/files/file1/edpb_guidelines_201904_dataprotection_by_design_ and_by_default_v2.0_en.pdf. See also, ICO. Data protection by design and default. https://ico.org.uk/ for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/ accountability-and-governance/data-protection-by-design-and-default/.
305/ In the subsequent iteration of this report, the notion of meaningful participation of public affairs as discussed in A/HRC/39/28 - E - A/HRC/39/28 -Desktop (https://undocs.org/A/HRC/39/28) will be elaborated.
306/ See e.g., Data Justice Lab. (2021). Advancing Civic Participation in Algorithmic Decision-Making: A Guidebook for the Public Sector. https://datajusticelab.org/wp-content/uploads/2021/06/PublicSectorToolkit_english. pdf
307/ See Article 35.9 GDPR (""Where appropriate, the controller shall seek the views of data subjects or their representatives on the intended processing, without prejudice to the protection of commercial or public interests or the security of processing operations"").
308/ See article 27, Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA.
309/ Consideration for Application of ""A Risk based approach"" see https://digital-strategy.ec.europa.eu/en/ policies/regulatory-framework-ai in line with EC proposal on AI will be taken to account during the next version of this report. 122
310/ See Council of Europe (2017) Guidelines on the protection of individuals with regard to the processing of personal data in a world of Big Data, il of Europe 2017, Section IV, para 3.3. https://rm.coe.int/ CoERMPublicCommonSearchServices/DisplayDCTMContent?documentId=09000016806ebe7a
311/ See e.g., Council of Europe, Consultative Committee of the Convention for the Protection of Individuals with regard to Automatic Processing of Personal Data (Convention 108) (2019) Guidelines on Artificial Intelligence and Data Protection, T-PD(2019)01. https://unesdoc.unesco.org/ark:/48223/pf0000377881. (""AI developers, manufacturers and service providers are encouraged to set up and consult independent committees of experts from a range of fields, as well as engage with independent academic institutions, which can contribute to designing human rights-based and ethically and socially-oriented AI applications, and to detecting potential bias. Such committees may play an especially important role in areas where transparency and stakeholder engagement can be more difficult due to competing interests and rights, such as in the fields of predictive justice, crime prevention and detection"").
312/ Independence is a requirement of national supervisory authorities, but not of the HRIA or DPIA, which in many cases are forms of self-assessment
313/ Mantelero, A., & Esposito, M.S. (2021). An evidence based methodology for human rights impact assessment (HRIA) in the development of AI data-intensive systems. Computer Law and Security Review, (41), 1-35.
314/ Cp. article 47 of the Charter of Fundamental Rights: https://eur-lex.europa.eu/legal-content/EN/TXT/ HTML/?uri=CELEX:12016P047&from=EN
315/ It should be noted that enforcement relates to the activity of DPAs and is not part of the DPIA; on the other hand, the HRIA is not necessarily enforceable.
316/ This is a general principle relating to the functioning of an organisation that is also reflected in its HRIA and DPIA practices, but not specifically addressed by them. The potential link relates to the required expertise and competence of those making the assessment.
317/ Justice and Home Affaires
318/ Europol's EU Terrorism Situation and Trend report (TE-SAT), published 23 June 2020
319/ We refer to 2019 figures here as explained in Europol's 2021 Terrorism Situation and Trend Report (TESAT) it is not yet clear whether changes in 2020 are simply an artefact of the pandemic and the impact of the United Kingdom leaving the European Union. https://www.europol.europa.eu/cms/sites/default/files/ documents/tesat_2021_0.pdf
320/ Europol's Exploiting Isolation: Offenders and victims of online child sexual abuse during the COVID-19 pandemic, published 19 June 2020.
321/ See e.g., Leclerc, B., Cale, J., Holt, T., and Drew, J. (2022). Child sexual abuse material online: The perspective of online investigators on training and support. Po
TARGETED NEWS SERVICE (founded 2004) features non-partisan 'edited journalism' news briefs and information for news organizations, public policy groups and individuals; as well as 'gathered' public policy information, including news releases, reports, speeches. For more information contact MYRON STRUCK, editor, editor@targetednews.com, Springfield, Virginia; 703/304-1897; https://targetednews.com
-1606679
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE (98%); NEGATIVE NEWS (92%); ORGANIZED CRIME (91%); EUROPEAN UNION (90%); TERRORISM (90%); TERRORISM & COUNTERTERRORISM (90%); CYBERCRIME (89%); EUROPEAN UNION INSTITUTIONS (89%); INTERNATIONAL ECONOMIC ORGANIZATIONS (89%); CRIME, LAW ENFORCEMENT & CORRECTIONS (78%); LAW ENFORCEMENT (78%); RESEARCH INSTITUTES (78%); BIOMETRICS (77%); IDENTIFICATION TECHNOLOGIES (77%); SAFETY (77%); SCIENTIFIC SOFTWARE (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); EUROPEAN UNION LAW (71%); LAW ENFORCEMENT TRAINING (71%); LEGISLATIVE BODIES (69%); WILDFIRES (67%); FOREST FIRES (52%)
Company:  ATA CREATIVITY GLOBAL (67%)
Organization: EUROPEAN POLICE OFFICE (94%);  EUROPEAN UNION (84%); EUROJUST (58%); EUROPEAN PARLIAMENT (55%)
Ticker: AACG (NASDAQ) (67%)
Industry: NAICS611710 EDUCATIONAL SUPPORT SERVICES (67%); NAICS611420 COMPUTER TRAINING (67%); SIC8748 BUSINESS CONSULTING SERVICES, NEC (67%); SIC8299 SCHOOLS & EDUCATIONAL SERVICES, NEC (67%); ARTIFICIAL INTELLIGENCE (98%); CYBERCRIME (89%); COMPUTER SOFTWARE (86%); PATTERN RECOGNITION (77%); SCIENTIFIC SOFTWARE (73%); SEARCH ENGINES (73%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (72%); IMAGE PROCESSING & COMPUTER VISION (72%); LAW ENFORCEMENT TRAINING (71%); VIRTUAL REALITY (71%); INTERNET OF THINGS (64%); AUTONOMOUS VEHICLES (62%); AUTONOMOUS MOTOR VEHICLES (60%)
Geographic: BRUSSELS, BELGIUM (79%); EUROPEAN UNION MEMBER STATES (94%); EUROPE (93%); BELGIUM (79%)
Load-Date: May 25, 2022",neutral,0.93413907289505,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'human rights', 'autonomy', 'agency', 'consent', 'access']","['justice', 'fairness', 'autonomy', 'dignity', 'justice']","['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'framework', 'legislation', 'law', 'compliance', 'should', 'must', 'need to']","['machine learning', 'computer vision', 'facial recognition', 'robotics', 'algorithm', 'data mining']",15,5,13,6
2021,Unknown Title,"Byline: Bryan.Passifiume@sunmedia.ca, Bryan.Passifiume@sunmedia.ca
Body
Tagging a rocking chair on Instagram has landed the federal NDP leader in discussions with the ethics commissioner.
On Sunday, a photo was posted to Jagmeet Singh's Instagram account seated in a grey wing-backed chair, his newborn daughter cradled in his arms.
That same chair, a $1,895 rocker manufactured by Toronto's Monte Design Group, made an appearance in early December in a now-deleted Instagram post on the account owned by Singh's wife, Gurkiran Kaur Sidhu.
Party officials confirmed the chair was gifted to her by the company with the expectation she'd promote it on social media.
Sunday's post was originally tagged with Monte Design's Instagram account, by Wednesday the tag had been removed.
Singh and immediate members of his family are forbidden from accepting such gifts under House of Commons rules - guidelines that apply to all MPs( https://www.ourcommons.ca/About/StandingOrders/appa1-e.htm ).
Section 14 of the House conflict of interest code states MPs and their family aren't allowed to, either directly or indirectly, accept ""any gift or other benefit"" that ""may influence the member in the exercise of a duty or function of his or her office.""
On Wednesday, NDP spokesperson Melanie Richer said the tagged post was merely part of efforts by the couple to promote made-in-Canada products.
""Jagmeet and Gurkiran love finding Canadian companies to support,"" Richer said.
""From the furniture they have in their home to the clothes they wear, they're proud to support Canadian companies and Canadian workers.""
The chair, she said, was specifically gifted to Singh's wife.
""There was no expectation that Jagmeet would post about it,"" Richer said.
""That being said, while they're extremely grateful, they've realized their error and have paid for the gift.""
How I'm spending my time these days // J'ai une nouvelle partenaire pour passer le temps
???? pic.twitter.com/NI77H2TLGA( https://t.co/NI77H2TLGA )
- Jagmeet Singh (@theJagmeetSingh) January 17, 2022( https://twitter.com/theJagmeetSingh/status/1483212807386669056?ref_src=twsrc%5Etfw )
The NDP's lapse-of-judgement defence isn't sitting well with some observers.
UBC political science professor Max Campbell told National Post that following the rules should be a no-brainer for the social media-savvy NDP leader.
""It's just so basic - you get a gift over a certain amount, you have to report it to the commissioner, period,"" he said.
""All politicians should know this, and it's certainly surprising that Singh didn't comply.""
Under the rules, all gifts worth over $200 must be disclosed to the federal ethics commissioner within 60 days of receipt.
Richer said the party is working with the ethics commissioner to ""ensure that any gifts received are declared and that we are in compliance with the Act.""
Canadian politicians are no stranger to ethical dilemmas, with Prime Minister Justin Trudeau and his family finding themselves embroiled in a number of high-profile scandals.
Trudeau became the first prime minister in Canadian history to be convicted of breaking ethics laws after his infamous 2016 Christmas vacation to the Aga Khan's private island in the Bahamas.
In 2018, the prime minister found himself under scrutiny again after the ethics commissioner determined he'd breached the Conflict of Interest Act by improperly pressuring then-Justice Minister Jody Wilson-Raybould to offer SNC-Lavalin a deferred prosecution agreement as the Quebec engineering firm was on trial facing criminal bribery charges.
Ties between the Trudeaus and WE Charity founders Craig and Marc Kielburger were at issue when the organization was chosen to run a nearly billion-dollar student service grant program in summer 2020.
While Ethics Commissioner Mario Dion found the prime minister provided no preferential treatment to the Kielburgers, he ruled former Finance Minister Bill Morneau did - writing in his report that Morneau permitted his ministerial staff to ""disproportionately assist"" the organization when it came seeking federal funding.
Ethics and conflict-of-interest rules are in place for a reason, Campbell said - particularly if Singh is expected to call out other politicians for not following ethics guidelines.
""If you get a gift, particularly a gift of any value, it creates a feeling of being beholden to the giver,"" Campbell said.
""We don't want our politicians to be in that position.""
bpassifiume@postmedia.com( https://can01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmail.google.com%2Fmail%2F%3Fview%3Dcm%26fs%3D1%26tf%3D1%26to%3Dbpassifiume%40postmedia.com&;data=04%7C01%7Cmhiggins%40postmedia.com%7C49f06fe300a948867e8808d9db97fb08%7C26a0106d7d5c4fc5ab9d7ee54dc28bca%7C0%7C0%7C637782268057337200%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&;sdata=GhSCHe4einE%2Bx%2FWdEohLMtBYIElzi4iaW4Mzgxqj96g%3D&;reserved=0 )
On Twitter: @bryanpassifiume( https://can01.safelinks.protection.outlook.com/?url=http%3A%2F%2Ftwitter.com%2Fbryanpassifiume&;data=04%7C01%7Cmhiggins%40postmedia.com%7C49f06fe300a948867e8808d9db97fb08%7C26a0106d7d5c4fc5ab9d7ee54dc28bca%7C0%7C0%7C637782268057337200%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&;sdata=btfzxqPSF0escIDKkrSBI9EmEU8hmIR%2FeZsnqIaMG38%3D&;reserved=0 ) !@COPYRIGHT=© 2022 Postmedia Network Inc. All rights reserved.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); ELECTIONS & POLITICS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); LEGISLATIVE BODIES (78%); SOCIAL MEDIA (78%); POLITICAL SCIENCE (73%); INFANTS & TODDLERS (57%); tagging,rocking,chair,instagram,landed,federal !@PERMALINK= https://nationalpost.com/news/politics/made-in-canada-rocker-lands-jagmeet-singh-in-ethical-trouble (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); SOCIAL MEDIA (78%)
Geographic: TORONTO, ON, CANADA (74%); ONTARIO, CANADA (59%); CANADA (92%)
Load-Date: January 19, 2022","Tagging a rocking chair on Instagram has landed the federal NDP leader in discussions with the ethics commissioner.
On Sunday, a photo was posted to Jagmeet Singh's Instagram account seated in a grey wing-backed chair, his newborn daughter cradled in his arms.
That same chair, a $1,895 rocker manufactured by Toronto's Monte Design Group, made an appearance in early December in a now-deleted Instagram post on the account owned by Singh's wife, Gurkiran Kaur Sidhu.
Party officials confirmed the chair was gifted to her by the company with the expectation she'd promote it on social media.
Sunday's post was originally tagged with Monte Design's Instagram account, by Wednesday the tag had been removed.
Singh and immediate members of his family are forbidden from accepting such gifts under House of Commons rules - guidelines that apply to all MPs( https://www.ourcommons.ca/About/StandingOrders/appa1-e.htm ).
Section 14 of the House conflict of interest code states MPs and their family aren't allowed to, either directly or indirectly, accept ""any gift or other benefit"" that ""may influence the member in the exercise of a duty or function of his or her office.""
On Wednesday, NDP spokesperson Melanie Richer said the tagged post was merely part of efforts by the couple to promote made-in-Canada products.
""Jagmeet and Gurkiran love finding Canadian companies to support,"" Richer said.
""From the furniture they have in their home to the clothes they wear, they're proud to support Canadian companies and Canadian workers.""
The chair, she said, was specifically gifted to Singh's wife.
""There was no expectation that Jagmeet would post about it,"" Richer said.
""That being said, while they're extremely grateful, they've realized their error and have paid for the gift.""
How I'm spending my time these days // J'ai une nouvelle partenaire pour passer le temps
???? pic.twitter.com/NI77H2TLGA( https://t.co/NI77H2TLGA )
- Jagmeet Singh (@theJagmeetSingh) January 17, 2022( https://twitter.com/theJagmeetSingh/status/1483212807386669056?ref_src=twsrc%5Etfw )
The NDP's lapse-of-judgement defence isn't sitting well with some observers.
UBC political science professor Max Campbell told National Post that following the rules should be a no-brainer for the social media-savvy NDP leader.
""It's just so basic - you get a gift over a certain amount, you have to report it to the commissioner, period,"" he said.
""All politicians should know this, and it's certainly surprising that Singh didn't comply.""
Under the rules, all gifts worth over $200 must be disclosed to the federal ethics commissioner within 60 days of receipt.
Richer said the party is working with the ethics commissioner to ""ensure that any gifts received are declared and that we are in compliance with the Act.""
Canadian politicians are no stranger to ethical dilemmas, with Prime Minister Justin Trudeau and his family finding themselves embroiled in a number of high-profile scandals.
Trudeau became the first prime minister in Canadian history to be convicted of breaking ethics laws after his infamous 2016 Christmas vacation to the Aga Khan's private island in the Bahamas.
In 2018, the prime minister found himself under scrutiny again after the ethics commissioner determined he'd breached the Conflict of Interest Act by improperly pressuring then-Justice Minister Jody Wilson-Raybould to offer SNC-Lavalin a deferred prosecution agreement as the Quebec engineering firm was on trial facing criminal bribery charges.
Ties between the Trudeaus and WE Charity founders Craig and Marc Kielburger were at issue when the organization was chosen to run a nearly billion-dollar student service grant program in summer 2020.
While Ethics Commissioner Mario Dion found the prime minister provided no preferential treatment to the Kielburgers, he ruled former Finance Minister Bill Morneau did - writing in his report that Morneau permitted his ministerial staff to ""disproportionately assist"" the organization when it came seeking federal funding.
Ethics and conflict-of-interest rules are in place for a reason, Campbell said - particularly if Singh is expected to call out other politicians for not following ethics guidelines.
""If you get a gift, particularly a gift of any value, it creates a feeling of being beholden to the giver,"" Campbell said.
""We don't want our politicians to be in that position.""
bpassifiume@postmedia.com( https://can01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fmail.google.com%2Fmail%2F%3Fview%3Dcm%26fs%3D1%26tf%3D1%26to%3Dbpassifiume%40postmedia.com&;data=04%7C01%7Cmhiggins%40postmedia.com%7C49f06fe300a948867e8808d9db97fb08%7C26a0106d7d5c4fc5ab9d7ee54dc28bca%7C0%7C0%7C637782268057337200%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&;sdata=GhSCHe4einE%2Bx%2FWdEohLMtBYIElzi4iaW4Mzgxqj96g%3D&;reserved=0 )
On Twitter: @bryanpassifiume( https://can01.safelinks.protection.outlook.com/?url=http%3A%2F%2Ftwitter.com%2Fbryanpassifiume&;data=04%7C01%7Cmhiggins%40postmedia.com%7C49f06fe300a948867e8808d9db97fb08%7C26a0106d7d5c4fc5ab9d7ee54dc28bca%7C0%7C0%7C637782268057337200%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&;sdata=btfzxqPSF0escIDKkrSBI9EmEU8hmIR%2FeZsnqIaMG38%3D&;reserved=0 ) !@COPYRIGHT=© 2022 Postmedia Network Inc. All rights reserved.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); ELECTIONS & POLITICS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); LEGISLATIVE BODIES (78%); SOCIAL MEDIA (78%); POLITICAL SCIENCE (73%); INFANTS & TODDLERS (57%); tagging,rocking,chair,instagram,landed,federal !@PERMALINK= https://nationalpost.com/news/politics/made-in-canada-rocker-lands-jagmeet-singh-in-ethical-trouble (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); SOCIAL MEDIA (78%)
Geographic: TORONTO, ON, CANADA (74%); ONTARIO, CANADA (59%); CANADA (92%)
Load-Date: January 19, 2022",neutral,0.8115801811218262,balanced/neutral,[],"['justice', 'justice']","['guidelines', 'compliance', 'should', 'must']",[],0,2,4,0
2021,Unknown Title,"Body
2022 JUL 04 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Robotics - Androids is the subject of a report. According to news reporting originating in Oxford, United Kingdom, by NewsRx journalists, research stated, ""The growing use of social robots in times of isolation refocuses ethical concerns for Human-Robot Interaction and its implications for social, emotional, and moral life. In this article we raise a virtue-ethics-based concern regarding deployment of social robots relying on deep learning AI and ask whether they may be endowed with ethical virtue, enabling us to speak of 'virtuous robotic AI systems'.""
 The news reporters obtained a quote from the research from Oxford Uehiro Center for Practical Ethics, ""In answering this question, we argue that AI systems cannot genuinely virtuous but can only in a virtuous way. To that end, we start from the philosophical understanding of the nature of virtue in the Aristotelian virtue ethics tradition, which we take to imply the ability to perform (1) the right actions (2) with the right feelings and (3) in the right way. We discuss each of the three requirements and conclude that AI is unable to satisfy any of them.""
 According to the news reporters, the research concluded: ""Furthermore, we relate our claims to current research in machine ethics, technology ethics, and Human-Robot Interaction, discussing various implications, such as the possibility to develop Autonomous Artificial Moral Agents in a virtue ethics framework.""
 This research has been peer-reviewed.
 For more information on this research see: Can Robotic AI Systems Be Virtuous and Why Does This Matter? International Journal of Social Robotics, 2022:1-11. International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; International Journal of Social Robotics - www.springerlink.com/content/1875-4791/)
 Our news correspondents report that additional information may be obtained by contacting Roger Crisp, Oxford Uehiro Center for Practical Ethics, Oxford, UK.
 The publisher of the International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands.
 Keywords for this news article include: Oxford, United Kingdom, Europe, Androids, Emerging Technologies, Human-Robot Interaction, Machine Learning, Nano-robot, Robot, Robotics, Robots.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (92%); ROBOTICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); EMOTIONS (76%); EMERGING TECHNOLOGY (74%); NANOTECHNOLOGY (74%); DEEP LEARNING (73%); WRITERS (73%); Oxford;United Kingdom;Europe;Androids;Emerging Technologies;Human-Robot Interaction;Machine Learning;Nano-robot;Robot;Robotics;Robots (%)
Industry: ROBOTICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); DEEP LEARNING (73%); WRITERS (73%)
Geographic: OXFORD, ENGLAND (92%); UNITED KINGDOM (90%); EUROPE (73%); NETHERLANDS (73%)
Load-Date: July 28, 2022","2022 JUL 04 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- New research on Robotics - Androids is the subject of a report. According to news reporting originating in Oxford, United Kingdom, by NewsRx journalists, research stated, ""The growing use of social robots in times of isolation refocuses ethical concerns for Human-Robot Interaction and its implications for social, emotional, and moral life. In this article we raise a virtue-ethics-based concern regarding deployment of social robots relying on deep learning AI and ask whether they may be endowed with ethical virtue, enabling us to speak of 'virtuous robotic AI systems'.""
 The news reporters obtained a quote from the research from Oxford Uehiro Center for Practical Ethics, ""In answering this question, we argue that AI systems cannot genuinely virtuous but can only in a virtuous way. To that end, we start from the philosophical understanding of the nature of virtue in the Aristotelian virtue ethics tradition, which we take to imply the ability to perform (1) the right actions (2) with the right feelings and (3) in the right way. We discuss each of the three requirements and conclude that AI is unable to satisfy any of them.""
 According to the news reporters, the research concluded: ""Furthermore, we relate our claims to current research in machine ethics, technology ethics, and Human-Robot Interaction, discussing various implications, such as the possibility to develop Autonomous Artificial Moral Agents in a virtue ethics framework.""
 This research has been peer-reviewed.
 For more information on this research see: Can Robotic AI Systems Be Virtuous and Why Does This Matter? International Journal of Social Robotics, 2022:1-11. International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; International Journal of Social Robotics - www.springerlink.com/content/1875-4791/)
 Our news correspondents report that additional information may be obtained by contacting Roger Crisp, Oxford Uehiro Center for Practical Ethics, Oxford, UK.
 The publisher of the International Journal of Social Robotics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands.
 Keywords for this news article include: Oxford, United Kingdom, Europe, Androids, Emerging Technologies, Human-Robot Interaction, Machine Learning, Nano-robot, Robot, Robotics, Robots.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (92%); ROBOTICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); EMOTIONS (76%); EMERGING TECHNOLOGY (74%); NANOTECHNOLOGY (74%); DEEP LEARNING (73%); WRITERS (73%); Oxford;United Kingdom;Europe;Androids;Emerging Technologies;Human-Robot Interaction;Machine Learning;Nano-robot;Robot;Robotics;Robots (%)
Industry: ROBOTICS (92%); MACHINE LEARNING (91%); ARTIFICIAL INTELLIGENCE (90%); HUMAN MACHINE INTERACTION (89%); NEWS REPORTING (78%); DEEP LEARNING (73%); WRITERS (73%)
Geographic: OXFORD, ENGLAND (92%); UNITED KINGDOM (90%); EUROPE (73%); NETHERLANDS (73%)
Load-Date: July 28, 2022",neutral,0.9317082166671753,balanced/neutral,[],"['virtue ethics', 'aristotelian']",['framework'],"['machine learning', 'deep learning', 'robot', 'robotics']",0,2,1,4
2021,Unknown Title,"Byline: Targeted News Service
Dateline: CHAM, Switzerland 
Body
The Journal of Business Ethics, a journal that says it focuses on methodological and disciplinary perspectives concerning ethical issues related to business, published research articles on the following topics in its Special Issue on Business Ethics in the Era of Artificial Intelligence (Vol. 178, No. 4):
Original Papers:
* Employee Perceptions of the Effective Adoption of AI Principles
* The Dawn of the AI Robots: Towards a New Framework of AI Robot Accountability
* Moral Judgments in the Age of Artificial Intelligence
* The Implications of Diverse Human Moral Foundations for Assessing the Ethicality of Artificial Intelligence
* The Ethics of Blockchain in Organizations
* Artificial Intelligence and Declined Guilt: Retailing Morality Comparison Between Human and AI
* Advertising Benefits from Ethical Artificial Intelligence Algorithmic Purchase Decision Pathways
Review Papers:
* Ethics of AI-Enabled Recruiting and Selection: A Review and Research Agenda
* From Reality to World. A Critical Perspective on AI Fairness
The Vol. 178, No. 4 edition of the Journal of Business Ethics can be viewed at https://link.springer.com/journal/10551/volumes-and-issues/178-4. The journal is published by Springer International Publishing.
[Category: Business]
MSTRUCK-7883687 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (97%); BUSINESS ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); RESEARCH REPORTS (90%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); PUBLISHING (90%); PERIODICAL PUBLISHING (79%); RETAIL & WHOLESALE TRADE (78%)
Load-Date: July 7, 2022","The Journal of Business Ethics, a journal that says it focuses on methodological and disciplinary perspectives concerning ethical issues related to business, published research articles on the following topics in its Special Issue on Business Ethics in the Era of Artificial Intelligence (Vol. 178, No. 4):
Original Papers:
* Employee Perceptions of the Effective Adoption of AI Principles
* The Dawn of the AI Robots: Towards a New Framework of AI Robot Accountability
* Moral Judgments in the Age of Artificial Intelligence
* The Implications of Diverse Human Moral Foundations for Assessing the Ethicality of Artificial Intelligence
* The Ethics of Blockchain in Organizations
* Artificial Intelligence and Declined Guilt: Retailing Morality Comparison Between Human and AI
* Advertising Benefits from Ethical Artificial Intelligence Algorithmic Purchase Decision Pathways
Review Papers:
* Ethics of AI-Enabled Recruiting and Selection: A Review and Research Agenda
* From Reality to World. A Critical Perspective on AI Fairness
The Vol. 178, No. 4 edition of the Journal of Business Ethics can be viewed at https://link.springer.com/journal/10551/volumes-and-issues/178-4. The journal is published by Springer International Publishing.
[Category: Business]
MSTRUCK-7883687 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (97%); BUSINESS ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (90%); RESEARCH REPORTS (90%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); PUBLISHING (90%); PERIODICAL PUBLISHING (79%); RETAIL & WHOLESALE TRADE (78%)
Load-Date: July 7, 2022",neutral,0.9179750084877014,balanced/neutral,"['fairness', 'accountability']",['fairness'],['framework'],['robot'],2,1,1,1
2021,Unknown Title,"Byline: Josh Archote
Body
An LSU philosophy professor received a grant from the Louisiana Board of Regents to incorporate ethics and values into the university's science, technology, engineering and math curriculum. 
Deborah Goldgaber, who has been teaching philosophy at LSU since 2014, will work with STEM professors to integrate ethical components to existing classes. The ultimate goal of the project  is to teach STEM students moral literacy so they have the language and skills to talk about ethical challenges in their fields, Goldgaber said. 
Computer science professors, for example, can learn about including lessons on the ethical implications of artificial intelligence, while biology professors explore ways to talk about moral dilemmas presented by advances in medicine and technology. 
""AI is a big area where ethics is constantly at risk of exploding onto the scene,"" Goldgaber said. ""AI is being asked to take the place of human decision makers. How do you have responsible AI? That's a big question.""
Goldgaber will recruit interested STEM professors over the summer and start the training in the fall. The goal is to have the professors incorporate modules into their courses in spring 2023. 
Once implemented, STEM students may come across additional lessons that stray away from the technical coursework - an assigned reading and discussion on privacy issues for a computer science class, for example. 
""Thinking about ethical problems in teaching students is absolutely fundamental and should be part of the behavioral patterns of every professor,"" said Hartmut Kaiser, a computer science professor and senior scientist of LSU's Center for Computation and Technology. 
Kaiser said that he talks about ethical issues surrounding software development with his graduate students. Implementing ethics into already rigorous STEM coursework could initially be a challenge for some professors, Kaiser said, but is nonetheless important. 
Kaiser said the same LSU students in STEM classes now could be the ones who are facing important questions about AI in 20 years. 
He gave the example of what happens when we develop self aware artificial intelligence - do these entities have rights like humans? Can these machines solve any problem a human can? 
Those questions are at the core of the ""philosophy of artificial intelligence,""  a branch of philosophy. But computer scientists will need to start thinking about these questions too, Kaiser said. 
Another issue is that AI relies on a tremendous amount of data that can be skewed or used in harmful ways. Gender bias, racial prejudice and age discrimination can make its way into AI systems since these machines are programmed by humans. 
How much ethics are discussed in STEM classes can vary by major and the course. Haley Devries, who is finishing her freshman year in industrial engineering, said that so far, ethical and workers' rights concerns have been fundamental to her coursework. 
For computer science junior Roshad Richard, classroom discussions surrounding ethics have been absent. 
""We get so wrapped up in the workflow and the engineering, design process, that oftentimes our morals slip out of the window,"" Richard said. ""We're almost seen as computers ourselves.""
Richard said he would welcome the introduction of more ethics and value discussion in STEM coursework. 
STEM students least likely to vote in presidential elections, study finds: LSU STEM educators and students weigh in
Goldgaber's program will be modeled after Harvard's EthiCS program, which is focused on ethics in computer science. But Goldgaber's program will cover all STEM fields at LSU, including bioethics, research ethics and human-centered design. 
""I was pleased to learn about Dr. Goldgaber's efforts to work with science faculty to incorporate ethics into the STEM courses,"" said College of Science dean Cynthia Peterson. ""Dr. Goldgaber embraces a collaborative approach to develop course components desired by our faculty and students.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (94%); PHILOSOPHY (92%); COLLEGE & UNIVERSITY PROFESSORS (90%); COLLEGES & UNIVERSITIES (90%); COMPUTER SCIENCE (90%); CURRICULA (90%); GRANTS & GIFTS (90%); LITERACY & ILLITERACY (90%); MATH & SCIENCE EDUCATION (90%); SOCIAL SCIENCE EDUCATION (90%); STEM EDUCATION (90%); TEACHING & TEACHERS (90%); ARTIFICIAL INTELLIGENCE (89%); ENGINEERING (89%); SCIENCE & TECHNOLOGY (89%); STUDENTS & STUDENT LIFE (89%); DISCRIMINATION (83%); ARTIFICIAL INTELLIGENCE ETHICS (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); LABOR & EMPLOYMENT (77%); GRADUATE & PROFESSIONAL SCHOOLS (73%); RACISM & XENOPHOBIA (73%); EMPLOYMENT DISCRIMINATION (63%); AGE DISCRIMINATION (60%); GENDER & SEX DISCRIMINATION (60%)
Company:  AI SYSTEMS (51%)
Industry: SIC7372 PREPACKAGED SOFTWARE (51%); COLLEGE & UNIVERSITY PROFESSORS (90%); COLLEGES & UNIVERSITIES (90%); COMPUTER SCIENCE (90%); ARTIFICIAL INTELLIGENCE (89%); ENGINEERING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SOFTWARE SERVICES & APPLICATIONS (78%); GRADUATE & PROFESSIONAL SCHOOLS (73%); SOFTWARE DEVELOPMENT & ENGINEERING (73%); COMPUTER SOFTWARE (70%)
Geographic: BATON ROUGE, LA, USA (74%); LOUISIANA, USA (90%); Baton Rouge; LA
Load-Date: May 1, 2022","An LSU philosophy professor received a grant from the Louisiana Board of Regents to incorporate ethics and values into the university's science, technology, engineering and math curriculum. 
Deborah Goldgaber, who has been teaching philosophy at LSU since 2014, will work with STEM professors to integrate ethical components to existing classes. The ultimate goal of the project  is to teach STEM students moral literacy so they have the language and skills to talk about ethical challenges in their fields, Goldgaber said. 
Computer science professors, for example, can learn about including lessons on the ethical implications of artificial intelligence, while biology professors explore ways to talk about moral dilemmas presented by advances in medicine and technology. 
""AI is a big area where ethics is constantly at risk of exploding onto the scene,"" Goldgaber said. ""AI is being asked to take the place of human decision makers. How do you have responsible AI? That's a big question.""
Goldgaber will recruit interested STEM professors over the summer and start the training in the fall. The goal is to have the professors incorporate modules into their courses in spring 2023. 
Once implemented, STEM students may come across additional lessons that stray away from the technical coursework - an assigned reading and discussion on privacy issues for a computer science class, for example. 
""Thinking about ethical problems in teaching students is absolutely fundamental and should be part of the behavioral patterns of every professor,"" said Hartmut Kaiser, a computer science professor and senior scientist of LSU's Center for Computation and Technology. 
Kaiser said that he talks about ethical issues surrounding software development with his graduate students. Implementing ethics into already rigorous STEM coursework could initially be a challenge for some professors, Kaiser said, but is nonetheless important. 
Kaiser said the same LSU students in STEM classes now could be the ones who are facing important questions about AI in 20 years. 
He gave the example of what happens when we develop self aware artificial intelligence - do these entities have rights like humans? Can these machines solve any problem a human can? 
Those questions are at the core of the ""philosophy of artificial intelligence,""  a branch of philosophy. But computer scientists will need to start thinking about these questions too, Kaiser said. 
Another issue is that AI relies on a tremendous amount of data that can be skewed or used in harmful ways. Gender bias, racial prejudice and age discrimination can make its way into AI systems since these machines are programmed by humans. 
How much ethics are discussed in STEM classes can vary by major and the course. Haley Devries, who is finishing her freshman year in industrial engineering, said that so far, ethical and workers' rights concerns have been fundamental to her coursework. 
For computer science junior Roshad Richard, classroom discussions surrounding ethics have been absent. 
""We get so wrapped up in the workflow and the engineering, design process, that oftentimes our morals slip out of the window,"" Richard said. ""We're almost seen as computers ourselves.""
Richard said he would welcome the introduction of more ethics and value discussion in STEM coursework. 
STEM students least likely to vote in presidential elections, study finds: LSU STEM educators and students weigh in
Goldgaber's program will be modeled after Harvard's EthiCS program, which is focused on ethics in computer science. But Goldgaber's program will cover all STEM fields at LSU, including bioethics, research ethics and human-centered design. 
""I was pleased to learn about Dr. Goldgaber's efforts to work with science faculty to incorporate ethics into the STEM courses,"" said College of Science dean Cynthia Peterson. ""Dr. Goldgaber embraces a collaborative approach to develop course components desired by our faculty and students.""
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: ETHICS (94%); PHILOSOPHY (92%); COLLEGE & UNIVERSITY PROFESSORS (90%); COLLEGES & UNIVERSITIES (90%); COMPUTER SCIENCE (90%); CURRICULA (90%); GRANTS & GIFTS (90%); LITERACY & ILLITERACY (90%); MATH & SCIENCE EDUCATION (90%); SOCIAL SCIENCE EDUCATION (90%); STEM EDUCATION (90%); TEACHING & TEACHERS (90%); ARTIFICIAL INTELLIGENCE (89%); ENGINEERING (89%); SCIENCE & TECHNOLOGY (89%); STUDENTS & STUDENT LIFE (89%); DISCRIMINATION (83%); ARTIFICIAL INTELLIGENCE ETHICS (78%); TECHNICIANS & TECHNOLOGICAL WORKERS (78%); LABOR & EMPLOYMENT (77%); GRADUATE & PROFESSIONAL SCHOOLS (73%); RACISM & XENOPHOBIA (73%); EMPLOYMENT DISCRIMINATION (63%); AGE DISCRIMINATION (60%); GENDER & SEX DISCRIMINATION (60%)
Company:  AI SYSTEMS (51%)
Industry: SIC7372 PREPACKAGED SOFTWARE (51%); COLLEGE & UNIVERSITY PROFESSORS (90%); COLLEGES & UNIVERSITIES (90%); COMPUTER SCIENCE (90%); ARTIFICIAL INTELLIGENCE (89%); ENGINEERING (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); SOFTWARE SERVICES & APPLICATIONS (78%); GRADUATE & PROFESSIONAL SCHOOLS (73%); SOFTWARE DEVELOPMENT & ENGINEERING (73%); COMPUTER SOFTWARE (70%)
Geographic: BATON ROUGE, LA, USA (74%); LOUISIANA, USA (90%); Baton Rouge; LA
Load-Date: May 1, 2022",neutral,0.7250708341598511,balanced/neutral,"['privacy', 'bias', 'discrimination']",[],"['should', 'need to']",[],3,0,2,0
2021,Unknown Title,"Body
Moscow: Sberbank has issued the following press release:
On November 23, the AI Journey international artificial intelligence conference hosted a meeting of the Russian Committee on the Ethics of Artificial Intelligence and AI Ethics Code Implementation featuring leading AI ethics experts who spoke about current activities and development plans in the area.
Head of the Russian President ’ s Office for Information and Communication Technology and Infrastructure Tatiana Matveeva and First Deputy Chairman of the Sberbank Executive Board Alexander Vedyakhin addressed the audience highlighting the importance of compliance with ethical principles as part of AI technology development and application, and the need to build people ’ s trust in emerging solutions.
Chairman of the Russian Committee on the Ethics of Artificial Intelligence and AI Ethics Code Implementation Andrey Neznamov moderated the AI Ethics Session and spoke about the current progress and high-potential areas of the Commission ’ s activities.
Participants and viewers learned about the AI Ethics Code provisions implementation mechanics, ongoing document preparation, and AI ethics development prospects.
AI System Risk and Humanitarian Impact Working Group Leaders Anna Abramova and Yuri Lindre noted a progress in methodology guidelines development based on global best practices in AI ethics and told the audience about a document under elaboration aimed to be the lighthouse of AI system developers and operators, mitigating potential implementation risks.
AI Life Cycle Ethical Issue Resolution Best Practice Manual Development Working Group Leaders Alexander Krainov and Yelena Suragina spoke about some of the currently considered ethical issues and about the best practice manual preparation driven by expert opinions on the arising ethical dilemmas to be published in open sources.
AI Ethics Code Implementation Effectiveness Evaluation Working Group Leaders Andrey Kuleshov and Alexander Malakhov reported on methodology materials and compliance criteria preparation. This working group also drafts standard provisions stipulating the status of the AI Ethics Officer and the Russian Committee on the Ethics of Artificial Intelligence within the organization. These standard provisions can later be included by any organization into its internal regulations.
Recommendation Services Working Group Leaders Alexey Byrdin and Andrey Rego shared some of the history of and reasons for establishing the group, interim results, and a draft document on the use of recommendation services, public disclosure formats for AI-driven recommendation services operating principles, and on drafting fair use standards for AI-driven recommendations as part of industry self-regulation.
Guest experts took the floor in the final block of the meeting. Head of the Russian Government ’ s National Artificial Intelligence Development Center Sergei Nakvasin spoke about engaging government bodies in AI ethics practices, and about plans to conduct the second AI Ethics Forum. President of the Big Data Association Anna Serebryanikova shared her big data self-regulation experience and reported on the current progress in drafting the special section of the AI Ethics code on data usage ethics.
AI Alliance Russia unites top tech companies to facilitate mutual development of their competences and accelerated AI adoption in education, research, and corporate operations. The mission of the Alliance is to be the center of development of artificial intelligence in Russia and to provide technological leadership for Russia and corporate members of the Alliance in the field of artificial intelligence globally.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (90%); CONFERENCES & CONVENTIONS (90%); TALKS & MEETINGS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BUSINESS NEWS (89%); REGULATORY COMPLIANCE (89%); SELF REGULATING ORGANIZATIONS (84%); BOARDS OF DIRECTORS (78%); BUSINESS ETHICS (78%); INTERIM FINANCIAL RESULTS (78%); HEADS OF STATE & GOVERNMENT (76%); PRESS RELEASES (73%)
Company:  SBERBANK ROSSII OAO (58%);  BEST INC (54%)
Ticker: SBER (LSE) (58%); SBER (RTS) (58%); BEST (NYSE) (54%)
Industry: NAICS522110 COMMERCIAL BANKING (58%); NAICS522299 INTERNATIONAL, SECONDARY MARKET, AND ALL OTHER NONDEPOSITORY CREDIT INTERMEDIATION (58%); SIC6021 NATIONAL COMMERCIAL BANKS (58%); SIC6082 FOREIGN TRADE & INTERNATIONAL BANKING INSTITUTIONS (58%); SIC5999 MISCELLANEOUS RETAIL STORES, NEC (54%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); COMPUTING & INFORMATION TECHNOLOGY (71%); BIG DATA (61%)
Geographic: MOSCOW, RUSSIAN FEDERATION (59%); RUSSIAN FEDERATION (91%)
Load-Date: November 25, 2022","Moscow: Sberbank has issued the following press release:
On November 23, the AI Journey international artificial intelligence conference hosted a meeting of the Russian Committee on the Ethics of Artificial Intelligence and AI Ethics Code Implementation featuring leading AI ethics experts who spoke about current activities and development plans in the area.
Head of the Russian President ’ s Office for Information and Communication Technology and Infrastructure Tatiana Matveeva and First Deputy Chairman of the Sberbank Executive Board Alexander Vedyakhin addressed the audience highlighting the importance of compliance with ethical principles as part of AI technology development and application, and the need to build people ’ s trust in emerging solutions.
Chairman of the Russian Committee on the Ethics of Artificial Intelligence and AI Ethics Code Implementation Andrey Neznamov moderated the AI Ethics Session and spoke about the current progress and high-potential areas of the Commission ’ s activities.
Participants and viewers learned about the AI Ethics Code provisions implementation mechanics, ongoing document preparation, and AI ethics development prospects.
AI System Risk and Humanitarian Impact Working Group Leaders Anna Abramova and Yuri Lindre noted a progress in methodology guidelines development based on global best practices in AI ethics and told the audience about a document under elaboration aimed to be the lighthouse of AI system developers and operators, mitigating potential implementation risks.
AI Life Cycle Ethical Issue Resolution Best Practice Manual Development Working Group Leaders Alexander Krainov and Yelena Suragina spoke about some of the currently considered ethical issues and about the best practice manual preparation driven by expert opinions on the arising ethical dilemmas to be published in open sources.
AI Ethics Code Implementation Effectiveness Evaluation Working Group Leaders Andrey Kuleshov and Alexander Malakhov reported on methodology materials and compliance criteria preparation. This working group also drafts standard provisions stipulating the status of the AI Ethics Officer and the Russian Committee on the Ethics of Artificial Intelligence within the organization. These standard provisions can later be included by any organization into its internal regulations.
Recommendation Services Working Group Leaders Alexey Byrdin and Andrey Rego shared some of the history of and reasons for establishing the group, interim results, and a draft document on the use of recommendation services, public disclosure formats for AI-driven recommendation services operating principles, and on drafting fair use standards for AI-driven recommendations as part of industry self-regulation.
Guest experts took the floor in the final block of the meeting. Head of the Russian Government ’ s National Artificial Intelligence Development Center Sergei Nakvasin spoke about engaging government bodies in AI ethics practices, and about plans to conduct the second AI Ethics Forum. President of the Big Data Association Anna Serebryanikova shared her big data self-regulation experience and reported on the current progress in drafting the special section of the AI Ethics code on data usage ethics.
AI Alliance Russia unites top tech companies to facilitate mutual development of their competences and accelerated AI adoption in education, research, and corporate operations. The mission of the Alliance is to be the center of development of artificial intelligence in Russia and to provide technological leadership for Russia and corporate members of the Alliance in the field of artificial intelligence globally.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ETHICS (96%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (90%); CONFERENCES & CONVENTIONS (90%); TALKS & MEETINGS (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BUSINESS NEWS (89%); REGULATORY COMPLIANCE (89%); SELF REGULATING ORGANIZATIONS (84%); BOARDS OF DIRECTORS (78%); BUSINESS ETHICS (78%); INTERIM FINANCIAL RESULTS (78%); HEADS OF STATE & GOVERNMENT (76%); PRESS RELEASES (73%)
Company:  SBERBANK ROSSII OAO (58%);  BEST INC (54%)
Ticker: SBER (LSE) (58%); SBER (RTS) (58%); BEST (NYSE) (54%)
Industry: NAICS522110 COMMERCIAL BANKING (58%); NAICS522299 INTERNATIONAL, SECONDARY MARKET, AND ALL OTHER NONDEPOSITORY CREDIT INTERMEDIATION (58%); SIC6021 NATIONAL COMMERCIAL BANKS (58%); SIC6082 FOREIGN TRADE & INTERNATIONAL BANKING INSTITUTIONS (58%); SIC5999 MISCELLANEOUS RETAIL STORES, NEC (54%); ARTIFICIAL INTELLIGENCE ETHICS (95%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); COMPUTING & INFORMATION TECHNOLOGY (71%); BIG DATA (61%)
Geographic: MOSCOW, RUSSIAN FEDERATION (59%); RUSSIAN FEDERATION (91%)
Load-Date: November 25, 2022",neutral,0.8517857789993286,balanced/neutral,[],[],"['regulation', 'standards', 'guidelines', 'compliance', 'need to']",[],0,0,5,0
2021,Unknown Title,"Dateline: India 
Body
India, April 4 -- When we hear of Artificial Intelligence (AI), we might assume it is something that primarily concerns large technology companies and their business processes. We sometimes forget that AI, for some time now, has become an integral part of our everyday lives, right from unlocking phones through facial recognition, to enabling voice assisted searches, social media platforms, e-Commerce deliveries, and spell checks on documents and work emails. Even at an enterprise level, AI is being widely adopted across functions and processes to understand customers and churn out insights based on the data that comes in. This helps businesses evolve, stay ahead of competition, and strategize according to real-time customer demands. And ever since the pandemic hit, the adoption of AI has increased manifold in India. A report by IDC has stated that India's AI market is expected to reach $7.8 billion by 2025, growing at a CAGR of 20.2%. According to the report, organizations were leveraging multiple AI applications such as customer relationship management (CRM), enterprise risk management (ERM), supply chains management, predicting demand, and improving return on investment (ROI).
While the industry is growing exponentially, it also amplified the need for organizations to outline well-defined ethics and governance.
While organizations are accelerating the pace of AI adoption across functions, a crucial focus is to ensure this AI is being ""responsible"" and ethical in practice. Ethical AI is putting in place systems and tools to govern the scope and operations of the technology. According to Gradient Institute, it is a multi-disciplinary effort to design and build AI systems that are fair and that improve our lives.
Ethical AI systems should be designed with careful consideration of their fairness, accountability, transparency, and impact on people and the world.
Among the many reasons why data is becoming imperative across business processes, is the crucial role it plays in determining the quality of AI technology. AI advances have been made in building systems that are trained on data that an enterprise gathers, instead of systems that make decisions based on human-defined rules. Designers and/or developers make conscious decisions when creating systems with human-defined rules, and the ethical implications of these rules are usually more transparent. However, as AI systems are developed based on Machine Learning and Deep Learning, this could give rise to systems with no ethical considerations.
An important aspect in ensuring AI is being ethical is in training the datasets. It is imperative that the data being fed to the algorithm has taken into account every aspect of the concerned population, to ensure there are no gaps in the filtering process. For instance, some organizations fall back on AI for their recruitment process. From the applications that come in, the candidates are first shortlisted by AI, and then called in for interviews with the respective teams. And the AI is programmed to filter out resumes based on criteria that the recruiter has fed into the system. Imagine, due to incomplete datasets, if the system ends up unfairly penalising a specific group based on gender, educational background, their current location, etc. It could have a negative impact on members of that particular demographic and potentially to the company that is recruiting. It could also end up placing the company in violation of organisational or industry guidelines, or in some cases even the law.
AI bias in real life
AI applications are being adopted across sectors like healthcare, education, banking and finance, retail, etc. However, these systems often come with their own set of biases. AI systems are made to duplicate human intelligence and therefore tend to discriminate in a similar manner to humans. There are several reasons for this bias but the primary one is the data that these systems are fed with. Let's take a look at a few examples of how AI has been biased against certain sections of the population.
In 2017, an AI robotic soap dispenser failed to distinguish dark-skinned hands. It only gave soap to persons with pale skin. In another example, AI used in courts had denied bail to people by looking at their pictures. AI used by some courts in the US to determine an offender's chances of committing a crime would often go against African American defendants.
Like mentioned in the earlier instance, recruitment is another crucial area where AI biases often show up. In 2015, an AI system that was used to shortlist candidates for a job at a global tech company, gave lower priority to women for several roles. A likely explanation for this is that the system probably deduced that the job was fit more for males and reflected this in its recommendations.
Additionally, when highlighting the bias in data, researchers at Google Brain observed that while India and China have the highest population in the world, they account for only 3 percent of images in a popular dataset, ImagesNet. On the other hand, the US, which consists of only 4 percent of the world's population, constitutes 45 percent of the images. As a result, regional views tend to often get underrepresented.
In light of this, the Indian government along with several other nations have been constantly working towards introducing policies that mitigate AI biases. And the key to achieving this is getting the algorithm right. Niti Aayog's 2020 draft on Responsible AI was a good start to introducing ethical AI regulations in the country. It recommends sector-specific regulations, so they are not subject to the same rules. Additionally, in 2021, India launched a handbook- INDIAai, to help mitigate biases in AI. This handbook provides a framework for companies to follow while creating AI systems and algorithms. As organizations, both public and private, quickly adopt emerging technologies like AI and machine learning (ML), it is imperative that the technology is governed by an ethical framework in order to eliminate any potential biases against any specific sector of the population.
A service like Cloudera Machine Learning coupled with robust data governance features of the Cloudera Shared Data Experience allows tracing of model lineage, as well as greater visibility, explainability, interpretability and reproducibility. All of these are essential in AI model governance which is a cornerstone in supporting the ethical use of AI for an organisation.
The author is Piyush Agarwal, SE Leader, India, Cloudera
Published by HT Digital Content Services with permission from Data Quest. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEEP LEARNING (78%); MACHINE LEARNING (78%); CUSTOMER RELATIONSHIP MANAGEMENT (77%); BIOMETRICS (76%); CUSTOMER RELATIONS (75%); BUSINESS FORECASTS (73%); ELECTRONIC COMMERCE (73%); RISK MANAGEMENT (73%); SOCIAL MEDIA (73%); BUSINESS REPORTS & FORECASTS (58%); RETURN ON INVESTMENT (51%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); BIG TECH (89%); DEEP LEARNING (78%); MACHINE LEARNING (78%); PATTERN RECOGNITION (78%); ELECTRONIC COMMERCE (73%); RISK MANAGEMENT (73%); SOCIAL MEDIA (73%)
Geographic: INDIA (91%)
Load-Date: April 4, 2022","India, April 4 -- When we hear of Artificial Intelligence (AI), we might assume it is something that primarily concerns large technology companies and their business processes. We sometimes forget that AI, for some time now, has become an integral part of our everyday lives, right from unlocking phones through facial recognition, to enabling voice assisted searches, social media platforms, e-Commerce deliveries, and spell checks on documents and work emails. Even at an enterprise level, AI is being widely adopted across functions and processes to understand customers and churn out insights based on the data that comes in. This helps businesses evolve, stay ahead of competition, and strategize according to real-time customer demands. And ever since the pandemic hit, the adoption of AI has increased manifold in India. A report by IDC has stated that India's AI market is expected to reach $7.8 billion by 2025, growing at a CAGR of 20.2%. According to the report, organizations were leveraging multiple AI applications such as customer relationship management (CRM), enterprise risk management (ERM), supply chains management, predicting demand, and improving return on investment (ROI).
While the industry is growing exponentially, it also amplified the need for organizations to outline well-defined ethics and governance.
While organizations are accelerating the pace of AI adoption across functions, a crucial focus is to ensure this AI is being ""responsible"" and ethical in practice. Ethical AI is putting in place systems and tools to govern the scope and operations of the technology. According to Gradient Institute, it is a multi-disciplinary effort to design and build AI systems that are fair and that improve our lives.
Ethical AI systems should be designed with careful consideration of their fairness, accountability, transparency, and impact on people and the world.
Among the many reasons why data is becoming imperative across business processes, is the crucial role it plays in determining the quality of AI technology. AI advances have been made in building systems that are trained on data that an enterprise gathers, instead of systems that make decisions based on human-defined rules. Designers and/or developers make conscious decisions when creating systems with human-defined rules, and the ethical implications of these rules are usually more transparent. However, as AI systems are developed based on Machine Learning and Deep Learning, this could give rise to systems with no ethical considerations.
An important aspect in ensuring AI is being ethical is in training the datasets. It is imperative that the data being fed to the algorithm has taken into account every aspect of the concerned population, to ensure there are no gaps in the filtering process. For instance, some organizations fall back on AI for their recruitment process. From the applications that come in, the candidates are first shortlisted by AI, and then called in for interviews with the respective teams. And the AI is programmed to filter out resumes based on criteria that the recruiter has fed into the system. Imagine, due to incomplete datasets, if the system ends up unfairly penalising a specific group based on gender, educational background, their current location, etc. It could have a negative impact on members of that particular demographic and potentially to the company that is recruiting. It could also end up placing the company in violation of organisational or industry guidelines, or in some cases even the law.
AI bias in real life
AI applications are being adopted across sectors like healthcare, education, banking and finance, retail, etc. However, these systems often come with their own set of biases. AI systems are made to duplicate human intelligence and therefore tend to discriminate in a similar manner to humans. There are several reasons for this bias but the primary one is the data that these systems are fed with. Let's take a look at a few examples of how AI has been biased against certain sections of the population.
In 2017, an AI robotic soap dispenser failed to distinguish dark-skinned hands. It only gave soap to persons with pale skin. In another example, AI used in courts had denied bail to people by looking at their pictures. AI used by some courts in the US to determine an offender's chances of committing a crime would often go against African American defendants.
Like mentioned in the earlier instance, recruitment is another crucial area where AI biases often show up. In 2015, an AI system that was used to shortlist candidates for a job at a global tech company, gave lower priority to women for several roles. A likely explanation for this is that the system probably deduced that the job was fit more for males and reflected this in its recommendations.
Additionally, when highlighting the bias in data, researchers at Google Brain observed that while India and China have the highest population in the world, they account for only 3 percent of images in a popular dataset, ImagesNet. On the other hand, the US, which consists of only 4 percent of the world's population, constitutes 45 percent of the images. As a result, regional views tend to often get underrepresented.
In light of this, the Indian government along with several other nations have been constantly working towards introducing policies that mitigate AI biases. And the key to achieving this is getting the algorithm right. Niti Aayog's 2020 draft on Responsible AI was a good start to introducing ethical AI regulations in the country. It recommends sector-specific regulations, so they are not subject to the same rules. Additionally, in 2021, India launched a handbook- INDIAai, to help mitigate biases in AI. This handbook provides a framework for companies to follow while creating AI systems and algorithms. As organizations, both public and private, quickly adopt emerging technologies like AI and machine learning (ML), it is imperative that the technology is governed by an ethical framework in order to eliminate any potential biases against any specific sector of the population.
A service like Cloudera Machine Learning coupled with robust data governance features of the Cloudera Shared Data Experience allows tracing of model lineage, as well as greater visibility, explainability, interpretability and reproducibility. All of these are essential in AI model governance which is a cornerstone in supporting the ethical use of AI for an organisation.
The author is Piyush Agarwal, SE Leader, India, Cloudera
Published by HT Digital Content Services with permission from Data Quest. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DEEP LEARNING (78%); MACHINE LEARNING (78%); CUSTOMER RELATIONSHIP MANAGEMENT (77%); BIOMETRICS (76%); CUSTOMER RELATIONS (75%); BUSINESS FORECASTS (73%); ELECTRONIC COMMERCE (73%); RISK MANAGEMENT (73%); SOCIAL MEDIA (73%); BUSINESS REPORTS & FORECASTS (58%); RETURN ON INVESTMENT (51%)
Industry: ARTIFICIAL INTELLIGENCE (90%); INFORMATION TECHNOLOGY INDUSTRY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); BIG TECH (89%); DEEP LEARNING (78%); MACHINE LEARNING (78%); PATTERN RECOGNITION (78%); ELECTRONIC COMMERCE (73%); RISK MANAGEMENT (73%); SOCIAL MEDIA (73%)
Geographic: INDIA (91%)
Load-Date: April 4, 2022",neutral,0.7708063125610352,balanced/neutral,"['bias', 'fairness', 'transparency', 'explainability', 'accountability']",['fairness'],"['governance', 'guidelines', 'framework', 'law', 'should']","['machine learning', 'deep learning', 'facial recognition', 'algorithm', 'ai model']",5,1,5,5
2021,Unknown Title,"Body
2022 AUG 16 (NewsRx) -- By a News Reporter-Staff News Editor at Ivy League Daily News -- New research on agriculture is the subject of a new report. According to news reporting originating from New York City, New York, by NewsRx correspondents, research stated, ""To review through an ethics lens the state of research in clinical natural language processing (NLP) for the study of bias and fairness, and to identify gaps in research."" 
 Funders for this research include National Library of Medicine; National Institute of General Medical Sciences. 
 Our news correspondents obtained a quote from the research from Columbia University: ""We queried PubMed and Google Scholar for articles published between 2015 and 2021 concerning clinical NLP, bias, and fairness. We analyzed articles using a framework that combines the machine learning (ML) development process (ie, design, data, algorithm, and critique) and bioethical concepts of beneficence, nonmaleficence, autonomy, justice, as well as explicability. Our approach further differentiated between biases of clinical text (eg, systemic or personal biases in clinical documentation towards patients) and biases in NLP applications. Out of 1162 articles screened, 22 met criteria for full text review. We categorized articles based on the design (N = 2), data (N = 12), algorithm (N = 14), and critique (N = 17) phases of the ML development process."" 
 According to the news reporters, the research concluded: ""Clinical NLP can be used to study bias in applications reliant on clinical text data as well as explore biases in the healthcare setting. We identify 3 areas of active research that require unique ethical considerations about the potential for clinical NLP to address and/or perpetuate bias: (1) selecting metrics that interrogate bias in models; (2) opportunities and risks of identifying sensitive patient attributes; and (3) best practices in reconciling individual autonomy, leveraging patient data, and inferring and manipulating sensitive information of subgroups. Finally, we address the limitations of current ethical frameworks to fully address concerns of justice. Clinical NLP is a rapidly advancing field, and assessing current approaches against ethical considerations can help the discipline use clinical NLP to explore both healthcare biases and equitable NLP applications."" 
 For more information on this research see: A scoping review of ethics considerations in clinical natural language processing. JAMIA Open, 2022,5(2). (JAMIA Open - https://academic.oup.com/jamiaopen). The publisher for JAMIA Open is Oxford University Press (OUP). 
 A free version of this journal article is available at https://doi.org/10.1093/jamiaopen/ooac039. 
 Our news editors report that more information may be obtained by contacting Oliver J Bear Don't Walk, Department of Biomedical Informatics, Columbia University, New York, New York, United States. Additional authors for this research include Harry Reyes Nieva, Sandra Soo-Jin Lee, Noemie Elhadad.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Harry Reyes Nieva (orcid.org/0000-0001-7774-2561). 
 Keywords for this news article include: Columbia University, New York City, New York, United States, North and Central America, Emerging Technologies, Health and Medicine, Machine Learning, Natural Language Processing. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: NATURAL LANGUAGE PROCESSING (92%); COLLEGES & UNIVERSITIES (91%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MEDICINE & HEALTH (90%); BIOETHICS (79%); BIOMEDICINE (79%); HEALTH CARE INFORMATION (79%); MEDICAL SCIENCE (79%); AGRICULTURAL RESEARCH (78%); ARTIFICIAL INTELLIGENCE (78%); MACHINE LEARNING (78%); NEWS REPORTING (78%); RESEARCH INSTITUTES (78%); HEALTH CARE INFORMATION TECHNOLOGY (73%); SPECIAL LIBRARIES (73%); WRITERS (73%); INFORMATION SCIENCE (72%); BEST PRACTICES (68%); LIBRARIES (55%); Emerging Technologies;Health and Medicine;Machine Learning;Natural Language Processing (%)
Organization: COLUMBIA UNIVERSITY (91%); NATIONAL LIBRARY OF MEDICINE (57%); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES (57%)
Industry: COLLEGES & UNIVERSITIES (91%); BIOMEDICINE (79%); HEALTH CARE INFORMATION (79%); AGRICULTURAL RESEARCH (78%); ARTIFICIAL INTELLIGENCE (78%); MACHINE LEARNING (78%); NEWS REPORTING (78%); PUBLISHING (78%); HEALTH CARE INFORMATION TECHNOLOGY (73%); SPECIAL LIBRARIES (73%); WRITERS (73%); LIBRARIES (55%)
Geographic: NEW YORK, NY, USA (92%); NEW YORK, USA (92%)
Load-Date: August 16, 2022","2022 AUG 16 (NewsRx) -- By a News Reporter-Staff News Editor at Ivy League Daily News -- New research on agriculture is the subject of a new report. According to news reporting originating from New York City, New York, by NewsRx correspondents, research stated, ""To review through an ethics lens the state of research in clinical natural language processing (NLP) for the study of bias and fairness, and to identify gaps in research."" 
 Funders for this research include National Library of Medicine; National Institute of General Medical Sciences. 
 Our news correspondents obtained a quote from the research from Columbia University: ""We queried PubMed and Google Scholar for articles published between 2015 and 2021 concerning clinical NLP, bias, and fairness. We analyzed articles using a framework that combines the machine learning (ML) development process (ie, design, data, algorithm, and critique) and bioethical concepts of beneficence, nonmaleficence, autonomy, justice, as well as explicability. Our approach further differentiated between biases of clinical text (eg, systemic or personal biases in clinical documentation towards patients) and biases in NLP applications. Out of 1162 articles screened, 22 met criteria for full text review. We categorized articles based on the design (N = 2), data (N = 12), algorithm (N = 14), and critique (N = 17) phases of the ML development process."" 
 According to the news reporters, the research concluded: ""Clinical NLP can be used to study bias in applications reliant on clinical text data as well as explore biases in the healthcare setting. We identify 3 areas of active research that require unique ethical considerations about the potential for clinical NLP to address and/or perpetuate bias: (1) selecting metrics that interrogate bias in models; (2) opportunities and risks of identifying sensitive patient attributes; and (3) best practices in reconciling individual autonomy, leveraging patient data, and inferring and manipulating sensitive information of subgroups. Finally, we address the limitations of current ethical frameworks to fully address concerns of justice. Clinical NLP is a rapidly advancing field, and assessing current approaches against ethical considerations can help the discipline use clinical NLP to explore both healthcare biases and equitable NLP applications."" 
 For more information on this research see: A scoping review of ethics considerations in clinical natural language processing. JAMIA Open, 2022,5(2). (JAMIA Open - https://academic.oup.com/jamiaopen). The publisher for JAMIA Open is Oxford University Press (OUP). 
 A free version of this journal article is available at https://doi.org/10.1093/jamiaopen/ooac039. 
 Our news editors report that more information may be obtained by contacting Oliver J Bear Don't Walk, Department of Biomedical Informatics, Columbia University, New York, New York, United States. Additional authors for this research include Harry Reyes Nieva, Sandra Soo-Jin Lee, Noemie Elhadad.  
 ORCID is an identifier for authors and includes bibliographic information. The following is ORCID information for the author of this research: Harry Reyes Nieva (orcid.org/0000-0001-7774-2561). 
 Keywords for this news article include: Columbia University, New York City, New York, United States, North and Central America, Emerging Technologies, Health and Medicine, Machine Learning, Natural Language Processing. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: NATURAL LANGUAGE PROCESSING (92%); COLLEGES & UNIVERSITIES (91%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); MEDICINE & HEALTH (90%); BIOETHICS (79%); BIOMEDICINE (79%); HEALTH CARE INFORMATION (79%); MEDICAL SCIENCE (79%); AGRICULTURAL RESEARCH (78%); ARTIFICIAL INTELLIGENCE (78%); MACHINE LEARNING (78%); NEWS REPORTING (78%); RESEARCH INSTITUTES (78%); HEALTH CARE INFORMATION TECHNOLOGY (73%); SPECIAL LIBRARIES (73%); WRITERS (73%); INFORMATION SCIENCE (72%); BEST PRACTICES (68%); LIBRARIES (55%); Emerging Technologies;Health and Medicine;Machine Learning;Natural Language Processing (%)
Organization: COLUMBIA UNIVERSITY (91%); NATIONAL LIBRARY OF MEDICINE (57%); NATIONAL INSTITUTE OF GENERAL MEDICAL SCIENCES (57%)
Industry: COLLEGES & UNIVERSITIES (91%); BIOMEDICINE (79%); HEALTH CARE INFORMATION (79%); AGRICULTURAL RESEARCH (78%); ARTIFICIAL INTELLIGENCE (78%); MACHINE LEARNING (78%); NEWS REPORTING (78%); PUBLISHING (78%); HEALTH CARE INFORMATION TECHNOLOGY (73%); SPECIAL LIBRARIES (73%); WRITERS (73%); LIBRARIES (55%)
Geographic: NEW YORK, NY, USA (92%); NEW YORK, USA (92%)
Load-Date: August 16, 2022",neutral,0.9072074294090271,balanced/neutral,"['bias', 'fairness', 'autonomy']","['justice', 'fairness', 'autonomy', 'beneficence', 'justice']",['framework'],"['machine learning', 'natural language processing', 'nlp', 'algorithm']",3,5,1,4
2021,Unknown Title,"Dateline: New Delhi, 2022-01-11 19:18:29 
Body
 January 11 -- The rocket ship trajectory of a startup is well known: Get an idea, build a team and slap together a minimum viable product (MVP) that you can get in front of users.
However, today's startups need to reconsider the MVP model as artificial intelligence (AI) and machine learning (ML) become ubiquitous in tech products and the market grows increasingly conscious of the ethical implications of AI augmenting or replacing humans in the decision-making process.
An MVP allows you to collect critical feedback from your target market that then informs the minimum development required to launch a product - creating a powerful feedback loop that drives today's customer-led business. This lean, agile model has been extremely successful over the past two decades - launching thousands of successful startups, some of which have grown into billion-dollar companies.
However, building high-performing products and solutions that work for the majority isn't enough anymore. From facial recognition technology that has a bias against people of color to credit-lending algorithms that discriminate against women, the past several years have seen multiple AI- or ML-powered products killed off because of ethical dilemmas that crop up downstream after millions of dollars have been funneled into their development and marketing. In a world where you have one chance to bring an idea to market, this risk can be fatal, even for well-established companies.
Startups do not have to scrap the lean business model in favor of a more risk-averse alternative. There is a middle ground that can introduce ethics into the startup mentality without sacrificing the agility of the lean model, and it starts with the initial goal of a startup - getting an early-stage proof of concept in front of potential customers.
However, instead of developing an MVP, companies should develop and roll out an ethically viable product (EVP) based on responsible artificial intelligence (RAI), an approach that considers the ethical, moral, legal, cultural, sustainable and social-economic considerations during the development, deployment and use of AI/ML systems.
And while this is a good practice for startups, it's also a good standard practice for big technology companies building AI/ML products.
Here are three steps that startups - especially the ones that incorporate significant AI/ML techniques in their products - can use to develop an EVP.
Find an ethics officer to lead the chargeStartups have chief strategy officers, chief investment officers - even chief fun officers. A chief ethics officer is just as important, if not more so. This person can work across different stakeholders to make sure the startup is developing a product that fits within the moral standards set by the company, the market and the public.
They should act as a liaison between the founders, the C-suite, investors and the board of directors with the development team - making sure everyone is asking the right ethical questions in a thoughtful, risk-averse manner.
Machines are trained based on historical data. If systemic bias exists in a current business process (such as unequal racial or gender lending practices), AI will pick up on that and think that's how it should continue to behave. If your product is later found to not meet the ethical standards of the market, you can't simply delete the data and find new data.
These algorithms have already been trained. You can't erase that influence any more than a 40-year-old man can undo the influence his parents or older siblings had on his upbringing. For better or for worse, you are stuck with the results. Chief ethics officers need to sniff out that inherent bias throughout the organization before it gets ingrained in AI-powered products.
Integrate ethics into the entire development processResponsible AI is not just a point in time. It is an end-to-end governance framework focused on the risks and controls of an organization's AI journey. This means that ethics should be integrated throughout the development process - starting with strategy and planning through development, deployment and operations.
During scoping, the development team should work with the chief ethics officer to be aware of general ethical AI principles that represent behavioral principles that are valid in many cultural and geographic applications. These principles prescribe, suggest or inspire how AI solutions should behave when faced with moral decisions or dilemmas in a specific field of usage.
Above all, a risk and harm assessment should be conducted, identifying any risk to anyone's physical, emotional or financial well-being. The assessment should look at sustainability as well and evaluate what harm the AI solution might do to the environment.
During the development phase, the team should be constantly asking how their use of AI is in alignment with the company's values, whether models are treating different people fairly and whether they are respecting people's right to privacy. They should also consider if their AI technology is safe, secure and robust and how effective the operating model is at ensuring accountability and quality.
A critical component of any machine learning model is the data that is used to train the model. Startups should be concerned not only about the MVP and how the model is proved initially, but also the eventual context and geographic reach of the model. This will allow the team to select the right representative dataset to avoid any future data bias issues.
Don't forget about ongoing AI governance and regulatory complianceGiven the implications on society, it's just a matter of time before the European Union, the United States or some other legislative body passes consumer protection laws governing the use of AI/ML. Once a law is passed, those protections are likely to spread to other regions and markets around the world.
It's happened before: The passage of the General Data Protection Regulation (GDPR) in the EU led to a wave of other consumer protections around the world that require companies to prove consent for collecting personal information. Now, people across the political and business spectrum are calling for ethical guidelines around AI. Again, the EU is leading the way after releasing a 2021 proposal for an AI legal framework.
Startups deploying products or services powered by AI/ML should be prepared to demonstrate ongoing governance and regulatory compliance - being careful to build these processes now before the regulations are imposed on them later. Performing a quick scan of the proposed legislation, guidance documents and other relevant guidelines before building the product is a necessary step of EVP.
In addition, revisiting the regulatory/policy landscape prior to launch is advisable. Having someone who is embedded within the active deliberations currently happening globally on your board of directors or advisory board would also help understand what is likely to happen. Regulations are coming, and it's good to be prepared.
There's no doubt that AI/ML will present an enormous benefit to humankind. The ability to automate manual tasks, streamline business processes and improve customer experiences are too great to dismiss. But startups need to be aware of the impacts AI/ML will have on their customers, the market and society at large.
Startups typically have one shot at success, and it would be a shame if an otherwise high-performing product is killed because some ethical concerns weren't uncovered until after it hits the market. Startups need to integrate ethics into the development process from the very beginning, develop an EVP based on RAI and continue to ensure AI governance post-launch.
AI is the future of business, but we can't lose sight of the need for compassion and the human element in innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS (89%); EXECUTIVES (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (77%); COMPANY ACTIVITIES & MANAGEMENT (77%); IDENTIFICATION TECHNOLOGIES (77%); PRODUCT DEVELOPMENT (77%); COMPANY STRATEGY (76%); SALES PROSPECTING (74%); GENDER EQUALITY (73%); DISCRIMINATION (72%); GREEN ECONOMY (69%); BIOMETRICS (67%); GENDER & SEX DISCRIMINATION (67%); RACE & ETHNICITY (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); AGILE DEVELOPMENT (77%); ARTIFICIAL INTELLIGENCE ETHICS (77%); PATTERN RECOGNITION (72%); BIG TECH (71%); GREEN ECONOMY (69%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: January 11, 2022","January 11 -- The rocket ship trajectory of a startup is well known: Get an idea, build a team and slap together a minimum viable product (MVP) that you can get in front of users.
However, today's startups need to reconsider the MVP model as artificial intelligence (AI) and machine learning (ML) become ubiquitous in tech products and the market grows increasingly conscious of the ethical implications of AI augmenting or replacing humans in the decision-making process.
An MVP allows you to collect critical feedback from your target market that then informs the minimum development required to launch a product - creating a powerful feedback loop that drives today's customer-led business. This lean, agile model has been extremely successful over the past two decades - launching thousands of successful startups, some of which have grown into billion-dollar companies.
However, building high-performing products and solutions that work for the majority isn't enough anymore. From facial recognition technology that has a bias against people of color to credit-lending algorithms that discriminate against women, the past several years have seen multiple AI- or ML-powered products killed off because of ethical dilemmas that crop up downstream after millions of dollars have been funneled into their development and marketing. In a world where you have one chance to bring an idea to market, this risk can be fatal, even for well-established companies.
Startups do not have to scrap the lean business model in favor of a more risk-averse alternative. There is a middle ground that can introduce ethics into the startup mentality without sacrificing the agility of the lean model, and it starts with the initial goal of a startup - getting an early-stage proof of concept in front of potential customers.
However, instead of developing an MVP, companies should develop and roll out an ethically viable product (EVP) based on responsible artificial intelligence (RAI), an approach that considers the ethical, moral, legal, cultural, sustainable and social-economic considerations during the development, deployment and use of AI/ML systems.
And while this is a good practice for startups, it's also a good standard practice for big technology companies building AI/ML products.
Here are three steps that startups - especially the ones that incorporate significant AI/ML techniques in their products - can use to develop an EVP.
Find an ethics officer to lead the chargeStartups have chief strategy officers, chief investment officers - even chief fun officers. A chief ethics officer is just as important, if not more so. This person can work across different stakeholders to make sure the startup is developing a product that fits within the moral standards set by the company, the market and the public.
They should act as a liaison between the founders, the C-suite, investors and the board of directors with the development team - making sure everyone is asking the right ethical questions in a thoughtful, risk-averse manner.
Machines are trained based on historical data. If systemic bias exists in a current business process (such as unequal racial or gender lending practices), AI will pick up on that and think that's how it should continue to behave. If your product is later found to not meet the ethical standards of the market, you can't simply delete the data and find new data.
These algorithms have already been trained. You can't erase that influence any more than a 40-year-old man can undo the influence his parents or older siblings had on his upbringing. For better or for worse, you are stuck with the results. Chief ethics officers need to sniff out that inherent bias throughout the organization before it gets ingrained in AI-powered products.
Integrate ethics into the entire development processResponsible AI is not just a point in time. It is an end-to-end governance framework focused on the risks and controls of an organization's AI journey. This means that ethics should be integrated throughout the development process - starting with strategy and planning through development, deployment and operations.
During scoping, the development team should work with the chief ethics officer to be aware of general ethical AI principles that represent behavioral principles that are valid in many cultural and geographic applications. These principles prescribe, suggest or inspire how AI solutions should behave when faced with moral decisions or dilemmas in a specific field of usage.
Above all, a risk and harm assessment should be conducted, identifying any risk to anyone's physical, emotional or financial well-being. The assessment should look at sustainability as well and evaluate what harm the AI solution might do to the environment.
During the development phase, the team should be constantly asking how their use of AI is in alignment with the company's values, whether models are treating different people fairly and whether they are respecting people's right to privacy. They should also consider if their AI technology is safe, secure and robust and how effective the operating model is at ensuring accountability and quality.
A critical component of any machine learning model is the data that is used to train the model. Startups should be concerned not only about the MVP and how the model is proved initially, but also the eventual context and geographic reach of the model. This will allow the team to select the right representative dataset to avoid any future data bias issues.
Don't forget about ongoing AI governance and regulatory complianceGiven the implications on society, it's just a matter of time before the European Union, the United States or some other legislative body passes consumer protection laws governing the use of AI/ML. Once a law is passed, those protections are likely to spread to other regions and markets around the world.
It's happened before: The passage of the General Data Protection Regulation (GDPR) in the EU led to a wave of other consumer protections around the world that require companies to prove consent for collecting personal information. Now, people across the political and business spectrum are calling for ethical guidelines around AI. Again, the EU is leading the way after releasing a 2021 proposal for an AI legal framework.
Startups deploying products or services powered by AI/ML should be prepared to demonstrate ongoing governance and regulatory compliance - being careful to build these processes now before the regulations are imposed on them later. Performing a quick scan of the proposed legislation, guidance documents and other relevant guidelines before building the product is a necessary step of EVP.
In addition, revisiting the regulatory/policy landscape prior to launch is advisable. Having someone who is embedded within the active deliberations currently happening globally on your board of directors or advisory board would also help understand what is likely to happen. Regulations are coming, and it's good to be prepared.
There's no doubt that AI/ML will present an enormous benefit to humankind. The ability to automate manual tasks, streamline business processes and improve customer experiences are too great to dismiss. But startups need to be aware of the impacts AI/ML will have on their customers, the market and society at large.
Startups typically have one shot at success, and it would be a shame if an otherwise high-performing product is killed because some ethical concerns weren't uncovered until after it hits the market. Startups need to integrate ethics into the development process from the very beginning, develop an EVP based on RAI and continue to ensure AI governance post-launch.
AI is the future of business, but we can't lose sight of the need for compassion and the human element in innovation.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS ETHICS (89%); EXECUTIVES (89%); MACHINE LEARNING (89%); ARTIFICIAL INTELLIGENCE ETHICS (77%); COMPANY ACTIVITIES & MANAGEMENT (77%); IDENTIFICATION TECHNOLOGIES (77%); PRODUCT DEVELOPMENT (77%); COMPANY STRATEGY (76%); SALES PROSPECTING (74%); GENDER EQUALITY (73%); DISCRIMINATION (72%); GREEN ECONOMY (69%); BIOMETRICS (67%); GENDER & SEX DISCRIMINATION (67%); RACE & ETHNICITY (67%)
Industry: ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (89%); INFORMATION TECHNOLOGY INDUSTRY (78%); AGILE DEVELOPMENT (77%); ARTIFICIAL INTELLIGENCE ETHICS (77%); PATTERN RECOGNITION (72%); BIG TECH (71%); GREEN ECONOMY (69%)
Geographic: NEW DELHI, INDIA (59%)
Load-Date: January 11, 2022",neutral,0.6614082455635071,balanced/neutral,"['privacy', 'bias', 'discrimination', 'accountability', 'consent']",['equality'],"['regulation', 'policy', 'governance', 'standards', 'guidelines', 'framework', 'legislation', 'law', 'compliance', 'should', 'need to', 'suggest']","['machine learning', 'facial recognition']",5,1,12,2
2021,Unknown Title,"Body
2022 JUL 11 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from the Institute of Business Administration by NewsRx correspondents, research stated, ""The twenty-first century technological advances driven by exponential rise of artificial intelligence (AI) technology have ushered in a new era that offers many of us hitherto unimagined luxuries and facilities.""
 Funders for this research include Facebook Research.
 Our news journalists obtained a quote from the research from Institute of Business Administration: ""However, under the guise of this progressive discourse, particularly in the backdrop of current neo-liberal late-capitalist postmodern world, AI development also has prompted an increasingly uncertain ethical tomorrow. This paper aims to probe the question of ethics by exploring the true ramifications of AI and interrogating its various ethical dimensions. It questions the essential goodness that is attributed to unstinted AI development before elucidating the ethical repercussions of AI advancements and the aptness of the current market logics and business models that govern the tech-industry. The paper next positions a holistic Islamic virtue-based AI ethics framework grounded in the context of Islamic objectives (maqasid) as an alternative ethical system for AI governance.""
 According to the news reporters, the research concluded: ""We argue that this distinctive Islamic virtue-based ethical approach, which can be used to explore AI-related ethical problems more holistically due to its ontological base and rich tradition while keeping in check undue influence from the current socio-politico-economic climate, can be a valuable addition to the global discourse on AI ethics.""
 For more information on this research see: Islamic virtue-based ethics for artificial intelligence. Discover Artificial Intelligence, 2022,2(1):1-16. The publisher for Discover Artificial Intelligence is Springer.
 A free version of this journal article is available at https://doi.org/10.1007/s44163-022-00028-2.
 Our news editors report that additional information may be obtained by contacting Amana Raquib, Department of Social Sciences and Liberal Arts, Institute of Business Administration (IBA). Additional authors for this research include Bilal Channa, Talat Zubair, Junaid Qadir.
 Keywords for this news article include: Institute of Business Administration, Artificial Intelligence, Emerging Technologies, Machine Learning.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); INVESTIGATIONS (91%); RELIGION (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS EDUCATION (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); LIBERALISM (78%); WRITERS (78%); HUMANITIES & SOCIAL SCIENCE (77%); EMERGING TECHNOLOGY (74%); ECONOMIC NEWS (73%); SOCIAL SCIENCE EDUCATION (73%); ECONOMIC CONDITIONS (50%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  META PLATFORMS INC (57%)
Ticker: FB (NASDAQ) (57%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (57%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); PUBLISHING (78%); WRITERS (78%)
Load-Date: July 28, 2022","2022 JUL 11 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News Daily News -- Investigators publish new report on artificial intelligence. According to news originating from the Institute of Business Administration by NewsRx correspondents, research stated, ""The twenty-first century technological advances driven by exponential rise of artificial intelligence (AI) technology have ushered in a new era that offers many of us hitherto unimagined luxuries and facilities.""
 Funders for this research include Facebook Research.
 Our news journalists obtained a quote from the research from Institute of Business Administration: ""However, under the guise of this progressive discourse, particularly in the backdrop of current neo-liberal late-capitalist postmodern world, AI development also has prompted an increasingly uncertain ethical tomorrow. This paper aims to probe the question of ethics by exploring the true ramifications of AI and interrogating its various ethical dimensions. It questions the essential goodness that is attributed to unstinted AI development before elucidating the ethical repercussions of AI advancements and the aptness of the current market logics and business models that govern the tech-industry. The paper next positions a holistic Islamic virtue-based AI ethics framework grounded in the context of Islamic objectives (maqasid) as an alternative ethical system for AI governance.""
 According to the news reporters, the research concluded: ""We argue that this distinctive Islamic virtue-based ethical approach, which can be used to explore AI-related ethical problems more holistically due to its ontological base and rich tradition while keeping in check undue influence from the current socio-politico-economic climate, can be a valuable addition to the global discourse on AI ethics.""
 For more information on this research see: Islamic virtue-based ethics for artificial intelligence. Discover Artificial Intelligence, 2022,2(1):1-16. The publisher for Discover Artificial Intelligence is Springer.
 A free version of this journal article is available at https://doi.org/10.1007/s44163-022-00028-2.
 Our news editors report that additional information may be obtained by contacting Amana Raquib, Department of Social Sciences and Liberal Arts, Institute of Business Administration (IBA). Additional authors for this research include Bilal Channa, Talat Zubair, Junaid Qadir.
 Keywords for this news article include: Institute of Business Administration, Artificial Intelligence, Emerging Technologies, Machine Learning.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Editor's Choice
Publication-Type: Newsletter
Subject: ETHICS (93%); ARTIFICIAL INTELLIGENCE ETHICS (91%); INVESTIGATIONS (91%); RELIGION (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS EDUCATION (90%); JOURNALISM (90%); MACHINE LEARNING (90%); ROBOTICS (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); LIBERALISM (78%); WRITERS (78%); HUMANITIES & SOCIAL SCIENCE (77%); EMERGING TECHNOLOGY (74%); ECONOMIC NEWS (73%); SOCIAL SCIENCE EDUCATION (73%); ECONOMIC CONDITIONS (50%); Artificial Intelligence;Emerging Technologies;Machine Learning (%)
Company:  META PLATFORMS INC (57%)
Ticker: FB (NASDAQ) (57%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (57%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); ROBOTICS (90%); PUBLISHING (78%); WRITERS (78%)
Load-Date: July 28, 2022",neutral,0.864977240562439,balanced/neutral,[],[],"['governance', 'framework']","['machine learning', 'robotics']",0,0,2,2
2021,Unknown Title,"Body
Link to Story
Bengaluru, India Apr. 14, 2022 -- A new IBM (NYSE: IBM) Institute for Business Value (IBV) study revealed a radical shift in the roles responsible for leading and upholding AI ethics at an organization. When asked which function is primarily accountable for AI ethics, 80% of respondents pointed to a non-technical executive, such as a CEO, as the primary 'champion' for AI ethics, a sharp uptick from 15% in 2018.
The global study* also indicates that despite a strong imperative for advancing trustworthy AI, including better performance compared to peers in sustainability, social responsibility, and diversity and inclusion, there remains a gap between leaders' intention and meaningful actions. The study found:
Business executives are now seen as the driving force in AI ethics
CEOs (28%) - but also Board members (10%), General Counsels (10%), Privacy Officers (8%), and Risk & Compliance Officers (6%) are viewed as being most accountable for AI ethics by those surveyed.
While 66% of respondents cite the CEO or other C-level executive as having a strong influence on their organization's ethics strategy, more than half cite board directives (58%) and the shareholder community (53%).
Building Trustworthy AI is perceived as a strategic differentiator and organizations are beginning to implement AI ethics mechanisms.
More than three-quarters of business leaders surveyed this year agree AI ethics is important to their organizations, up from about 50% in 2018.
At the same time, 75% of respondents believe ethics is a source of competitive differentiation, and more than 67% of respondents that view AI and AI ethics as important indicate their organizations outperform their peers in sustainability, social responsibility, and diversity and inclusion.
Many companies have started making strides. In fact, more than half of respondents say their organizations have taken steps to embed AI ethics into their existing approach to business ethics.
More than 45% of respondents say their organizations have created AI-specific ethics mechanisms, such as an AI project risk assessment framework and auditing/review process.
Ensuring ethical principles are embedded in AI solutions is an urgent need for organizations, but progress is still too slow
More surveyed CEOs (79%) are now prepared to embed AI ethics into their AI practices - up from 20% in 2018 -- and more than half of responding organizations have publicly endorsed common principles of AI ethics.
Yet, less than a quarter of responding organizations have operationalized AI ethics, and fewer than 20% of respondents strongly agreed that their organization's practices and actions match (or exceed) their stated principles and values.
68% of surveyed organizations acknowledge that having a diverse and inclusive workplace is important to mitigating bias in AI, but findings indicate that AI teams are still substantially less diverse than their organizations' workforces: 5.5 times less inclusive of women, 4 times less inclusive of LGBT+ individuals and 1.7 times less racially inclusive.
""As many companies today use AI algorithms across their business, they potentially face increasing internal and external demands to design these algorithms to be fair, secured and trustworthy; yet, there has been little progress across the industry in embedding AI ethics into their practices,"" said Jesus Mantas, Global Managing Partner, IBM Consulting.""Our IBV study findings demonstrate that building trustworthy AI is a business imperative and a societal expectation, not just a compliance issue. As such, companies can implement a governance model and embed ethical principles across the full AI life cycle.""
The time for companies to act is now. The study data suggests that those organizations who implement a broad AI ethics strategy interwoven throughout business units may have a competitive advantage moving forward. The study provides recommended actions for business leaders including:
Take a cross-functional, collaborative approach - ethical AI requires a holistic approach, and a holistic set of skills across all stakeholders involved in the AI ethics process. C-Suite executives, designers, behavioral scientists, data scientists, and AI engineers each have a distinct role to play in the trustworthy AI journey.
Establish both organizational and AI lifecycle governance to operationalize the discipline of AI ethics - take a holistic approach to incentivizing, managing and governing AI solutions across the full AI lifecycle, from establishing the right culture to nurture AI responsibly, to practices and policies to products.
Reach beyond your organization for partnership - expand your approach by identifying and engaging key AI-focused technology partners, academics, startups, and other ecosystem partners to establish""ethical interoperability.""
About IBM Institute for Business Value
For two decades, the IBM Institute for Business Value has served as the thought leadership think tank for IBM. What inspires us is producing research-backed, technology-informed strategic insights that help leaders make smarter business decisions.
From our unique position at the intersection of business, technology, and society, we survey, interview, and engage with thousands of executives, consumers, and experts each year, synthesizing their perspectives into credible, inspiring, and actionable insights.
Company :-Weber Shandwick
User :- Mekhala Maitra
Email :
Mobile:- +91.9547520522
MENAFN15042022003198003206ID1104030016
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EXECUTIVES (91%); ASSOCIATIONS & ORGANIZATIONS (90%); ETHICS (90%); POLLS & SURVEYS (90%); PUBLIC COMPANIES (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); DIVERSITY & INCLUSION (89%); BUSINESS ETHICS (78%); ARTIFICIAL INTELLIGENCE (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); BOARDS OF DIRECTORS (76%); WORKPLACE DIVERSITY & INCLUSION (74%); REGULATORY COMPLIANCE (73%); RESEARCH REPORTS (73%); RISK MANAGEMENT (70%); LAWYERS (53%)
Company:  INTERNATIONAL BUSINESS MACHINES CORP (91%)
Ticker: IBM (NYSE) (91%); IBM (LSE) (91%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (91%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (91%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (91%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (77%); RISK MANAGEMENT (70%); LAWYERS (53%)
Geographic: BANGALORE, KARNATAKA, INDIA (58%)
Load-Date: September 2, 2022","Link to Story
Bengaluru, India Apr. 14, 2022 -- A new IBM (NYSE: IBM) Institute for Business Value (IBV) study revealed a radical shift in the roles responsible for leading and upholding AI ethics at an organization. When asked which function is primarily accountable for AI ethics, 80% of respondents pointed to a non-technical executive, such as a CEO, as the primary 'champion' for AI ethics, a sharp uptick from 15% in 2018.
The global study* also indicates that despite a strong imperative for advancing trustworthy AI, including better performance compared to peers in sustainability, social responsibility, and diversity and inclusion, there remains a gap between leaders' intention and meaningful actions. The study found:
Business executives are now seen as the driving force in AI ethics
CEOs (28%) - but also Board members (10%), General Counsels (10%), Privacy Officers (8%), and Risk & Compliance Officers (6%) are viewed as being most accountable for AI ethics by those surveyed.
While 66% of respondents cite the CEO or other C-level executive as having a strong influence on their organization's ethics strategy, more than half cite board directives (58%) and the shareholder community (53%).
Building Trustworthy AI is perceived as a strategic differentiator and organizations are beginning to implement AI ethics mechanisms.
More than three-quarters of business leaders surveyed this year agree AI ethics is important to their organizations, up from about 50% in 2018.
At the same time, 75% of respondents believe ethics is a source of competitive differentiation, and more than 67% of respondents that view AI and AI ethics as important indicate their organizations outperform their peers in sustainability, social responsibility, and diversity and inclusion.
Many companies have started making strides. In fact, more than half of respondents say their organizations have taken steps to embed AI ethics into their existing approach to business ethics.
More than 45% of respondents say their organizations have created AI-specific ethics mechanisms, such as an AI project risk assessment framework and auditing/review process.
Ensuring ethical principles are embedded in AI solutions is an urgent need for organizations, but progress is still too slow
More surveyed CEOs (79%) are now prepared to embed AI ethics into their AI practices - up from 20% in 2018 -- and more than half of responding organizations have publicly endorsed common principles of AI ethics.
Yet, less than a quarter of responding organizations have operationalized AI ethics, and fewer than 20% of respondents strongly agreed that their organization's practices and actions match (or exceed) their stated principles and values.
68% of surveyed organizations acknowledge that having a diverse and inclusive workplace is important to mitigating bias in AI, but findings indicate that AI teams are still substantially less diverse than their organizations' workforces: 5.5 times less inclusive of women, 4 times less inclusive of LGBT+ individuals and 1.7 times less racially inclusive.
""As many companies today use AI algorithms across their business, they potentially face increasing internal and external demands to design these algorithms to be fair, secured and trustworthy; yet, there has been little progress across the industry in embedding AI ethics into their practices,"" said Jesus Mantas, Global Managing Partner, IBM Consulting.""Our IBV study findings demonstrate that building trustworthy AI is a business imperative and a societal expectation, not just a compliance issue. As such, companies can implement a governance model and embed ethical principles across the full AI life cycle.""
The time for companies to act is now. The study data suggests that those organizations who implement a broad AI ethics strategy interwoven throughout business units may have a competitive advantage moving forward. The study provides recommended actions for business leaders including:
Take a cross-functional, collaborative approach - ethical AI requires a holistic approach, and a holistic set of skills across all stakeholders involved in the AI ethics process. C-Suite executives, designers, behavioral scientists, data scientists, and AI engineers each have a distinct role to play in the trustworthy AI journey.
Establish both organizational and AI lifecycle governance to operationalize the discipline of AI ethics - take a holistic approach to incentivizing, managing and governing AI solutions across the full AI lifecycle, from establishing the right culture to nurture AI responsibly, to practices and policies to products.
Reach beyond your organization for partnership - expand your approach by identifying and engaging key AI-focused technology partners, academics, startups, and other ecosystem partners to establish""ethical interoperability.""
About IBM Institute for Business Value
For two decades, the IBM Institute for Business Value has served as the thought leadership think tank for IBM. What inspires us is producing research-backed, technology-informed strategic insights that help leaders make smarter business decisions.
From our unique position at the intersection of business, technology, and society, we survey, interview, and engage with thousands of executives, consumers, and experts each year, synthesizing their perspectives into credible, inspiring, and actionable insights.
Company :-Weber Shandwick
User :- Mekhala Maitra
Email :
Mobile:- +91.9547520522
MENAFN15042022003198003206ID1104030016
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); EXECUTIVES (91%); ASSOCIATIONS & ORGANIZATIONS (90%); ETHICS (90%); POLLS & SURVEYS (90%); PUBLIC COMPANIES (90%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (89%); DIVERSITY & INCLUSION (89%); BUSINESS ETHICS (78%); ARTIFICIAL INTELLIGENCE (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); BOARDS OF DIRECTORS (76%); WORKPLACE DIVERSITY & INCLUSION (74%); REGULATORY COMPLIANCE (73%); RESEARCH REPORTS (73%); RISK MANAGEMENT (70%); LAWYERS (53%)
Company:  INTERNATIONAL BUSINESS MACHINES CORP (91%)
Ticker: IBM (NYSE) (91%); IBM (LSE) (91%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (91%); NAICS334112 COMPUTER STORAGE DEVICE MANUFACTURING (91%); NAICS334111 ELECTRONIC COMPUTER MANUFACTURING (91%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (77%); RISK MANAGEMENT (70%); LAWYERS (53%)
Geographic: BANGALORE, KARNATAKA, INDIA (58%)
Load-Date: September 2, 2022",neutral,0.8487916588783264,balanced/neutral,"['privacy', 'bias']",[],"['governance', 'framework', 'compliance']",[],2,0,3,0
2021,Unknown Title,"Body
The National Institutes of Health will invest $ 130 million over four years, pending the availability of funds, to accelerate the widespread use of artificial intelligence (AI) by the biomedical and behavioral research communities. The NIH Common Fund's Bridge to Artificial Intelligence (Bridge2AI) program is assembling team members from diverse disciplines and backgrounds to generate tools, resources, and richly detailed data that are responsive to AI approaches. At the same time, the program will ensure its tools and data do not perpetuate inequities or ethical problems that may occur during data collection and analysis. Through extensive collaboration across projects, Bridge2AI researchers will create guidance and standards for the development of ethically sourced, state-of-the-art, AI-ready data sets that have the potential to help solve some of the most pressing challenges in human health - such as uncovering how genetic, behavioral, and environmental factors influence a person's physical condition throughout their life.
'Generating high-quality ethically sourced data sets is crucial for enabling the use of next-generation AI technologies that transform how we do research,' said Lawrence A. Tabak, D.D.S., Ph.D., Performing the Duties of the Director of NIH. 'The solutions to long-standing challenges in human health are at our fingertips, and now is the time to connect researchers and AI technologies to tackle our most difficult research questions and ultimately help improve human health.'
AI is both a field of science and a set of technologies that enable computers to mimic how humans sense, learn, reason, and take action. Although AI is already used in biomedical research and healthcare, its widespread adoption has been limited in part due to challenges of applying AI technologies to diverse data types. This is because routinely collected biomedical and behavioral data sets are often insufficient, meaning they lack important contextual information about the data type, collection conditions, or other parameters. Without this information, AI technologies cannot accurately analyze and interpret data. AI technologies may also inadvertently incorporate bias or inequities unless careful attention is paid to the social and ethical contexts in which the data is collected. In order to harness the power of AI for biomedical discovery and accelerate its use, scientists first need well-described and ethically created data sets, standards, and best practices for generating biomedical and behavioral data that is ready for AI analyses.
As it creates tools and best practices for making data AI-ready, Bridge2AI will also produce a variety of diverse data types ready to be used by the research community for AI analyses. These types include voice and other data to help identify abnormal changes in the body. Researchers will also generate data that can be used to make new connections between complex genetic pathways and changes in cell shape or function to better understand how they work together to influence health. In addition, AI-ready data will be prepared to help improve decision making in critical care settings to speed recovery from acute illnesses and to help uncover the complex biological processes underlying an individual's recovery from illness.
The Bridge2AI program is committed to fostering the formation of research teams richly diverse in perspectives, backgrounds, and academic and technical disciplines. Diversity is fundamental to the ethical generation of data sets, and for training future AI technologies to reduce bias and improve effectiveness for all populations, including those who are underrepresented in biomedical and behavioral research. Bridge2AI will develop ethical practices for data generation and use, addressing key issues such as privacy, data trustworthiness, and reducing bias.
NIH has issued four awards for data generation projects, and three awards to create a Bridge Center for integration, dissemination and evaluation activities. The data generation projects will generate new biomedical and behavioral data sets ready to be used for developing AI technologies, along with creating data standards and tools for ensuring data are findable, accessible, interoperable, and reusable, a principle known as FAIR. In addition, data generation projects will develop training materials that promote a culture of diversity and the use of ethical practices throughout the data generation process. The Bridge Center will be responsible for integrating activities and knowledge across data generation projects, and disseminating products, best-practices, and training materials.
The Bridge2AI program is an NIH-wide effort managed collaboratively by the NIH Common Fund, the National Center for Complementary and Integrative Health, the National Eye Institute, the National Human Genome Research Institute, the National Institute of Biomedical Imaging and Bioengineering, and the National Library of Medicine. To learn more about the Bridge2AI program, visit the Musings from the Mezzanine blog from the National Library of Medicine, and watch this video(link is external) about the Bridge2AI program.
About the NIH Common Fund: The NIH Common Fund encourages collaboration and supports a series of exceptionally high-impact, trans-NIH programs. Common Fund programs are managed by the Office of Strategic Coordination in the Division of Program Coordination, Planning, and Strategic Initiatives within the NIH Office of the Director in partnership with the NIH Institutes, Centers, and Offices. More information is available at the Common Fund website: https://commonfund.nih.gov.
About the National Institutes of Health (NIH): NIH, the nation's medical research agency, includes 27 Institutes and Centers and is a component of the U.S. Department of Health and Human Services. NIH is the primary federal agency conducting and supporting basic, clinical, and translational medical research, and is investigating the causes, treatments, and cures for both common and rare diseases. For more information about NIH and its programs, visit www.nih.gov.
Contact:
Rachel Britt
301-435-0968
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ARTIFICIAL INTELLIGENCE (90%); BEHAVIOR & COGNITION (90%); ETHICS (90%); MEDICINE & HEALTH (90%); RESEARCH INSTITUTES (90%); SCIENCE & TECHNOLOGY (90%); BIOMEDICINE (89%); BEST PRACTICES (88%); PRESS RELEASES (79%); BIOETHICS (78%); DATA ANALYTICS (78%); HEALTH DEPARTMENTS (78%); MEDICAL RESEARCH (78%)
Industry: ARTIFICIAL INTELLIGENCE (90%); BIOMEDICINE (89%); DATA ANALYTICS (78%); HEALTH DEPARTMENTS (78%)
Load-Date: September 14, 2022","The National Institutes of Health will invest $ 130 million over four years, pending the availability of funds, to accelerate the widespread use of artificial intelligence (AI) by the biomedical and behavioral research communities. The NIH Common Fund's Bridge to Artificial Intelligence (Bridge2AI) program is assembling team members from diverse disciplines and backgrounds to generate tools, resources, and richly detailed data that are responsive to AI approaches. At the same time, the program will ensure its tools and data do not perpetuate inequities or ethical problems that may occur during data collection and analysis. Through extensive collaboration across projects, Bridge2AI researchers will create guidance and standards for the development of ethically sourced, state-of-the-art, AI-ready data sets that have the potential to help solve some of the most pressing challenges in human health - such as uncovering how genetic, behavioral, and environmental factors influence a person's physical condition throughout their life.
'Generating high-quality ethically sourced data sets is crucial for enabling the use of next-generation AI technologies that transform how we do research,' said Lawrence A. Tabak, D.D.S., Ph.D., Performing the Duties of the Director of NIH. 'The solutions to long-standing challenges in human health are at our fingertips, and now is the time to connect researchers and AI technologies to tackle our most difficult research questions and ultimately help improve human health.'
AI is both a field of science and a set of technologies that enable computers to mimic how humans sense, learn, reason, and take action. Although AI is already used in biomedical research and healthcare, its widespread adoption has been limited in part due to challenges of applying AI technologies to diverse data types. This is because routinely collected biomedical and behavioral data sets are often insufficient, meaning they lack important contextual information about the data type, collection conditions, or other parameters. Without this information, AI technologies cannot accurately analyze and interpret data. AI technologies may also inadvertently incorporate bias or inequities unless careful attention is paid to the social and ethical contexts in which the data is collected. In order to harness the power of AI for biomedical discovery and accelerate its use, scientists first need well-described and ethically created data sets, standards, and best practices for generating biomedical and behavioral data that is ready for AI analyses.
As it creates tools and best practices for making data AI-ready, Bridge2AI will also produce a variety of diverse data types ready to be used by the research community for AI analyses. These types include voice and other data to help identify abnormal changes in the body. Researchers will also generate data that can be used to make new connections between complex genetic pathways and changes in cell shape or function to better understand how they work together to influence health. In addition, AI-ready data will be prepared to help improve decision making in critical care settings to speed recovery from acute illnesses and to help uncover the complex biological processes underlying an individual's recovery from illness.
The Bridge2AI program is committed to fostering the formation of research teams richly diverse in perspectives, backgrounds, and academic and technical disciplines. Diversity is fundamental to the ethical generation of data sets, and for training future AI technologies to reduce bias and improve effectiveness for all populations, including those who are underrepresented in biomedical and behavioral research. Bridge2AI will develop ethical practices for data generation and use, addressing key issues such as privacy, data trustworthiness, and reducing bias.
NIH has issued four awards for data generation projects, and three awards to create a Bridge Center for integration, dissemination and evaluation activities. The data generation projects will generate new biomedical and behavioral data sets ready to be used for developing AI technologies, along with creating data standards and tools for ensuring data are findable, accessible, interoperable, and reusable, a principle known as FAIR. In addition, data generation projects will develop training materials that promote a culture of diversity and the use of ethical practices throughout the data generation process. The Bridge Center will be responsible for integrating activities and knowledge across data generation projects, and disseminating products, best-practices, and training materials.
The Bridge2AI program is an NIH-wide effort managed collaboratively by the NIH Common Fund, the National Center for Complementary and Integrative Health, the National Eye Institute, the National Human Genome Research Institute, the National Institute of Biomedical Imaging and Bioengineering, and the National Library of Medicine. To learn more about the Bridge2AI program, visit the Musings from the Mezzanine blog from the National Library of Medicine, and watch this video(link is external) about the Bridge2AI program.
About the NIH Common Fund: The NIH Common Fund encourages collaboration and supports a series of exceptionally high-impact, trans-NIH programs. Common Fund programs are managed by the Office of Strategic Coordination in the Division of Program Coordination, Planning, and Strategic Initiatives within the NIH Office of the Director in partnership with the NIH Institutes, Centers, and Offices. More information is available at the Common Fund website: https://commonfund.nih.gov.
About the National Institutes of Health (NIH): NIH, the nation's medical research agency, includes 27 Institutes and Centers and is a component of the U.S. Department of Health and Human Services. NIH is the primary federal agency conducting and supporting basic, clinical, and translational medical research, and is investigating the causes, treatments, and cures for both common and rare diseases. For more information about NIH and its programs, visit www.nih.gov.
Contact:
Rachel Britt
301-435-0968
[Editorial queries for this story should be sent to newswire@enpublishing.co.uk ]   
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ENPN
Subject: ARTIFICIAL INTELLIGENCE (90%); BEHAVIOR & COGNITION (90%); ETHICS (90%); MEDICINE & HEALTH (90%); RESEARCH INSTITUTES (90%); SCIENCE & TECHNOLOGY (90%); BIOMEDICINE (89%); BEST PRACTICES (88%); PRESS RELEASES (79%); BIOETHICS (78%); DATA ANALYTICS (78%); HEALTH DEPARTMENTS (78%); MEDICAL RESEARCH (78%)
Industry: ARTIFICIAL INTELLIGENCE (90%); BIOMEDICINE (89%); DATA ANALYTICS (78%); HEALTH DEPARTMENTS (78%)
Load-Date: September 14, 2022",neutral,0.5587745904922485,balanced/neutral,"['privacy', 'bias', 'agency']",[],"['standards', 'should']",[],3,0,2,0
2021,Unknown Title,"Body
Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency & explainability, and accountability & responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data & AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit ""We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO’s Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom’s efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
--SPA
14:22 LOCAL TIME 11:22 GMT
0014
All Rights Reversed for Saudi Press Agency  
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (71%); EXECUTIVES (68%); ENVIRONMENT & NATURAL RESOURCES (54%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); PRESS AGENCY RELEASES (90%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (97%)
Load-Date: September 15, 2022","Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency & explainability, and accountability & responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data & AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit ""We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO’s Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom’s efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
--SPA
14:22 LOCAL TIME 11:22 GMT
0014
All Rights Reversed for Saudi Press Agency  
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 368
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (71%); EXECUTIVES (68%); ENVIRONMENT & NATURAL RESOURCES (54%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); PRESS AGENCY RELEASES (90%)
Geographic: RIYADH, SAUDI ARABIA (74%); SAUDI ARABIA (97%)
Load-Date: September 15, 2022",positive,0.6352922320365906,balanced/neutral,"['privacy', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security', 'agency']",['fairness'],"['standards', 'guidelines', 'framework']",[],8,1,3,0
2021,Unknown Title,"Body
2022 AUG 09 (NewsRx) -- By a News Reporter-Staff News Editor at Middle East Daily -- New research on Artificial Intelligence is the subject of a report. According to news reporting originating from Tehran, Iran, by NewsRx editors, the research stated, ""Artificial intelligence and its societal and ethical implications are complicated and conflictingly interpreted. Surveillance is one of the most ethically challenging concepts in AI."" 
 Our news editors obtained a quote from the research from Tarbiat Modares University, ""Within the domain of artificial intelligence, this study conducts a topic modeling analysis of scientific research on the concept of surveillance. Seven significant scholarly topics that receive significant attention from the scientific community were discovered throughout our research. These topics demonstrate how ambiguous the lines between dichotomous forms of surveillance are: public health surveillance versus state surveillance; transportation surveillance versus national security surveillance; peace surveillance versus military surveillance; disease surveillance versus surveillance capitalism; urban surveillance versus citizen ubiquitous surveillance; computational surveillance versus fakeness surveillance; and data surveillance versus invasive surveillance. This study adds to the body of knowledge on AI ethics by focusing on controversial aspects of AI surveillance."" 
 According to the news editors, the research concluded: ""In practice, it will serve as a guideline for policymakers and technology companies to focus more on the intended and unintended consequences of various forms of AI surveillance in society."" 
 This research has been peer-reviewed. 
 For more information on this research see: ""Ethically contentious aspects of artificial intelligence surveillance: a social science perspective."" AI and Ethics, 2022:1-11. 
 The news editors report that additional information may be obtained by contacting Tahereh Saheb, Management Studies Center, Tarbiat Modares University, Tehran, Iran. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00196-y. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Tehran, Iran, Asia, Artificial Intelligence, Emerging Technologies, Health and Medicine, Machine Learning, Social Science. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: SURVEILLANCE (96%); ETHICS (91%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); EPIDEMIOLOGY (90%); ESPIONAGE (90%); JOURNALISM (90%); PUBLIC HEALTH SURVEILLANCE (90%); SCIENCE & TECHNOLOGY (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HUMANITIES & SOCIAL SCIENCE (89%); DISEASES & DISORDERS (78%); MEDICINE & HEALTH (78%); MILITARY SURVEILLANCE (78%); NEWS REPORTING (78%); RESEARCH INSTITUTES (78%); PUBLIC HEALTH (77%); DISEASE REPORTING (76%); EMERGING TECHNOLOGY (74%); MACHINE LEARNING (74%); NATIONAL SECURITY (73%); COLLEGES & UNIVERSITIES (72%); SURVEILLANCE TECHNOLOGY (71%); Tehran;Iran;Asia;Artificial Intelligence;Emerging Technologies;Health and Medicine;Machine Learning;Social Science (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); EPIDEMIOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); MILITARY SURVEILLANCE (78%); NEWS REPORTING (78%); MACHINE LEARNING (74%); COLLEGES & UNIVERSITIES (72%)
Geographic: TEHRAN, IRAN, ISLAMIC REPUBLIC OF (90%); IRAN, ISLAMIC REPUBLIC OF (95%); MIDDLE EAST (91%); ASIA (90%)
Load-Date: August 11, 2022","2022 AUG 09 (NewsRx) -- By a News Reporter-Staff News Editor at Middle East Daily -- New research on Artificial Intelligence is the subject of a report. According to news reporting originating from Tehran, Iran, by NewsRx editors, the research stated, ""Artificial intelligence and its societal and ethical implications are complicated and conflictingly interpreted. Surveillance is one of the most ethically challenging concepts in AI."" 
 Our news editors obtained a quote from the research from Tarbiat Modares University, ""Within the domain of artificial intelligence, this study conducts a topic modeling analysis of scientific research on the concept of surveillance. Seven significant scholarly topics that receive significant attention from the scientific community were discovered throughout our research. These topics demonstrate how ambiguous the lines between dichotomous forms of surveillance are: public health surveillance versus state surveillance; transportation surveillance versus national security surveillance; peace surveillance versus military surveillance; disease surveillance versus surveillance capitalism; urban surveillance versus citizen ubiquitous surveillance; computational surveillance versus fakeness surveillance; and data surveillance versus invasive surveillance. This study adds to the body of knowledge on AI ethics by focusing on controversial aspects of AI surveillance."" 
 According to the news editors, the research concluded: ""In practice, it will serve as a guideline for policymakers and technology companies to focus more on the intended and unintended consequences of various forms of AI surveillance in society."" 
 This research has been peer-reviewed. 
 For more information on this research see: ""Ethically contentious aspects of artificial intelligence surveillance: a social science perspective."" AI and Ethics, 2022:1-11. 
 The news editors report that additional information may be obtained by contacting Tahereh Saheb, Management Studies Center, Tarbiat Modares University, Tehran, Iran. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s43681-022-00196-y. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 Keywords for this news article include: Tehran, Iran, Asia, Artificial Intelligence, Emerging Technologies, Health and Medicine, Machine Learning, Social Science. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: SURVEILLANCE (96%); ETHICS (91%); EXPERIMENTATION & RESEARCH (91%); ARTIFICIAL INTELLIGENCE (90%); EPIDEMIOLOGY (90%); ESPIONAGE (90%); JOURNALISM (90%); PUBLIC HEALTH SURVEILLANCE (90%); SCIENCE & TECHNOLOGY (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); HUMANITIES & SOCIAL SCIENCE (89%); DISEASES & DISORDERS (78%); MEDICINE & HEALTH (78%); MILITARY SURVEILLANCE (78%); NEWS REPORTING (78%); RESEARCH INSTITUTES (78%); PUBLIC HEALTH (77%); DISEASE REPORTING (76%); EMERGING TECHNOLOGY (74%); MACHINE LEARNING (74%); NATIONAL SECURITY (73%); COLLEGES & UNIVERSITIES (72%); SURVEILLANCE TECHNOLOGY (71%); Tehran;Iran;Asia;Artificial Intelligence;Emerging Technologies;Health and Medicine;Machine Learning;Social Science (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); EPIDEMIOLOGY (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); MILITARY SURVEILLANCE (78%); NEWS REPORTING (78%); MACHINE LEARNING (74%); COLLEGES & UNIVERSITIES (72%)
Geographic: TEHRAN, IRAN, ISLAMIC REPUBLIC OF (90%); IRAN, ISLAMIC REPUBLIC OF (95%); MIDDLE EAST (91%); ASIA (90%)
Load-Date: August 11, 2022",neutral,0.9252361059188843,balanced/neutral,"['surveillance', 'security']",[],[],['machine learning'],2,0,0,1
2021,Unknown Title,"Byline: Targeted News Service
Dateline: WASHINGTON 
Body
WASHINGTON, Nov. 7 (TNSrep) -- CFA Institute, Charlottesville, Virginia, issued an 18-page report in 2022 entitled ""Ethics and Artificial Intelligence in Investment Management: A Framework for Professionals.""
Here are excerpts:
* * *
Table of Contents
Executive Summary ... 1
1 Introduction ... 2
2 AI Applications in Investment Management ... 3
3 Ethical Considerations and Professional Standards ... 5
4 An Ethical Framework for AI ... 10
5 Conclusion ... 12
* * *
EXECUTIVE SUMMARY
The use of artificial intelligence (AI) in investment management is rapidly increasing, posing both opportunities and challenges--including ethical challenges--for firms and professionals working to adopt these technologies in investment processes.
This paper addresses the ethical considerations of using AI in investment management. It is designed to inform investment professionals and firms on the spectrum of issues brought about by the use of AI tools and big data in investing. It thereby aims to advance and motivate the evolution of ethical practices in the development of AI technologies.
AI adoption offers significant potential benefits, yet it also entails several risks. Instilling an ethical framework in the design, development, and deployment of AI is critical to ensure that the applications firms deploy serve the best interest of clients.
Ethical considerations span the AI workflow, and this paper sets out questions for professionals to evaluate at each step via an ethical decision framework. It combines fundamental ethical principles with the applicability of relevant professional standards.
In addition to an ethical framework, the organization's senior leadership must establish (i) a culture conducive to client-centric AI innovation and collaboration, (ii) a robust risk management and governance framework, and (iii) a talent development programme to ensure teams possess the appropriate knowledge, skills, and abilities. Taken together, these elements provide the most supportive environment for AI to be successfully used in the investment context.
* * *
CONCLUSION
The use of AI in investment management will disrupt existing business models and investment processes and carries the potential to bring about the most significant changes to the investment industry seen in decades.
The manner in which investment firms ethically develop AI is essential to ensure that client interests are best served. In this context, investment professionals--those with a duty to clients--have the onus and responsibility to provide ethical leadership and ensure such considerations are imparted to the teams developing AI-driven solutions.
An ethical decision framework comprising principle considerations and professional standards can provide needed guidance to support the thinking and actions of investment teams. By embracing this approach, firms can demonstrate their ethical commitment to the advancement of new, client-centric technologies in investment management.
* * *
The report is posted at: https://www.cfainstitute.org/-/media/documents/article/industry-research/Ethics-and-Artificial-Intelligence-in-Investment-Management_Online.pdf
TARGETED NEWS SERVICE (founded 2004) features non-partisan 'edited journalism' news briefs and information for news organizations, public policy groups and individuals; as well as 'gathered' public policy information, including news releases, reports, speeches. For more information contact MYRON STRUCK, editor, editor@targetednews.com, Springfield, Virginia; 703/304-1897; https://targetednews.com
-1634466
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (98%); INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); PROFESSIONAL WORKERS (90%); INVESTMENT ADVISERS (89%); INVESTMENT SERVICES (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); CORPORATE GOVERNANCE (78%); NEWS BRIEFS (78%); RISK MANAGEMENT (77%); ASSOCIATIONS & ORGANIZATIONS (64%)
Industry: INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INVESTMENT ADVISERS (89%); INVESTMENT SERVICES (89%); RISK MANAGEMENT (77%)
Geographic: VIRGINIA, USA (58%)
Load-Date: November 7, 2022","WASHINGTON, Nov. 7 (TNSrep) -- CFA Institute, Charlottesville, Virginia, issued an 18-page report in 2022 entitled ""Ethics and Artificial Intelligence in Investment Management: A Framework for Professionals.""
Here are excerpts:
* * *
Table of Contents
Executive Summary ... 1
1 Introduction ... 2
2 AI Applications in Investment Management ... 3
3 Ethical Considerations and Professional Standards ... 5
4 An Ethical Framework for AI ... 10
5 Conclusion ... 12
* * *
EXECUTIVE SUMMARY
The use of artificial intelligence (AI) in investment management is rapidly increasing, posing both opportunities and challenges--including ethical challenges--for firms and professionals working to adopt these technologies in investment processes.
This paper addresses the ethical considerations of using AI in investment management. It is designed to inform investment professionals and firms on the spectrum of issues brought about by the use of AI tools and big data in investing. It thereby aims to advance and motivate the evolution of ethical practices in the development of AI technologies.
AI adoption offers significant potential benefits, yet it also entails several risks. Instilling an ethical framework in the design, development, and deployment of AI is critical to ensure that the applications firms deploy serve the best interest of clients.
Ethical considerations span the AI workflow, and this paper sets out questions for professionals to evaluate at each step via an ethical decision framework. It combines fundamental ethical principles with the applicability of relevant professional standards.
In addition to an ethical framework, the organization's senior leadership must establish (i) a culture conducive to client-centric AI innovation and collaboration, (ii) a robust risk management and governance framework, and (iii) a talent development programme to ensure teams possess the appropriate knowledge, skills, and abilities. Taken together, these elements provide the most supportive environment for AI to be successfully used in the investment context.
* * *
CONCLUSION
The use of AI in investment management will disrupt existing business models and investment processes and carries the potential to bring about the most significant changes to the investment industry seen in decades.
The manner in which investment firms ethically develop AI is essential to ensure that client interests are best served. In this context, investment professionals--those with a duty to clients--have the onus and responsibility to provide ethical leadership and ensure such considerations are imparted to the teams developing AI-driven solutions.
An ethical decision framework comprising principle considerations and professional standards can provide needed guidance to support the thinking and actions of investment teams. By embracing this approach, firms can demonstrate their ethical commitment to the advancement of new, client-centric technologies in investment management.
* * *
The report is posted at: https://www.cfainstitute.org/-/media/documents/article/industry-research/Ethics-and-Artificial-Intelligence-in-Investment-Management_Online.pdf
TARGETED NEWS SERVICE (founded 2004) features non-partisan 'edited journalism' news briefs and information for news organizations, public policy groups and individuals; as well as 'gathered' public policy information, including news releases, reports, speeches. For more information contact MYRON STRUCK, editor, editor@targetednews.com, Springfield, Virginia; 703/304-1897; https://targetednews.com
-1634466
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (98%); INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); PROFESSIONAL WORKERS (90%); INVESTMENT ADVISERS (89%); INVESTMENT SERVICES (89%); COMPANY ACTIVITIES & MANAGEMENT (78%); CORPORATE GOVERNANCE (78%); NEWS BRIEFS (78%); RISK MANAGEMENT (77%); ASSOCIATIONS & ORGANIZATIONS (64%)
Industry: INVESTMENT MANAGEMENT (95%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INVESTMENT ADVISERS (89%); INVESTMENT SERVICES (89%); RISK MANAGEMENT (77%)
Geographic: VIRGINIA, USA (58%)
Load-Date: November 7, 2022",neutral,0.9064298868179321,balanced/neutral,[],[],"['policy', 'governance', 'standards', 'framework', 'must']",[],0,0,5,0
2021,Unknown Title,"Dateline: ATLANTA, Dec. 15, 2022 
Body
PR Newswire
Enhancements include unique capabilities to support 2023 US state privacy laws, new data transfer and data deletion support, certification automation and IT audit support for ISO 27001:2022, and platform-wide insights and analytics
OneTrust, the market-defining leader for trust intelligence, today announced new enhancements across the Trust Intelligence Platform, the first platform designed to help companies manage trust across privacy, risk, ethics, and environmental and social governance (ESG) and sustainability. These latest innovations give customers the visibility, control, intelligence, and efficiency needed to make trust a competitive advantage.
Trust is quickly becoming a top priority for business leaders
""Trust is quickly becoming a top priority for business leaders, and they are looking for a whole new level of automation to scale their programs,"" said Blake Brannon, chief product and strategy officer at OneTrust. ""OneTrust took a bold step to deliver the world's first Trust Intelligence Platform that enables customers to operationalize privacy management and data ethics, remain resilient with robust governance and third-party risk management, drive a speak-up culture rooted in ethical practices, and demonstrate progress against ESG and sustainability commitments.""
Brannon added, ""Organizations of all sizes are increasingly needing to be more transparent about each of these trust indices as acritical enabler for their top line growth as a business. Our continued innovation and cloud-native platform allow us to remain unique in the comprehensiveness of our solutions and depth of capabilities we're enabling for our customers. This gives organizations a strategic advantage through scale, automation, and transparency.""
TheTrust Intelligence Platformis the first in a new software category to break down siloes across privacy, GRC, ethics, and ESG to offer the visibility, action, and accountability organizations need to generate a centralized understanding of business trust. OneTrust continues to advance the flagship Trust Intelligence Platform:
Platform-Wide OneTrust Insights and Analytics: As every organization becomes more data-driven, privacy, marketing, and security teams can leverage new reporting and decision-making capabilities with OneTrust Insights and Analytics on the Trust Intelligence Platform. Solution-based dashboards can be viewed across multiple risk domains to monitor programs, generate actionable insights, and break down siloes between workstreams for a unified view of the business.  
As five new state privacy laws come into effect in the United States in 2023, new innovations help customers beat regulatory complexity and build holistic privacy programs that encompass cross-regulation frameworks and best practices:
Out-of-the-Box Regulatory Content and Support: Comprehensive privacy program management capabilities help further streamline requirements with new laws, such as CTDPA and UCPA in the United States and APPI in Japan, including out-of-the-box templates for managing risk, record keeping, and subject rights and deletion requests.Improved Response Deadline Accuracy: Customers can pause the countdown for data subject right to appeal request and response deadlines.Cross-Border Data Transfers: Improved support allows teams to capture specific details of a data transfer and classify the legal basis for each set of data elements, as well as the ability to model and calculate the risk of transfers.Data Deletion: Customers can set up data deletion of personal data based on consent withdrawal or data subject rights requests to comply with new privacy guidelines. Updates to hundreds of data retention schedules enable users to validate compliance with internal data retention policies. 
OneTrust continues to enhance its privacy management, data governance, and consent and preferences solutions allowing customers to gain regulatory agility, improve data quality, and enable trusted data use:
Intelligent Consent and Data Policy Management: Dynamic governance and management enable companies with a highly flexible consent management solution that can be configured based on where, how, and for what purpose consumer consent needs to be collected. Customers can also merge multiple identities into a single source of truth to prevent the creation of duplicate data subjects and disparate audit records, reduce database costs, and ensure communications preferences are respected.New Data Discovery Risk Insights: A single-pane-of-glass experience allows users to gain visibility into the sensitive data housed throughout their organization, including personal and sensitive information, and obsolete and trivial data. Dynamic insights allow users to report on sensitive data where it does not belong, as well as violations of retention and access policies. Users can leverage AI-based classifiers to tag data and take action to remediate violations via out-of-the-box and custom integrations, and reference regulatory guidance to meet compliance obligations.Improved Google Data Safety Mobile App Report: Coverage has doubled, with more than 800 SDK detectors minimizing risk by validating actual data. To simplify Google Data Safety Requirements, users can export mobile app metadata in a spreadsheet from the mobile app scanner, pre-formatted for direct upload when publishing on Google Play.
As the global threat landscape evolves, automation helps customers more efficiently manage certification for and compliance with increasingly complex security standards, as well as scale their risk management programs to keep pace with fast-expanding IT ecosystems:
Automate Evidence Collection for ISO Certifications: Certification Automation dramatically reduces the time and manual effort required to achieve certification, prepare for third-party audits, and prove compliance across ISO 27001 and adjacent security and privacy frameworks, including to the new ISO 27001:2022 standard.Risk Lifecycle and Aggregation Improvements: With expanded risk automation, customers can better manage and remediate risk with new capabilities to streamline the risk lifecycle, including enhanced risk assessments, custom risk workflows, and risk lifecycle automation. With engagement risk quantification and reporting for Third-Party Risk Management, users can now calculate risk at an individual engagement level, and aggregate as factors into the overall Vendor Risk Score.
OneTrust also unveiled multiple integrations, providing companies with the analytics and intelligence to more accurately measure and address third-party risk and drive trusted supply chains:
Cybersecurity and Supplier ESG Ratings Available in the Third-Party Risk Exchange: A new integration with RiskRecon, a Mastercard Company, makes cybersecurity ratings available out-of-the-box to all Third-Party Risk Exchange customers. Cybersecurity ratings from SecurityScorecard help customers determine the cyber risk posture of third-parties. ISS scores available within the Third-Party Risk Exchange enable companies to understand external cybersecurity risk posture with the ISS Cyber Risk Score, and how companies can manage ESG risks through the ISS ESG rating.Contract Lifecycle Management: Through an integration with Ironclad, customers can better understand contract risk by increasing oversight control, streamlining approvals, reducing workflow complexity, and generating data-driven insights to improve business processes.New Third-Party Due Diligence Capabilities: Ethics and compliance teams can now leverage data from Dow Jones on the OneTrust Third-Party Due Diligence platform to drive a more trusted supply chain. Customers can identify ethics and compliance violations among partners and stay up to date with ongoing monitoring.
Customers can also drive more effective ethics and compliance programs with a higher level of transparency and accountability:
Improved Ethics and Compliance Disclosure and Policy Management: Ethics and Compliance teams can strengthen their programs with automation, collaboration, deeper management capabilities, and more flexible workflows. Increased visibility helps teams make data-driven decisions and drive organizational awareness.
About OneTrust
As society redefines risk and opportunity, OneTrust empowers tomorrow's leaders to succeed through trust and impact with the Trust Intelligence Platform. The market-defining Trust Intelligence Platform from OneTrust connects privacy, GRC, ethics, and ESG teams, data, and processes, so all companies can collaborate seamlessly and put trust at the center of their operations and culture by unlocking their value and potential to thrive by doing what's good for people and the planet.
Learn more at OneTrust.com.
Media Contact
Ainslee Shea
+1 (
media@onetrust.com
 View original content to download multimedia:https://www.prnewswire.com/news-releases/onetrust-advances-the-trust-intelligence-platform-to-ready-organizations-for-top-2023-initiatives-301703760.html
SOURCE OneTrust
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ASSOCIATIONS & ORGANIZATIONS (90%); ESG FACTORS (90%); ETHICS (90%); PRESS RELEASES (90%); PRODUCT ENHANCEMENTS (90%); DATA ANALYTICS (89%); DATA PROTECTION LAWS (89%); ESG FACTORS - ENVIRONMENTAL (89%); PRIVACY RIGHTS (89%); RISK MANAGEMENT (89%); COMPANY STRATEGY (79%); BEST PRACTICES (78%); PSYCHOLOGICAL SAFETY (78%); LEGISLATION (73%); ONETRUST-Updates (%)
Company: OneTrust
Industry: DATA ANALYTICS (89%); DATA PROTECTION LAWS (89%); RISK MANAGEMENT (89%); PSYCHOLOGICAL SAFETY (78%); COMPUTER SOFTWARE (58%); STW Computer Software (%); CPR Computer; Electronics Products (%); DTA Data Analytics (%); HTS Makers and developers of computer and network security products and services, Internet firewalls, intrusion detection, encryption software, virus protection (%)
Geographic: ATLANTA, GA, USA (59%); GEORGIA, USA (79%); UNITED STATES (92%); JAPAN (79%); Georgia
Load-Date: December 15, 2022","PR Newswire
Enhancements include unique capabilities to support 2023 US state privacy laws, new data transfer and data deletion support, certification automation and IT audit support for ISO 27001:2022, and platform-wide insights and analytics
OneTrust, the market-defining leader for trust intelligence, today announced new enhancements across the Trust Intelligence Platform, the first platform designed to help companies manage trust across privacy, risk, ethics, and environmental and social governance (ESG) and sustainability. These latest innovations give customers the visibility, control, intelligence, and efficiency needed to make trust a competitive advantage.
Trust is quickly becoming a top priority for business leaders
""Trust is quickly becoming a top priority for business leaders, and they are looking for a whole new level of automation to scale their programs,"" said Blake Brannon, chief product and strategy officer at OneTrust. ""OneTrust took a bold step to deliver the world's first Trust Intelligence Platform that enables customers to operationalize privacy management and data ethics, remain resilient with robust governance and third-party risk management, drive a speak-up culture rooted in ethical practices, and demonstrate progress against ESG and sustainability commitments.""
Brannon added, ""Organizations of all sizes are increasingly needing to be more transparent about each of these trust indices as acritical enabler for their top line growth as a business. Our continued innovation and cloud-native platform allow us to remain unique in the comprehensiveness of our solutions and depth of capabilities we're enabling for our customers. This gives organizations a strategic advantage through scale, automation, and transparency.""
TheTrust Intelligence Platformis the first in a new software category to break down siloes across privacy, GRC, ethics, and ESG to offer the visibility, action, and accountability organizations need to generate a centralized understanding of business trust. OneTrust continues to advance the flagship Trust Intelligence Platform:
Platform-Wide OneTrust Insights and Analytics: As every organization becomes more data-driven, privacy, marketing, and security teams can leverage new reporting and decision-making capabilities with OneTrust Insights and Analytics on the Trust Intelligence Platform. Solution-based dashboards can be viewed across multiple risk domains to monitor programs, generate actionable insights, and break down siloes between workstreams for a unified view of the business.  
As five new state privacy laws come into effect in the United States in 2023, new innovations help customers beat regulatory complexity and build holistic privacy programs that encompass cross-regulation frameworks and best practices:
Out-of-the-Box Regulatory Content and Support: Comprehensive privacy program management capabilities help further streamline requirements with new laws, such as CTDPA and UCPA in the United States and APPI in Japan, including out-of-the-box templates for managing risk, record keeping, and subject rights and deletion requests.Improved Response Deadline Accuracy: Customers can pause the countdown for data subject right to appeal request and response deadlines.Cross-Border Data Transfers: Improved support allows teams to capture specific details of a data transfer and classify the legal basis for each set of data elements, as well as the ability to model and calculate the risk of transfers.Data Deletion: Customers can set up data deletion of personal data based on consent withdrawal or data subject rights requests to comply with new privacy guidelines. Updates to hundreds of data retention schedules enable users to validate compliance with internal data retention policies. 
OneTrust continues to enhance its privacy management, data governance, and consent and preferences solutions allowing customers to gain regulatory agility, improve data quality, and enable trusted data use:
Intelligent Consent and Data Policy Management: Dynamic governance and management enable companies with a highly flexible consent management solution that can be configured based on where, how, and for what purpose consumer consent needs to be collected. Customers can also merge multiple identities into a single source of truth to prevent the creation of duplicate data subjects and disparate audit records, reduce database costs, and ensure communications preferences are respected.New Data Discovery Risk Insights: A single-pane-of-glass experience allows users to gain visibility into the sensitive data housed throughout their organization, including personal and sensitive information, and obsolete and trivial data. Dynamic insights allow users to report on sensitive data where it does not belong, as well as violations of retention and access policies. Users can leverage AI-based classifiers to tag data and take action to remediate violations via out-of-the-box and custom integrations, and reference regulatory guidance to meet compliance obligations.Improved Google Data Safety Mobile App Report: Coverage has doubled, with more than 800 SDK detectors minimizing risk by validating actual data. To simplify Google Data Safety Requirements, users can export mobile app metadata in a spreadsheet from the mobile app scanner, pre-formatted for direct upload when publishing on Google Play.
As the global threat landscape evolves, automation helps customers more efficiently manage certification for and compliance with increasingly complex security standards, as well as scale their risk management programs to keep pace with fast-expanding IT ecosystems:
Automate Evidence Collection for ISO Certifications: Certification Automation dramatically reduces the time and manual effort required to achieve certification, prepare for third-party audits, and prove compliance across ISO 27001 and adjacent security and privacy frameworks, including to the new ISO 27001:2022 standard.Risk Lifecycle and Aggregation Improvements: With expanded risk automation, customers can better manage and remediate risk with new capabilities to streamline the risk lifecycle, including enhanced risk assessments, custom risk workflows, and risk lifecycle automation. With engagement risk quantification and reporting for Third-Party Risk Management, users can now calculate risk at an individual engagement level, and aggregate as factors into the overall Vendor Risk Score.
OneTrust also unveiled multiple integrations, providing companies with the analytics and intelligence to more accurately measure and address third-party risk and drive trusted supply chains:
Cybersecurity and Supplier ESG Ratings Available in the Third-Party Risk Exchange: A new integration with RiskRecon, a Mastercard Company, makes cybersecurity ratings available out-of-the-box to all Third-Party Risk Exchange customers. Cybersecurity ratings from SecurityScorecard help customers determine the cyber risk posture of third-parties. ISS scores available within the Third-Party Risk Exchange enable companies to understand external cybersecurity risk posture with the ISS Cyber Risk Score, and how companies can manage ESG risks through the ISS ESG rating.Contract Lifecycle Management: Through an integration with Ironclad, customers can better understand contract risk by increasing oversight control, streamlining approvals, reducing workflow complexity, and generating data-driven insights to improve business processes.New Third-Party Due Diligence Capabilities: Ethics and compliance teams can now leverage data from Dow Jones on the OneTrust Third-Party Due Diligence platform to drive a more trusted supply chain. Customers can identify ethics and compliance violations among partners and stay up to date with ongoing monitoring.
Customers can also drive more effective ethics and compliance programs with a higher level of transparency and accountability:
Improved Ethics and Compliance Disclosure and Policy Management: Ethics and Compliance teams can strengthen their programs with automation, collaboration, deeper management capabilities, and more flexible workflows. Increased visibility helps teams make data-driven decisions and drive organizational awareness.
About OneTrust
As society redefines risk and opportunity, OneTrust empowers tomorrow's leaders to succeed through trust and impact with the Trust Intelligence Platform. The market-defining Trust Intelligence Platform from OneTrust connects privacy, GRC, ethics, and ESG teams, data, and processes, so all companies can collaborate seamlessly and put trust at the center of their operations and culture by unlocking their value and potential to thrive by doing what's good for people and the planet.
Learn more at OneTrust.com.
Media Contact
Ainslee Shea
+1 (
media@onetrust.com
 View original content to download multimedia:https://www.prnewswire.com/news-releases/onetrust-advances-the-trust-intelligence-platform-to-ready-organizations-for-top-2023-initiatives-301703760.html
SOURCE OneTrust
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ASSOCIATIONS & ORGANIZATIONS (90%); ESG FACTORS (90%); ETHICS (90%); PRESS RELEASES (90%); PRODUCT ENHANCEMENTS (90%); DATA ANALYTICS (89%); DATA PROTECTION LAWS (89%); ESG FACTORS - ENVIRONMENTAL (89%); PRIVACY RIGHTS (89%); RISK MANAGEMENT (89%); COMPANY STRATEGY (79%); BEST PRACTICES (78%); PSYCHOLOGICAL SAFETY (78%); LEGISLATION (73%); ONETRUST-Updates (%)
Company: OneTrust
Industry: DATA ANALYTICS (89%); DATA PROTECTION LAWS (89%); RISK MANAGEMENT (89%); PSYCHOLOGICAL SAFETY (78%); COMPUTER SOFTWARE (58%); STW Computer Software (%); CPR Computer; Electronics Products (%); DTA Data Analytics (%); HTS Makers and developers of computer and network security products and services, Internet firewalls, intrusion detection, encryption software, virus protection (%)
Geographic: ATLANTA, GA, USA (59%); GEORGIA, USA (79%); UNITED STATES (92%); JAPAN (79%); Georgia
Load-Date: December 15, 2022",positive,0.4948042333126068,balanced/neutral,"['privacy', 'transparency', 'accountability', 'safety', 'security', 'consent', 'access']",[],"['regulation', 'policy', 'governance', 'oversight', 'standards', 'guidelines', 'legislation', 'compliance', 'audit', 'certification', 'need to']",[],7,0,11,0
2021,Unknown Title,"Byline: Targeted News Service
Dateline: NOTRE DAME, Indiana 
Body
(TNSRes) -- The University of Notre Dame issued the following news:
What are the ethical responsibilities associated with developing artificial intelligence systems? What about the moral obligations of the companies and other entities that subsequently use those AI systems to automate aspects of their work? How do we address and prevent bias in decisions made by computers?
Or take the many and ever-expanding ways our lives are lived online. Can we do anything to fight mis- and disinformation? How much privacy should we expect in exchange for the convenience of online transactions? What do institutions owe us when it comes to protecting our data?
Already topics of national and international conversation, technology ethics questions such as these have only grown more pressing over the course of the pandemic, which has heightened our real-world dependence on our virtual existence, both personally and professionally.
To give students a firm foundation in these issues, the Notre Dame Technology Ethics Center (ND TEC) has created an undergraduate minor in technology ethics, a course of study with applications in all manner of careers and that will be relevant to whatever ways students interact with and think about technology.
""Much of what we do at ND TEC proceeds from the basic idea that it's not enough to ask whether a new technology can be developed,"" said Kirsten Martin, ND TEC director, the William P. and Hazel B. White Center Professor of Technology Ethics, and a professor of IT, analytics and operations. ""We also have to examine whether a given piece of technology -- a social media algorithm that pushes specific types of content, the latest facial recognition software, etc. -- should be developed, and if so, what the appropriate uses are. Students who pursue the undergraduate minor in tech ethics will be prepared to tackle emerging issues in a responsible and meaningful way.""
""Technological advances have enormous potential to improve individual lives, increase the general welfare, improve quality of life and reverse environmental degradation,"" added Warren von Eschenbach, ND TEC's associate director for academic affairs. ""But achieving these goods isn't a given. Rather, it requires that the development and application of new technologies be subject to ethical analysis and integration.
""As Pope Francis has noted, 'The indisputable benefit that humanity will be able to draw from technological progress depends on the degree to which the new possibilities at our disposal are employed in an ethical manner.' This is the work in which we hope to engage Notre Dame students so that they might become leaders in the ethical development of technology.""
The undergraduate minor in tech ethics, which was approved by the University's Academic Council to formally launch in fall 2022, is open to students from all colleges and schools at Notre Dame and consists of five courses or 15 credits.
It begins with a required gateway class, Fundamentals of Technology Ethics and Society, and also features an advanced seminar on a current issue in tech ethics. Representative electives include courses like Algorithms, Data and Society; Application, Ethics and Governance of AI; Ethics of Data Analytics; Ethics of Emerging Weapon Technologies; Future of Labor; Race and Technologies of Surveillance; and Robot Ethics.
Classes are taught by faculty members from various disciplines, but especially those from the College of Arts and Letters, College of Engineering, Mendoza College of Business and Keough School of Global Affairs.
For more information about the undergraduate minor, visit techethics.nd.edu/education/tech-ethics-minor/.
ND TEC was established in 2019 to advance interdisciplinary research and education concerned with the impact of technology on humanity. The center connects some 30 faculty from more than a dozen academic units at Notre Dame who explore enduring and emerging ethical questions in a wide range of technological contexts and from a variety of different disciplinary backgrounds and perspectives. These faculty are united by the belief that technology should promote human flourishing and that ethical considerations must be integrated into every stage of the development of technology and social, political and cultural engagement with it.
MSTRUCK-7816102 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); DATA ANALYTICS (78%); EMERGING TECHNOLOGY (78%); IDENTIFICATION TECHNOLOGIES (78%); BUSINESS ANALYTICS (77%); DISINFORMATION & MISINFORMATION (76%); SOCIAL MEDIA (71%); APPROVALS (67%); BIOMETRICS (63%); ENVIRONMENT & NATURAL RESOURCES (50%)
Company:  AI SYSTEMS (58%)
Organization: UNIVERSITY OF NOTRE DAME (84%)
Industry: SIC7372 PREPACKAGED SOFTWARE (58%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); DATA ANALYTICS (78%); EDUCATIONAL SERVICES (78%); BUSINESS ANALYTICS (77%); COMPUTER SOFTWARE (76%); PATTERN RECOGNITION (73%); SOCIAL MEDIA (71%); INFORMATION SECURITY & PRIVACY (70%)
Person: ANDREW VON ESCHENBACH (50%)
Geographic: INDIANA, USA (79%)
Load-Date: April 23, 2022","(TNSRes) -- The University of Notre Dame issued the following news:
What are the ethical responsibilities associated with developing artificial intelligence systems? What about the moral obligations of the companies and other entities that subsequently use those AI systems to automate aspects of their work? How do we address and prevent bias in decisions made by computers?
Or take the many and ever-expanding ways our lives are lived online. Can we do anything to fight mis- and disinformation? How much privacy should we expect in exchange for the convenience of online transactions? What do institutions owe us when it comes to protecting our data?
Already topics of national and international conversation, technology ethics questions such as these have only grown more pressing over the course of the pandemic, which has heightened our real-world dependence on our virtual existence, both personally and professionally.
To give students a firm foundation in these issues, the Notre Dame Technology Ethics Center (ND TEC) has created an undergraduate minor in technology ethics, a course of study with applications in all manner of careers and that will be relevant to whatever ways students interact with and think about technology.
""Much of what we do at ND TEC proceeds from the basic idea that it's not enough to ask whether a new technology can be developed,"" said Kirsten Martin, ND TEC director, the William P. and Hazel B. White Center Professor of Technology Ethics, and a professor of IT, analytics and operations. ""We also have to examine whether a given piece of technology -- a social media algorithm that pushes specific types of content, the latest facial recognition software, etc. -- should be developed, and if so, what the appropriate uses are. Students who pursue the undergraduate minor in tech ethics will be prepared to tackle emerging issues in a responsible and meaningful way.""
""Technological advances have enormous potential to improve individual lives, increase the general welfare, improve quality of life and reverse environmental degradation,"" added Warren von Eschenbach, ND TEC's associate director for academic affairs. ""But achieving these goods isn't a given. Rather, it requires that the development and application of new technologies be subject to ethical analysis and integration.
""As Pope Francis has noted, 'The indisputable benefit that humanity will be able to draw from technological progress depends on the degree to which the new possibilities at our disposal are employed in an ethical manner.' This is the work in which we hope to engage Notre Dame students so that they might become leaders in the ethical development of technology.""
The undergraduate minor in tech ethics, which was approved by the University's Academic Council to formally launch in fall 2022, is open to students from all colleges and schools at Notre Dame and consists of five courses or 15 credits.
It begins with a required gateway class, Fundamentals of Technology Ethics and Society, and also features an advanced seminar on a current issue in tech ethics. Representative electives include courses like Algorithms, Data and Society; Application, Ethics and Governance of AI; Ethics of Data Analytics; Ethics of Emerging Weapon Technologies; Future of Labor; Race and Technologies of Surveillance; and Robot Ethics.
Classes are taught by faculty members from various disciplines, but especially those from the College of Arts and Letters, College of Engineering, Mendoza College of Business and Keough School of Global Affairs.
For more information about the undergraduate minor, visit techethics.nd.edu/education/tech-ethics-minor/.
ND TEC was established in 2019 to advance interdisciplinary research and education concerned with the impact of technology on humanity. The center connects some 30 faculty from more than a dozen academic units at Notre Dame who explore enduring and emerging ethical questions in a wide range of technological contexts and from a variety of different disciplinary backgrounds and perspectives. These faculty are united by the belief that technology should promote human flourishing and that ethical considerations must be integrated into every stage of the development of technology and social, political and cultural engagement with it.
MSTRUCK-7816102 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); STUDENTS & STUDENT LIFE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); DATA ANALYTICS (78%); EMERGING TECHNOLOGY (78%); IDENTIFICATION TECHNOLOGIES (78%); BUSINESS ANALYTICS (77%); DISINFORMATION & MISINFORMATION (76%); SOCIAL MEDIA (71%); APPROVALS (67%); BIOMETRICS (63%); ENVIRONMENT & NATURAL RESOURCES (50%)
Company:  AI SYSTEMS (58%)
Organization: UNIVERSITY OF NOTRE DAME (84%)
Industry: SIC7372 PREPACKAGED SOFTWARE (58%); ARTIFICIAL INTELLIGENCE (90%); COLLEGE & UNIVERSITY PROFESSORS (89%); DATA ANALYTICS (78%); EDUCATIONAL SERVICES (78%); BUSINESS ANALYTICS (77%); COMPUTER SOFTWARE (76%); PATTERN RECOGNITION (73%); SOCIAL MEDIA (71%); INFORMATION SECURITY & PRIVACY (70%)
Person: ANDREW VON ESCHENBACH (50%)
Geographic: INDIANA, USA (79%)
Load-Date: April 23, 2022",neutral,0.8940345048904419,balanced/neutral,"['privacy', 'surveillance', 'bias', 'security', 'misinformation', 'disinformation']",[],"['governance', 'should', 'must']","['facial recognition', 'robot', 'algorithm']",6,0,3,3
2021,Unknown Title,"Body
TORONTO, March 24, 2022 /CNW/ -Scotiabank announced today the launch of Ethics Assistant, in collaboration with Deloitte Canada, to further enhance the Bank's investments in data and analytics to derive customer insights that are more accurate, personalized, and free of bias. Ethics Assistant also ensures that data collected by Scotiabank is leveraged in a manner that reinforces the importance of transparency and trust in how customer information is accessed and used.
""As we continue to unlock the potential of data and analytics, Ethics Assistant helps us advance how we responsibly collect, share, store, and use data,"" says Grace Lee, Senior Vice President and Chief Data & Analytics Officer, Scotiabank.""This new solution gives us the confidence that the enhancements we are making to develop personalized solutions for our customers are aligned with and strengthen our data ethics practices.""
Using Deloitte's Artificial Intelligence (AI) Impact Assessment tool, Scotiabank was able to successfully build and deploy Ethics Assistant which helps advance responsible AI-based innovation and adoption to benefit and enhance how data is used to deliver value and build trust with the Bank's customers.
""Data ethics and customer trust is a top priority for financial institutions across the globe,"" says Preeti Shivpuri, Trustworthy AI Leader at Deloitte Canada. ""As Deloitte works towards fostering further AI adoption and innovation across Canada, we're thrilled to collaborate with Scotiabank to launch Ethics Assistant to support the responsible design, development, and deployment of AI solutions across the Bank.""
The tool helps practitioners think about ethical considerations early on before AI and machine learning projects are deployedimproving consistency, transparency, and fairness.
""Including ethicalconsiderations early in the design stage of a use case helps us take a proactive approach throughout the development process,"" says Anna Hannem, Director of Data Ethics & Use. ""The result is more ethical, trustworthy use cases which benefit our customers and our businesses.""
Scotiabank plans to scale Ethics Assistant for all new AI and machine learning projects across the Bank this year.
About ScotiabankScotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. With a team of approximately 90,000 employees and assets of approximately $1.2 trillion (as at January 31, 2022), Scotiabank trades on the Toronto Stock Exchange (TSX: BNS) and New York Stock Exchange (NYSE: BNS). For more information, please visit http://www.scotiabank.comand follow us on Twitter @ScotiabankViews.
About DeloitteDeloitte provides audit and assurance, consulting, financial advisory, risk advisory, tax, and related services to public and private clients spanning multiple industries. Deloitte servesfour out of five Fortune Global 500® companies through a globally connected network of member firms in more than 150 countries and territories bringing world-class capabilities, insights, and service to address clients' most complex business challenges. Deloitte LLP, an Ontario limited liability partnership, is the Canadian member firm of Deloitte Touche Tohmatsu Limited. Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee, and its network of member firms, each of which is a legally separate and independent entity. Please see www.deloitte.com/aboutfor a detailed description of the legal structure of Deloitte Touche Tohmatsu Limited and its member firms.
Our global Purpose is making an impact that matters. At Deloitte Canada, that translates into building a better future by accelerating and expanding access to knowledge. We believe we can achieve this Purpose by living our shared values to lead the way, serve with integrity, take care of each other, foster inclusion, and collaborate for measurable impact.
To learn more about Deloitte's approximately 330,000 professionals, over 11,000 of whom are part of the Canadian firm, please connect with us on LinkedIn, Twitter, Instagram, or Facebook.
SOURCE  Scotiabank
 View original content to download multimedia: http://www.newswire.ca/en/releases/archive/March2022/24/c5679.html
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: DATA ANALYTICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); PRESS RELEASES (90%); STOCK EXCHANGES (89%); PUBLIC COMPANIES (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CUSTOMER RELATIONS (77%); MACHINE LEARNING (77%); EXECUTIVES (74%); SECURITIES TRADING (60%); Scotiabank-EthicsAssi (%)
Company:  DELOITTE LLP (92%);  BANK OF NOVA SCOTIA (92%);  TMX GROUP LTD (59%);  NEW YORK STOCK EXCHANGE LLC (50%)
Ticker: BNS (TSX) (92%); BNS (NYSE) (92%); X (TSX) (59%); TXQ (FRA) (59%)
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (92%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (92%); NAICS522110 COMMERCIAL BANKING (92%); SIC6029 COMMERCIAL BANKS, NEC (92%); NAICS523210 SECURITIES & COMMODITY EXCHANGES (59%); SIC6231 SECURITIES & COMMODITY EXCHANGES (59%); DATA ANALYTICS (91%); ARTIFICIAL INTELLIGENCE (90%); BANKING & FINANCE (89%); COMMERCIAL BANKING (89%); STOCK EXCHANGES (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INVESTMENT BANKING (78%); MERCHANT BANKING (78%); FINANCIAL PLANNING (77%); MACHINE LEARNING (77%); RETAIL BANKING (73%); PRIVATE BANKING (72%); WEALTH MANAGEMENT (63%); SECURITIES TRADING (60%)
Geographic: TORONTO, ON, CANADA (89%); ONTARIO, CANADA (74%); CANADA (94%)
Load-Date: March 24, 2022","TORONTO, March 24, 2022 /CNW/ -Scotiabank announced today the launch of Ethics Assistant, in collaboration with Deloitte Canada, to further enhance the Bank's investments in data and analytics to derive customer insights that are more accurate, personalized, and free of bias. Ethics Assistant also ensures that data collected by Scotiabank is leveraged in a manner that reinforces the importance of transparency and trust in how customer information is accessed and used.
""As we continue to unlock the potential of data and analytics, Ethics Assistant helps us advance how we responsibly collect, share, store, and use data,"" says Grace Lee, Senior Vice President and Chief Data & Analytics Officer, Scotiabank.""This new solution gives us the confidence that the enhancements we are making to develop personalized solutions for our customers are aligned with and strengthen our data ethics practices.""
Using Deloitte's Artificial Intelligence (AI) Impact Assessment tool, Scotiabank was able to successfully build and deploy Ethics Assistant which helps advance responsible AI-based innovation and adoption to benefit and enhance how data is used to deliver value and build trust with the Bank's customers.
""Data ethics and customer trust is a top priority for financial institutions across the globe,"" says Preeti Shivpuri, Trustworthy AI Leader at Deloitte Canada. ""As Deloitte works towards fostering further AI adoption and innovation across Canada, we're thrilled to collaborate with Scotiabank to launch Ethics Assistant to support the responsible design, development, and deployment of AI solutions across the Bank.""
The tool helps practitioners think about ethical considerations early on before AI and machine learning projects are deployedimproving consistency, transparency, and fairness.
""Including ethicalconsiderations early in the design stage of a use case helps us take a proactive approach throughout the development process,"" says Anna Hannem, Director of Data Ethics & Use. ""The result is more ethical, trustworthy use cases which benefit our customers and our businesses.""
Scotiabank plans to scale Ethics Assistant for all new AI and machine learning projects across the Bank this year.
About ScotiabankScotiabank is a leading bank in the Americas. Guided by our purpose: ""for every future"", we help our customers, their families and their communities achieve success through a broad range of advice, products and services, including personal and commercial banking, wealth management and private banking, corporate and investment banking, and capital markets. With a team of approximately 90,000 employees and assets of approximately $1.2 trillion (as at January 31, 2022), Scotiabank trades on the Toronto Stock Exchange (TSX: BNS) and New York Stock Exchange (NYSE: BNS). For more information, please visit http://www.scotiabank.comand follow us on Twitter @ScotiabankViews.
About DeloitteDeloitte provides audit and assurance, consulting, financial advisory, risk advisory, tax, and related services to public and private clients spanning multiple industries. Deloitte servesfour out of five Fortune Global 500® companies through a globally connected network of member firms in more than 150 countries and territories bringing world-class capabilities, insights, and service to address clients' most complex business challenges. Deloitte LLP, an Ontario limited liability partnership, is the Canadian member firm of Deloitte Touche Tohmatsu Limited. Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee, and its network of member firms, each of which is a legally separate and independent entity. Please see www.deloitte.com/aboutfor a detailed description of the legal structure of Deloitte Touche Tohmatsu Limited and its member firms.
Our global Purpose is making an impact that matters. At Deloitte Canada, that translates into building a better future by accelerating and expanding access to knowledge. We believe we can achieve this Purpose by living our shared values to lead the way, serve with integrity, take care of each other, foster inclusion, and collaborate for measurable impact.
To learn more about Deloitte's approximately 330,000 professionals, over 11,000 of whom are part of the Canadian firm, please connect with us on LinkedIn, Twitter, Instagram, or Facebook.
SOURCE  Scotiabank
 View original content to download multimedia: http://www.newswire.ca/en/releases/archive/March2022/24/c5679.html
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: DATA ANALYTICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); PRESS RELEASES (90%); STOCK EXCHANGES (89%); PUBLIC COMPANIES (85%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CUSTOMER RELATIONS (77%); MACHINE LEARNING (77%); EXECUTIVES (74%); SECURITIES TRADING (60%); Scotiabank-EthicsAssi (%)
Company:  DELOITTE LLP (92%);  BANK OF NOVA SCOTIA (92%);  TMX GROUP LTD (59%);  NEW YORK STOCK EXCHANGE LLC (50%)
Ticker: BNS (TSX) (92%); BNS (NYSE) (92%); X (TSX) (59%); TXQ (FRA) (59%)
Industry: NAICS541211 OFFICES OF CERTIFIED PUBLIC ACCOUNTANTS (92%); SIC8721 ACCOUNTING, AUDITING, & BOOKKEEPING SERVICES (92%); NAICS522110 COMMERCIAL BANKING (92%); SIC6029 COMMERCIAL BANKS, NEC (92%); NAICS523210 SECURITIES & COMMODITY EXCHANGES (59%); SIC6231 SECURITIES & COMMODITY EXCHANGES (59%); DATA ANALYTICS (91%); ARTIFICIAL INTELLIGENCE (90%); BANKING & FINANCE (89%); COMMERCIAL BANKING (89%); STOCK EXCHANGES (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INVESTMENT BANKING (78%); MERCHANT BANKING (78%); FINANCIAL PLANNING (77%); MACHINE LEARNING (77%); RETAIL BANKING (73%); PRIVATE BANKING (72%); WEALTH MANAGEMENT (63%); SECURITIES TRADING (60%)
Geographic: TORONTO, ON, CANADA (89%); ONTARIO, CANADA (74%); CANADA (94%)
Load-Date: March 24, 2022",positive,0.6718444228172302,balanced/neutral,"['bias', 'fairness', 'transparency', 'access']",['fairness'],['audit'],['machine learning'],4,1,1,1
2021,Unknown Title,"Byline: States News Service
Dateline: BEIJING, China 
Body
The following information was released by the Ministry of Foreign Affairs of the People's Republic of China:
I. As the most representative disruptive technology, artificial intelligence""(AI),""while providing enormous potential development benefits to human society, has also brought uncertainty that may give rise to multiple global challenges and even fundamental ethical concerns. At the ethical level, there are widespread concerns in the international community that, if left unregulated, the misuse and abuse of AI technologies may undermine human dignity and equality, violate human rights and fundamental freedoms, exacerbate discrimination and prejudice, disrupt existing legal systems, and have far-reaching impacts on government administration,building of national defense, social stability and even global governance.
China is committed to building a community with a shared future for mankind in the domain of AI,""advocating a people-centered approach and the principle of AI for good. China finds it important to enhance the understanding of all countries on AI ethics, and ensure that AI is safe, reliable, controllable, and capable of better empowering global sustainable development and enhancing the common well-being of all mankind. To this end, China calls on all parties to uphold the principles of extensive consultation, joint contribution and shared benefits, and advance international AI ethical governance.
II. In December 2021, China released the""Position Paper of""the Peoples' Republic of China on Regulating Military Applications of Artificial Intelligence (AI), calling on parties to""observe national or regional ethical norms for AI. In this connection, China, based on its own policies and practices and""with reference to useful international experience, makes the following points in the aspects of regulation, research and development, utilization and international cooperation.
(1) Regulation
Governments should give priority to ethics, establish and improve rules, norms and accountability mechanisms for AI ethics, clarify responsibilities and power boundaries of AI-related entities, fully respect and protect the legitimate rights and interests of all groups, and respond to relevant ethical concerns at home and abroad in a timely manner.
Governments should place emphasis on research on fundamental theoretical issues regarding AI ethics and laws, gradually put in place and improve AI ethical norms, laws, regulations, and policies, formulate guidelines on AI ethics, establish review and regulation mechanisms for ethics in science and technology, and strengthen evaluation and management capacity for AI security.
Governments should bear in mind worst-case scenarios and enhance risk awareness, better identify potential ethical risks that AI technologies may entail, gradually establish an effective early warning mechanism, apply agile governance and tiered and categorized management, and continuously improve risk management, control and settlement capacity.
Governments should, in light of their own stage of AI development as well as social and cultural characteristics, and in""accordance with the new features of scientific and technological""innovation, gradually establish AI ethical systems suited to their national conditions, and improve AI ethical governance mechanisms featuring wide participation and cooperative governance.
(2) Research and Development (RandD)
Governments should require RandD entities to strengthen self-discipline, voluntarily incorporate ethics into the whole process of AI RandD, avoid premature use of technologies that may cause serious consequences, and ensure that AI is always under the control of humans.
Governments should require RandD entities to strive for algorithm security and controllability throughout the AI RandD process, improve transparency, explainability and reliability in the stages of algorithm design, implementation, application, etc., and gradually make AI verifiable, regulatable, traceable, predictable and trustworthy.
Governments should require RandD entities to strive for better""data quality during AI RandD, strictly abide by data security regulations, ethics and relevant laws and standards in the phases of data collection, storage, utilization, etc., and improve the completeness, timeliness, consistency, normalization and accuracy of data.
Governments should require RandD entities to strengthen ethics review of data collection and algorithm development, fully consider diversified demands, avoid potential data and algorithms bias, and strive to achieve the universality, fairness and non-discrimination of AI systems.
(3) Utilization
Governments should prohibit using AI technologies and relevant applications which run counter to laws, regulations, ethics and standards, strengthen quality monitoring and evaluations on the use of AI products and services, and formulate emergency mechanisms and compensation measures.
Governments should strengthen pre-use study and evaluations""of AI products and services, and promote institutionalized training on AI ethics. Relevant personnel should fully understand the functions, features, limitations and potential risks""and consequences of AI technologies, and acquire necessary""professional expertise and skills.
Governments should safeguard individual privacy and data""security of Al products and services, strictly follow international""or regional norms for handling of personal information, improve""the mechanism for revoking personal data authorization, and oppose illegal collection and utilization of personal information.
Governments should attach importance to public education on AI ethics, guarantee the public's rights of knowledge and meaningful participation, give full play to the roles of scientific and technological communities, guide all sectors of society to comply with AI ethical rules and norms, and raise AI ethical awareness.
(4) International cooperation
Governments should encourage transnational, interdisciplinary, and cross-cultural exchanges and cooperation, ensure that the benefits of AI technologies are shared by all countries, promote joint participation of countries in international discussions and rules-making on major issues regarding AI ethics, and oppose the building of exclusive groups and malicious obstruction of other countries' technological development.
Governments should strengthen the regulation of AI ethics for""international cooperative research activities. Relevant science and technology activities should comply with the requirements of AI ethics management in the countries where the cooperating parties are located, and pass the AI ethics review accordingly.
China calls on the international community to reach international agreement on the issue of AI ethics on the basis of""wide participation, and work to formulate widely accepted international AI governance framework, standards and norms while fully respecting the principles and practices of different countries' AI governance.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DISRUPTIVE INNOVATION (90%); EMERGING TECHNOLOGY (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); NEGATIVE SOCIETAL NEWS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); NEGATIVE NEWS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); STATE DEPARTMENTS & FOREIGN SERVICES (89%); RESEARCH & DEVELOPMENT (78%); DEFENSE & MILITARY POLICY (77%); INTERNATIONAL RELATIONS (77%); DISCRIMINATION (76%); HUMAN RIGHTS VIOLATIONS (76%); LAW & LEGAL SYSTEM (75%); SUSTAINABLE DEVELOPMENT (72%); RISK MANAGEMENT (63%); SUSTAINABILITY (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); DEFENSE & MILITARY POLICY (77%); SUSTAINABLE DEVELOPMENT (72%); RISK MANAGEMENT (63%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (79%); CHINA (95%); TAIWAN (93%)
Load-Date: November 17, 2022","The following information was released by the Ministry of Foreign Affairs of the People's Republic of China:
I. As the most representative disruptive technology, artificial intelligence""(AI),""while providing enormous potential development benefits to human society, has also brought uncertainty that may give rise to multiple global challenges and even fundamental ethical concerns. At the ethical level, there are widespread concerns in the international community that, if left unregulated, the misuse and abuse of AI technologies may undermine human dignity and equality, violate human rights and fundamental freedoms, exacerbate discrimination and prejudice, disrupt existing legal systems, and have far-reaching impacts on government administration,building of national defense, social stability and even global governance.
China is committed to building a community with a shared future for mankind in the domain of AI,""advocating a people-centered approach and the principle of AI for good. China finds it important to enhance the understanding of all countries on AI ethics, and ensure that AI is safe, reliable, controllable, and capable of better empowering global sustainable development and enhancing the common well-being of all mankind. To this end, China calls on all parties to uphold the principles of extensive consultation, joint contribution and shared benefits, and advance international AI ethical governance.
II. In December 2021, China released the""Position Paper of""the Peoples' Republic of China on Regulating Military Applications of Artificial Intelligence (AI), calling on parties to""observe national or regional ethical norms for AI. In this connection, China, based on its own policies and practices and""with reference to useful international experience, makes the following points in the aspects of regulation, research and development, utilization and international cooperation.
(1) Regulation
Governments should give priority to ethics, establish and improve rules, norms and accountability mechanisms for AI ethics, clarify responsibilities and power boundaries of AI-related entities, fully respect and protect the legitimate rights and interests of all groups, and respond to relevant ethical concerns at home and abroad in a timely manner.
Governments should place emphasis on research on fundamental theoretical issues regarding AI ethics and laws, gradually put in place and improve AI ethical norms, laws, regulations, and policies, formulate guidelines on AI ethics, establish review and regulation mechanisms for ethics in science and technology, and strengthen evaluation and management capacity for AI security.
Governments should bear in mind worst-case scenarios and enhance risk awareness, better identify potential ethical risks that AI technologies may entail, gradually establish an effective early warning mechanism, apply agile governance and tiered and categorized management, and continuously improve risk management, control and settlement capacity.
Governments should, in light of their own stage of AI development as well as social and cultural characteristics, and in""accordance with the new features of scientific and technological""innovation, gradually establish AI ethical systems suited to their national conditions, and improve AI ethical governance mechanisms featuring wide participation and cooperative governance.
(2) Research and Development (RandD)
Governments should require RandD entities to strengthen self-discipline, voluntarily incorporate ethics into the whole process of AI RandD, avoid premature use of technologies that may cause serious consequences, and ensure that AI is always under the control of humans.
Governments should require RandD entities to strive for algorithm security and controllability throughout the AI RandD process, improve transparency, explainability and reliability in the stages of algorithm design, implementation, application, etc., and gradually make AI verifiable, regulatable, traceable, predictable and trustworthy.
Governments should require RandD entities to strive for better""data quality during AI RandD, strictly abide by data security regulations, ethics and relevant laws and standards in the phases of data collection, storage, utilization, etc., and improve the completeness, timeliness, consistency, normalization and accuracy of data.
Governments should require RandD entities to strengthen ethics review of data collection and algorithm development, fully consider diversified demands, avoid potential data and algorithms bias, and strive to achieve the universality, fairness and non-discrimination of AI systems.
(3) Utilization
Governments should prohibit using AI technologies and relevant applications which run counter to laws, regulations, ethics and standards, strengthen quality monitoring and evaluations on the use of AI products and services, and formulate emergency mechanisms and compensation measures.
Governments should strengthen pre-use study and evaluations""of AI products and services, and promote institutionalized training on AI ethics. Relevant personnel should fully understand the functions, features, limitations and potential risks""and consequences of AI technologies, and acquire necessary""professional expertise and skills.
Governments should safeguard individual privacy and data""security of Al products and services, strictly follow international""or regional norms for handling of personal information, improve""the mechanism for revoking personal data authorization, and oppose illegal collection and utilization of personal information.
Governments should attach importance to public education on AI ethics, guarantee the public's rights of knowledge and meaningful participation, give full play to the roles of scientific and technological communities, guide all sectors of society to comply with AI ethical rules and norms, and raise AI ethical awareness.
(4) International cooperation
Governments should encourage transnational, interdisciplinary, and cross-cultural exchanges and cooperation, ensure that the benefits of AI technologies are shared by all countries, promote joint participation of countries in international discussions and rules-making on major issues regarding AI ethics, and oppose the building of exclusive groups and malicious obstruction of other countries' technological development.
Governments should strengthen the regulation of AI ethics for""international cooperative research activities. Relevant science and technology activities should comply with the requirements of AI ethics management in the countries where the cooperating parties are located, and pass the AI ethics review accordingly.
China calls on the international community to reach international agreement on the issue of AI ethics on the basis of""wide participation, and work to formulate widely accepted international AI governance framework, standards and norms while fully respecting the principles and practices of different countries' AI governance.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); DISRUPTIVE INNOVATION (90%); EMERGING TECHNOLOGY (90%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); NEGATIVE SOCIETAL NEWS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); NEGATIVE NEWS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (89%); STATE DEPARTMENTS & FOREIGN SERVICES (89%); RESEARCH & DEVELOPMENT (78%); DEFENSE & MILITARY POLICY (77%); INTERNATIONAL RELATIONS (77%); DISCRIMINATION (76%); HUMAN RIGHTS VIOLATIONS (76%); LAW & LEGAL SYSTEM (75%); SUSTAINABLE DEVELOPMENT (72%); RISK MANAGEMENT (63%); SUSTAINABILITY (52%)
Industry: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ARTIFICIAL INTELLIGENCE REGULATION & POLICY (89%); DEFENSE & MILITARY POLICY (77%); SUSTAINABLE DEVELOPMENT (72%); RISK MANAGEMENT (63%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (79%); CHINA (95%); TAIWAN (93%)
Load-Date: November 17, 2022",neutral,0.7493470907211304,balanced/neutral,"['privacy', 'bias', 'discrimination', 'fairness', 'transparency', 'explainability', 'accountability', 'security', 'human rights']","['fairness', 'equality', 'dignity']","['regulation', 'policy', 'governance', 'standards', 'guidelines', 'framework', 'law', 'should']",['algorithm'],9,3,8,1
2021,Unknown Title,"Byline: ACCESSWIRE
Body
NEW YORK, NY / ACCESSWIRE / March 8, 2022 / Amina Alsherif founded the nonprofit Data Ethics Consortium for Security (DECS) to respond to a growing problem in digital security: As artificial intelligence and machine learning become a more prominent component in the world - both for corporations and in national security - how can developers and policy makers ensure that these tools are used safely?
DECS exists to solve that problem, providing expert guidance, advice, and input on the ethical application of artificial intelligence and machine learning. Rather than serving as a purely research or educational institution, DECS is led by practitioners, for practitioners.
DECS has already created frameworks and technical solutions to implement ethical artificial intelligence in both the operational and policy making space, and Alsherif recently shared research findings with members of the association.
""It outlines how a company can create an ethical machine learning training data set collection plan,"" Alsherif explains. ""What it boils down to is data privacy, how companies working in the national security space, corporate security, and law enforcement can be more conscious about handling issues of data privacy.""
One of the major points of emphasis for DECS is to become a proactive solution for ethical uses of AI. Rather than reacting to policy after the fact, DECS strives to engage policy makers to help shape policy from the outset - allowing companies to manage data privacy more effectively in the long term. Since they help shape policy so companies of all shapes and sizes have some level of certainty or consistency about coming rules or guidelines, in return, these companies have the confidence to accelerate innovation or product development.
As part of that mission, DECS produces policy documents targeted towards Capitol Hill and other foreign governments for implementation. Working with startups in the national security, law enforcement, and corporate security spaces, DECS also delivers technical solutions that ensure that ethical AI practices are in place.
Becky Fair, the CEO of Thresher.ai, a founding member of DECS, said:
""Thresher decided to join DECS because it offered a community where we could have the informed, relevant, and sometimes hard conversations that folks need to be having about ethics and AI in the national security space. Our clients expect us to have done this thinking and incorporate it into our approach to AI.""
The CEO of Trueface, Shaun Moore, shared:
""Trueface decided to join DECS because we wanted to pioneer the ethics conversation with like minded organizations. We firmly believe that ethics needs to be a core tenant of all AI businesses and by working with the group at DECS we can make more informed decisions and solve larger problems.""
Hannah Mezei the Innovation Ecosystem Lead at CalypsoAI stated:
""CalypsoAI joined DECS because ethics is at the heart of our mission to build trust in artificial intelligence (AI) systems. Without prioritizing ethics, stakeholders across the national security and commercial sector communities cannot have confidence that their AI models will align with the most fundamental U.S. values or perform as intended. As a result, CalypsoAI makes every business decision with a commitment to promoting data ethics through model explainability, auditability, and standardization, which enable us to harness the benefits of AI as it is democratized.""
Chief of Staff at ZeroEyes, Kieran Carroll, shared:
""ZeroEyes is excited to participate in DECS as we feel that their mission aligns closely with the values of privacy rights, anti-bias, and ethical AI implementation that our company practices every day. Educating lawmakers, policymakers, and operators on topics like inherent bias, data integrity, and compromised methodologies is extremely important to both the company and the industry at large.""
Pablo Gomez at Clarifai said:
""Clarifai joined DECS because we strongly believe in the importance of ethics in the national security space and its broader impact on future policy direction. Policy has always lagged technology advances, and it is important that industry and government stay at the forefront of ensuring ethical standards across the AI landscape. Clarifai takes data ethics very seriously, as things like model explainability and other ethics topics determine the success of our business. We are excited to join DECS in furthering our commitment to ethical industry standards.""
At a recent virtual seminar, Alsherif discussed general ethical data collection governance principles with attendees - including three sets of principles within that general overview. The first, responsible AI collection principles, require that data collection be responsible, equitable, traceable, reliable, and governable.
Those principles have been set by the Department of Defense, Alsherif says, ""and we have declared that we will adopt them as our responsible AI collection principles.""
Another principle is to not store data that is not needed, a principle that Alsherif admits can be difficult to achieve due to the shifting nature of startups, and the ever-evolving need of diverse data sources for machine learning problems.
""This is a pretty complicated step,"" Alsherif says, ""Requirements and the nature of the business changes what feels like weekly, so being able to project a year or two into the future is very difficult.""
To adapt to those challenges, Alsherif says there are steps companies can take to keep data sets safe.
""The guidance we have given is, if there is a possibility of needing that data set in the future, go ahead and go through steps to store that data responsibly,"" Alsherif says. ""As opposed to unnecessarily purging that data set.""
One of the most important ways that a company can practice ethical data collection is to create data exploration reports, which provide a breakdown of how the data is being used.
""A lot of customers will hand us data sets to perform machine learning algorithmic development on, and they don't exactly know what is contained in the data set,"" Alsherif says, ""So a data set exploration is required to let them know, hey, here are the features that are in your data set.""
In addition to showing customers the data that is being used, Alsherif says companies can help their customers better understand the data cleansing services that they are performing. It is not only an ethical issue, but an opportunity to educate clients.
""Those data points are important to communicate back to the customer if you are performing services,"" Alsherif says.
As DECS continues to grow its membership, Alsherif is confident that startups working in the national security, corporate security and law enforcement space will be better prepared to proactively use ethical data collection principles to help serve their customers.
""We are finding that curating data sets and maintaining them is central to creating value in an early-stage startup that is in the national security space,"" Alsherif says, ""So having those unique aspects of being a startup and in the national security space need to be accounted for.""
DECS is dedicated to helping startups address ethical data practices in the national security, law enforcement and corporate security spaces. Learn more about DECS by following them on LinkedIn.
DECS- Looking Ahead
The team at DECS is looking for more policy maker engagement to share research findings to better inform policy related to data and AI ethics. They are also expanding to include more startups from NATO countries that operate in the law enforcement, corporate security, and national security space. If you or your company fall under these categories and are interested, please email contact@decs.org 
CONTACT:
Company Name: Data Ethics Consortium for Security
Contact Person: Amina Alsherif
Website Links:
https://www.decs.org 
http://www.linkedin.com/showcase/the-data-ethics-consortium-/
Email: contact@decs.org 
SOURCE: Data Ethics Consortium for Security
View source version on accesswire.com: 
https://www.accesswire.com/692022/Data-Ethics-Consortium-for-Security-DECS-Guides-Startups-and-Policy-Makers-on-Ethical-AI-Practices
Classification
Language: ENGLISH
Publication-Type: Wire
Journal Code: 1458
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); NATIONAL SECURITY (90%); PUBLIC POLICY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); LAW ENFORCEMENT (78%); NONPROFIT ORGANIZATIONS (78%); PRODUCT DEVELOPMENT (78%); PRODUCT INNOVATION (77%); EXECUTIVES (72%); RESEARCH REPORTS (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (90%); MACHINE LEARNING (90%)
Geographic: NEW YORK, NY, USA (59%); NEW YORK, USA (74%)
Load-Date: March 8, 2022","NEW YORK, NY / ACCESSWIRE / March 8, 2022 / Amina Alsherif founded the nonprofit Data Ethics Consortium for Security (DECS) to respond to a growing problem in digital security: As artificial intelligence and machine learning become a more prominent component in the world - both for corporations and in national security - how can developers and policy makers ensure that these tools are used safely?
DECS exists to solve that problem, providing expert guidance, advice, and input on the ethical application of artificial intelligence and machine learning. Rather than serving as a purely research or educational institution, DECS is led by practitioners, for practitioners.
DECS has already created frameworks and technical solutions to implement ethical artificial intelligence in both the operational and policy making space, and Alsherif recently shared research findings with members of the association.
""It outlines how a company can create an ethical machine learning training data set collection plan,"" Alsherif explains. ""What it boils down to is data privacy, how companies working in the national security space, corporate security, and law enforcement can be more conscious about handling issues of data privacy.""
One of the major points of emphasis for DECS is to become a proactive solution for ethical uses of AI. Rather than reacting to policy after the fact, DECS strives to engage policy makers to help shape policy from the outset - allowing companies to manage data privacy more effectively in the long term. Since they help shape policy so companies of all shapes and sizes have some level of certainty or consistency about coming rules or guidelines, in return, these companies have the confidence to accelerate innovation or product development.
As part of that mission, DECS produces policy documents targeted towards Capitol Hill and other foreign governments for implementation. Working with startups in the national security, law enforcement, and corporate security spaces, DECS also delivers technical solutions that ensure that ethical AI practices are in place.
Becky Fair, the CEO of Thresher.ai, a founding member of DECS, said:
""Thresher decided to join DECS because it offered a community where we could have the informed, relevant, and sometimes hard conversations that folks need to be having about ethics and AI in the national security space. Our clients expect us to have done this thinking and incorporate it into our approach to AI.""
The CEO of Trueface, Shaun Moore, shared:
""Trueface decided to join DECS because we wanted to pioneer the ethics conversation with like minded organizations. We firmly believe that ethics needs to be a core tenant of all AI businesses and by working with the group at DECS we can make more informed decisions and solve larger problems.""
Hannah Mezei the Innovation Ecosystem Lead at CalypsoAI stated:
""CalypsoAI joined DECS because ethics is at the heart of our mission to build trust in artificial intelligence (AI) systems. Without prioritizing ethics, stakeholders across the national security and commercial sector communities cannot have confidence that their AI models will align with the most fundamental U.S. values or perform as intended. As a result, CalypsoAI makes every business decision with a commitment to promoting data ethics through model explainability, auditability, and standardization, which enable us to harness the benefits of AI as it is democratized.""
Chief of Staff at ZeroEyes, Kieran Carroll, shared:
""ZeroEyes is excited to participate in DECS as we feel that their mission aligns closely with the values of privacy rights, anti-bias, and ethical AI implementation that our company practices every day. Educating lawmakers, policymakers, and operators on topics like inherent bias, data integrity, and compromised methodologies is extremely important to both the company and the industry at large.""
Pablo Gomez at Clarifai said:
""Clarifai joined DECS because we strongly believe in the importance of ethics in the national security space and its broader impact on future policy direction. Policy has always lagged technology advances, and it is important that industry and government stay at the forefront of ensuring ethical standards across the AI landscape. Clarifai takes data ethics very seriously, as things like model explainability and other ethics topics determine the success of our business. We are excited to join DECS in furthering our commitment to ethical industry standards.""
At a recent virtual seminar, Alsherif discussed general ethical data collection governance principles with attendees - including three sets of principles within that general overview. The first, responsible AI collection principles, require that data collection be responsible, equitable, traceable, reliable, and governable.
Those principles have been set by the Department of Defense, Alsherif says, ""and we have declared that we will adopt them as our responsible AI collection principles.""
Another principle is to not store data that is not needed, a principle that Alsherif admits can be difficult to achieve due to the shifting nature of startups, and the ever-evolving need of diverse data sources for machine learning problems.
""This is a pretty complicated step,"" Alsherif says, ""Requirements and the nature of the business changes what feels like weekly, so being able to project a year or two into the future is very difficult.""
To adapt to those challenges, Alsherif says there are steps companies can take to keep data sets safe.
""The guidance we have given is, if there is a possibility of needing that data set in the future, go ahead and go through steps to store that data responsibly,"" Alsherif says. ""As opposed to unnecessarily purging that data set.""
One of the most important ways that a company can practice ethical data collection is to create data exploration reports, which provide a breakdown of how the data is being used.
""A lot of customers will hand us data sets to perform machine learning algorithmic development on, and they don't exactly know what is contained in the data set,"" Alsherif says, ""So a data set exploration is required to let them know, hey, here are the features that are in your data set.""
In addition to showing customers the data that is being used, Alsherif says companies can help their customers better understand the data cleansing services that they are performing. It is not only an ethical issue, but an opportunity to educate clients.
""Those data points are important to communicate back to the customer if you are performing services,"" Alsherif says.
As DECS continues to grow its membership, Alsherif is confident that startups working in the national security, corporate security and law enforcement space will be better prepared to proactively use ethical data collection principles to help serve their customers.
""We are finding that curating data sets and maintaining them is central to creating value in an early-stage startup that is in the national security space,"" Alsherif says, ""So having those unique aspects of being a startup and in the national security space need to be accounted for.""
DECS is dedicated to helping startups address ethical data practices in the national security, law enforcement and corporate security spaces. Learn more about DECS by following them on LinkedIn.
DECS- Looking Ahead
The team at DECS is looking for more policy maker engagement to share research findings to better inform policy related to data and AI ethics. They are also expanding to include more startups from NATO countries that operate in the law enforcement, corporate security, and national security space. If you or your company fall under these categories and are interested, please email contact@decs.org 
CONTACT:
Company Name: Data Ethics Consortium for Security
Contact Person: Amina Alsherif
Website Links:
https://www.decs.org 
http://www.linkedin.com/showcase/the-data-ethics-consortium-/
Email: contact@decs.org 
SOURCE: Data Ethics Consortium for Security
View source version on accesswire.com: 
https://www.accesswire.com/692022/Data-Ethics-Consortium-for-Security-DECS-Guides-Startups-and-Policy-Makers-on-Ethical-AI-Practices
Classification
Language: ENGLISH
Publication-Type: Wire
Journal Code: 1458
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (90%); NATIONAL SECURITY (90%); PUBLIC POLICY (90%); ASSOCIATIONS & ORGANIZATIONS (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); LAW ENFORCEMENT (78%); NONPROFIT ORGANIZATIONS (78%); PRODUCT DEVELOPMENT (78%); PRODUCT INNOVATION (77%); EXECUTIVES (72%); RESEARCH REPORTS (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (90%); MACHINE LEARNING (90%)
Geographic: NEW YORK, NY, USA (59%); NEW YORK, USA (74%)
Load-Date: March 8, 2022",neutral,0.8560607433319092,balanced/neutral,"['privacy', 'bias', 'explainability', 'security']",[],"['policy', 'governance', 'standards', 'guidelines', 'law', 'need to']",['machine learning'],4,0,6,1
2021,Unknown Title,"Body
2022 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Math Daily News -- New research on Science is the subject of a report. According to news originating from Zurich, Switzerland, by NewsRx correspondents, research stated, ""Artificial intelligence (AI) systems are quickly gaining ground in healthcare and clinical decision-making. However, it is still unclear in what way AI can or should support decision-making that is based on incapacitated patients' values and goals of care, which often requires input from clinicians and loved ones."" 
 Our news journalists obtained a quote from the research from the Swiss Federal Institute of Technology Zurich (ETH), ""Although the use of algorithms to predict patients' most likely preferred treatment has been discussed in the medical ethics literature, no example has been realised in clinical practice. This is due, arguably, to the lack of a structured approach to the epistemological, ethical and pragmatic challenges arising from the design and use of such algorithms. The present paper offers a new perspective on the problem by suggesting that preference predicting AIs be viewed as sociotechnical systems with distinctive life-cycles."" 
 According to the news editors, the research concluded: ""We explore how both known and novel challenges map onto the different stages of development, highlighting interdisciplinary strategies for their resolution."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethics of the algorithmic prediction of goal of care preferences: from theory to practice. Journal of Medical Ethics, 2022. Journal of Medical Ethics can be contacted at: Bmj Publishing Group, British Med Assoc House, Tavistock Square, London WC1H 9JR, England. (BMJ Publishing Group - group.bmj.com/; Journal of Medical Ethics - jme.bmj.com/) 
 The news correspondents report that additional information may be obtained from Andrea Ferrario, Swiss Federal Institute of Technology Zurich (ETH), Zurich, Switzerland. Additional authors for this research include Sophie Gloeckler and Nikola Biller-Andorno. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1136/jme-2022-108371. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher's contact information for the Journal of Medical Ethics is: Bmj Publishing Group, British Med Assoc House, Tavistock Square, London WC1H 9JR, England. 
 Keywords for this news article include: Zurich, Switzerland, Europe, Algorithms, Science. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (89%); CLINICAL DECISION SUPPORT (78%); JOURNALISM (78%); WRITERS (78%); NOVELS & SHORT STORIES (73%); Zurich;Switzerland;Europe;Algorithms;Science (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); PUBLISHING (89%); BOOK PUBLISHING (88%); CLINICAL DECISION SUPPORT (78%); WRITERS (78%)
Geographic: ZURICH (92%); LONDON, ENGLAND (68%); SWITZERLAND (94%); ENGLAND (73%); EUROPE (73%)
Load-Date: November 22, 2022","2022 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Math Daily News -- New research on Science is the subject of a report. According to news originating from Zurich, Switzerland, by NewsRx correspondents, research stated, ""Artificial intelligence (AI) systems are quickly gaining ground in healthcare and clinical decision-making. However, it is still unclear in what way AI can or should support decision-making that is based on incapacitated patients' values and goals of care, which often requires input from clinicians and loved ones."" 
 Our news journalists obtained a quote from the research from the Swiss Federal Institute of Technology Zurich (ETH), ""Although the use of algorithms to predict patients' most likely preferred treatment has been discussed in the medical ethics literature, no example has been realised in clinical practice. This is due, arguably, to the lack of a structured approach to the epistemological, ethical and pragmatic challenges arising from the design and use of such algorithms. The present paper offers a new perspective on the problem by suggesting that preference predicting AIs be viewed as sociotechnical systems with distinctive life-cycles."" 
 According to the news editors, the research concluded: ""We explore how both known and novel challenges map onto the different stages of development, highlighting interdisciplinary strategies for their resolution."" 
 This research has been peer-reviewed. 
 For more information on this research see: Ethics of the algorithmic prediction of goal of care preferences: from theory to practice. Journal of Medical Ethics, 2022. Journal of Medical Ethics can be contacted at: Bmj Publishing Group, British Med Assoc House, Tavistock Square, London WC1H 9JR, England. (BMJ Publishing Group - group.bmj.com/; Journal of Medical Ethics - jme.bmj.com/) 
 The news correspondents report that additional information may be obtained from Andrea Ferrario, Swiss Federal Institute of Technology Zurich (ETH), Zurich, Switzerland. Additional authors for this research include Sophie Gloeckler and Nikola Biller-Andorno. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1136/jme-2022-108371. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher's contact information for the Journal of Medical Ethics is: Bmj Publishing Group, British Med Assoc House, Tavistock Square, London WC1H 9JR, England. 
 Keywords for this news article include: Zurich, Switzerland, Europe, Algorithms, Science. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EXPERIMENTATION & RESEARCH (90%); HUMAN SUBJECTS (90%); MEDICAL ETHICS (89%); CLINICAL DECISION SUPPORT (78%); JOURNALISM (78%); WRITERS (78%); NOVELS & SHORT STORIES (73%); Zurich;Switzerland;Europe;Algorithms;Science (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); PUBLISHING (89%); BOOK PUBLISHING (88%); CLINICAL DECISION SUPPORT (78%); WRITERS (78%)
Geographic: ZURICH (92%); LONDON, ENGLAND (68%); SWITZERLAND (94%); ENGLAND (73%); EUROPE (73%)
Load-Date: November 22, 2022",neutral,0.8668876886367798,balanced/neutral,[],[],['should'],[],0,0,1,0
2021,Unknown Title,"Byline: Express Computer
Body
By Hasit Trivedi, CTO Digital Technologies & Global Head - AI, Tech Mahindra
With great potential comes great accountability and Artificial Intelligence (AI) is no different. The advancement of AI is creating new openings to enhance the lives of people around the world, bringing far-reaching changes to how we interact, do our work, understand our world, and pretty much everything we do. AI can bring in sustainable and equitable economic growth and tackle global challenges at a scale that has proven difficult to tackle till recently, helping businesses to reach a greater height quickly and efficiently. However, if not designed and governed properly, AI can go awry, it can increase societal bias, damage customer relationships for businesses, and erode finely balanced institutions that we have built over our history.
Undoubtedly, AI and Machine Learning (ML) solutions are transforming several industries' operational, functional, and strategic landscapes. In the enterprise context, AI systems have the potential to improve productivity and open up new avenues of revenue by building insights from data that define business and customer interaction patterns. On the flip side, perceived unfair treatment by the AI and ML model can lead to trust issues, brand value erosion, talent retention, and acquisition, and missed business opportunities-all directly impacting the top line.
Decoding ethics, bias, and fairness
As organisations arescaling up their usage of AIto obtain higher business outcomes, concerns around AI ethics are also becoming significant.
While AI can be a powerful tool to help companies make decisions, it also has the potential to be harmful if not carefully managed. AI is more about how decisions are made. If we want our employees and customers to feel safe and valued, then we need to make sure that the systems we use for decision-making have been thoughtfully designed from the ground up.
The goal of responsible AI is to design and deploy AI with good intentions to empower employees and businesses and fairly impact customers and society. This allows companies to generate trust in their products while also scaling their processes with confidence.
AI ethics is associated with a variety of subjects like privacy and surveillance, behaviour manipulation, accountability of autonomous systems, robotic rights, etc. Organisations should begin with a deep understanding of the ethical problems that they are trying to solve to implement, scale, and maintain effective AI ethical risk mitigation strategies. The first step should consist of learning how to talk about it in concrete and actionable ways.
An example of this could be a person being asked to pay a higher premium based on the predictions made by the model which took into account some of the attributes such as gender and race for making the predictions. Another instance is if an application for a credit card or bank loan does not get approved due to the educational background or race of an applicant, though he/she ticked all criteria which are required to be approved.
There are myriad of such examples. Thus, organisations must choose the right data sampling strategy based on predictable discrimination issues in the ML model. Proper fairness metrics must be implemented at the testing phase to weed out fairness-related issues before the ML model is live. Moreover, a live model has to be continuously assessed for fairness as a part of the overall performance monitoring.
Building an AI Ethics Framework from a people, process, and technology standpoint
Ethical AI and ML fairness are still very new and evolving concepts. Given the importance of ethics in AI, companies are now creating an ethics officer role tasked with ensuring compliance at all levels - people, processes, and technology. 
At the people level, awareness of AI ethical practices, the possibility of injecting bias through the data science lifecycle, and the potential business impact of bias and fairness are necessary. Establishing courses to train data engineers, data scientists, ML modelers, and operations personnel are essential.
Ethical practices at the process level include establishing an end-to-end Data Science Lifecycle and proper governance. This should encompass information architecture that considers the necessary bias-related checks on the input data and AI fairness algorithmic design principles. The data and delivery process should include clear guidelines for diversity requirements in data, choosing fairness measures, coverage of model user profiles, identification of advantaged and disadvantaged groups, and data sampling to check bias and fairness. Further, establishing end-to-end traceability and accountability is an essential foundation for auditing, tracing, identifying, and fixing issues as they occur. Operational practices would include processes to flag bias-related issues and steps for manual intervention.
From a technology standpoint, ethical practices include Responsible First approach while designing and developing AI work package. This means the use of right tools and techniques to detect bias and fairness in data to detect bias and fairness in models, to monitor AI performance on an ongoing basis, to explain models, and to mask data wherever applicable. Besides, a structured and comprehensive Responsible AI maturity assessment and human-in-loop approach in critical AI-led inferences and actions are also essential.
Way forward for ethical AI
An ethical approach to AI is an absolute imperative. Knowing that an AI system will do whatever it is assigned to without considering its effects or legality, we must have strict regulations to prevent AI from generating adverse outcomes. In this direction, organisations must make their algorithms more transparent, introduce model milestones that make it possible to understand and correct the output at each stage and study the diversity of biases that occur to eliminate them. Fortunately, the government, private organisations, and institutions are already categorising and identifying safe ways to deploy AI into their daily operations and secure sustainable growth.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); MACHINE LEARNING (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ECONOMIC GROWTH (76%); APPROVALS (74%); CUSTOMER RELATIONS (74%); CUSTOMER SERVICE (74%); SURVEILLANCE (73%); GREEN ECONOMY (71%); RISK MANAGEMENT (71%); BRAND EQUITY (66%); BRANDING (51%)
Company:  AI SYSTEMS (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); GREEN ECONOMY (71%); RISK MANAGEMENT (71%); BRAND EQUITY (66%); CREDIT CARDS (60%); BRANDING (51%)
Load-Date: December 8, 2022","By Hasit Trivedi, CTO Digital Technologies & Global Head - AI, Tech Mahindra
With great potential comes great accountability and Artificial Intelligence (AI) is no different. The advancement of AI is creating new openings to enhance the lives of people around the world, bringing far-reaching changes to how we interact, do our work, understand our world, and pretty much everything we do. AI can bring in sustainable and equitable economic growth and tackle global challenges at a scale that has proven difficult to tackle till recently, helping businesses to reach a greater height quickly and efficiently. However, if not designed and governed properly, AI can go awry, it can increase societal bias, damage customer relationships for businesses, and erode finely balanced institutions that we have built over our history.
Undoubtedly, AI and Machine Learning (ML) solutions are transforming several industries' operational, functional, and strategic landscapes. In the enterprise context, AI systems have the potential to improve productivity and open up new avenues of revenue by building insights from data that define business and customer interaction patterns. On the flip side, perceived unfair treatment by the AI and ML model can lead to trust issues, brand value erosion, talent retention, and acquisition, and missed business opportunities-all directly impacting the top line.
Decoding ethics, bias, and fairness
As organisations arescaling up their usage of AIto obtain higher business outcomes, concerns around AI ethics are also becoming significant.
While AI can be a powerful tool to help companies make decisions, it also has the potential to be harmful if not carefully managed. AI is more about how decisions are made. If we want our employees and customers to feel safe and valued, then we need to make sure that the systems we use for decision-making have been thoughtfully designed from the ground up.
The goal of responsible AI is to design and deploy AI with good intentions to empower employees and businesses and fairly impact customers and society. This allows companies to generate trust in their products while also scaling their processes with confidence.
AI ethics is associated with a variety of subjects like privacy and surveillance, behaviour manipulation, accountability of autonomous systems, robotic rights, etc. Organisations should begin with a deep understanding of the ethical problems that they are trying to solve to implement, scale, and maintain effective AI ethical risk mitigation strategies. The first step should consist of learning how to talk about it in concrete and actionable ways.
An example of this could be a person being asked to pay a higher premium based on the predictions made by the model which took into account some of the attributes such as gender and race for making the predictions. Another instance is if an application for a credit card or bank loan does not get approved due to the educational background or race of an applicant, though he/she ticked all criteria which are required to be approved.
There are myriad of such examples. Thus, organisations must choose the right data sampling strategy based on predictable discrimination issues in the ML model. Proper fairness metrics must be implemented at the testing phase to weed out fairness-related issues before the ML model is live. Moreover, a live model has to be continuously assessed for fairness as a part of the overall performance monitoring.
Building an AI Ethics Framework from a people, process, and technology standpoint
Ethical AI and ML fairness are still very new and evolving concepts. Given the importance of ethics in AI, companies are now creating an ethics officer role tasked with ensuring compliance at all levels - people, processes, and technology. 
At the people level, awareness of AI ethical practices, the possibility of injecting bias through the data science lifecycle, and the potential business impact of bias and fairness are necessary. Establishing courses to train data engineers, data scientists, ML modelers, and operations personnel are essential.
Ethical practices at the process level include establishing an end-to-end Data Science Lifecycle and proper governance. This should encompass information architecture that considers the necessary bias-related checks on the input data and AI fairness algorithmic design principles. The data and delivery process should include clear guidelines for diversity requirements in data, choosing fairness measures, coverage of model user profiles, identification of advantaged and disadvantaged groups, and data sampling to check bias and fairness. Further, establishing end-to-end traceability and accountability is an essential foundation for auditing, tracing, identifying, and fixing issues as they occur. Operational practices would include processes to flag bias-related issues and steps for manual intervention.
From a technology standpoint, ethical practices include Responsible First approach while designing and developing AI work package. This means the use of right tools and techniques to detect bias and fairness in data to detect bias and fairness in models, to monitor AI performance on an ongoing basis, to explain models, and to mask data wherever applicable. Besides, a structured and comprehensive Responsible AI maturity assessment and human-in-loop approach in critical AI-led inferences and actions are also essential.
Way forward for ethical AI
An ethical approach to AI is an absolute imperative. Knowing that an AI system will do whatever it is assigned to without considering its effects or legality, we must have strict regulations to prevent AI from generating adverse outcomes. In this direction, organisations must make their algorithms more transparent, introduce model milestones that make it possible to understand and correct the output at each stage and study the diversity of biases that occur to eliminate them. Fortunately, the government, private organisations, and institutions are already categorising and identifying safe ways to deploy AI into their daily operations and secure sustainable growth.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); ETHICS (90%); MACHINE LEARNING (90%); COMPANY ACTIVITIES & MANAGEMENT (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); ECONOMIC GROWTH (76%); APPROVALS (74%); CUSTOMER RELATIONS (74%); CUSTOMER SERVICE (74%); SURVEILLANCE (73%); GREEN ECONOMY (71%); RISK MANAGEMENT (71%); BRAND EQUITY (66%); BRANDING (51%)
Company:  AI SYSTEMS (56%)
Industry: SIC7372 PREPACKAGED SOFTWARE (56%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); MACHINE LEARNING (90%); GREEN ECONOMY (71%); RISK MANAGEMENT (71%); BRAND EQUITY (66%); CREDIT CARDS (60%); BRANDING (51%)
Load-Date: December 8, 2022",positive,0.5998697280883789,balanced/neutral,"['privacy', 'surveillance', 'bias', 'discrimination', 'fairness', 'accountability', 'manipulation']","['fairness', 'equity']","['governance', 'guidelines', 'framework', 'compliance', 'should', 'must', 'need to']",['machine learning'],7,2,7,1
2021,Unknown Title,"Body
2022 DEC 08 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating in London, United Kingdom, by NewsRx editors, the research stated, ""Many researchers have documented how AI and data driven technologies have the potential to have profound effects on our lives-in ways that make these technologies stand out from those that went before. Around the world, we are seeing a significant growth in interest and investment in AI in healthcare."" 
 Financial supporters for this research include Alan Turing Institute Fellowship, Arts and Humanities Research Council. 
 The news reporters obtained a quote from the research from University College London (UCL), ""This has been coupled with rising concerns about the ethical implications of these technologies and an array of ethical guidelines for the use of AI and data in healthcare has arisen. Nevertheless, the question of if and how AI and data technologies can be ethical remains open to debate. This paper aims to contribute to this debate by considering the wide range of implications that have been attributed to these technologies and asking whether current ethical guidelines take these factors into account. In particular, the paper argues that while current ethics guidelines for AI in healthcare effectively account for the four key issues identified in the ethics literature (transparency; fairness; responsibility and privacy), they have largely neglected wider issues relating to the way in which these technologies shape institutional and social arrangements. This, I argue, has given current ethics guidelines a strong focus on evaluating the impact of these technologies on the individual, while not accounting for the powerful social shaping effects of these technologies."" 
 According to the news reporters, the research concluded: ""To address this, the paper proposes a Multiscale Ethics Framework, which aims to help technology developers and ethical evaluations to consider the wider implications of these technologies."" 
 This research has been peer-reviewed. 
 For more information on this research see: Multi Scale Ethics-Why We Need to Consider the Ethics of AI in Healthcare at Different Scales. Science and Engineering Ethics, 2022;28(6):63. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 Our news correspondents report that additional information may be obtained by contacting Melanie Smallman, Alan Turing Institute & Dept. of Science and Technology Studies, University College London (UCL), Gower Street, London, WC1E 6BT, UK. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-022-00396-z. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: London, United Kingdom, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); HUMANITIES & SOCIAL SCIENCE (78%); COLLEGES & UNIVERSITIES (74%); London;United Kingdom;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (90%); NEWS REPORTING (90%); COLLEGES & UNIVERSITIES (74%)
Geographic: LONDON, ENGLAND (91%); UNITED KINGDOM (89%); EUROPE (58%); NETHERLANDS (58%)
Load-Date: December 8, 2022","2022 DEC 08 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating in London, United Kingdom, by NewsRx editors, the research stated, ""Many researchers have documented how AI and data driven technologies have the potential to have profound effects on our lives-in ways that make these technologies stand out from those that went before. Around the world, we are seeing a significant growth in interest and investment in AI in healthcare."" 
 Financial supporters for this research include Alan Turing Institute Fellowship, Arts and Humanities Research Council. 
 The news reporters obtained a quote from the research from University College London (UCL), ""This has been coupled with rising concerns about the ethical implications of these technologies and an array of ethical guidelines for the use of AI and data in healthcare has arisen. Nevertheless, the question of if and how AI and data technologies can be ethical remains open to debate. This paper aims to contribute to this debate by considering the wide range of implications that have been attributed to these technologies and asking whether current ethical guidelines take these factors into account. In particular, the paper argues that while current ethics guidelines for AI in healthcare effectively account for the four key issues identified in the ethics literature (transparency; fairness; responsibility and privacy), they have largely neglected wider issues relating to the way in which these technologies shape institutional and social arrangements. This, I argue, has given current ethics guidelines a strong focus on evaluating the impact of these technologies on the individual, while not accounting for the powerful social shaping effects of these technologies."" 
 According to the news reporters, the research concluded: ""To address this, the paper proposes a Multiscale Ethics Framework, which aims to help technology developers and ethical evaluations to consider the wider implications of these technologies."" 
 This research has been peer-reviewed. 
 For more information on this research see: Multi Scale Ethics-Why We Need to Consider the Ethics of AI in Healthcare at Different Scales. Science and Engineering Ethics, 2022;28(6):63. Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Science and Engineering Ethics - www.springerlink.com/content/1353-3452/) 
 Our news correspondents report that additional information may be obtained by contacting Melanie Smallman, Alan Turing Institute & Dept. of Science and Technology Studies, University College London (UCL), Gower Street, London, WC1E 6BT, UK. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11948-022-00396-z. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal Science and Engineering Ethics can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: London, United Kingdom, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); HUMANITIES & SOCIAL SCIENCE (78%); COLLEGES & UNIVERSITIES (74%); London;United Kingdom;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (90%); NEWS REPORTING (90%); COLLEGES & UNIVERSITIES (74%)
Geographic: LONDON, ENGLAND (91%); UNITED KINGDOM (89%); EUROPE (58%); NETHERLANDS (58%)
Load-Date: December 8, 2022",neutral,0.7420883774757385,balanced/neutral,"['privacy', 'fairness', 'transparency']",['fairness'],"['guidelines', 'framework', 'need to']",[],3,1,3,0
2021,Unknown Title,"Body
The Inter-American Development Bank's innovation lab, IDB Lab, has selected 11 solutions from Latin America that use artificial intelligence to help reduce bias and discrimination based on sex or gender. These projects were submitted to the regional call for proposals for open innovation on gender and artificial intelligence launched by IDB Lab within the framework of its fAIr LAC initiative to address gender inequality gaps in Latin America and the Caribbean in the areas of financial inclusion, health, and well-being, and education and employment.
Key Highlights:
* The call, which was supported by Accenture, AWS, Globant, Google for Startups, Microsoft, NTT Data Foundation, Oracle, Red Hat, and SONDA, received a total of 66 proposals.
* In addition, they pre-selected 24 organizations to participate in a bootcamp with specialized content on artificial intelligence and ethics, bias, access to responsible financing, and technical considerations to incorporate diversity and inclusion approaches in technological development.
Original Press Release:
Dec. 1 -- Inter-American Development Bank issued the following news release:
- THE CHALLENGE RECEIVED 66 AI-BASED SOLUTIONS TO REDUCE GENDER DISCRIMINATION, AND 11 WERE SELECTED
The Inter-American Development Bank's innovation lab, IDB Lab, has selected 11 solutions from Latin America that use artificial intelligence to help reduce bias and discrimination based on sex or gender.
These projects were submitted to the regional call for proposals for open innovation on gender and artificial intelligence launched by IDB Lab within the framework of its fAIr LAC initiative to address gender inequality gaps in Latin America and the Caribbean in the areas of financial inclusion, health, and well-being, and education and employment.
The call, which was supported by Accenture, AWS, Globant, Google for Startups, Microsoft, NTT Data Foundation, Oracle, Red Hat, and SONDA, received a total of 66 proposals. Fifty-four sector experts evaluated the solutions in artificial intelligence, entrepreneurship, business, and social impact. In addition, they pre-selected 24 organizations to participate in a bootcamp with specialized content on artificial intelligence and ethics, bias, access to responsible financing, and technical considerations to incorporate diversity and inclusion approaches in technological development.
The participants also had access to individualized mentoring and presented their projects in a Demo Day where the final evaluation and selection were made.
The 11 selected proposals are:
1. Genomawork (Chile): Solutions to promote diversity and labor inclusion in Latin America.
2. hiSofi (Brazil): Financial health portal.
3. Jobecam (Brazil): Automated platform to optimize hiring.
4. Ethics (Mexico/Spain): Algorithmic audits to ensure data ethics.
5. Quipu Market (Colombia): Digital bank for the informal economy.
6. C-Minds (Mexico): Solutions to improve the care economy.
7. Tirando por Colombia (Colombia): Solutions for preventing teenage pregnancy.
8. Quantil (Colombia): Solution for developing AI models.
9. Thermy (Mexico): Medical device for image analysis.
10. Munay (Bolivia): Solutions for the financial inclusion of women entrepreneurs.
11. Bancolombia (Colombia): Financial education solutions for women.
In accordance with the Gender and Artificial Intelligence Challenge Guidelines, the selected proposals will initiate an eligibility and due diligence analysis process to potentially receive the financing that will allow them to implement their solution in one of the IDB's 26 borrowing countries.
About IDB Lab
IDB Lab is the innovation laboratory of the Inter-American Development Bank Group, the primary source of financing and knowledge for development focused on improving lives in Latin America and the Caribbean. IDB Lab aims to promote innovation for inclusion in the region, mobilizing financing, knowledge, and connections to test early-stage private sector solutions with the potential to transform the lives of vulnerable populations through economic, social, and environmental conditions. Since 1993, IDB Lab has approved more than $2 billion in projects deployed in 26 countries in Latin America and the Caribbean. www.bidlab.org
About fAIrLAC
fAIr LAC is an alliance between the public and private sectors, civil society, and academia to promote the responsible and ethical use of artificial intelligence in Latin America and the Caribbean to improve the delivery of social services, thereby attenuating growing inequality. https://fairlac.iadb.org/en
Source: Inter-American Development Bank
[Category: Banking & Finance, Procurement and Sales, ESG, Artificial Intelligence]
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: DEVELOPMENT BANKS (93%); GENDER & SEX DISCRIMINATION (92%); DISCRIMINATION (91%); ARTIFICIAL INTELLIGENCE (90%); ECONOMIC DEVELOPMENT (90%); GENDER & SEX DISCRIMINATION IN EMPLOYMENT (90%); GENDER EQUALITY (90%); INTERNATIONAL ASSISTANCE (90%); INTERNATIONAL ECONOMIC DEVELOPMENT (90%); NEGATIVE SOCIETAL NEWS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DIVERSITY & INCLUSION (89%); ETHICS (89%); ELECTRONIC BANKING (78%); FINANCIAL TECHNOLOGY (78%); MENTORS & ROLE MODELS (78%); SCIENCE & TECHNOLOGY (78%); ENTREPRENEURSHIP (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); COMPANY PRESS RELEASES (73%); ADOLESCENTS & TEENS (72%); ESG FACTORS - SOCIAL (72%); TEENAGE PREGNANCY (72%); MEDICINE & HEALTH (70%); PREGNANCY & CHILDBIRTH (60%); UNOFFICIAL ECONOMY (60%)
Company:  INTER-AMERICAN DEVELOPMENT BANK (94%);  MICROSOFT CORP (57%);  ACCENTURE PLC (57%);  GOOGLE LLC (57%)
Ticker: ACN (NYSE) (57%)
Industry: NAICS921130 PUBLIC FINANCE ACTIVITIES (94%); NAICS521110 MONETARY AUTHORITIES - CENTRAL BANK (94%); SIC6082 FOREIGN TRADE & INTERNATIONAL BANKING INSTITUTIONS (94%); NAICS513210 SOFTWARE PUBLISHERS (57%); SIC7372 PREPACKAGED SOFTWARE (57%); NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (57%); SIC8742 MANAGEMENT CONSULTING SERVICES (57%); NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); DEVELOPMENT BANKS (93%); ARTIFICIAL INTELLIGENCE (90%); FINANCIAL INCLUSION (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ELECTRONIC BANKING (78%); FINANCIAL TECHNOLOGY (78%); WEBSITES & PORTALS (78%)
Geographic: LATIN AMERICA (94%); MEXICO (93%); BRAZIL (92%); CARIBBEAN ISLANDS (90%); CHILE (79%)
Load-Date: December 2, 2022","The Inter-American Development Bank's innovation lab, IDB Lab, has selected 11 solutions from Latin America that use artificial intelligence to help reduce bias and discrimination based on sex or gender. These projects were submitted to the regional call for proposals for open innovation on gender and artificial intelligence launched by IDB Lab within the framework of its fAIr LAC initiative to address gender inequality gaps in Latin America and the Caribbean in the areas of financial inclusion, health, and well-being, and education and employment.
Key Highlights:
* The call, which was supported by Accenture, AWS, Globant, Google for Startups, Microsoft, NTT Data Foundation, Oracle, Red Hat, and SONDA, received a total of 66 proposals.
* In addition, they pre-selected 24 organizations to participate in a bootcamp with specialized content on artificial intelligence and ethics, bias, access to responsible financing, and technical considerations to incorporate diversity and inclusion approaches in technological development.
Original Press Release:
Dec. 1 -- Inter-American Development Bank issued the following news release:
- THE CHALLENGE RECEIVED 66 AI-BASED SOLUTIONS TO REDUCE GENDER DISCRIMINATION, AND 11 WERE SELECTED
The Inter-American Development Bank's innovation lab, IDB Lab, has selected 11 solutions from Latin America that use artificial intelligence to help reduce bias and discrimination based on sex or gender.
These projects were submitted to the regional call for proposals for open innovation on gender and artificial intelligence launched by IDB Lab within the framework of its fAIr LAC initiative to address gender inequality gaps in Latin America and the Caribbean in the areas of financial inclusion, health, and well-being, and education and employment.
The call, which was supported by Accenture, AWS, Globant, Google for Startups, Microsoft, NTT Data Foundation, Oracle, Red Hat, and SONDA, received a total of 66 proposals. Fifty-four sector experts evaluated the solutions in artificial intelligence, entrepreneurship, business, and social impact. In addition, they pre-selected 24 organizations to participate in a bootcamp with specialized content on artificial intelligence and ethics, bias, access to responsible financing, and technical considerations to incorporate diversity and inclusion approaches in technological development.
The participants also had access to individualized mentoring and presented their projects in a Demo Day where the final evaluation and selection were made.
The 11 selected proposals are:
1. Genomawork (Chile): Solutions to promote diversity and labor inclusion in Latin America.
2. hiSofi (Brazil): Financial health portal.
3. Jobecam (Brazil): Automated platform to optimize hiring.
4. Ethics (Mexico/Spain): Algorithmic audits to ensure data ethics.
5. Quipu Market (Colombia): Digital bank for the informal economy.
6. C-Minds (Mexico): Solutions to improve the care economy.
7. Tirando por Colombia (Colombia): Solutions for preventing teenage pregnancy.
8. Quantil (Colombia): Solution for developing AI models.
9. Thermy (Mexico): Medical device for image analysis.
10. Munay (Bolivia): Solutions for the financial inclusion of women entrepreneurs.
11. Bancolombia (Colombia): Financial education solutions for women.
In accordance with the Gender and Artificial Intelligence Challenge Guidelines, the selected proposals will initiate an eligibility and due diligence analysis process to potentially receive the financing that will allow them to implement their solution in one of the IDB's 26 borrowing countries.
About IDB Lab
IDB Lab is the innovation laboratory of the Inter-American Development Bank Group, the primary source of financing and knowledge for development focused on improving lives in Latin America and the Caribbean. IDB Lab aims to promote innovation for inclusion in the region, mobilizing financing, knowledge, and connections to test early-stage private sector solutions with the potential to transform the lives of vulnerable populations through economic, social, and environmental conditions. Since 1993, IDB Lab has approved more than $2 billion in projects deployed in 26 countries in Latin America and the Caribbean. www.bidlab.org
About fAIrLAC
fAIr LAC is an alliance between the public and private sectors, civil society, and academia to promote the responsible and ethical use of artificial intelligence in Latin America and the Caribbean to improve the delivery of social services, thereby attenuating growing inequality. https://fairlac.iadb.org/en
Source: Inter-American Development Bank
[Category: Banking & Finance, Procurement and Sales, ESG, Artificial Intelligence]
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: DEVELOPMENT BANKS (93%); GENDER & SEX DISCRIMINATION (92%); DISCRIMINATION (91%); ARTIFICIAL INTELLIGENCE (90%); ECONOMIC DEVELOPMENT (90%); GENDER & SEX DISCRIMINATION IN EMPLOYMENT (90%); GENDER EQUALITY (90%); INTERNATIONAL ASSISTANCE (90%); INTERNATIONAL ECONOMIC DEVELOPMENT (90%); NEGATIVE SOCIETAL NEWS (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); DIVERSITY & INCLUSION (89%); ETHICS (89%); ELECTRONIC BANKING (78%); FINANCIAL TECHNOLOGY (78%); MENTORS & ROLE MODELS (78%); SCIENCE & TECHNOLOGY (78%); ENTREPRENEURSHIP (77%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); COMPANY PRESS RELEASES (73%); ADOLESCENTS & TEENS (72%); ESG FACTORS - SOCIAL (72%); TEENAGE PREGNANCY (72%); MEDICINE & HEALTH (70%); PREGNANCY & CHILDBIRTH (60%); UNOFFICIAL ECONOMY (60%)
Company:  INTER-AMERICAN DEVELOPMENT BANK (94%);  MICROSOFT CORP (57%);  ACCENTURE PLC (57%);  GOOGLE LLC (57%)
Ticker: ACN (NYSE) (57%)
Industry: NAICS921130 PUBLIC FINANCE ACTIVITIES (94%); NAICS521110 MONETARY AUTHORITIES - CENTRAL BANK (94%); SIC6082 FOREIGN TRADE & INTERNATIONAL BANKING INSTITUTIONS (94%); NAICS513210 SOFTWARE PUBLISHERS (57%); SIC7372 PREPACKAGED SOFTWARE (57%); NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (57%); SIC8742 MANAGEMENT CONSULTING SERVICES (57%); NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); DEVELOPMENT BANKS (93%); ARTIFICIAL INTELLIGENCE (90%); FINANCIAL INCLUSION (90%); ARTIFICIAL INTELLIGENCE ETHICS (89%); ELECTRONIC BANKING (78%); FINANCIAL TECHNOLOGY (78%); WEBSITES & PORTALS (78%)
Geographic: LATIN AMERICA (94%); MEXICO (93%); BRAZIL (92%); CARIBBEAN ISLANDS (90%); CHILE (79%)
Load-Date: December 2, 2022",neutral,0.7530349493026733,balanced/neutral,"['bias', 'discrimination', 'access', 'inequality']",['equality'],"['guidelines', 'framework']",[],4,1,2,0
2021,Unknown Title,"Byline: Catherine Deveney
Body
Earlier this year, Google engineer Blake Lemoine was fired after claiming that the artificially intelligent chatbot he worked on was actually sentient. How crazy! A machine being mistaken for a thinking, feeling human being? But that was before the stratospheric rise of Liz Truss and, now, I have some sympathy with
Lemoine’s confusion
. How DO you tell a fully functioning human being from a pre-programmed robot with limited vocabulary? Tax cuts! Private profit! More tax cuts! Profit, pro…fit, pro…fit… Oh, switch her off someone, please.
Boris Johnson resigning outside Downing Street (Photo: Vedat Xhymshiti/News Pictures/Shutterstock)
The Truss-bot makes a bull in a China shop look like a ballerina. She has blustered her way to the front of the leadership contest with policy statements that suggest she consistently selects the wrong linguistic programme, her answers displaying the same frustratingly vague relevance as chatbot conversations. Regional pay boards? Didn’t mean it! No heating handouts? Only kidding! Will if I have to! But nothing is more disturbing than
Truss’s refusal to commit to appointing a government ethics adviser.
Truss thinks she’s only accountable to herself
Her explanation is even more disturbing than her decision. She doesn’t need one. We have too many advisers, she insists. (If we’re talking
Dominic Cummings
here, perhaps we can agree.) Too many rules and regulations. Liz Truss knows right from wrong. She has always acted with integrity. Says who? Says Liz – as if her personal interpretation of integrity is the gold standard. Full stop. It is hard to know where to begin with this – the fact that she was central to a government discredited for its ethical lapses, perhaps? – but let’s try. The last Tory government ethics adviser walked after Boris Johnson (who also claimed to have integrity) asked him to behave, well, unethically.
Boris Johnson resigning outside Downing Street (Photo: Vedat Xhymshiti/News Pictures/Shutterstock)
But, at least Johnson had enough nous to know that, even if he didn’t personally care about ethics, he’d better pretend he did. Truss is despotic enough to think she doesn’t even need a kiddie-on adviser. In case she hasn’t noticed, “trust me – I’m prime minister” doesn’t really cut it anymore. Back in 1994, John Major appointed a committee to investigate standards in public life, led by the late Lord Nolan. They identified seven principles, known as the
Nolan principles,
which are still used today as the guiding lights for anyone holding public office. They are: selflessness, honesty, objectivity, integrity, openness, leadership, and accountability. Truss clearly thinks she’s only accountable to herself.
Ethics are a crucial part of politics
Ethical dilemmas – and choices – lurk in every political decision. Back in May,
I wrote about oil giant Shell’s profit reaching £7.5 billion in the first three months of this year
– treble the same period last year. Is that ethical, when Shell knows their increased profit will result in increased winter mortality? Is it ethical for Truss to sanction that, saying: “Profit is not a dirty word”; to take the ideology of private enterprise to such extremes that dead bodies are fair exchange for extra bucks for big business? Or, is it ethical to take energy into public ownership, as France has done, thereby limiting increases in bills to 4%?
Liz Truss has the same need for reality checks as anyone else (Photo: Jacob King/PA Wire)
This week,
a poll suggested that more than half the nation has lost faith in the NHS,
don’t feel confident they will be treated quickly if they become ill, and believe that GP services have deteriorated. Days later, a story emerged of an elderly woman who called her GP when her husband died to ask for a death certificate. The doctor refused to visit personally. It was done by smartphone now, he said, instructing her to hold the phone to the dead man’s chest. Unsurprisingly, her friend had to take over. Ethical healthcare?
What is this? Debt pass the parcel?
Chief executive of the NHS Confederation, Matthew Taylor, this week demanded a “realism reset”. The health service is in a “terrible situation”, facing “more demand than we can deal with”. Yet, Truss wants to move £10 billion from health to another crisis zone: social care. What is this? Debt pass the parcel? Move it around quickly and, if the music stops, you have to pay? No wonder Truss doesn’t want an ethics adviser. I once heard of a university lecturer who set a self-reflective essay on discrimination. If you say anywhere in this essay that you are not discriminatory, students were warned, you will automatically fail. The point, of course, was that anyone who considered they were outside of a human frailty merely proved they were at the heart of it. People fear artificial intelligence will become more powerful than humans, but less ethical. The ability to assess right and wrong distinguishes human beings from machines, but, individually, we don’t always get it right. Assuming Liz Truss is actually sentient – in this campaign, that’s been a stretch – she is subject to the same frailties, the same blinkered vision, the same need for reality checks as anyone else. Her inability to understand that, if she is elected prime minister this weekend, she needs to be visibly accountable rings alarm bells about her suitability for that office.
Catherine Deveney is an award-winning investigative journalist, novelist and television presenter
Liz Truss speaks at a final hustings at Wembley Arena, before the UK's next prime minister is decided (Photo: Tom Bowles/Story Picture Agency/Shutterstock)
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); BRITISH PRIME MINISTERS (89%); GOVERNMENT ETHICS (89%); RESIGNATIONS (89%); INVESTIGATIONS (78%); TAXES & TAXATION (77%); TAX LAW (76%); ELECTIONS & POLITICS (72%); POLITICS (67%); EDITORIALS & OPINIONS (58%); Columnists (%); Opinion (%); Catherine Deveney (%); ethics (%); Liz Truss (%)
Company:  GOOGLE LLC (58%);  SHUTTERSTOCK INC (56%)
Ticker: SSTK (NYSE) (56%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (58%); ARTIFICIAL INTELLIGENCE (90%); OIL & GAS INDUSTRY (71%)
Person: LIZ TRUSS (94%); BORIS JOHNSON (89%)
Load-Date: September 2, 2022","Earlier this year, Google engineer Blake Lemoine was fired after claiming that the artificially intelligent chatbot he worked on was actually sentient. How crazy! A machine being mistaken for a thinking, feeling human being? But that was before the stratospheric rise of Liz Truss and, now, I have some sympathy with
Lemoine’s confusion
. How DO you tell a fully functioning human being from a pre-programmed robot with limited vocabulary? Tax cuts! Private profit! More tax cuts! Profit, pro…fit, pro…fit… Oh, switch her off someone, please.
Boris Johnson resigning outside Downing Street (Photo: Vedat Xhymshiti/News Pictures/Shutterstock)
The Truss-bot makes a bull in a China shop look like a ballerina. She has blustered her way to the front of the leadership contest with policy statements that suggest she consistently selects the wrong linguistic programme, her answers displaying the same frustratingly vague relevance as chatbot conversations. Regional pay boards? Didn’t mean it! No heating handouts? Only kidding! Will if I have to! But nothing is more disturbing than
Truss’s refusal to commit to appointing a government ethics adviser.
Truss thinks she’s only accountable to herself
Her explanation is even more disturbing than her decision. She doesn’t need one. We have too many advisers, she insists. (If we’re talking
Dominic Cummings
here, perhaps we can agree.) Too many rules and regulations. Liz Truss knows right from wrong. She has always acted with integrity. Says who? Says Liz – as if her personal interpretation of integrity is the gold standard. Full stop. It is hard to know where to begin with this – the fact that she was central to a government discredited for its ethical lapses, perhaps? – but let’s try. The last Tory government ethics adviser walked after Boris Johnson (who also claimed to have integrity) asked him to behave, well, unethically.
Boris Johnson resigning outside Downing Street (Photo: Vedat Xhymshiti/News Pictures/Shutterstock)
But, at least Johnson had enough nous to know that, even if he didn’t personally care about ethics, he’d better pretend he did. Truss is despotic enough to think she doesn’t even need a kiddie-on adviser. In case she hasn’t noticed, “trust me – I’m prime minister” doesn’t really cut it anymore. Back in 1994, John Major appointed a committee to investigate standards in public life, led by the late Lord Nolan. They identified seven principles, known as the
Nolan principles,
which are still used today as the guiding lights for anyone holding public office. They are: selflessness, honesty, objectivity, integrity, openness, leadership, and accountability. Truss clearly thinks she’s only accountable to herself.
Ethics are a crucial part of politics
Ethical dilemmas – and choices – lurk in every political decision. Back in May,
I wrote about oil giant Shell’s profit reaching £7.5 billion in the first three months of this year
– treble the same period last year. Is that ethical, when Shell knows their increased profit will result in increased winter mortality? Is it ethical for Truss to sanction that, saying: “Profit is not a dirty word”; to take the ideology of private enterprise to such extremes that dead bodies are fair exchange for extra bucks for big business? Or, is it ethical to take energy into public ownership, as France has done, thereby limiting increases in bills to 4%?
Liz Truss has the same need for reality checks as anyone else (Photo: Jacob King/PA Wire)
This week,
a poll suggested that more than half the nation has lost faith in the NHS,
don’t feel confident they will be treated quickly if they become ill, and believe that GP services have deteriorated. Days later, a story emerged of an elderly woman who called her GP when her husband died to ask for a death certificate. The doctor refused to visit personally. It was done by smartphone now, he said, instructing her to hold the phone to the dead man’s chest. Unsurprisingly, her friend had to take over. Ethical healthcare?
What is this? Debt pass the parcel?
Chief executive of the NHS Confederation, Matthew Taylor, this week demanded a “realism reset”. The health service is in a “terrible situation”, facing “more demand than we can deal with”. Yet, Truss wants to move £10 billion from health to another crisis zone: social care. What is this? Debt pass the parcel? Move it around quickly and, if the music stops, you have to pay? No wonder Truss doesn’t want an ethics adviser. I once heard of a university lecturer who set a self-reflective essay on discrimination. If you say anywhere in this essay that you are not discriminatory, students were warned, you will automatically fail. The point, of course, was that anyone who considered they were outside of a human frailty merely proved they were at the heart of it. People fear artificial intelligence will become more powerful than humans, but less ethical. The ability to assess right and wrong distinguishes human beings from machines, but, individually, we don’t always get it right. Assuming Liz Truss is actually sentient – in this campaign, that’s been a stretch – she is subject to the same frailties, the same blinkered vision, the same need for reality checks as anyone else. Her inability to understand that, if she is elected prime minister this weekend, she needs to be visibly accountable rings alarm bells about her suitability for that office.
Catherine Deveney is an award-winning investigative journalist, novelist and television presenter
Liz Truss speaks at a final hustings at Wembley Arena, before the UK's next prime minister is decided (Photo: Tom Bowles/Story Picture Agency/Shutterstock)
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); BRITISH PRIME MINISTERS (89%); GOVERNMENT ETHICS (89%); RESIGNATIONS (89%); INVESTIGATIONS (78%); TAXES & TAXATION (77%); TAX LAW (76%); ELECTIONS & POLITICS (72%); POLITICS (67%); EDITORIALS & OPINIONS (58%); Columnists (%); Opinion (%); Catherine Deveney (%); ethics (%); Liz Truss (%)
Company:  GOOGLE LLC (58%);  SHUTTERSTOCK INC (56%)
Ticker: SSTK (NYSE) (56%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (58%); ARTIFICIAL INTELLIGENCE (90%); OIL & GAS INDUSTRY (71%)
Person: LIZ TRUSS (94%); BORIS JOHNSON (89%)
Load-Date: September 2, 2022",negative,0.7564294934272766,balanced/neutral,"['discrimination', 'accountability', 'agency']",[],"['policy', 'standards', 'law', 'suggest']",['robot'],3,0,4,1
2021,Unknown Title,"Dateline: MENLO PARK, Calif., April 21, 2022 
Body
PR Newswire
The Ethical AI Governance Group (EAIGG) announced its formal launch yesterday with a mission to promote AI governance, data privacy, and climate technologies. A special event was held in partnership with founding memberBGVto celebrate the formation of EAIGG and to formally unveil the Ethics Maturity Continuum, a practical framework for investors to diligence AI-first startups to assess the underlying risks and maturity around AI Governance and Data Privacy.
Given the widespread deployments of machine learning algorithms and AI models over the last few years, it has become increasingly important for leading startups, investors and enterprise executives to provide visibility into otherwise opaque AI systems. With new regulations emerging in Brussels, and increasing scrutiny of Big Data companies in Washington, technology companies of all sizes are making organizational changes to their businesses and development processes, and many are seeking guidance in doing so. EAIGG was established to support this movement.
In conjunction with BGV andEthical Intelligence, EAIGG released a groundbreaking new tool to help businesses assess their level of maturity in the adoption of ethical AI standards, and identify key areas for improvement. ""The Ethics Maturity Continuum was designed as a framework to provide a granular approach for AI-first startups to operationalize best practices around accountability, intentional design, fairness, social impact, trust, and transparency,"" said Olivia Gambelin, Founder of Ethical Intelligence. ""We believe this framework can play an instrumental role in helping investors and AI-first startup leaders evaluate their existing efforts and navigate responsible value creation journeys."" Access to the Ethics Maturity Continuum survey is available on EAIGG'swebsite. Interested parties can also download ""Ethical AI Governance – A Call for Action,"" a white paper illustrating the need and application of the maturity continuum framework.
""Absent clear regulations, and growing pressures from a variety of stakeholders, we began leveraging the insights developed by leaders, across all stages of startup development, to inform a set of best practices that will influence enterprise AI market adoption and ultimately value creation,"" explained Anik Bose, Executive Director of EAIGG.
""As the public debate ramps, our group emerged organically,"" noted Emmanuel Benhamou, Managing Director of EAIGG, ""and we decided to formally launch EAIGG to open-source these best practices, and to share insights from a variety of perspectives, including investors de-risking their portfolio companies, startup execs de-risking their product offerings, and thought leaders seeking to responsibly steer innovation.""
To mark the launch of EAIGG, the organization held a special ""Investing in Ethical AI"" event in partnership with BGV. Speakers included ethical AI specialist and founder of Anch.ai Anna Fellander, who discussed a European perspective on AI risk and incoming regulations from Brussels; Corporate Venture Capital investors from Intel Capital, Schneider Electric, EWE, Qualcomm, and Micron Ventures, discussing how they embed ethical AI into their investment filters and their portfolio companies' boardrooms; founders from exemplary AI-focused startups including Snorkel, Zelros, AI Dash, Evinced and Fiddler; and the founder of Ethical Intelligence, Olivia Gambelin to present the launch of the Ethics Maturity Continuum, amongst others.
The event also focused on investment trends and AI developments with regard to Health Tech and Climate Tech. Barak Ben-Avinoam, CEO of NetZero, a new climate tech incubator in Israel, discussed how new investment trends and AI technologies are powering a renewed global climate tech movement. NetZero is one of five new tech incubators licensed by the Israel Innovation Authority announced in February of 2022. 
About EAIGG
The Ethical AI Governance Group (EAIGG) is a grassroots community platform established to democratize best practices around responsible AI governance. The group is composed of AI practitioners, entrepreneurs, and technology investors dedicated to sharing practical insights and promoting the adoption of ethical AI covering governance, data privacy, and climate tech. EAIGG harnesses the practical insights of its members to develop research that can foster and sustain responsible innovation in AI-first startups and enterprise technology companies. To take the Ethics Maturity Continuum Assessment and to learn more about EAIGG visithttp://www.eaigg.org.
Press Contact Emmanuel Benhamou 
emmanuel@eaigg.org 
+1.202.341.0269
 View original content to download multimedia:https://www.prnewswire.com/news-releases/ethical-ai-governance-group-eaigg-announces-formal-launch-unveils-ethics-maturity-continuum-301530584.html
SOURCE Ethical AI Governance Group (EAIGG)
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); PRESS RELEASES (90%); BEST PRACTICES (89%); EXECUTIVES (89%); PRIVACY RIGHTS (89%); TRENDS & EVENTS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); ASSOCIATIONS & ORGANIZATIONS (78%); VENTURE CAPITAL (76%); MACHINE LEARNING (73%); MANAGERS & SUPERVISORS (71%); Ethical-AI-Group (%); NPT Not-for-Profits (%)
Company:  INTEL CORP (83%);  AI SYSTEMS (57%);  SCHNEIDER ELECTRIC SA (50%);  QUALCOMM INC (50%); Ethical AI Governance Group (EAIGG)
Ticker: INTC (NASDAQ) (83%); SU (PAR) (50%); QCOM (NASDAQ) (50%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (83%); SIC7372 PREPACKAGED SOFTWARE (57%); NAICS335313 SWITCHGEAR & SWITCHBOARD APPARATUS MANUFACTURING (50%); NAICS335311 POWER, DISTRIBUTION & SPECIALTY TRANSFORMER MANUFACTURING (50%); SIC3613 SWITCHGEAR & SWITCHBOARD APPARATUS (50%); SIC3612 POWER, DISTRIBUTION, & SPECIALTY TRANSFORMERS (50%); NAICS334220 RADIO & TELEVISION BROADCASTING & WIRELESS COMMUNICATIONS EQUIPMENT MANUFACTURING (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); VENTURE CAPITAL (76%); OPEN SOURCE SOFTWARE (75%); BIG DATA (73%); MACHINE LEARNING (73%); CPR Computer; Electronics Products (%)
Geographic: SAN FRANCISCO BAY AREA, CA, USA (74%); BRUSSELS, BELGIUM (71%); CALIFORNIA, USA (90%); California
Load-Date: April 21, 2022","PR Newswire
The Ethical AI Governance Group (EAIGG) announced its formal launch yesterday with a mission to promote AI governance, data privacy, and climate technologies. A special event was held in partnership with founding memberBGVto celebrate the formation of EAIGG and to formally unveil the Ethics Maturity Continuum, a practical framework for investors to diligence AI-first startups to assess the underlying risks and maturity around AI Governance and Data Privacy.
Given the widespread deployments of machine learning algorithms and AI models over the last few years, it has become increasingly important for leading startups, investors and enterprise executives to provide visibility into otherwise opaque AI systems. With new regulations emerging in Brussels, and increasing scrutiny of Big Data companies in Washington, technology companies of all sizes are making organizational changes to their businesses and development processes, and many are seeking guidance in doing so. EAIGG was established to support this movement.
In conjunction with BGV andEthical Intelligence, EAIGG released a groundbreaking new tool to help businesses assess their level of maturity in the adoption of ethical AI standards, and identify key areas for improvement. ""The Ethics Maturity Continuum was designed as a framework to provide a granular approach for AI-first startups to operationalize best practices around accountability, intentional design, fairness, social impact, trust, and transparency,"" said Olivia Gambelin, Founder of Ethical Intelligence. ""We believe this framework can play an instrumental role in helping investors and AI-first startup leaders evaluate their existing efforts and navigate responsible value creation journeys."" Access to the Ethics Maturity Continuum survey is available on EAIGG'swebsite. Interested parties can also download ""Ethical AI Governance – A Call for Action,"" a white paper illustrating the need and application of the maturity continuum framework.
""Absent clear regulations, and growing pressures from a variety of stakeholders, we began leveraging the insights developed by leaders, across all stages of startup development, to inform a set of best practices that will influence enterprise AI market adoption and ultimately value creation,"" explained Anik Bose, Executive Director of EAIGG.
""As the public debate ramps, our group emerged organically,"" noted Emmanuel Benhamou, Managing Director of EAIGG, ""and we decided to formally launch EAIGG to open-source these best practices, and to share insights from a variety of perspectives, including investors de-risking their portfolio companies, startup execs de-risking their product offerings, and thought leaders seeking to responsibly steer innovation.""
To mark the launch of EAIGG, the organization held a special ""Investing in Ethical AI"" event in partnership with BGV. Speakers included ethical AI specialist and founder of Anch.ai Anna Fellander, who discussed a European perspective on AI risk and incoming regulations from Brussels; Corporate Venture Capital investors from Intel Capital, Schneider Electric, EWE, Qualcomm, and Micron Ventures, discussing how they embed ethical AI into their investment filters and their portfolio companies' boardrooms; founders from exemplary AI-focused startups including Snorkel, Zelros, AI Dash, Evinced and Fiddler; and the founder of Ethical Intelligence, Olivia Gambelin to present the launch of the Ethics Maturity Continuum, amongst others.
The event also focused on investment trends and AI developments with regard to Health Tech and Climate Tech. Barak Ben-Avinoam, CEO of NetZero, a new climate tech incubator in Israel, discussed how new investment trends and AI technologies are powering a renewed global climate tech movement. NetZero is one of five new tech incubators licensed by the Israel Innovation Authority announced in February of 2022. 
About EAIGG
The Ethical AI Governance Group (EAIGG) is a grassroots community platform established to democratize best practices around responsible AI governance. The group is composed of AI practitioners, entrepreneurs, and technology investors dedicated to sharing practical insights and promoting the adoption of ethical AI covering governance, data privacy, and climate tech. EAIGG harnesses the practical insights of its members to develop research that can foster and sustain responsible innovation in AI-first startups and enterprise technology companies. To take the Ethics Maturity Continuum Assessment and to learn more about EAIGG visithttp://www.eaigg.org.
Press Contact Emmanuel Benhamou 
emmanuel@eaigg.org 
+1.202.341.0269
 View original content to download multimedia:https://www.prnewswire.com/news-releases/ethical-ai-governance-group-eaigg-announces-formal-launch-unveils-ethics-maturity-continuum-301530584.html
SOURCE Ethical AI Governance Group (EAIGG)
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); PRESS RELEASES (90%); BEST PRACTICES (89%); EXECUTIVES (89%); PRIVACY RIGHTS (89%); TRENDS & EVENTS (89%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (79%); ASSOCIATIONS & ORGANIZATIONS (78%); VENTURE CAPITAL (76%); MACHINE LEARNING (73%); MANAGERS & SUPERVISORS (71%); Ethical-AI-Group (%); NPT Not-for-Profits (%)
Company:  INTEL CORP (83%);  AI SYSTEMS (57%);  SCHNEIDER ELECTRIC SA (50%);  QUALCOMM INC (50%); Ethical AI Governance Group (EAIGG)
Ticker: INTC (NASDAQ) (83%); SU (PAR) (50%); QCOM (NASDAQ) (50%)
Industry: NAICS334413 SEMICONDUCTOR & RELATED DEVICE MANUFACTURING (83%); SIC7372 PREPACKAGED SOFTWARE (57%); NAICS335313 SWITCHGEAR & SWITCHBOARD APPARATUS MANUFACTURING (50%); NAICS335311 POWER, DISTRIBUTION & SPECIALTY TRANSFORMER MANUFACTURING (50%); SIC3613 SWITCHGEAR & SWITCHBOARD APPARATUS (50%); SIC3612 POWER, DISTRIBUTION, & SPECIALTY TRANSFORMERS (50%); NAICS334220 RADIO & TELEVISION BROADCASTING & WIRELESS COMMUNICATIONS EQUIPMENT MANUFACTURING (50%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); INFORMATION SECURITY & PRIVACY (90%); INFORMATION TECHNOLOGY INDUSTRY (78%); VENTURE CAPITAL (76%); OPEN SOURCE SOFTWARE (75%); BIG DATA (73%); MACHINE LEARNING (73%); CPR Computer; Electronics Products (%)
Geographic: SAN FRANCISCO BAY AREA, CA, USA (74%); BRUSSELS, BELGIUM (71%); CALIFORNIA, USA (90%); California
Load-Date: April 21, 2022",positive,0.5189565420150757,balanced/neutral,"['privacy', 'fairness', 'transparency', 'accountability', 'security', 'access']",['fairness'],"['governance', 'standards', 'framework']","['machine learning', 'transformer']",6,1,3,2
2021,Unknown Title,"Body
Beijing, China: Government of the People's Republic of China has issued the following news release:
China has released a set of guidelines to strengthen the governance over ethics in science and technology, given the rapid progress of the country's sci-tech innovation and the growing challenges facing ethics in the field.
Ethics compliance should be emphasized throughout the process of scientific research and technological development, according to the guidelines, which were issued by the General Office of the Communist Party of China Central Committee and the General Office of the State Council.
The governance should be based on laws and regulations, and should suit the conditions of the country, the document said. Opening-up and cooperation were also emphasized.
The document clarified the ethical principles in science and technology, saying that scientific activities should serve the well-being of humanity, respect people's right to life, adhere to fairness and justice, control risks in an appropriate way, and maintain openness and transparency.
It urged efforts to make and improve regulations and standards for ethics in key areas such as the life sciences, medicine and artificial intelligence, improve the rules and processes of ethical review, risk management and the handling of violations, and boost theoretical research in ethics.
Ethical review and regulations should be strengthened, the guidelines said. A contingency mechanism should also be prepared for public health emergencies.
Authorities should push colleges and universities, scientific research institutions, medical institutions, social groups and enterprises to improve the monitoring and early warning mechanism for ethical risks, and follow up development in emerging sci-tech fields.
Ethics education in science and technology, the institutionalization of ethical training programs and the popularization of ethical codes among the general public were also underlined in the document.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (93%); EXPERIMENTATION & RESEARCH (90%); RISK MANAGEMENT (88%); COMMUNISM (78%); SCIENCE & TECHNOLOGY (77%); RESEARCH INSTITUTES (76%); HEALTH CARE REGULATION & POLICY (75%); LAW & LEGAL SYSTEM (75%); PUBLIC HEALTH (74%); POLITICAL PARTIES (73%); PUBLIC HEALTH ADMINISTRATION (71%); ARTIFICIAL INTELLIGENCE (52%)
Industry: RISK MANAGEMENT (88%); EDUCATIONAL SERVICES (78%); HEALTH CARE REGULATION & POLICY (75%); ARTIFICIAL INTELLIGENCE (52%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (59%); CHINA (94%); TAIWAN (79%)
Load-Date: March 23, 2022","Beijing, China: Government of the People's Republic of China has issued the following news release:
China has released a set of guidelines to strengthen the governance over ethics in science and technology, given the rapid progress of the country's sci-tech innovation and the growing challenges facing ethics in the field.
Ethics compliance should be emphasized throughout the process of scientific research and technological development, according to the guidelines, which were issued by the General Office of the Communist Party of China Central Committee and the General Office of the State Council.
The governance should be based on laws and regulations, and should suit the conditions of the country, the document said. Opening-up and cooperation were also emphasized.
The document clarified the ethical principles in science and technology, saying that scientific activities should serve the well-being of humanity, respect people's right to life, adhere to fairness and justice, control risks in an appropriate way, and maintain openness and transparency.
It urged efforts to make and improve regulations and standards for ethics in key areas such as the life sciences, medicine and artificial intelligence, improve the rules and processes of ethical review, risk management and the handling of violations, and boost theoretical research in ethics.
Ethical review and regulations should be strengthened, the guidelines said. A contingency mechanism should also be prepared for public health emergencies.
Authorities should push colleges and universities, scientific research institutions, medical institutions, social groups and enterprises to improve the monitoring and early warning mechanism for ethical risks, and follow up development in emerging sci-tech fields.
Ethics education in science and technology, the institutionalization of ethical training programs and the popularization of ethical codes among the general public were also underlined in the document.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: ETHICS (93%); EXPERIMENTATION & RESEARCH (90%); RISK MANAGEMENT (88%); COMMUNISM (78%); SCIENCE & TECHNOLOGY (77%); RESEARCH INSTITUTES (76%); HEALTH CARE REGULATION & POLICY (75%); LAW & LEGAL SYSTEM (75%); PUBLIC HEALTH (74%); POLITICAL PARTIES (73%); PUBLIC HEALTH ADMINISTRATION (71%); ARTIFICIAL INTELLIGENCE (52%)
Industry: RISK MANAGEMENT (88%); EDUCATIONAL SERVICES (78%); HEALTH CARE REGULATION & POLICY (75%); ARTIFICIAL INTELLIGENCE (52%)
Geographic: BEIJING, CHINA (59%); NORTH CENTRAL CHINA (59%); CHINA (94%); TAIWAN (79%)
Load-Date: March 23, 2022",neutral,0.6164990067481995,balanced/neutral,"['fairness', 'transparency']","['justice', 'fairness', 'justice']","['regulation', 'policy', 'governance', 'standards', 'guidelines', 'law', 'compliance', 'should']",[],2,3,8,0
2021,Unknown Title,"Body
Washington: Office of the Senator Elizabeth Warren has issued the following news release:
United States Senator Elizabeth Warren (D-Mass.) sent a letter to Defense Secretary Lloyd Austin raising a series of questions for the Department of Defense (DoD) regarding press reports that former Google chief executive officer Eric Schmidt used his positions on defense advisory boards to further his own financial interests. Under the Federal Advisory Committee Act (FACA) the Secretary of Defense is responsible for ensuring that defense advisory board members adhere to ethics standards, including following ethics laws that prohibit participating personally and substantially in matters relating to individuals ’ financial interests.
“Mr. Schmidt ’ s investment activities, and the lack of public disclosure, create the appearance that these boards are yet another tool for influence-peddling and profiteering at DoD, raising concerns about the ethics of their members and the utility of their recommendations,” wrote Senator Warren.
Reports have revealed several instances where companies Mr. Schmidt has invested in received multimillion-dollar Department of Defense contracts and may have created a direct financial conflict of interest with his roles as chair of the Defense Innovation Board and of the National Security Commission on Artificial Intelligence (NSCAI).
In late 2021, the NSCAI published a report recommending that the federal government “significantly increase spending on artificial intelligence” to reach $32 billion annually by 2026. In response to these suggestions, the Senate version of the National Defense Authorization Act provided an additional $75 million “for implementing the National Security Commission on Artificial Intelligence recommendations. ” Mr. Schmidt stands to benefit from this increase as he and his business partners have invested more than $2 billion in companies focused on artificial intelligence.
“The public deserves to know that members of DoD ’ s advisory boards are providing the department with the best and most appropriate advice to support national security, and are not abusing their authority to advance their own financial interests,” concluded Senator Warren.
Senator Warren ’ s Anti-Corruption and Public Integrity Act would require all agencies to post federal advisory committee information, including ethics and recusal information for members. Senator Warren is requesting that Secretary Austin address her concerns over this potential conflict of interest and respond to her questions no later than January 17, 2023.
Senator Warren has long championed stronger ethics rules to prevent billionaires from exploiting the government for their own financial ends:
In May 2022, Senator Warren introduced the Department of Defense Ethics and Anti-Corruption Act, which would enforce limits to the influence of contractors on the military, restrict foreign influence on retired senior military officers, and assert greater transparency over contractors and their interaction with the DoD. In March 2021, Senator Warren sent a letter to Secretary of Defense Lloyd Austin praising his decision to suspend dozens of Defense Department advisory boards and relieve hundreds of appointees to these boards pending a “zero-based review. ” In the letter, Senator Warren also called for improvements as the Department of Defense (DoD) considers candidates for repopulating the boards that survive DoD's review. Senator Warren has also fought to preserve existing ethics laws, including defeating a provision from DoD and Senator Inhofe in the fiscal year 2021 National Defense Authorization Act to weaken Section 1045. In December 2020, Senator Warren and Congresswoman Pramila Jayapal (D-Wash.) reintroduced the Anti-Corruption & Public Integrity Act, bicameral legislation to fundamentally change the way Washington does business and includes provisions that would strengthen ethics laws and disclosure for federal advisory committees.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: US FEDERAL GOVERNMENT (92%); DEFENSE DEPARTMENTS (91%); LEGISLATIVE BODIES (91%); ETHICS (90%); GOVERNMENT ADVISORS & MINISTERS (90%); DEFENSE SPENDING (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); NATIONAL SECURITY (89%); NEGATIVE NEWS (89%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); US CONGRESS (78%); BOARDS OF DIRECTORS (77%); DEFENSE CONTRACTING (77%); LEGISLATION (76%); ANTI-CORRUPTION (75%); CORRUPTION (75%); EXECUTIVES (72%); ARTIFICIAL INTELLIGENCE (71%); WEALTHY PEOPLE (69%)
Industry: DEFENSE DEPARTMENTS (91%); DEFENSE SPENDING (89%); DEFENSE CONTRACTING (77%); DEFENSE INDUSTRY REGULATION & POLICY (77%); DEFENSE INDUSTRY (72%); ARTIFICIAL INTELLIGENCE (71%)
Person: ELIZABETH WARREN (90%); ERIC E SCHMIDT (79%)
Geographic: UNITED STATES (92%)
Load-Date: December 15, 2022","Washington: Office of the Senator Elizabeth Warren has issued the following news release:
United States Senator Elizabeth Warren (D-Mass.) sent a letter to Defense Secretary Lloyd Austin raising a series of questions for the Department of Defense (DoD) regarding press reports that former Google chief executive officer Eric Schmidt used his positions on defense advisory boards to further his own financial interests. Under the Federal Advisory Committee Act (FACA) the Secretary of Defense is responsible for ensuring that defense advisory board members adhere to ethics standards, including following ethics laws that prohibit participating personally and substantially in matters relating to individuals ’ financial interests.
“Mr. Schmidt ’ s investment activities, and the lack of public disclosure, create the appearance that these boards are yet another tool for influence-peddling and profiteering at DoD, raising concerns about the ethics of their members and the utility of their recommendations,” wrote Senator Warren.
Reports have revealed several instances where companies Mr. Schmidt has invested in received multimillion-dollar Department of Defense contracts and may have created a direct financial conflict of interest with his roles as chair of the Defense Innovation Board and of the National Security Commission on Artificial Intelligence (NSCAI).
In late 2021, the NSCAI published a report recommending that the federal government “significantly increase spending on artificial intelligence” to reach $32 billion annually by 2026. In response to these suggestions, the Senate version of the National Defense Authorization Act provided an additional $75 million “for implementing the National Security Commission on Artificial Intelligence recommendations. ” Mr. Schmidt stands to benefit from this increase as he and his business partners have invested more than $2 billion in companies focused on artificial intelligence.
“The public deserves to know that members of DoD ’ s advisory boards are providing the department with the best and most appropriate advice to support national security, and are not abusing their authority to advance their own financial interests,” concluded Senator Warren.
Senator Warren ’ s Anti-Corruption and Public Integrity Act would require all agencies to post federal advisory committee information, including ethics and recusal information for members. Senator Warren is requesting that Secretary Austin address her concerns over this potential conflict of interest and respond to her questions no later than January 17, 2023.
Senator Warren has long championed stronger ethics rules to prevent billionaires from exploiting the government for their own financial ends:
In May 2022, Senator Warren introduced the Department of Defense Ethics and Anti-Corruption Act, which would enforce limits to the influence of contractors on the military, restrict foreign influence on retired senior military officers, and assert greater transparency over contractors and their interaction with the DoD. In March 2021, Senator Warren sent a letter to Secretary of Defense Lloyd Austin praising his decision to suspend dozens of Defense Department advisory boards and relieve hundreds of appointees to these boards pending a “zero-based review. ” In the letter, Senator Warren also called for improvements as the Department of Defense (DoD) considers candidates for repopulating the boards that survive DoD's review. Senator Warren has also fought to preserve existing ethics laws, including defeating a provision from DoD and Senator Inhofe in the fiscal year 2021 National Defense Authorization Act to weaken Section 1045. In December 2020, Senator Warren and Congresswoman Pramila Jayapal (D-Wash.) reintroduced the Anti-Corruption & Public Integrity Act, bicameral legislation to fundamentally change the way Washington does business and includes provisions that would strengthen ethics laws and disclosure for federal advisory committees.
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: INS
Subject: US FEDERAL GOVERNMENT (92%); DEFENSE DEPARTMENTS (91%); LEGISLATIVE BODIES (91%); ETHICS (90%); GOVERNMENT ADVISORS & MINISTERS (90%); DEFENSE SPENDING (89%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (89%); NATIONAL SECURITY (89%); NEGATIVE NEWS (89%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); US CONGRESS (78%); BOARDS OF DIRECTORS (77%); DEFENSE CONTRACTING (77%); LEGISLATION (76%); ANTI-CORRUPTION (75%); CORRUPTION (75%); EXECUTIVES (72%); ARTIFICIAL INTELLIGENCE (71%); WEALTHY PEOPLE (69%)
Industry: DEFENSE DEPARTMENTS (91%); DEFENSE SPENDING (89%); DEFENSE CONTRACTING (77%); DEFENSE INDUSTRY REGULATION & POLICY (77%); DEFENSE INDUSTRY (72%); ARTIFICIAL INTELLIGENCE (71%)
Person: ELIZABETH WARREN (90%); ERIC E SCHMIDT (79%)
Geographic: UNITED STATES (92%)
Load-Date: December 15, 2022",neutral,0.9278241991996765,balanced/neutral,"['transparency', 'security']",[],"['regulation', 'policy', 'standards', 'legislation']",[],2,0,4,0
2021,Unknown Title,"Body
London: techUK has issued the following press release:
New research from a panel of industry experts convened by Kainos and Tortoise Media calls for immediate action to improve trust for artificial intelligence systems.
techUK members Kainos has partnered with award-winning slow news organisation, Tortoise, to investigate how business leaders should respond to challenges around trust in AI now.
Through interviews with twenty international AI experts – from companies including Accenture, The Alan Turing Institute, and UNESCO – Kainos and Tortoise Media identified three guiding hypotheses to improve trust in AI. These are: harnessing the role of the AI ethicist; embedding pluralistic governing principles to adapt to emerging regulation; and delivering holistic explainability.
'The AI ecosystem has the potential to deliver huge societal benefits in everything from health to education to sustainability,' commented Tom Gray, Group CTO and Director of Innovation, Kainos.
'However, the benefits are likely to unequally benefit the already well off unless we take action. As these technologies become increasingly embedded into society, there are big questions to be answered to assure us that we can trust the fairness of these systems.
'We know what can happen when AI is deployed irresponsibly or inexpertly, from perpetuating systemic biases in justice systems to making an incorrect medical diagnosis. Organisations are now learning the importance of ethical and responsible AI implementation, just as the corporate world has been on a similar journey with other urgent issues – like improving sustainability.
'To help organisations, a practical, nuanced, and sophisticated approach to AI governance is needed now.'
“Trust is a much discussed, but often misunderstood subject in the field of artificial intelligence. This research has given us a clear view from the leading-edge, and access to the perspectives of some of the most prominent experts in the world. At Tortoise, we see AI as a potent enabler, but also as a real threat to democracy, safety and society when it is misused. If there is a real focus on ethics, standards, and social transparency, we think the next five years in AI will be transformational for its power to do good, and well-placed trust is a crucial ingredient,” said Alexandra Mousavizadeh, Director of Tortoise Intelligence.Kainos and Tortoise Media identified the following three hypotheses for establishing trust in AI:
Responsibility is not only a role: The ethicist is necessary but not sufficient to achieve trust throughout the artificial intelligence lifecycle. Many companies are hiring an 'AI ethicist', but this is just one step in the process – the responsibility for trust is best diffused across an organisation rather than placed on a single individual. Ray Eitel-Porter, Global Lead for Responsible AI, Accenture, commented, 'We very much take the view that Responsible AI is a responsibility and a business imperative that has to be embedded across the whole of the organisation and not just within the technology people.' Standardisation from diversity: Standards throughout ethical AI development can help to cultivate trust through the sharing of best practice. Algorithm Watch found 173 AI 'guidelines' were published between 2018 and 2020. Yet, it concluded there was 'a lot of virtue signalling going on and few efforts of enforcement.' Standardisation of ethical AI practices is needed, but they must be developed with a diversity of perspectives. This includes addressing what Emma Ruttkamp-Bloem, Chairperson for UNESCO ’ s Recommendation on AI Ethics, calls an 'epistemic injustice' in the Global South, given that the global AI ecosystem is today dominated by the Global North. From explainability to understandability and prospect to procedure: Technical explainability hasn ’ t enabled trust, but a number of overlapping procedures are emerging as helpful alternatives. The value of 'opening the black box' is limited, and complex AI systems can only be understood by few stakeholders. Explainability that is both holistic – covering project impact, data provenance, fairness, responsibility – and context-specific to each user, delivers greater transparency. Organisations should embrace multiple explainability procedures, including auditing algorithms. Dr Gemma Galdón-Clavell, Founder, Eticas Consulting, commented, 'Algorithmic audits are one of the most practical things we can do in terms of increasing trust in AI… it ’ s about taking back control.'
'The harms that emerge from reinforcing racial, gender or other socio-economic biases are down to poor AI design, governance and implementation,' commented Peter Campbell, Data & AI Practice Director at Kainos.
'Mitigating this risk and building trust between practitioners, business leaders, regulators, and consumers will require collaboration, upskilling and investment. Kainos is at the forefront of this drive and we ’ ve partnered with Tortoise Media on this report in order to advance the conversation around AI ethics.
'We are also committed to taking real action in this area and are currently refining the Kainos Code of Ethics to guide our own work, hiring data ethicists, and integrating understandability into our processes. Kainos has retained the IEEE as an ethics advisory body, and joined the TechUK Data Analytics & AI Leadership Committee.'
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS NEWS (90%); ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (89%); EXPERIMENTATION & RESEARCH (89%); INVESTIGATIONS (78%); PRESS RELEASES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EXECUTIVES (77%); TYPES OF GOVERNMENT (77%); SAFETY (74%); DEMOCRACIES (73%)
Company:  ACCENTURE PLC (57%)
Ticker: ACN (NYSE) (57%)
Industry: NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (57%); SIC8742 MANAGEMENT CONSULTING SERVICES (57%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%)
Geographic: LONDON, ENGLAND (59%)
Load-Date: May 9, 2022","London: techUK has issued the following press release:
New research from a panel of industry experts convened by Kainos and Tortoise Media calls for immediate action to improve trust for artificial intelligence systems.
techUK members Kainos has partnered with award-winning slow news organisation, Tortoise, to investigate how business leaders should respond to challenges around trust in AI now.
Through interviews with twenty international AI experts – from companies including Accenture, The Alan Turing Institute, and UNESCO – Kainos and Tortoise Media identified three guiding hypotheses to improve trust in AI. These are: harnessing the role of the AI ethicist; embedding pluralistic governing principles to adapt to emerging regulation; and delivering holistic explainability.
'The AI ecosystem has the potential to deliver huge societal benefits in everything from health to education to sustainability,' commented Tom Gray, Group CTO and Director of Innovation, Kainos.
'However, the benefits are likely to unequally benefit the already well off unless we take action. As these technologies become increasingly embedded into society, there are big questions to be answered to assure us that we can trust the fairness of these systems.
'We know what can happen when AI is deployed irresponsibly or inexpertly, from perpetuating systemic biases in justice systems to making an incorrect medical diagnosis. Organisations are now learning the importance of ethical and responsible AI implementation, just as the corporate world has been on a similar journey with other urgent issues – like improving sustainability.
'To help organisations, a practical, nuanced, and sophisticated approach to AI governance is needed now.'
“Trust is a much discussed, but often misunderstood subject in the field of artificial intelligence. This research has given us a clear view from the leading-edge, and access to the perspectives of some of the most prominent experts in the world. At Tortoise, we see AI as a potent enabler, but also as a real threat to democracy, safety and society when it is misused. If there is a real focus on ethics, standards, and social transparency, we think the next five years in AI will be transformational for its power to do good, and well-placed trust is a crucial ingredient,” said Alexandra Mousavizadeh, Director of Tortoise Intelligence.Kainos and Tortoise Media identified the following three hypotheses for establishing trust in AI:
Responsibility is not only a role: The ethicist is necessary but not sufficient to achieve trust throughout the artificial intelligence lifecycle. Many companies are hiring an 'AI ethicist', but this is just one step in the process – the responsibility for trust is best diffused across an organisation rather than placed on a single individual. Ray Eitel-Porter, Global Lead for Responsible AI, Accenture, commented, 'We very much take the view that Responsible AI is a responsibility and a business imperative that has to be embedded across the whole of the organisation and not just within the technology people.' Standardisation from diversity: Standards throughout ethical AI development can help to cultivate trust through the sharing of best practice. Algorithm Watch found 173 AI 'guidelines' were published between 2018 and 2020. Yet, it concluded there was 'a lot of virtue signalling going on and few efforts of enforcement.' Standardisation of ethical AI practices is needed, but they must be developed with a diversity of perspectives. This includes addressing what Emma Ruttkamp-Bloem, Chairperson for UNESCO ’ s Recommendation on AI Ethics, calls an 'epistemic injustice' in the Global South, given that the global AI ecosystem is today dominated by the Global North. From explainability to understandability and prospect to procedure: Technical explainability hasn ’ t enabled trust, but a number of overlapping procedures are emerging as helpful alternatives. The value of 'opening the black box' is limited, and complex AI systems can only be understood by few stakeholders. Explainability that is both holistic – covering project impact, data provenance, fairness, responsibility – and context-specific to each user, delivers greater transparency. Organisations should embrace multiple explainability procedures, including auditing algorithms. Dr Gemma Galdón-Clavell, Founder, Eticas Consulting, commented, 'Algorithmic audits are one of the most practical things we can do in terms of increasing trust in AI… it ’ s about taking back control.'
'The harms that emerge from reinforcing racial, gender or other socio-economic biases are down to poor AI design, governance and implementation,' commented Peter Campbell, Data & AI Practice Director at Kainos.
'Mitigating this risk and building trust between practitioners, business leaders, regulators, and consumers will require collaboration, upskilling and investment. Kainos is at the forefront of this drive and we ’ ve partnered with Tortoise Media on this report in order to advance the conversation around AI ethics.
'We are also committed to taking real action in this area and are currently refining the Kainos Code of Ethics to guide our own work, hiring data ethicists, and integrating understandability into our processes. Kainos has retained the IEEE as an ethics advisory body, and joined the TechUK Data Analytics & AI Leadership Committee.'
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: IFN
Subject: ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); BUSINESS NEWS (90%); ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%); ASSOCIATIONS & ORGANIZATIONS (89%); EXPERIMENTATION & RESEARCH (89%); INVESTIGATIONS (78%); PRESS RELEASES (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EXECUTIVES (77%); TYPES OF GOVERNMENT (77%); SAFETY (74%); DEMOCRACIES (73%)
Company:  ACCENTURE PLC (57%)
Ticker: ACN (NYSE) (57%)
Industry: NAICS541611 ADMINISTRATIVE MANAGEMENT & GENERAL MANAGEMENT CONSULTING SERVICES (57%); SIC8742 MANAGEMENT CONSULTING SERVICES (57%); ARTIFICIAL INTELLIGENCE (90%); ARTIFICIAL INTELLIGENCE ETHICS (90%); SUSTAINABLE DEVELOPMENT (90%)
Geographic: LONDON, ENGLAND (59%)
Load-Date: May 9, 2022",neutral,0.7024106979370117,balanced/neutral,"['fairness', 'transparency', 'explainability', 'safety', 'access']","['justice', 'fairness', 'justice']","['regulation', 'governance', 'standards', 'guidelines', 'should', 'must', 'calls for']",['algorithm'],5,3,7,1
2021,Unknown Title,"Byline: Targeted News Service
Dateline: WEST LAFAYETTE, Indiana 
Body
(TNSres) -- Purdue University issued the following news release:
Building upon its initiative to create a model program focusing on professional ethics at the intersection of the liberal arts and technological innovation, the Purdue University College of Liberal Arts has released a video series exploring the topics as a part of the ""Leading Ethically in the Age of AI and Big Data"" project, supported by a grant from Lilly Endowment Inc.
The ""Tech Ethics Video Series"" includes 22 presentations by leading technology and ethics experts from diverse professional backgrounds, including industry, academia, the nonprofit sector and government. The series features both national and international speakers exploring a wide array of themes regarding ethical considerations across new digital technologies. Topics discussed include responsible and equitable technology, autonomous technologies, the future of work, data governance and privacy, algorithmic bias, artificial intelligence and K12 education, public interest technology and natural language processing.
""As emerging technologies continue to change all sectors of our society, it's important for us to consider their ethical implications,"" said David A. Reingold, the Justin S. Morrill Dean of the College of Liberal Arts and Professor of Sociology at Purdue, who led the project. ""The next generation of leaders must be prepared to navigate the complex challenges that emerging technologies create. The video series encourages future leaders to ask thoughtful questions in pursuit of ethical and sensible solutions to issues surrounding emerging technologies.""
Among the featured experts are Vint Cerf, recognized as one of the ""fathers of the Internet"" and now vice president and chief internet evangelist at Google; Shannon Vallor, the Baillie Gifford Professor in the Ethics of Data and AI at the University of Edinburgh; Jeroen van den Hoven, professor of ethics and technology at Delft University of Technology, Netherlands; and Ora Tanner, founder and CEO of Black Unicorn Education[TM] and co-founder of the AI Education Project.
The ""Tech Ethics Video Series"" is a free resource for educators and communities of experts. The brief videos are presented as concise introductions to complex ethical topics that will stimulate discussions in the classroom, workplace, and among individual users who interact with technology on a daily basis.
The ""Tech Ethics Videos Series"" is a part of the ""Leading Ethically in the Age of AI and Big Data"" initiative supported by a grant from Lilly Endowment Inc. ""Leading Ethically in the Age of AI and Big Data"" focuses on establishing Purdue as a national leader in the ethics of Big Data and AI by fostering an expert community on campus through organizing events and developing a blueprint for undergraduate professional ethics curricula that will address the many ethical challenges presented by fast-evolving digital technologies.
You can watch the Tech Ethics Video Series here (https://www.cla.purdue.edu/about/college-initiatives/leadingethically/techethics.html?_ga=2.184206437.2109790007.1668499711-593498725.1655793326).
* * *
Original text here: https://www.purdue.edu/newsroom/releases/2022/Q4/college-of-liberal-arts-tech-ethics-video-series-explores-the-ethical-leadership-of-emerging-digital-technologies.html
null-7999175 T40-MgEditor
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); EMERGING TECHNOLOGY (93%); ENDOWMENTS (90%); HUMANITIES & SOCIAL SCIENCE (90%); ARTIFICIAL INTELLIGENCE (89%); BUSINESS ETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); FILM (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CURRICULA (78%); NONPROFIT ORGANIZATIONS (78%); UNIVERSITY ADMINISTRATION (78%); EXECUTIVES (77%); FUTURE OF WORK (77%); FOUNDATIONS (76%); NATURAL LANGUAGE PROCESSING (71%); SOCIOLOGY (67%)
Company:  GOOGLE LLC (57%)
Organization: PURDUE UNIVERSITY (93%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE (89%); BIG DATA (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); FILM (89%); COMPUTER NETWORKS (86%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INTERNET & WWW (77%); DATA GOVERNANCE & STEWARDSHIP (76%)
Person: VINTON CERF (79%)
Geographic: INDIANA, USA (79%); NETHERLANDS (72%)
Load-Date: November 17, 2022","(TNSres) -- Purdue University issued the following news release:
Building upon its initiative to create a model program focusing on professional ethics at the intersection of the liberal arts and technological innovation, the Purdue University College of Liberal Arts has released a video series exploring the topics as a part of the ""Leading Ethically in the Age of AI and Big Data"" project, supported by a grant from Lilly Endowment Inc.
The ""Tech Ethics Video Series"" includes 22 presentations by leading technology and ethics experts from diverse professional backgrounds, including industry, academia, the nonprofit sector and government. The series features both national and international speakers exploring a wide array of themes regarding ethical considerations across new digital technologies. Topics discussed include responsible and equitable technology, autonomous technologies, the future of work, data governance and privacy, algorithmic bias, artificial intelligence and K12 education, public interest technology and natural language processing.
""As emerging technologies continue to change all sectors of our society, it's important for us to consider their ethical implications,"" said David A. Reingold, the Justin S. Morrill Dean of the College of Liberal Arts and Professor of Sociology at Purdue, who led the project. ""The next generation of leaders must be prepared to navigate the complex challenges that emerging technologies create. The video series encourages future leaders to ask thoughtful questions in pursuit of ethical and sensible solutions to issues surrounding emerging technologies.""
Among the featured experts are Vint Cerf, recognized as one of the ""fathers of the Internet"" and now vice president and chief internet evangelist at Google; Shannon Vallor, the Baillie Gifford Professor in the Ethics of Data and AI at the University of Edinburgh; Jeroen van den Hoven, professor of ethics and technology at Delft University of Technology, Netherlands; and Ora Tanner, founder and CEO of Black Unicorn Education[TM] and co-founder of the AI Education Project.
The ""Tech Ethics Video Series"" is a free resource for educators and communities of experts. The brief videos are presented as concise introductions to complex ethical topics that will stimulate discussions in the classroom, workplace, and among individual users who interact with technology on a daily basis.
The ""Tech Ethics Videos Series"" is a part of the ""Leading Ethically in the Age of AI and Big Data"" initiative supported by a grant from Lilly Endowment Inc. ""Leading Ethically in the Age of AI and Big Data"" focuses on establishing Purdue as a national leader in the ethics of Big Data and AI by fostering an expert community on campus through organizing events and developing a blueprint for undergraduate professional ethics curricula that will address the many ethical challenges presented by fast-evolving digital technologies.
You can watch the Tech Ethics Video Series here (https://www.cla.purdue.edu/about/college-initiatives/leadingethically/techethics.html?_ga=2.184206437.2109790007.1668499711-593498725.1655793326).
* * *
Original text here: https://www.purdue.edu/newsroom/releases/2022/Q4/college-of-liberal-arts-tech-ethics-video-series-explores-the-ethical-leadership-of-emerging-digital-technologies.html
null-7999175 T40-MgEditor
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (95%); EMERGING TECHNOLOGY (93%); ENDOWMENTS (90%); HUMANITIES & SOCIAL SCIENCE (90%); ARTIFICIAL INTELLIGENCE (89%); BUSINESS ETHICS (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); FILM (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); CURRICULA (78%); NONPROFIT ORGANIZATIONS (78%); UNIVERSITY ADMINISTRATION (78%); EXECUTIVES (77%); FUTURE OF WORK (77%); FOUNDATIONS (76%); NATURAL LANGUAGE PROCESSING (71%); SOCIOLOGY (67%)
Company:  GOOGLE LLC (57%)
Organization: PURDUE UNIVERSITY (93%)
Industry: NAICS519290 WEB SEARCH PORTALS AND ALL OTHER INFORMATION SERVICES (57%); ARTIFICIAL INTELLIGENCE (89%); BIG DATA (89%); COLLEGE & UNIVERSITY PROFESSORS (89%); FILM (89%); COMPUTER NETWORKS (86%); ARTIFICIAL INTELLIGENCE ETHICS (78%); INTERNET & WWW (77%); DATA GOVERNANCE & STEWARDSHIP (76%)
Person: VINTON CERF (79%)
Geographic: INDIANA, USA (79%); NETHERLANDS (72%)
Load-Date: November 17, 2022",neutral,0.6772460341453552,balanced/neutral,"['privacy', 'bias']",[],"['governance', 'must']",['natural language processing'],2,0,2,1
2021,Unknown Title,"Body
Hiroaki Kitano, CEO, Sony AI, has been appointed by Singapore's Minister for Communications and Information to continue to serve as a member of Singapore's Advisory Council on the Ethical Use of AI and Data (Advisory Council) for the next three-year term, starting this year (2022  2025). Kitano is being invited to remain on the Advisory Council to provide his expertise and perspectives in support of the development of Singapore's approach to trustworthy AI and data governance.
The Advisory Council was formed in 2018 for the purpose of advising Singapore Government on ethical, policy and governance issues arising from the use of data-driven technologies in the private sector and providing general guidance to businesses to minimize risks, and to mitigate the adverse impact on consumers from the use of data-driven technologies.
Kitano, along with fellow members of the Advisory Council, will contribute to the strategic objectives of strengthening trust and adoption in AI technologies and working with international partners to shape international discourse on AI.
""I am honored to be invited to continue my tenure and serve another term on Singapore's Advisory Council on the Ethical Use of AI and Data,"" said Kitano. ""I look forward to working with the Council to continue to provide practical guidance in the development and deployment of trustworthy AI in Singapore and around the globe.""
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 812
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); APPOINTMENTS (91%); ETHICS (90%); CORPORATE GOVERNANCE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT ADVISORS & MINISTERS (78%); TELECOMMUNICATIONS DEPARTMENTS (78%)
Company: SONY GROUP CORP (93%)
Ticker: SONY (93%)
Industry: NAICS512250 RECORD PRODUCTION & DISTRIBUTION (93%); NAICS339930 DOLL, TOY & GAME MANUFACTURING (93%); NAICS334310 AUDIO & VIDEO EQUIPMENT MANUFACTURING (93%); SIC3651 HOUSEHOLD AUDIO & VIDEO EQUIPMENT (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); TELECOMMUNICATIONS DEPARTMENTS (78%); DATA GOVERNANCE & STEWARDSHIP (77%)
Geographic: SINGAPORE (90%)
Load-Date: March 17, 2022","Hiroaki Kitano, CEO, Sony AI, has been appointed by Singapore's Minister for Communications and Information to continue to serve as a member of Singapore's Advisory Council on the Ethical Use of AI and Data (Advisory Council) for the next three-year term, starting this year (2022  2025). Kitano is being invited to remain on the Advisory Council to provide his expertise and perspectives in support of the development of Singapore's approach to trustworthy AI and data governance.
The Advisory Council was formed in 2018 for the purpose of advising Singapore Government on ethical, policy and governance issues arising from the use of data-driven technologies in the private sector and providing general guidance to businesses to minimize risks, and to mitigate the adverse impact on consumers from the use of data-driven technologies.
Kitano, along with fellow members of the Advisory Council, will contribute to the strategic objectives of strengthening trust and adoption in AI technologies and working with international partners to shape international discourse on AI.
""I am honored to be invited to continue my tenure and serve another term on Singapore's Advisory Council on the Ethical Use of AI and Data,"" said Kitano. ""I look forward to working with the Council to continue to provide practical guidance in the development and deployment of trustworthy AI in Singapore and around the globe.""
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 812
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); APPOINTMENTS (91%); ETHICS (90%); CORPORATE GOVERNANCE (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); GOVERNMENT ADVISORS & MINISTERS (78%); TELECOMMUNICATIONS DEPARTMENTS (78%)
Company: SONY GROUP CORP (93%)
Ticker: SONY (93%)
Industry: NAICS512250 RECORD PRODUCTION & DISTRIBUTION (93%); NAICS339930 DOLL, TOY & GAME MANUFACTURING (93%); NAICS334310 AUDIO & VIDEO EQUIPMENT MANUFACTURING (93%); SIC3651 HOUSEHOLD AUDIO & VIDEO EQUIPMENT (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); TELECOMMUNICATIONS DEPARTMENTS (78%); DATA GOVERNANCE & STEWARDSHIP (77%)
Geographic: SINGAPORE (90%)
Load-Date: March 17, 2022",neutral,0.7337513566017151,balanced/neutral,[],[],"['policy', 'governance']",[],0,0,2,0
2021,Unknown Title,"Dateline: New Delhi, 2022-03-17 15:27:38 
Body
 March 17 -- With a plethora of stakeholders in the healthcare space and an expanding list of digital tools, it can be a challenge to find a starting place for a national digital health strategy. France decided to put ethics at the center of its approach to creating digital health services. 
""In France we have a patient-centered approach ... We want the patients to be full members of their healthcare team. So we want the patient to be informed, we want the patient to be involved in the digital process, we want the patient to be in control of their data and we want them to be really engaged,"" Dr. Brigitte Séroussi, Director of Projects in charge of digital health ethics at the eHealth Delegation of the French Ministry of Health, said this during a panel discussion of HIMSS22. 
""There are some concerns about the counterparts of digital health. Patients are very conscious about the fact there should be a face-to-face relationship when they request it. They want to have real transparency of the data processing. Who has access to their data, when and why? They want AI solutions guaranteed to have no bias. They also want to have digital health that is conscious of the environmental impact.""
The team took into account the four principles of medicine: beneficence, autonomy, non-maleficence, justice and the Hippocratic Oath. They then combined these with digital health principals. 
""We have to cross the ethical dimensions related with the dimensions with digital ethics. When you have a digital tool you want a tool that is easy to use, that is accessible to use, that is at the user's service, not the reverse. ... When you cross these two dimensions you ... have information transparency, then you have information transparency with trust, and then we have adoptions.""
But the government didn't just look at traditional health ethics metrics. It also explored how digital's environmental impact. 
""Digital is not material, but it has an environmental impact, and this has to be taken into account when deploying digital health. We know the digital economy is 3.5% of greenhouse gas emission worldwide, and in France we know the health sector is 8% of greenhouse gas emissions,"" she said. 
Now France is helping to spread their digital health methods in other parts of the E.U. 
""What is at stake is to provide the right services to the E.U. citizen,"" Isabelle Zablit-Schmitz, eHealth Europe and International Director for the French Ministry of Health, said during the panel. 
Séroussi said that at the end of the day having patients lead the efforts is crucial, and patients need the assurance of an ethical system. 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (90%); POLLUTION & ENVIRONMENTAL IMPACTS (89%); HEALTH DEPARTMENTS (78%); MEDICAL ETHICS (78%); GOVERNMENT BODIES & OFFICES (74%); DIGITAL ECONOMY (73%); EMISSIONS (70%); GREENHOUSE GASES (64%); EUROPEAN UNION CITIZENSHIP (50%)
Industry: HEALTH CARE (89%); HEALTH DEPARTMENTS (78%); DIGITAL ECONOMY (73%); EMISSIONS (70%)
Geographic: NEW DELHI, INDIA (79%); FRANCE (95%); EUROPE (79%)
Load-Date: March 17, 2022","March 17 -- With a plethora of stakeholders in the healthcare space and an expanding list of digital tools, it can be a challenge to find a starting place for a national digital health strategy. France decided to put ethics at the center of its approach to creating digital health services. 
""In France we have a patient-centered approach ... We want the patients to be full members of their healthcare team. So we want the patient to be informed, we want the patient to be involved in the digital process, we want the patient to be in control of their data and we want them to be really engaged,"" Dr. Brigitte Séroussi, Director of Projects in charge of digital health ethics at the eHealth Delegation of the French Ministry of Health, said this during a panel discussion of HIMSS22. 
""There are some concerns about the counterparts of digital health. Patients are very conscious about the fact there should be a face-to-face relationship when they request it. They want to have real transparency of the data processing. Who has access to their data, when and why? They want AI solutions guaranteed to have no bias. They also want to have digital health that is conscious of the environmental impact.""
The team took into account the four principles of medicine: beneficence, autonomy, non-maleficence, justice and the Hippocratic Oath. They then combined these with digital health principals. 
""We have to cross the ethical dimensions related with the dimensions with digital ethics. When you have a digital tool you want a tool that is easy to use, that is accessible to use, that is at the user's service, not the reverse. ... When you cross these two dimensions you ... have information transparency, then you have information transparency with trust, and then we have adoptions.""
But the government didn't just look at traditional health ethics metrics. It also explored how digital's environmental impact. 
""Digital is not material, but it has an environmental impact, and this has to be taken into account when deploying digital health. We know the digital economy is 3.5% of greenhouse gas emission worldwide, and in France we know the health sector is 8% of greenhouse gas emissions,"" she said. 
Now France is helping to spread their digital health methods in other parts of the E.U. 
""What is at stake is to provide the right services to the E.U. citizen,"" Isabelle Zablit-Schmitz, eHealth Europe and International Director for the French Ministry of Health, said during the panel. 
Séroussi said that at the end of the day having patients lead the efforts is crucial, and patients need the assurance of an ethical system. 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (90%); POLLUTION & ENVIRONMENTAL IMPACTS (89%); HEALTH DEPARTMENTS (78%); MEDICAL ETHICS (78%); GOVERNMENT BODIES & OFFICES (74%); DIGITAL ECONOMY (73%); EMISSIONS (70%); GREENHOUSE GASES (64%); EUROPEAN UNION CITIZENSHIP (50%)
Industry: HEALTH CARE (89%); HEALTH DEPARTMENTS (78%); DIGITAL ECONOMY (73%); EMISSIONS (70%)
Geographic: NEW DELHI, INDIA (79%); FRANCE (95%); EUROPE (79%)
Load-Date: March 17, 2022",neutral,0.8253295421600342,balanced/neutral,"['bias', 'transparency', 'autonomy', 'access', 'environmental impact']","['justice', 'autonomy', 'beneficence', 'non-maleficence', 'justice']",['should'],[],5,5,1,0
2021,Unknown Title,"Body
2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at CDC & FDA Daily -- New study results on robotics have been published. According to news originating from Cheongju, South Korea, by NewsRx correspondents, research stated, ""With continuing developments in artificial intelligence (AI) and robot technology, ethical issues related to digital humans, AI avatars, intelligent process automation, robots, cyborgs, and autonomous vehicles are emerging, and the need for cultural and social sustainability through AI ethics is increasing."" 
 The news editors obtained a quote from the research from Cheongju National University of Education: ""Moreover, as the use of video conferencing and metaverse platforms has increased due to COVID-19, ethics concepts and boundaries related to information and communications technology, cyber etiquette, AI ethics, and robot ethics have become more ambiguous. Because the definitions of ethics domains may be confusing due to the various types of computing platforms available, this paper attempts to classify these ethics domains according to three main platforms: computing devices, intermediary platforms, and physical computing devices. This classification provides a conceptual ethics framework that encompasses computer ethics, information ethics, cyber ethics, robot ethics, and AI ethics. Several examples are provided to clarify the boundaries between the various ethics and platforms."" 
 According to the news editors, the research concluded: ""The results of this study can be the educational basis for the sustainability of society on ethical issues according to the development of technology."" 
 For more information on this research see: An Information Ethics Framework Based on ICT Platforms. Information, 2022,13(440):440. (Information - http://www.mdpi.com/journal/information/). The publisher for Information is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/info13090440. 
 Our news journalists report that additional information may be obtained by contacting Jeonghye Han, Department of Computer Education, Cheongju National University of Education, Cheongju 28690, South Korea. 
 Keywords for this news article include: Cheongju National University of Education, Cheongju, South Korea, Asia, Emerging Technologies, Machine Learning, Robot, Robotics, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); SOCIAL SCIENCE EDUCATION (90%); COMPUTER SCIENCE (79%); EMERGING TECHNOLOGY (79%); INFECTIOUS DISEASE (79%); JOURNALISM (78%); MACHINE LEARNING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); COVID CORONAVIRUS (74%); EXPERIMENTATION & RESEARCH (73%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); VIDEO CONFERENCING (71%); SUSTAINABILITY (70%); COVID-19 CORONAVIRUS (54%); Emerging Technologies;Machine Learning;Robot;Robotics;Technology (%)
Organization: FOOD & DRUG ADMINISTRATION (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); ROBOTICS (90%); COMPUTER EQUIPMENT (89%); COMPUTER SCIENCE (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); MACHINE LEARNING (78%); PUBLISHING (78%); METAVERSE (77%); AUTONOMOUS VEHICLES (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); VIDEO CONFERENCING (71%)
Geographic: ASIA (58%)
Load-Date: October 7, 2022","2022 OCT 07 (NewsRx) -- By a News Reporter-Staff News Editor at CDC & FDA Daily -- New study results on robotics have been published. According to news originating from Cheongju, South Korea, by NewsRx correspondents, research stated, ""With continuing developments in artificial intelligence (AI) and robot technology, ethical issues related to digital humans, AI avatars, intelligent process automation, robots, cyborgs, and autonomous vehicles are emerging, and the need for cultural and social sustainability through AI ethics is increasing."" 
 The news editors obtained a quote from the research from Cheongju National University of Education: ""Moreover, as the use of video conferencing and metaverse platforms has increased due to COVID-19, ethics concepts and boundaries related to information and communications technology, cyber etiquette, AI ethics, and robot ethics have become more ambiguous. Because the definitions of ethics domains may be confusing due to the various types of computing platforms available, this paper attempts to classify these ethics domains according to three main platforms: computing devices, intermediary platforms, and physical computing devices. This classification provides a conceptual ethics framework that encompasses computer ethics, information ethics, cyber ethics, robot ethics, and AI ethics. Several examples are provided to clarify the boundaries between the various ethics and platforms."" 
 According to the news editors, the research concluded: ""The results of this study can be the educational basis for the sustainability of society on ethical issues according to the development of technology."" 
 For more information on this research see: An Information Ethics Framework Based on ICT Platforms. Information, 2022,13(440):440. (Information - http://www.mdpi.com/journal/information/). The publisher for Information is MDPI AG. 
 A free version of this journal article is available at https://doi.org/10.3390/info13090440. 
 Our news journalists report that additional information may be obtained by contacting Jeonghye Han, Department of Computer Education, Cheongju National University of Education, Cheongju 28690, South Korea. 
 Keywords for this news article include: Cheongju National University of Education, Cheongju, South Korea, Asia, Emerging Technologies, Machine Learning, Robot, Robotics, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); RESEARCH REPORTS (90%); ROBOTICS (90%); SOCIAL SCIENCE EDUCATION (90%); COMPUTER SCIENCE (79%); EMERGING TECHNOLOGY (79%); INFECTIOUS DISEASE (79%); JOURNALISM (78%); MACHINE LEARNING (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (77%); COVID CORONAVIRUS (74%); EXPERIMENTATION & RESEARCH (73%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); VIDEO CONFERENCING (71%); SUSTAINABILITY (70%); COVID-19 CORONAVIRUS (54%); Emerging Technologies;Machine Learning;Robot;Robotics;Technology (%)
Organization: FOOD & DRUG ADMINISTRATION (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); CHATBOTS (90%); ROBOTICS (90%); COMPUTER EQUIPMENT (89%); COMPUTER SCIENCE (79%); COMPUTING & INFORMATION TECHNOLOGY (78%); MACHINE LEARNING (78%); PUBLISHING (78%); METAVERSE (77%); AUTONOMOUS VEHICLES (74%); WRITERS (73%); COLLEGES & UNIVERSITIES (72%); VIDEO CONFERENCING (71%)
Geographic: ASIA (58%)
Load-Date: October 7, 2022",neutral,0.9078807234764099,balanced/neutral,[],[],['framework'],"['machine learning', 'robot', 'robotics']",0,0,1,3
2021,Unknown Title,"Body
2022 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating in Heidelberg, Germany, by NewsRx journalists, research stated, ""AAL encompasses smart home technologies that are installed in the personal living environment in order to support older, disabled, as well as chronically ill people with the goal of delaying or reducing their need for nursing care in a care facility. Artificial intelligence (AI) is seen as an important tool for assisting the target group in their daily lives."" 
 Financial supporters for this research include Ministerium fur Wissenschaft, Forschung und Kunst Baden-Wurttemberg, Hans-Bockler-Stiftung, Medizinische Fakultat Heidelberg der Universitat Heidelberg. 
 The news reporters obtained a quote from the research from Ruprecht-Karls-University Heidelberg, ""A literature search and qualitative content analysis of 255 articles from computer science and engineering was conducted to explore the usage of ethical concepts. From an ethical point of view, the concept of independence and self-determination on the one hand and the possible loss of privacy on the other hand are widely discussed in the context of AAL. These concepts are adopted by the technical discourse in the sense that independence, self-determination and privacy are recognized as important values. Nevertheless, our research shows that these concepts have different usages and meanings in the ethical and the technical discourses. In the paper, we aim to map the different meanings of independence, self-determination and privacy as they can be found in the context of technological research on AI-based AAL systems. It investigates the interpretation of these ethical and social concepts which technicians try to build into AAL systems."" 
 According to the news reporters, the research concluded: ""In a second step, these interpretations are contextualized with concepts from the ethical discourse on AI-based assistive technologies."" 
 This research has been peer-reviewed. 
 For more information on this research see: Lost in translation? Conceptions of privacy and independence in the technical development of AI-based AAL. Medicine, Health Care and Philosophy, 2022. Medicine, Health Care and Philosophy can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Medicine, Health Care and Philosophy - www.springerlink.com/content/1386-7423/) 
 Our news correspondents report that additional information may be obtained by contacting Kris Vera Hartmann, Institute for History and Ethics of Medicine, Faculty of Medicine, Ruprecht-Karls-University Heidelberg, Heidelberg, Germany. Additional authors for this research include Nadia Primc and Giovanni Rubeis. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11019-022-10126-8. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal Medicine, Health Care and Philosophy can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Heidelberg, Germany, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); INVESTIGATIONS (89%); MEDICINE & HEALTH (89%); ENGINEERING (79%); COMPUTER SCIENCE (78%); NURSES & NURSING (78%); WRITERS (78%); PRIVACY RIGHTS (76%); CHRONIC DISEASES (71%); MEDICAL ETHICS (71%); PROSTHETIC & ASSISTIVE DEVICES (71%); Heidelberg;Germany;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); NEWS REPORTING (90%); HEALTH CARE (89%); ENGINEERING (79%); COMPUTER SCIENCE (78%); NURSES & NURSING (78%); WRITERS (78%); SMART HOMES (74%); PROSTHETIC & ASSISTIVE DEVICES (71%); BUILDING AUTOMATION (57%)
Geographic: BADEN-WURTTEMBERG, GERMANY (79%); GERMANY (94%); EUROPE (73%); NETHERLANDS (58%)
Load-Date: November 22, 2022","2022 NOV 22 (NewsRx) -- By a News Reporter-Staff News Editor at Tech Daily News -- New research on Technology is the subject of a report. According to news reporting originating in Heidelberg, Germany, by NewsRx journalists, research stated, ""AAL encompasses smart home technologies that are installed in the personal living environment in order to support older, disabled, as well as chronically ill people with the goal of delaying or reducing their need for nursing care in a care facility. Artificial intelligence (AI) is seen as an important tool for assisting the target group in their daily lives."" 
 Financial supporters for this research include Ministerium fur Wissenschaft, Forschung und Kunst Baden-Wurttemberg, Hans-Bockler-Stiftung, Medizinische Fakultat Heidelberg der Universitat Heidelberg. 
 The news reporters obtained a quote from the research from Ruprecht-Karls-University Heidelberg, ""A literature search and qualitative content analysis of 255 articles from computer science and engineering was conducted to explore the usage of ethical concepts. From an ethical point of view, the concept of independence and self-determination on the one hand and the possible loss of privacy on the other hand are widely discussed in the context of AAL. These concepts are adopted by the technical discourse in the sense that independence, self-determination and privacy are recognized as important values. Nevertheless, our research shows that these concepts have different usages and meanings in the ethical and the technical discourses. In the paper, we aim to map the different meanings of independence, self-determination and privacy as they can be found in the context of technological research on AI-based AAL systems. It investigates the interpretation of these ethical and social concepts which technicians try to build into AAL systems."" 
 According to the news reporters, the research concluded: ""In a second step, these interpretations are contextualized with concepts from the ethical discourse on AI-based assistive technologies."" 
 This research has been peer-reviewed. 
 For more information on this research see: Lost in translation? Conceptions of privacy and independence in the technical development of AI-based AAL. Medicine, Health Care and Philosophy, 2022. Medicine, Health Care and Philosophy can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. (Springer - www.springer.com; Medicine, Health Care and Philosophy - www.springerlink.com/content/1386-7423/) 
 Our news correspondents report that additional information may be obtained by contacting Kris Vera Hartmann, Institute for History and Ethics of Medicine, Faculty of Medicine, Ruprecht-Karls-University Heidelberg, Heidelberg, Germany. Additional authors for this research include Nadia Primc and Giovanni Rubeis. 
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s11019-022-10126-8. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation. 
 The publisher of the journal Medicine, Health Care and Philosophy can be contacted at: Springer, Van Godewijckstraat 30, 3311 Gz Dordrecht, Netherlands. 
 Keywords for this news article include: Heidelberg, Germany, Europe, Technology. 
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC 
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); NEWS REPORTING (90%); INVESTIGATIONS (89%); MEDICINE & HEALTH (89%); ENGINEERING (79%); COMPUTER SCIENCE (78%); NURSES & NURSING (78%); WRITERS (78%); PRIVACY RIGHTS (76%); CHRONIC DISEASES (71%); MEDICAL ETHICS (71%); PROSTHETIC & ASSISTIVE DEVICES (71%); Heidelberg;Germany;Europe;Technology (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); NEWS REPORTING (90%); HEALTH CARE (89%); ENGINEERING (79%); COMPUTER SCIENCE (78%); NURSES & NURSING (78%); WRITERS (78%); SMART HOMES (74%); PROSTHETIC & ASSISTIVE DEVICES (71%); BUILDING AUTOMATION (57%)
Geographic: BADEN-WURTTEMBERG, GERMANY (79%); GERMANY (94%); EUROPE (73%); NETHERLANDS (58%)
Load-Date: November 22, 2022",neutral,0.8056080341339111,balanced/neutral,['privacy'],[],[],[],1,0,0,0
2021,Unknown Title,"Body
PETAH TIKVA, Israel and TYSONS CORNER, Va., March  08, 2022  (GLOBE NEWSWIRE) -- Cellebrite DI Ltd. (Nasdaq: CLBT), a global leader in Digital Intelligence (DI) solutions for the public and private sectors, today announced that Dr. Guy Rotkopf, former Director General of the Israel Ministry of Justice, has been named as the new Chairperson of Cellebrite’s Ethics & Integrity Committee. Dr. Rotkopf brings to the Committee a strong law and academic background. Dr. Rotkopf has a PH. D. in law from Bar-Ilan University, an LL. M from Duke University School of Law, and an LL. B in law from the Academic College of Management.
Founded in August of 2021, the Committee advises the Board of Directors on matters pertaining to evolving international law, ethical considerations related to responsible business practices, and requirements under law and regulations applied to the sale and use of Cellebrite’s technologies. Rotkopf will oversee a committee currently comprised of eight members with diverse backgrounds in human rights, education, foreign affairs, defense, national security, and technology use in the public and in the private sector. Cellebrite CEO, Yossi Carmil, said, “We welcome the addition of Dr. Rotkopf to the Ethics and Integrity Committee. His skillset and experience will complement the backgrounds of the existing committee members and provide us with added perspective to ensure Cellebrite receives expert recommendations and consultancy on implementing best practices in ethics as part of our ongoing business practices.”“It’s with great integrity that I accept this appointment and I will, together with the members of the Ethics and Integrity Committee, work hard to provide guidance towards ethical practices that support the principles and policies guiding Cellebrite’s sales of solutions and services, stance on emerging and developing trends, and adapting policies to address ethics and human rights matters,” said Dr. Guy Rotkopf.
Cellebrite’s mission is to enable its customers to protect and save lives, accelerate justice, and preserve privacy in communities around the globe. The Ethics & Integrity Committee will further this mission by providing the Board with unbiased, expert advice to ensure adherence to high ethical standards for the benefit of all stakeholders. For more information about Cellebrite’s commitment to Ethics and Integrity, please visit:https://cellebrite.com/en/ethics-integrity.
About CellebriteCellebrite’s (Nasdaq: CLBT) mission is to enable its customers to protect and save lives, accelerate justice, and preserve privacy in communities around the world. We are a global leader in Digital Intelligence solutions for the public and private sectors, empowering organizations in mastering the complexities of legally sanctioned digital investigations by streamlining intelligence processes. Trusted by thousands of leading agencies and companies worldwide, Cellebrite’s Digital Intelligence platform and solutions transform how customers collect, review, analyze and manage data in legally sanctioned investigations. To learn more visit us at www.cellebrite.com, https://investors.cellebrite.com, or follow us on Twitter at @Cellebrite.
Caution Regarding Forward Looking Statements
This document includes “forward looking statements” within the meaning of the “safe harbor” provisions of the United States Private Securities Litigation Reform Act of 1995. Forward-looking statements may be identified by the use of words such as “forecast,” “intend,” “seek,” “target,” “anticipate,” “believe,” “could,” “continue,” “expect,” “estimate,” “may,” “plan,” “outlook,” “future” and “project” and other similar expressions that predict, project or indicate future events or trends or that are not statements of historical matters. Such forward looking statements include estimated financial information. Such forward looking statements with respect to revenues, earnings, performance, strategies, prospects and other aspects of the business of Cellebrite are based on current expectations that are subject to risks and uncertainties. A number of factors could cause actual results or outcomes to differ materially from those indicated by such forward looking statements. These factors include, but are not limited to: Cellebrite’s ability to develop technologically advanced solutions and successfully integrate with the software solutions used by customers; acceptance of solutions by customers; errors, failures, defects or bugs in solutions; a failure to maintain sales and marketing personnel productivity or hire, integrate and retain additional sales and marketing personnel; the impact of the global COVID-19 pandemic; the impact of competition on pricing and on Cellebrite’s market share; sub-optimal results from products due to misuse by customers; Cellebrite’s failure to maintain and enhance its reputation and brand; inaccuracy of the estimates of Cellebrite’s market opportunity and forecasts of market growth; changes to packaging and licensing models that adversely affect the ability to attract or retain customers; failure to manage future growth effectively; failure to introduce new solutions and add-ons; issues in the use of artificial intelligence resulting in reputational harm or liability; the need for additional capital to support the growth of Cellebrite’s business; a failure to maintain the security of operations and the integrity of software solutions; the impact of government budgeting cycles and appropriations, early termination, audits, investigations, sanctions and penalties; a decline in government budgets, changes in spending or budgetary priorities, or delays in contract awards; a failure to adequately obtain, maintain, protect and enforce Cellebrite’s intellectual property or infringement of the intellectual property rights of others; perceptions or court or regulatory decisions that Cellebrite’s solutions violate privacy rights; the use of solutions by customers in a way that is, or that is perceived to be, incompatible with human rights; failure to comply with laws regarding privacy, data protection and security, technology protection, sanctions, export controls and other matters; and other factors, risks and uncertainties set forth in the sections titled “Risk Factors” and “Cautionary Note Regarding Forward-Looking Statements” in the final proxy statement/prospectus filed with the SEC on August 5, 2021 and in other documents filed by Cellebrite with the SEC, which are available free of charge at www.sec.gov. You are cautioned not to place undue reliance upon any forward-looking statements, which speak only as of the date made, in this communication or elsewhere. Cellebrite undertakes no obligation to update its forward-looking statements, whether as a result of new information, future developments or otherwise, should circumstances change, except as otherwise required by securities and other applicable laws.   
ContactsMedia Adam Jaffe VP of Global Communications+1 973 206 7643adam.jaffe@cellebrite.com - or -RapidResponse@cellebrite.com
InvestorsAnat Earon-Heilborn VP Investor Relations+972 73 394 8440investors@cellebrite.com
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (92%); ETHICS (91%); COMPANY ACTIVITIES & MANAGEMENT (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); JUSTICE DEPARTMENTS (90%); INVESTIGATIONS (89%); APPOINTMENTS (79%); ASSOCIATIONS & ORGANIZATIONS (79%); BOARDS OF DIRECTORS (79%); EXECUTIVES (79%); BEST PRACTICES (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); HUMAN RIGHTS (78%); INTERNATIONAL LAW (78%); LAW SCHOOLS (78%); BUSINESS EDUCATION (76%); GRADUATE & PROFESSIONAL SCHOOLS (76%); LAW & LEGAL SYSTEM (76%); NATIONAL SECURITY (73%); CELLEBRITE (%); ENTERPRISE SAAS (%); SAAS (%); ETHICS AND INTEGRITY (%); LAW ENFORCEMENT (%); DIGITAL INTELLIGENCE (%)
Company: CELLEBRITE DI LTD
Organization: DUKE UNIVERSITY (57%)
Ticker: CLBT (NASDAQ); CLBTW (NASDAQ)
Industry: LAW SCHOOLS (78%); GRADUATE & PROFESSIONAL SCHOOLS (76%); CONSULTING SERVICES (72%); Mobile Telecommunications (%)
Company-Terms: Mobile Telecommunications Cellebrite DI Ltd CLBT (NASDAQ) CLBTW (NASDAQ) Petah Tikva ::issuer-country=IL:: IL
Geographic: VIRGINIA, USA (79%)
Load-Date: March 8, 2022","PETAH TIKVA, Israel and TYSONS CORNER, Va., March  08, 2022  (GLOBE NEWSWIRE) -- Cellebrite DI Ltd. (Nasdaq: CLBT), a global leader in Digital Intelligence (DI) solutions for the public and private sectors, today announced that Dr. Guy Rotkopf, former Director General of the Israel Ministry of Justice, has been named as the new Chairperson of Cellebrite’s Ethics & Integrity Committee. Dr. Rotkopf brings to the Committee a strong law and academic background. Dr. Rotkopf has a PH. D. in law from Bar-Ilan University, an LL. M from Duke University School of Law, and an LL. B in law from the Academic College of Management.
Founded in August of 2021, the Committee advises the Board of Directors on matters pertaining to evolving international law, ethical considerations related to responsible business practices, and requirements under law and regulations applied to the sale and use of Cellebrite’s technologies. Rotkopf will oversee a committee currently comprised of eight members with diverse backgrounds in human rights, education, foreign affairs, defense, national security, and technology use in the public and in the private sector. Cellebrite CEO, Yossi Carmil, said, “We welcome the addition of Dr. Rotkopf to the Ethics and Integrity Committee. His skillset and experience will complement the backgrounds of the existing committee members and provide us with added perspective to ensure Cellebrite receives expert recommendations and consultancy on implementing best practices in ethics as part of our ongoing business practices.”“It’s with great integrity that I accept this appointment and I will, together with the members of the Ethics and Integrity Committee, work hard to provide guidance towards ethical practices that support the principles and policies guiding Cellebrite’s sales of solutions and services, stance on emerging and developing trends, and adapting policies to address ethics and human rights matters,” said Dr. Guy Rotkopf.
Cellebrite’s mission is to enable its customers to protect and save lives, accelerate justice, and preserve privacy in communities around the globe. The Ethics & Integrity Committee will further this mission by providing the Board with unbiased, expert advice to ensure adherence to high ethical standards for the benefit of all stakeholders. For more information about Cellebrite’s commitment to Ethics and Integrity, please visit:https://cellebrite.com/en/ethics-integrity.
About CellebriteCellebrite’s (Nasdaq: CLBT) mission is to enable its customers to protect and save lives, accelerate justice, and preserve privacy in communities around the world. We are a global leader in Digital Intelligence solutions for the public and private sectors, empowering organizations in mastering the complexities of legally sanctioned digital investigations by streamlining intelligence processes. Trusted by thousands of leading agencies and companies worldwide, Cellebrite’s Digital Intelligence platform and solutions transform how customers collect, review, analyze and manage data in legally sanctioned investigations. To learn more visit us at www.cellebrite.com, https://investors.cellebrite.com, or follow us on Twitter at @Cellebrite.
Caution Regarding Forward Looking Statements
This document includes “forward looking statements” within the meaning of the “safe harbor” provisions of the United States Private Securities Litigation Reform Act of 1995. Forward-looking statements may be identified by the use of words such as “forecast,” “intend,” “seek,” “target,” “anticipate,” “believe,” “could,” “continue,” “expect,” “estimate,” “may,” “plan,” “outlook,” “future” and “project” and other similar expressions that predict, project or indicate future events or trends or that are not statements of historical matters. Such forward looking statements include estimated financial information. Such forward looking statements with respect to revenues, earnings, performance, strategies, prospects and other aspects of the business of Cellebrite are based on current expectations that are subject to risks and uncertainties. A number of factors could cause actual results or outcomes to differ materially from those indicated by such forward looking statements. These factors include, but are not limited to: Cellebrite’s ability to develop technologically advanced solutions and successfully integrate with the software solutions used by customers; acceptance of solutions by customers; errors, failures, defects or bugs in solutions; a failure to maintain sales and marketing personnel productivity or hire, integrate and retain additional sales and marketing personnel; the impact of the global COVID-19 pandemic; the impact of competition on pricing and on Cellebrite’s market share; sub-optimal results from products due to misuse by customers; Cellebrite’s failure to maintain and enhance its reputation and brand; inaccuracy of the estimates of Cellebrite’s market opportunity and forecasts of market growth; changes to packaging and licensing models that adversely affect the ability to attract or retain customers; failure to manage future growth effectively; failure to introduce new solutions and add-ons; issues in the use of artificial intelligence resulting in reputational harm or liability; the need for additional capital to support the growth of Cellebrite’s business; a failure to maintain the security of operations and the integrity of software solutions; the impact of government budgeting cycles and appropriations, early termination, audits, investigations, sanctions and penalties; a decline in government budgets, changes in spending or budgetary priorities, or delays in contract awards; a failure to adequately obtain, maintain, protect and enforce Cellebrite’s intellectual property or infringement of the intellectual property rights of others; perceptions or court or regulatory decisions that Cellebrite’s solutions violate privacy rights; the use of solutions by customers in a way that is, or that is perceived to be, incompatible with human rights; failure to comply with laws regarding privacy, data protection and security, technology protection, sanctions, export controls and other matters; and other factors, risks and uncertainties set forth in the sections titled “Risk Factors” and “Cautionary Note Regarding Forward-Looking Statements” in the final proxy statement/prospectus filed with the SEC on August 5, 2021 and in other documents filed by Cellebrite with the SEC, which are available free of charge at www.sec.gov. You are cautioned not to place undue reliance upon any forward-looking statements, which speak only as of the date made, in this communication or elsewhere. Cellebrite undertakes no obligation to update its forward-looking statements, whether as a result of new information, future developments or otherwise, should circumstances change, except as otherwise required by securities and other applicable laws.   
ContactsMedia Adam Jaffe VP of Global Communications+1 973 206 7643adam.jaffe@cellebrite.com - or -RapidResponse@cellebrite.com
InvestorsAnat Earon-Heilborn VP Investor Relations+972 73 394 8440investors@cellebrite.com
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: PRESS RELEASES (92%); ETHICS (91%); COMPANY ACTIVITIES & MANAGEMENT (90%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (90%); JUSTICE DEPARTMENTS (90%); INVESTIGATIONS (89%); APPOINTMENTS (79%); ASSOCIATIONS & ORGANIZATIONS (79%); BOARDS OF DIRECTORS (79%); EXECUTIVES (79%); BEST PRACTICES (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); HUMAN RIGHTS (78%); INTERNATIONAL LAW (78%); LAW SCHOOLS (78%); BUSINESS EDUCATION (76%); GRADUATE & PROFESSIONAL SCHOOLS (76%); LAW & LEGAL SYSTEM (76%); NATIONAL SECURITY (73%); CELLEBRITE (%); ENTERPRISE SAAS (%); SAAS (%); ETHICS AND INTEGRITY (%); LAW ENFORCEMENT (%); DIGITAL INTELLIGENCE (%)
Company: CELLEBRITE DI LTD
Organization: DUKE UNIVERSITY (57%)
Ticker: CLBT (NASDAQ); CLBTW (NASDAQ)
Industry: LAW SCHOOLS (78%); GRADUATE & PROFESSIONAL SCHOOLS (76%); CONSULTING SERVICES (72%); Mobile Telecommunications (%)
Company-Terms: Mobile Telecommunications Cellebrite DI Ltd CLBT (NASDAQ) CLBTW (NASDAQ) Petah Tikva ::issuer-country=IL:: IL
Geographic: VIRGINIA, USA (79%)
Load-Date: March 8, 2022",neutral,0.6780169010162354,balanced/neutral,"['privacy', 'security', 'human rights']","['justice', 'justice']","['standards', 'law', 'should']",[],3,2,3,0
2021,Unknown Title,"Body
RIYADH - Saudi Arabia announced its AI Ethics Principles for public consultation, it was reported on Wednesday during the Global AI Summit in Riyadh.
The principles were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle.
AI Ethics Principles recognizes the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors.
After analyzing global and domestic standards and guidelines for AI use, the authority has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations.
The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency & explainability, and accountability & responsibility.
Dr. Abdullah Alghamdi, president of SDAIA said: ""We believe these principles will help us move into the next generation of innovation in a multitude of projects.
&ldquo;SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit that &ldquo;We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations.
&ldquo;The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.&rdquo;
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021. - SG
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1526
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (68%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: RIYADH, SAUDI ARABIA (89%); SAUDI ARABIA (96%)
Load-Date: September 22, 2022","RIYADH - Saudi Arabia announced its AI Ethics Principles for public consultation, it was reported on Wednesday during the Global AI Summit in Riyadh.
The principles were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle.
AI Ethics Principles recognizes the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors.
After analyzing global and domestic standards and guidelines for AI use, the authority has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations.
The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency & explainability, and accountability & responsibility.
Dr. Abdullah Alghamdi, president of SDAIA said: ""We believe these principles will help us move into the next generation of innovation in a multitude of projects.
&ldquo;SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit that &ldquo;We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations.
&ldquo;The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.&rdquo;
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021. - SG
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: 1526
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (68%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: RIYADH, SAUDI ARABIA (89%); SAUDI ARABIA (96%)
Load-Date: September 22, 2022",neutral,0.6814747452735901,balanced/neutral,"['privacy', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security']",['fairness'],"['standards', 'guidelines', 'framework']",[],7,1,3,0
2021,Unknown Title,"Body
Amman, August 3 (Petra) - A Cabinet session held Wednesday, headed by Prime Minister Dr. Bishr Khasawneh, decided to approve ""National Charter for Artificial Intelligence (AI) Ethics"" and circulate the document to all ministries, public institutions and departments to abide by its provisions.
The charter comes in implementation of requirements of the Jordanian Artificial Intelligence Policy, which stipulated development of national regulatory frameworks to ensure ""responsible"" use of AI technologies, which stimulates creativity and innovation.
The charter also seeks to find a common ethical base that regulates development of artificial intelligence technologies, based on human and religious values, and Jordanian society's customs and traditions and raise awareness on dangers resulting from AI practices outside the ""responsible and safe"" ethical framework.
The charter provides a set of basic ethical principles that include: Accountability, transparency, impartiality, respect for personal privacy, promotion of human values and other guidelines that promote rule of law, human rights, democratic values and diversity.
In addition, the guidelines take into account the most important ethical issues for AI use and protection of creativity and intellectual property rights.
//Petra// AG
03/08/2022 17:55:50
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 364
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); APPROVALS (90%); ARTIFICIAL INTELLIGENCE (90%); CABINET OFFICES (90%); HEADS OF STATE & GOVERNMENT (90%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); INTELLIGENCE SERVICES (78%); PRIME MINISTERS (78%); RULE OF LAW (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (76%); CUSTOMS & CULTURAL HERITAGE (55%); RELIGION (55%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: AMMAN, JORDAN (59%); JORDAN (90%)
Load-Date: August 3, 2022","Amman, August 3 (Petra) - A Cabinet session held Wednesday, headed by Prime Minister Dr. Bishr Khasawneh, decided to approve ""National Charter for Artificial Intelligence (AI) Ethics"" and circulate the document to all ministries, public institutions and departments to abide by its provisions.
The charter comes in implementation of requirements of the Jordanian Artificial Intelligence Policy, which stipulated development of national regulatory frameworks to ensure ""responsible"" use of AI technologies, which stimulates creativity and innovation.
The charter also seeks to find a common ethical base that regulates development of artificial intelligence technologies, based on human and religious values, and Jordanian society's customs and traditions and raise awareness on dangers resulting from AI practices outside the ""responsible and safe"" ethical framework.
The charter provides a set of basic ethical principles that include: Accountability, transparency, impartiality, respect for personal privacy, promotion of human values and other guidelines that promote rule of law, human rights, democratic values and diversity.
In addition, the guidelines take into account the most important ethical issues for AI use and protection of creativity and intellectual property rights.
//Petra// AG
03/08/2022 17:55:50
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: 364
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); APPROVALS (90%); ARTIFICIAL INTELLIGENCE (90%); CABINET OFFICES (90%); HEADS OF STATE & GOVERNMENT (90%); INTELLECTUAL PROPERTY (78%); INTELLECTUAL PROPERTY LAW (78%); INTELLIGENCE SERVICES (78%); PRIME MINISTERS (78%); RULE OF LAW (78%); HUMAN RIGHTS & CIVIL LIBERTIES LAW (76%); CUSTOMS & CULTURAL HERITAGE (55%); RELIGION (55%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: AMMAN, JORDAN (59%); JORDAN (90%)
Load-Date: August 3, 2022",neutral,0.861269474029541,balanced/neutral,"['privacy', 'transparency', 'accountability', 'human rights']",[],"['policy', 'guidelines', 'framework', 'law']",[],4,0,4,0
2021,Unknown Title,"Byline: Targeted News Service
Dateline: GAINESVILLE, Florida 
Body
(TNSpar) -- The University of Florida issued the following news:
The University of Florida, a proponent for ethics in artificial intelligence, is part of a new global agreement with seven other worldwide universities that are committed to the development of human-centered approaches to artificial intelligence (AI) that will impact people everywhere.
During the Global University Summit at Notre Dame University, Joseph Glover, UF provost and senior vice president of academic affairs, signed The Rome Call for AI Ethics on October 27 on behalf of the University of Florida and served as a panelist for the two-day summit attended by 36 universities invited from around the world. The event was held in Notre Dame, IN.
The signing indicates a commitment to the principles of the Rome Call for AI Ethics: to ensure artificial intelligence serves the interests of humanity and to support regulations and principles to deliver emerging technologies that are ethically centered. UF joins a network of universities that will share best practices, tools, and educational content, as well as meet regularly to share updates and discuss innovative ideas.
Other universities signing the call include the University of Navarra in Spain, Catholic University of Croatia, SWPS University in Poland, Schiller International University in Spain, Chuo University in Japan, University of Johannesburg and the University of Notre Dame.
Regina Rodriquez, a provost fellow for professional education at UF, shared a poster during the summit highlighting UF's multidisciplinary approach to building an AI University at UF.
""Any AI university needs to be built on a firm ethical foundation so that the technology and its applications are developed to support life, prosperity, and the best interests of all people,"" according to provost Joseph Glover. ""That is our commitment at UF through the Rome Call for AI Ethics.""
The Rome Call for AI Ethic's principles ask for transparency, inclusion, responsibility, impartiality, reliability and security in building AI systems, research, education and workforce development.
The Rome Call was established in 2020 and originally signed by the Pontifical Academy for Life, Microsoft, IBM, the Food and Agriculture Organization of the United Nations, and the Italian Ministry of Innovation. Each year, higher ed institutions and public and private companies add their signatures to endorse the call's principles to identify and address AI ethics issues.
The University of Florida is transforming rapidly into an ""AI University"" by incorporating artificial intelligence and data science into all its research and educational programs and its mission to advance the state's economy. As the university's AI Across the Curriculum program matures, UF will graduate thousands of AI-enabled students into the workforce.
UF is also leveraging its artificial intelligence expertise and resources by partnering with other institutions around the State of Florida and the Southeast Conference Artificial Intelligence Consortium comprised of universities in the SEC athletics conference. These partnerships show the university's commitment to equitable access and collaboration in the development and implementation of AI tools and solutions.
* * *
Original text here: https://news.ufl.edu/2022/11/rome-ethics/
MSTRUCK-7990475 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (92%); AGREEMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); UNIVERSITY ADMINISTRATION (90%); CONFERENCES & CONVENTIONS (89%); CURRICULA (78%); EDUCATION & TRAINING (78%); EMERGING TECHNOLOGY (78%); BEST PRACTICES (77%); BUSINESS NEWS (77%); EMPLOYEE TRAINING & ASSISTANCE (77%); UNITED NATIONS (77%); DATA SCIENCE (73%); PRIVATELY HELD COMPANIES (72%); TREATIES & AGREEMENTS (72%); CATHOLICS & CATHOLICISM (71%); AGRICULTURE DEPARTMENTS (68%); ECONOMIC NEWS (68%); LABOR & EMPLOYMENT (65%); LABOR FORCE (60%); UNITED NATIONS INSTITUTIONS (60%); ECONOMY & ECONOMIC INDICATORS (50%)
Company:  AI SYSTEMS (53%);  MICROSOFT CORP (52%)
Organization: UNIVERSITY OF FLORIDA (94%); UNIVERSITY OF NOTRE DAME (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); NAICS511210 SOFTWARE PUBLISHERS (52%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (73%); AGRICULTURE DEPARTMENTS (68%)
Geographic: FLORIDA, USA (95%); NAVARRE, SPAIN (55%); SPAIN (90%); CROATIA (79%); JAPAN (79%); POLAND (55%)
Load-Date: November 5, 2022","(TNSpar) -- The University of Florida issued the following news:
The University of Florida, a proponent for ethics in artificial intelligence, is part of a new global agreement with seven other worldwide universities that are committed to the development of human-centered approaches to artificial intelligence (AI) that will impact people everywhere.
During the Global University Summit at Notre Dame University, Joseph Glover, UF provost and senior vice president of academic affairs, signed The Rome Call for AI Ethics on October 27 on behalf of the University of Florida and served as a panelist for the two-day summit attended by 36 universities invited from around the world. The event was held in Notre Dame, IN.
The signing indicates a commitment to the principles of the Rome Call for AI Ethics: to ensure artificial intelligence serves the interests of humanity and to support regulations and principles to deliver emerging technologies that are ethically centered. UF joins a network of universities that will share best practices, tools, and educational content, as well as meet regularly to share updates and discuss innovative ideas.
Other universities signing the call include the University of Navarra in Spain, Catholic University of Croatia, SWPS University in Poland, Schiller International University in Spain, Chuo University in Japan, University of Johannesburg and the University of Notre Dame.
Regina Rodriquez, a provost fellow for professional education at UF, shared a poster during the summit highlighting UF's multidisciplinary approach to building an AI University at UF.
""Any AI university needs to be built on a firm ethical foundation so that the technology and its applications are developed to support life, prosperity, and the best interests of all people,"" according to provost Joseph Glover. ""That is our commitment at UF through the Rome Call for AI Ethics.""
The Rome Call for AI Ethic's principles ask for transparency, inclusion, responsibility, impartiality, reliability and security in building AI systems, research, education and workforce development.
The Rome Call was established in 2020 and originally signed by the Pontifical Academy for Life, Microsoft, IBM, the Food and Agriculture Organization of the United Nations, and the Italian Ministry of Innovation. Each year, higher ed institutions and public and private companies add their signatures to endorse the call's principles to identify and address AI ethics issues.
The University of Florida is transforming rapidly into an ""AI University"" by incorporating artificial intelligence and data science into all its research and educational programs and its mission to advance the state's economy. As the university's AI Across the Curriculum program matures, UF will graduate thousands of AI-enabled students into the workforce.
UF is also leveraging its artificial intelligence expertise and resources by partnering with other institutions around the State of Florida and the Southeast Conference Artificial Intelligence Consortium comprised of universities in the SEC athletics conference. These partnerships show the university's commitment to equitable access and collaboration in the development and implementation of AI tools and solutions.
* * *
Original text here: https://news.ufl.edu/2022/11/rome-ethics/
MSTRUCK-7990475 MSTRUCK
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (92%); AGREEMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); UNIVERSITY ADMINISTRATION (90%); CONFERENCES & CONVENTIONS (89%); CURRICULA (78%); EDUCATION & TRAINING (78%); EMERGING TECHNOLOGY (78%); BEST PRACTICES (77%); BUSINESS NEWS (77%); EMPLOYEE TRAINING & ASSISTANCE (77%); UNITED NATIONS (77%); DATA SCIENCE (73%); PRIVATELY HELD COMPANIES (72%); TREATIES & AGREEMENTS (72%); CATHOLICS & CATHOLICISM (71%); AGRICULTURE DEPARTMENTS (68%); ECONOMIC NEWS (68%); LABOR & EMPLOYMENT (65%); LABOR FORCE (60%); UNITED NATIONS INSTITUTIONS (60%); ECONOMY & ECONOMIC INDICATORS (50%)
Company:  AI SYSTEMS (53%);  MICROSOFT CORP (52%)
Organization: UNIVERSITY OF FLORIDA (94%); UNIVERSITY OF NOTRE DAME (54%)
Industry: SIC7372 PREPACKAGED SOFTWARE (53%); NAICS511210 SOFTWARE PUBLISHERS (52%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (73%); AGRICULTURE DEPARTMENTS (68%)
Geographic: FLORIDA, USA (95%); NAVARRE, SPAIN (55%); SPAIN (90%); CROATIA (79%); JAPAN (79%); POLAND (55%)
Load-Date: November 5, 2022",neutral,0.6596363186836243,balanced/neutral,"['transparency', 'security', 'access']",[],[],[],3,0,0,0
2021,Unknown Title,"Body
Link to Story
Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency &explainability, and accountability & responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data & AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit ""We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom's efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
MENAFN15092022003982000056ID1104868972
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (67%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: RIYADH, SAUDI ARABIA (73%); SAUDI ARABIA (94%)
Load-Date: October 27, 2022","Link to Story
Riyadh, September 14, 2022 -- The Kingdom of Saudi Arabia proudly announces its AI Ethics Principles for public consultation. They were designed by the Saudi Data and Artificial Intelligence Authority (SDAIA) to be a practical guide to incorporating AI ethics throughout the AI system development life cycle. AI Ethics principles recognize the importance of developing artificial intelligence and technology innovation into the Kingdom's services for its citizens and visitors. After analyzing global and domestic standards and guidelines for AI use, SDAIA has developed an operational framework that entities can use to promote AI while limiting the technology's irresponsible use.
AI ethics will provide a common ground or standards to help the Kingdom avoid or reduce technology limitations. The seven AI ethics principles are fairness, privacy & security, humanity, social & environmental benefits, reliability & safety, transparency &explainability, and accountability & responsibility.
H.E. Dr Abdullah bin Sharaf Alghamdi, President of the Saudi Data & AI Authority (SDAIA) said ""We believe these principles will help us move into the next generation of innovation in a multitude of projects. SDAIA has done an excellent job in encapsulating our responsibilities in implementing AI, and we hope to continue developing and implementing AI that exceeds these expectations.""
Dr. Majid Altuwaijri, CEO of the National Center for AI, stated during the announcement at the Global AI Summit ""We are excited to advance our technology capacity through implementing AI solutions into our current processes and operations. The AI Ethics principles will also help us ensure that we implement these capabilities in a measured, data-responsible and ethical way.""
Saudi Arabia is one of the earliest counties to adopt UNESCO's Recommendation on the ethics of artificial intelligence, endorsed by 193 countries in November 2021.
The AI Ethics principles is one of the many initiatives that will support the Kingdom's efforts toward achieving its Vision 2030 and national strategies related to adopting AI technology, encouraging research and innovation, and driving economic growth for prosperity and development.
MENAFN15092022003982000056ID1104868972
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); EMERGING TECHNOLOGY (78%); RESEARCH & DEVELOPMENT (78%); PRODUCT INNOVATION (71%); STANDARDS & MEASUREMENTS (70%); EXECUTIVES (67%); ENVIRONMENT & NATURAL RESOURCES (53%)
Company:  AI SYSTEMS (57%)
Industry: SIC7372 PREPACKAGED SOFTWARE (57%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: RIYADH, SAUDI ARABIA (73%); SAUDI ARABIA (94%)
Load-Date: October 27, 2022",positive,0.5456404685974121,balanced/neutral,"['privacy', 'fairness', 'transparency', 'explainability', 'accountability', 'safety', 'security']",['fairness'],"['standards', 'guidelines', 'framework']",[],7,1,3,0
2021,Unknown Title,"Body
Helsinki: Helsinki Municipality, Finland has issued the following news release:
Helsinki has drawn up principles for the ethical use of data and artificial intelligence. Helsinki wants to use data and artificial intelligence responsibly and ethically and act as a role model for others.
With the help of data and artificial intelligence, the city can automate operations more efficiently than before and improve the quality of services, and therefore they want to make more use of them. However, this involves ethical questions, which is why the principles have been drawn up.
Data is accumulated in a large part of the city's operations, for example in traffic systems or when using city services. Artificial intelligence is a tool that enables, supports and enhances the utilization of city data.
Eight ethical principles in totalThere are eight principles, and by following them, the city minimizes risks related to data and artificial intelligence.
The ethical principles are:
Human orientationWe develop services using data and artificial intelligence for the benefit of people and listening to them.TransparencyWe communicated as clearly as possible how and where we use data and artificial intelligence.ExplainabilityWe are able to explain a single result or the general operating logic of an algorithm in an understandable way.Fairness and equalityThe starting point for data use and artificial intelligence solutions is respect for every human dignity and rights.Responsibility and maintaining trustWe assign a responsible party to each service that uses artificial intelligence, with which our customers have the opportunity to get in touch.PrivacyWe process personal data carefully and securely throughout the entire life cycle of the system.SafetySystems that utilize data and artificial intelligence are well protected and controlledUnder human controlThe person in charge is able to monitor and control the operation of the system and, if necessary, intervene in it.The principles also include a list of questions that the city's artificial intelligence developers can use to evaluate the practical implementation of the principles.
Helsinki invites city residents, personnel and companies to hear more about the principlesHelsinki invites its residents, personnel and companies to hear more and discuss the ethical principles of data and artificial intelligence. At the events, the representatives of the city who have drawn up ethical principles present the principles, after which the guidelines are promoted together by discussion.
A discussion event open to all city residents will be held on Thursday, December 8 at 17:30 – 19:30 at Helsinki City Hall on the Event Market (entrance Pohjoisesplanadi 11 – 13).
This is an automated translated version of the story which may have translation errors. Please always refer to the original story:https://www.hel.fi/fi/uutiset/helsinki-laati-periaatteet-datan-ja-tekoalyn-eettiselle-kaytolle
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ND
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CALENDARS (90%); CITIES (89%); CITY LIFE (89%); MENTORS & ROLE MODELS (77%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: HELSINKI, FINLAND (95%)
Load-Date: November 24, 2022","Helsinki: Helsinki Municipality, Finland has issued the following news release:
Helsinki has drawn up principles for the ethical use of data and artificial intelligence. Helsinki wants to use data and artificial intelligence responsibly and ethically and act as a role model for others.
With the help of data and artificial intelligence, the city can automate operations more efficiently than before and improve the quality of services, and therefore they want to make more use of them. However, this involves ethical questions, which is why the principles have been drawn up.
Data is accumulated in a large part of the city's operations, for example in traffic systems or when using city services. Artificial intelligence is a tool that enables, supports and enhances the utilization of city data.
Eight ethical principles in totalThere are eight principles, and by following them, the city minimizes risks related to data and artificial intelligence.
The ethical principles are:
Human orientationWe develop services using data and artificial intelligence for the benefit of people and listening to them.TransparencyWe communicated as clearly as possible how and where we use data and artificial intelligence.ExplainabilityWe are able to explain a single result or the general operating logic of an algorithm in an understandable way.Fairness and equalityThe starting point for data use and artificial intelligence solutions is respect for every human dignity and rights.Responsibility and maintaining trustWe assign a responsible party to each service that uses artificial intelligence, with which our customers have the opportunity to get in touch.PrivacyWe process personal data carefully and securely throughout the entire life cycle of the system.SafetySystems that utilize data and artificial intelligence are well protected and controlledUnder human controlThe person in charge is able to monitor and control the operation of the system and, if necessary, intervene in it.The principles also include a list of questions that the city's artificial intelligence developers can use to evaluate the practical implementation of the principles.
Helsinki invites city residents, personnel and companies to hear more about the principlesHelsinki invites its residents, personnel and companies to hear more and discuss the ethical principles of data and artificial intelligence. At the events, the representatives of the city who have drawn up ethical principles present the principles, after which the guidelines are promoted together by discussion.
A discussion event open to all city residents will be held on Thursday, December 8 at 17:30 – 19:30 at Helsinki City Hall on the Event Market (entrance Pohjoisesplanadi 11 – 13).
This is an automated translated version of the story which may have translation errors. Please always refer to the original story:https://www.hel.fi/fi/uutiset/helsinki-laati-periaatteet-datan-ja-tekoalyn-eettiselle-kaytolle
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: ND
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CALENDARS (90%); CITIES (89%); CITY LIFE (89%); MENTORS & ROLE MODELS (77%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%)
Geographic: HELSINKI, FINLAND (95%)
Load-Date: November 24, 2022",neutral,0.6804882884025574,balanced/neutral,['fairness'],"['fairness', 'dignity']",['guidelines'],['algorithm'],1,2,1,1
2021,Unknown Title,"Body
Nov 09, 2021( Carnegie Council Transcripts and Articles: http://carnegiecouncil.org Delivered by Newstex)  
 The eighth annual Global Ethics Day[1]—a project of Carnegie Council[2]—was held on October 20, 2021, with over 170 organizations and institutions participating in 45 countries with a theme of ""Ethics Empowered."" 
Launched in 2014 and held on the third Wednesday of every October, Global Ethics Day is an opportunity for individuals and organizations to explore the meaning of ethics in daily life and come together to identify and address the most critical issues facing society. This year, events focused on democracy promotion, racial injustice, the COVID-19 pandemic, climate change, and much more. 
Carnegie Council hosted a live virtual panel and Q&A on October 20, titled ""On the Frontlines of Democracy[3]."" The event featured activists who are fighting around the world to uphold and strengthen democracy. In addition to hearing from those working on the frontline and debating the role of international organizations like the United Nations, the panel explored how ethical actions by individual citizens can help to support and revitalize democracy. 
Moderated by Jennifer Williams[4], deputy editor at Foreign Policy, the event featured panelists Nathan Law[5], Hong Kong democratic activist and former legislator; Alfredo Romero[6], president, Foro Penal; Wai Hnin Pwint Thon[7], senior advocacy officer, Burma Campaign UK; and Franak Viačorka[8], senior advisor to Sviatlana Tsikhanouskaya. Joel Rosenthal[9], president of Carnegie Council, introduced and closed the event with a special message for Global Ethics Day. 
In addition to the panel and Global Ethics Day explainer video[10], Rosenthal shared a special letter[11] calling upon the global community to ""use today to empower ethics."" Cynthia Scharf, senior strategy director of the Carnegie Climate Governance Initiative (C2G), released a video[12] with a Global Ethics Day message focused on fighting climate change; and the Artificial Intelligence & Equality Initiative (AIEI) posted a message[13] from Senior Fellow Wendell Wallach about AI and ethics, and debuted its ""Technosocial Contract[14],"" a series of blog posts from Tom Philbeck, senior program advisor. 
In addition to Carnegie Council's activations, dozens of organizations, institutions, and individuals around the world participated through social media messages on Twitter, Instagram, Facebook, YouTube, and LinkedIn. Many organizations also held activities, virtual and in-person, including panel discussions, debates, tree-planting and other outdoor activities, and workshops. Organizations also posted video messages and podcasts focused on the importance of ethics. Photos, videos, and social media messages for Global Ethics Day 2021 have all been collected on GlobalEthicsDay.org[15]. 
Highlights from Global Ethics Day 2021 include: PepsiCo produced a series of video features from their executive team discussing the critical importance of ethics in business.Jeff Thomson, CEO of the Institute of Management Accountants (IMA), published a Global Ethics Day opinion piece in Forbes[16], ""Technology and Covid-19: The Perfect Storm for Ethics Violations.""The European Central Bank (ECB) posted social video messages as part of its Ethical Awareness Week, including a video message from Christine Lagarde, president of the ECB.International Council of Nurses published its revised Code of Ethics.The University of North Carolina at Chapel Hill Office of Ethics and Policy launched a Global Ethics Month webinar series with topics ranging from ""Leading and Healing in the Aftermath of 9/11"" to ethical consumerism.The Vietnam Chamber of Commerce and Industry, the United Nations Development Programme in Vietnam, the Vietnam Association of Certified Public Accountants, and the Association of Chartered Certified Accountants, with the support of UK government, jointly hosted a webinar, ""Towards Sustainable Business: Business Integrity and Compliance with Code of Ethics."" 
 [ 1]: https://www.globalethicsday.org/ [ 2]: https://www.carnegiecouncil.org/ [ 3]: https://www.carnegiecouncil.org/studio/multimedia/20211021-global-ethics-day-frontlines-of-democracy [ 4]: https://foreignpolicy.com/author/jennifer-williams/ [ 5]: https://twitter.com/nathanlawkc [ 6]: https://twitter.com/alfredoromero?lang=en [ 7]: https://twitter.com/MissWHPT [ 8]: https://twitter.com/franakviacorka?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor [ 9]: https://www.carnegiecouncil.org/people/joel-h-rosenthal [ 10]: https://youtu.be/mGKtLxl8cT8 [ 11]: https://www.carnegiecouncil.org/publications/articles_papers_reports/global-ethics-day-2021-empower-ethics-joel-rosenthal [ 12]: https://youtu.be/DKdNjs2fasI [ 13]: https://www.carnegieaie.org/blog/are-you-actually-interested-in-ai-ethics/ [ 14]: https://www.carnegieaie.org/blog/technosocial-contract-1/ [ 15]: https://www.globalethicsday.org/ [ 16]: https://www.forbes.com/sites/jeffthomson/2021/10/20/technology-and-covid-19-the-perfect-storm-for-ethics-violations/?sh=355243ad28a5 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CCIL-8167
Subject: ASSOCIATIONS & ORGANIZATIONS (91%); ETHICS (91%); DEMOCRACIES (90%); TYPES OF GOVERNMENT (90%); BLOGS & MESSAGE BOARDS (89%); INTERNET SOCIAL NETWORKING (89%); REPORTS, REVIEWS & SECTIONS (89%); SOCIAL MEDIA (89%); TRANSCRIPTS (89%); EXECUTIVES (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BUSINESS ETHICS (78%); CORPORATE GOVERNANCE (78%); GLOBALIZATION (78%); INTERNATIONAL RELATIONS (78%); LEGISLATIVE BODIES (78%); PHOTO & VIDEO SHARING (78%); RACISM & XENOPHOBIA (78%); SOCIETAL ISSUES (78%); CLIMATE ACTION (77%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); NEGATIVE SOCIETAL NEWS (75%); BUSINESS & PROFESSIONAL ASSOCIATIONS (73%); UNITED NATIONS INSTITUTIONS (73%); COVID CORONAVIRUS (69%); COVID-19 CORONAVIRUS (69%); INFECTIOUS DISEASE (69%); RACIAL JUSTICE (69%); UNITED NATIONS (67%); ARTIFICIAL INTELLIGENCE (61%); EPIDEMICS (55%)
Company:  META PLATFORMS INC (51%);  PEPSICO INC (50%)
Ticker: FB (NASDAQ) (51%); PEP (NYSE) (50%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (51%); NAICS312111 SOFT DRINK MANUFACTURING (50%); NAICS311919 OTHER SNACK FOOD MANUFACTURING (50%); NAICS311513 CHEESE MANUFACTURING (50%); NAICS311511 FLUID MILK MANUFACTURING (50%); NAICS311411 FROZEN FRUIT, JUICE & VEGETABLE MANUFACTURING (50%); SIC2096 POTATO CHIPS, CORN CHIPS, & SIMILAR SNACKS (50%); SIC2086 BOTTLED & CANNED SOFT DRINKS & CARBONATED WATER (50%); BLOGS & MESSAGE BOARDS (89%); INTERNET SOCIAL NETWORKING (89%); SOCIAL MEDIA (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); PHOTO & VIDEO SHARING (78%); PODCASTING (73%); VIDEO INDUSTRY (68%); ARTIFICIAL INTELLIGENCE (61%)
Load-Date: May 14, 2022","Nov 09, 2021( Carnegie Council Transcripts and Articles: http://carnegiecouncil.org Delivered by Newstex)  
 The eighth annual Global Ethics Day[1]—a project of Carnegie Council[2]—was held on October 20, 2021, with over 170 organizations and institutions participating in 45 countries with a theme of ""Ethics Empowered."" 
Launched in 2014 and held on the third Wednesday of every October, Global Ethics Day is an opportunity for individuals and organizations to explore the meaning of ethics in daily life and come together to identify and address the most critical issues facing society. This year, events focused on democracy promotion, racial injustice, the COVID-19 pandemic, climate change, and much more. 
Carnegie Council hosted a live virtual panel and Q&A on October 20, titled ""On the Frontlines of Democracy[3]."" The event featured activists who are fighting around the world to uphold and strengthen democracy. In addition to hearing from those working on the frontline and debating the role of international organizations like the United Nations, the panel explored how ethical actions by individual citizens can help to support and revitalize democracy. 
Moderated by Jennifer Williams[4], deputy editor at Foreign Policy, the event featured panelists Nathan Law[5], Hong Kong democratic activist and former legislator; Alfredo Romero[6], president, Foro Penal; Wai Hnin Pwint Thon[7], senior advocacy officer, Burma Campaign UK; and Franak Viačorka[8], senior advisor to Sviatlana Tsikhanouskaya. Joel Rosenthal[9], president of Carnegie Council, introduced and closed the event with a special message for Global Ethics Day. 
In addition to the panel and Global Ethics Day explainer video[10], Rosenthal shared a special letter[11] calling upon the global community to ""use today to empower ethics."" Cynthia Scharf, senior strategy director of the Carnegie Climate Governance Initiative (C2G), released a video[12] with a Global Ethics Day message focused on fighting climate change; and the Artificial Intelligence & Equality Initiative (AIEI) posted a message[13] from Senior Fellow Wendell Wallach about AI and ethics, and debuted its ""Technosocial Contract[14],"" a series of blog posts from Tom Philbeck, senior program advisor. 
In addition to Carnegie Council's activations, dozens of organizations, institutions, and individuals around the world participated through social media messages on Twitter, Instagram, Facebook, YouTube, and LinkedIn. Many organizations also held activities, virtual and in-person, including panel discussions, debates, tree-planting and other outdoor activities, and workshops. Organizations also posted video messages and podcasts focused on the importance of ethics. Photos, videos, and social media messages for Global Ethics Day 2021 have all been collected on GlobalEthicsDay.org[15]. 
Highlights from Global Ethics Day 2021 include: PepsiCo produced a series of video features from their executive team discussing the critical importance of ethics in business.Jeff Thomson, CEO of the Institute of Management Accountants (IMA), published a Global Ethics Day opinion piece in Forbes[16], ""Technology and Covid-19: The Perfect Storm for Ethics Violations.""The European Central Bank (ECB) posted social video messages as part of its Ethical Awareness Week, including a video message from Christine Lagarde, president of the ECB.International Council of Nurses published its revised Code of Ethics.The University of North Carolina at Chapel Hill Office of Ethics and Policy launched a Global Ethics Month webinar series with topics ranging from ""Leading and Healing in the Aftermath of 9/11"" to ethical consumerism.The Vietnam Chamber of Commerce and Industry, the United Nations Development Programme in Vietnam, the Vietnam Association of Certified Public Accountants, and the Association of Chartered Certified Accountants, with the support of UK government, jointly hosted a webinar, ""Towards Sustainable Business: Business Integrity and Compliance with Code of Ethics."" 
 [ 1]: https://www.globalethicsday.org/ [ 2]: https://www.carnegiecouncil.org/ [ 3]: https://www.carnegiecouncil.org/studio/multimedia/20211021-global-ethics-day-frontlines-of-democracy [ 4]: https://foreignpolicy.com/author/jennifer-williams/ [ 5]: https://twitter.com/nathanlawkc [ 6]: https://twitter.com/alfredoromero?lang=en [ 7]: https://twitter.com/MissWHPT [ 8]: https://twitter.com/franakviacorka?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor [ 9]: https://www.carnegiecouncil.org/people/joel-h-rosenthal [ 10]: https://youtu.be/mGKtLxl8cT8 [ 11]: https://www.carnegiecouncil.org/publications/articles_papers_reports/global-ethics-day-2021-empower-ethics-joel-rosenthal [ 12]: https://youtu.be/DKdNjs2fasI [ 13]: https://www.carnegieaie.org/blog/are-you-actually-interested-in-ai-ethics/ [ 14]: https://www.carnegieaie.org/blog/technosocial-contract-1/ [ 15]: https://www.globalethicsday.org/ [ 16]: https://www.forbes.com/sites/jeffthomson/2021/10/20/technology-and-covid-19-the-perfect-storm-for-ethics-violations/?sh=355243ad28a5 
The views expressed in any and all content distributed by Newstex and its re-distributors (collectively, the ""Newstex Authoritative Content"") are solely those of the respective author(s) and not necessarily the views of Newstex or its re-distributors. Stories from such authors are provided ""AS IS,"" with no warranties, and confer no rights. The material and information provided in Newstex Authoritative Content are for general information only and should not, in any respect, be relied on as professional advice. Newstex Authoritative Content is not ""read and approved"" before it is posted. Accordingly, neither Newstex nor its re-distributors make any claims, promises or guarantees about the accuracy, completeness, or adequacy of the information contained therein or linked to from such content, nor do they take responsibility for any aspect of such content. The Newstex Authoritative Content shall be construed as author-based content and commentary. Accordingly, no warranties or other guarantees are offered as to the quality of the opinions, commentary or anything else appearing in such Newstex Authoritative Content. Newstex and its re-distributors expressly reserve the right to delete stories at its and their sole discretion.
Classification
Language: English
Publication-Type: Web Blog
Journal Code: CCIL-8167
Subject: ASSOCIATIONS & ORGANIZATIONS (91%); ETHICS (91%); DEMOCRACIES (90%); TYPES OF GOVERNMENT (90%); BLOGS & MESSAGE BOARDS (89%); INTERNET SOCIAL NETWORKING (89%); REPORTS, REVIEWS & SECTIONS (89%); SOCIAL MEDIA (89%); TRANSCRIPTS (89%); EXECUTIVES (87%); ARTIFICIAL INTELLIGENCE ETHICS (78%); BUSINESS ETHICS (78%); CORPORATE GOVERNANCE (78%); GLOBALIZATION (78%); INTERNATIONAL RELATIONS (78%); LEGISLATIVE BODIES (78%); PHOTO & VIDEO SHARING (78%); RACISM & XENOPHOBIA (78%); SOCIETAL ISSUES (78%); CLIMATE ACTION (77%); INTERNATIONAL RELATIONS & NATIONAL SECURITY (77%); NEGATIVE SOCIETAL NEWS (75%); BUSINESS & PROFESSIONAL ASSOCIATIONS (73%); UNITED NATIONS INSTITUTIONS (73%); COVID CORONAVIRUS (69%); COVID-19 CORONAVIRUS (69%); INFECTIOUS DISEASE (69%); RACIAL JUSTICE (69%); UNITED NATIONS (67%); ARTIFICIAL INTELLIGENCE (61%); EPIDEMICS (55%)
Company:  META PLATFORMS INC (51%);  PEPSICO INC (50%)
Ticker: FB (NASDAQ) (51%); PEP (NYSE) (50%)
Industry: NAICS519130 INTERNET PUBLISHING & BROADCASTING & WEB SEARCH PORTALS (51%); NAICS312111 SOFT DRINK MANUFACTURING (50%); NAICS311919 OTHER SNACK FOOD MANUFACTURING (50%); NAICS311513 CHEESE MANUFACTURING (50%); NAICS311511 FLUID MILK MANUFACTURING (50%); NAICS311411 FROZEN FRUIT, JUICE & VEGETABLE MANUFACTURING (50%); SIC2096 POTATO CHIPS, CORN CHIPS, & SIMILAR SNACKS (50%); SIC2086 BOTTLED & CANNED SOFT DRINKS & CARBONATED WATER (50%); BLOGS & MESSAGE BOARDS (89%); INTERNET SOCIAL NETWORKING (89%); SOCIAL MEDIA (89%); ARTIFICIAL INTELLIGENCE ETHICS (78%); PHOTO & VIDEO SHARING (78%); PODCASTING (73%); VIDEO INDUSTRY (68%); ARTIFICIAL INTELLIGENCE (61%)
Load-Date: May 14, 2022",neutral,0.7818752527236938,balanced/neutral,['security'],"['justice', 'equality', 'justice']","['policy', 'governance', 'law', 'compliance', 'should']",[],1,3,5,0
2021,Unknown Title,"Dateline: BENGALURU, India, March 21, 2022 
Body
PR Newswire
Recognition honors companies demonstrating exceptional leadership and a commitment tobusiness integrity through best-in-class ethics, compliance, and governance practices
 Infosys(NSE: INFY) (BSE: INFY) (NYSE: INFY), a global leader in next-generation digital services and consulting, today announced that it has been recognized byEthisphere Institute, a global leader in defining and advancing the standards of ethical business practices, as one of the2022 World's Most Ethical Companies, for the second consecutive year. Through this recognition, Infosys has become the only company in India, and one of the four honorees globally, in the software & services industry.
In 2022, 136 honorees were recognized from 22 countries and across 45 industries. These companies were evaluated based on the Ethisphere Ethics Quotient® across multiple categories, including culture, environmental and social practices, ethics and compliance, governance, diversity, and initiatives to support a strong value chain.
""Today, business leaders face their greatest mandate yet to be ethical, accountable, and trusted to drive positive change,"" saidTimothy Erblich, Chief Executive Officer, Ethisphere. ""We continue to be inspired by the World's Most Ethical Companies honorees and their dedication to integrity, sustainability, governance, and community. Congratulations to Infosys for earning the World's Most Ethical Companies designation.""
Salil Parekh, Chief Executive Officer and Managing Director, Infosys, said, ""Being ethical is at the heart of everything we do, and one of the core values on which Infosys has built its success over the years. We are honored to receive this recognition from the prestigious Ethisphere Institute. Receiving this recognition for the second consecutive year is a testament to our excellence in ethical practices and our commitment to operate with utmost integrity and transparency as articulated in our C-LIFE values.""
The complete list of 2022 World's Most Ethical Companies can be found at: https://worldsmostethicalcompanies.com/honorees
Methodology & Scoring
Grounded in Ethisphere's proprietary Ethics Quotient®, the World's Most Ethical Companies assessment process includes more than 200 questions on culture, environmental and social practices, ethics and compliance activities, governance, diversity, and initiatives to support a strong value chain. The process serves as an operating framework to capture and codify the leading practices of organizations across industries and around the globe.
About Ethisphere
Ethisphere® is the global leader in defining and advancing the standards of ethical business practices that fuel corporate character, marketplace trust and business success. Ethisphere has deep expertise in measuring and defining core ethics standards using data-driven insights that help companies enhance corporate character and measure and improve culture. Ethisphere honors superior achievement through its World's Most Ethical Companies recognition program and provides a community of industry experts with the Business Ethics Leadership Alliance (BELA).
More information about Ethisphere can be found at: https://ethisphere.com.
About Infosys
Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.
Visithttp://www.infosys.comto see how Infosys (NSE, BSE, NYSE: INFY) can help your enterprise navigate your next.
Safe Harbor
Certain statements in this release concerning our future growth prospects, financial expectations and plans for navigating the COVID-19 impact on our employees, clients and stakeholders are forward-looking statements intended to qualify for the 'safe harbor' under the Private Securities Litigation Reform Act of 1995, which involve a number of risks and uncertainties that could cause actual results to differ materially from those in such forward-looking statements. The risks and uncertainties relating to these statements include, but are not limited to, risks and uncertainties regarding COVID-19 and the effects of government and other measures seeking to contain its spread, risks related to an economic downturn or recession in India, the United States and other countries around the world, changes in political, business, and economic conditions, fluctuations in earnings, fluctuations in foreign exchange rates, our ability to manage growth, intense competition in IT services including those factors which may affect our cost advantage, wage increases in India, our ability to attract and retain highly skilled professionals, time and cost overruns on fixed-price, fixed-time frame contracts, client concentration, restrictions on immigration, industry segment concentration, our ability to manage our international operations, reduced demand for technology in our key focus areas, disruptions in telecommunication networks or system failures, our ability to successfully complete and integrate potential acquisitions, liability for damages on our service contracts, the success of the companies in which Infosys has made strategic investments, withdrawal or expiration of governmental fiscal incentives, political instability and regional conflicts, legal restrictions on raising capital or acquiring companies outside India, unauthorized use of our intellectual property and general economic conditions affecting our industry and the outcome of pending litigation and government investigation. Additional risks that could affect our future operating results are more fully described in our United States Securities and Exchange Commission filings including our Annual Report on Form 20-F for the fiscal year ended March 31, 2021. These filings are available at http://www.sec.gov. Infosys may, from time to time, make additional written and oral forward-looking statements, including statements contained in the Company's filings with the Securities and Exchange Commission and our reports to shareholders. The Company does not undertake to update any forward-looking statements that may be made from time to time by or on behalf of the Company unless it is required by law.
SOURCE Infosys
CONTACT: For more information, PR_Global@Infosys.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); BUSINESS ETHICS (91%); CORPORATE GOVERNANCE (90%); EXECUTIVES (90%); PRESS RELEASES (90%); PUBLIC COMPANIES (90%); ASSOCIATIONS & ORGANIZATIONS (89%); COMPANY ACTIVITIES & MANAGEMENT (89%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); SUSTAINABLE DEVELOPMENT (74%); MANAGERS & SUPERVISORS (73%); REGULATORY COMPLIANCE (73%); VALUE CHAIN (73%); Infosys (%); SVY Surveys, polls & research studies (%)
Company:  INFOSYS LTD (90%); Infosys
Ticker: INFY (PAR) (90%); INFY (NYSE) (90%); INFY (NSE) (90%); 500209 (Bombay); INFY (NYSE); INFY (Bombay); INFY.BO (Bombay); EQINFY (India); INFY.NS (India); 0XSE (LSE); INFY (India)
Industry: NAICS541511 CUSTOM COMPUTER PROGRAMMING SERVICES (90%); SIC7371 COMPUTER PROGRAMMING SERVICES (90%); SUSTAINABLE DEVELOPMENT (74%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Person: SALIL PAREKH (79%)
Geographic: MUMBAI, MAHARASHTRA, INDIA (88%); BANGALORE, KARNATAKA, INDIA (79%); INDIA (94%); ASIA (92%); GERMANY (79%); UNITED KINGDOM (79%); UNITED STATES (79%); BELGIUM (73%); SPAIN (73%); NETHERLANDS (58%); SWITZERLAND (58%); Austria; Belgium; France; Germany; Italy; Netherlands; Spain; Switzerland; United Kingdom; United States of America; Canada; India; Brazil; Mexico; Argentina
Load-Date: March 21, 2022","PR Newswire
Recognition honors companies demonstrating exceptional leadership and a commitment tobusiness integrity through best-in-class ethics, compliance, and governance practices
 Infosys(NSE: INFY) (BSE: INFY) (NYSE: INFY), a global leader in next-generation digital services and consulting, today announced that it has been recognized byEthisphere Institute, a global leader in defining and advancing the standards of ethical business practices, as one of the2022 World's Most Ethical Companies, for the second consecutive year. Through this recognition, Infosys has become the only company in India, and one of the four honorees globally, in the software & services industry.
In 2022, 136 honorees were recognized from 22 countries and across 45 industries. These companies were evaluated based on the Ethisphere Ethics Quotient® across multiple categories, including culture, environmental and social practices, ethics and compliance, governance, diversity, and initiatives to support a strong value chain.
""Today, business leaders face their greatest mandate yet to be ethical, accountable, and trusted to drive positive change,"" saidTimothy Erblich, Chief Executive Officer, Ethisphere. ""We continue to be inspired by the World's Most Ethical Companies honorees and their dedication to integrity, sustainability, governance, and community. Congratulations to Infosys for earning the World's Most Ethical Companies designation.""
Salil Parekh, Chief Executive Officer and Managing Director, Infosys, said, ""Being ethical is at the heart of everything we do, and one of the core values on which Infosys has built its success over the years. We are honored to receive this recognition from the prestigious Ethisphere Institute. Receiving this recognition for the second consecutive year is a testament to our excellence in ethical practices and our commitment to operate with utmost integrity and transparency as articulated in our C-LIFE values.""
The complete list of 2022 World's Most Ethical Companies can be found at: https://worldsmostethicalcompanies.com/honorees
Methodology & Scoring
Grounded in Ethisphere's proprietary Ethics Quotient®, the World's Most Ethical Companies assessment process includes more than 200 questions on culture, environmental and social practices, ethics and compliance activities, governance, diversity, and initiatives to support a strong value chain. The process serves as an operating framework to capture and codify the leading practices of organizations across industries and around the globe.
About Ethisphere
Ethisphere® is the global leader in defining and advancing the standards of ethical business practices that fuel corporate character, marketplace trust and business success. Ethisphere has deep expertise in measuring and defining core ethics standards using data-driven insights that help companies enhance corporate character and measure and improve culture. Ethisphere honors superior achievement through its World's Most Ethical Companies recognition program and provides a community of industry experts with the Business Ethics Leadership Alliance (BELA).
More information about Ethisphere can be found at: https://ethisphere.com.
About Infosys
Infosys is a global leader in next-generation digital services and consulting. We enable clients in more than 50 countries to navigate their digital transformation. With over four decades of experience in managing the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver unprecedented levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.
Visithttp://www.infosys.comto see how Infosys (NSE, BSE, NYSE: INFY) can help your enterprise navigate your next.
Safe Harbor
Certain statements in this release concerning our future growth prospects, financial expectations and plans for navigating the COVID-19 impact on our employees, clients and stakeholders are forward-looking statements intended to qualify for the 'safe harbor' under the Private Securities Litigation Reform Act of 1995, which involve a number of risks and uncertainties that could cause actual results to differ materially from those in such forward-looking statements. The risks and uncertainties relating to these statements include, but are not limited to, risks and uncertainties regarding COVID-19 and the effects of government and other measures seeking to contain its spread, risks related to an economic downturn or recession in India, the United States and other countries around the world, changes in political, business, and economic conditions, fluctuations in earnings, fluctuations in foreign exchange rates, our ability to manage growth, intense competition in IT services including those factors which may affect our cost advantage, wage increases in India, our ability to attract and retain highly skilled professionals, time and cost overruns on fixed-price, fixed-time frame contracts, client concentration, restrictions on immigration, industry segment concentration, our ability to manage our international operations, reduced demand for technology in our key focus areas, disruptions in telecommunication networks or system failures, our ability to successfully complete and integrate potential acquisitions, liability for damages on our service contracts, the success of the companies in which Infosys has made strategic investments, withdrawal or expiration of governmental fiscal incentives, political instability and regional conflicts, legal restrictions on raising capital or acquiring companies outside India, unauthorized use of our intellectual property and general economic conditions affecting our industry and the outcome of pending litigation and government investigation. Additional risks that could affect our future operating results are more fully described in our United States Securities and Exchange Commission filings including our Annual Report on Form 20-F for the fiscal year ended March 31, 2021. These filings are available at http://www.sec.gov. Infosys may, from time to time, make additional written and oral forward-looking statements, including statements contained in the Company's filings with the Securities and Exchange Commission and our reports to shareholders. The Company does not undertake to update any forward-looking statements that may be made from time to time by or on behalf of the Company unless it is required by law.
SOURCE Infosys
CONTACT: For more information, PR_Global@Infosys.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (92%); BUSINESS ETHICS (91%); CORPORATE GOVERNANCE (90%); EXECUTIVES (90%); PRESS RELEASES (90%); PUBLIC COMPANIES (90%); ASSOCIATIONS & ORGANIZATIONS (89%); COMPANY ACTIVITIES & MANAGEMENT (89%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); SUSTAINABLE DEVELOPMENT (74%); MANAGERS & SUPERVISORS (73%); REGULATORY COMPLIANCE (73%); VALUE CHAIN (73%); Infosys (%); SVY Surveys, polls & research studies (%)
Company:  INFOSYS LTD (90%); Infosys
Ticker: INFY (PAR) (90%); INFY (NYSE) (90%); INFY (NSE) (90%); 500209 (Bombay); INFY (NYSE); INFY (Bombay); INFY.BO (Bombay); EQINFY (India); INFY.NS (India); 0XSE (LSE); INFY (India)
Industry: NAICS541511 CUSTOM COMPUTER PROGRAMMING SERVICES (90%); SIC7371 COMPUTER PROGRAMMING SERVICES (90%); SUSTAINABLE DEVELOPMENT (74%); CPR Computer; Electronics Products (%); STW Computer Software (%)
Person: SALIL PAREKH (79%)
Geographic: MUMBAI, MAHARASHTRA, INDIA (88%); BANGALORE, KARNATAKA, INDIA (79%); INDIA (94%); ASIA (92%); GERMANY (79%); UNITED KINGDOM (79%); UNITED STATES (79%); BELGIUM (73%); SPAIN (73%); NETHERLANDS (58%); SWITZERLAND (58%); Austria; Belgium; France; Germany; Italy; Netherlands; Spain; Switzerland; United Kingdom; United States of America; Canada; India; Brazil; Mexico; Argentina
Load-Date: March 21, 2022",positive,0.8627045750617981,balanced/neutral,['transparency'],['character'],"['governance', 'standards', 'framework', 'law', 'compliance']",[],1,1,5,0
2021,Unknown Title,"Dateline: SHANGHAI, Sept. 5, 2022 
Body
PR Newswire
SenseTime, a leading global artificial intelligence (AI) software company, released its latest white paper ""AI Governance for Balanced Development"" at the 2022 World Artificial Intelligence Conference(WAIC). The white paper expounds SenseTime's insights, goals and achievements in promoting AI governance.
Tian Feng, Dean of SenseTime's Intelligence Industry Research Institute, was invited to attend the 2022 WAIC and share key massages in the white paper.  During the speech, Mr. Tian stated that AI governance has entered the ""Stage of Implementation"" in which companies and their stakeholders should promote transparency through technical verification.
As more companies around the world use AI in their products and services, cultivating public trust in AI technologies remains a key step in unleashing the potential of AI. This year, regulators and organizations in Singapore, the European Union, the United States, China and other countries released several AI governance toolkits and sandboxes to promote the implementation of AI governance.
""As the world's leading AI software company, SenseTime actively promotes the importance of AI ethics and governance based on its three core ethical principles of responsible AI: sustainability, applying a human-centric approach, and controllable technology. As AI governance enters the next stage, developing responsible and verifiable AI is SenseTime's next goal to help the industry improve the trustworthiness of their AI products and services,"" said Tian Feng.
Four levels of AI governance to develop responsible and verifiable AI
Establishing a comprehensive AI governance system is the first step to developing responsible and verifiable AI, which is a core component of ethical AI to build trust in the technology. Over the years, AI governance has moved from discussion on principles (Stage 1.0) and discussion on policies (Stage 2.0) into technical verification for industry applications (Stage 3.0).  To accelerate the implementation of AI ethics governance, in this white paper, SenseTime shares thought-provoking ideas on how to  best administer AI governance noting that it is a dynamic process driven by value, supported by technical tools, implemented with collaboration and achieved through hierarchical progression.SenseTime also presents the hierarchy of AI governance, which is divided into four levels: Functional, Reliable, Controllable and Trustworthy, covering the functionality, security and robustness, controllability and ethical requirements of AI governance.
By Implementing AI governance throughout the whole life cycle of product design, research and development, release and operation, companies will build a greater public trust towards the use of AI.
Robust internal initiatives to reinforce AI ethics efforts
SenseTime not only attaches a high level of importance to the innovation and R&D of AI, but also places AI ethics and governance as a top priority. In January 2020, the company established the Committee of AI Ethics and Governance to promote the construction of an AI ethical governance system, and ensure AI governance is applied throughout all aspects of operations.
Information security and data privacy protection are always among the top priorities for SenseTime. Accordingly, the company established a dedicated Data Security and Personal Information Protection Committee, which is responsible for the strict implementation and promotion of data security control measures.
SenseTime has also established a strict ethical risk control system and ethical review mechanism to devise ethical review and risk control standards and set up AI ethical review procedures.
In order to promote responsible and verifiable AI, SenseTime continuously improves its AI ethics governance system.  The company has established a comprehensive product review process covering the product design, development and deployment. Trainings on ethical risk control and review mechanism are also provided for employees to safeguard the smooth operation of ethical risk control and review.
To ensure the implementation of the AI governance system, SenseTime introduced mechanisms to effectively manage ethical risks includingEthics Risk Management Goal-setting, Ethics Incidents Reporting and Mitigation Mechanism, Ethics Governance Review Mechanism. A series of internal process tools and technology platforms covering data governance, algorithm evaluation, model examination, and ethical review have also been developed and deployed.
At 2022 WAIC, Gong Chao, Head of Technology Policy and Ethics Research at SenseTime's Intelligence Industry Research Institute also participated in a panel discussion titled ""Embracing technology governance systems to empower a path to sustainable development"". Mr. Gong shared SenseTime's views on AI governance along with various industry applications.
Promoting the need of responsible and verifiable AI is a never-ending goal, and it will always be a fundamental strategy for SenseTime as it expands and diversifies its technology offerings. SenseTime will continue to work to promote fair, responsible, and legally complaint applications of AI technology, and strive to improve the quality of its products and services.
About SenseTime
SenseTime is a leading AI software company founded in Hong Kong in 2014, focused on creating a better AI-empowered future through innovation. Upholding a vision of advancing the interconnection of the physical and digital worlds with AI, driving sustainable productivity growth and seamless interactive experiences, SenseTime is committed to advancing the state of the art in AI research, developing scalable and affordable AI software platforms that benefit businesses, people and society, and attracting and nurturing top talents, shaping the future together.
With our roots in the academic world, we invest in our original and cutting-edge research that allows us to offer and continuously improve industry-leading, full-stack AI capabilities, covering key fields across perception intelligence, decision intelligence, AI-enabled content generation and AI-enabled content enhancement, as well as key capabilities in AI chips, sensors and computing infrastructure. Our proprietary AI infrastructure, SenseCore, allows us to develop powerful and efficient AI software platforms that are scalable and adaptable for a wide range of applications.
Today, our technologies are trusted by customers and partners in many industry verticals including Smart Business, Smart City, Smart Life and Smart Auto.
SenseTime Group Inc. (stock code: 0020.HK) has successfully listed on the Main Board of the Stock Exchange of Hong Kong Limited (HKEX). We have offices in markets including Hong Kong, Mainland China, Taiwan, Macau, Japan, Singapore, Saudi Arabia, the United Arab Emirates, Malaysia and South Korea, etc., as well as presences in Thailand, Indonesia and the Philippines. For more information, please visit SenseTime'swebsiteas well as itsLinkedIn,Twitter,Facebook andYouTube pages.
SOURCE SenseTime
CONTACT: SenseTime Group Limited, Email: pr@sensetime.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); PRESS RELEASES (90%); CORPORATE GOVERNANCE (89%); ASSOCIATIONS & ORGANIZATIONS (78%); PRODUCT DEVELOPMENT (78%); RESEARCH & DEVELOPMENT (78%); SUSTAINABLE DEVELOPMENT (78%); INTERNATIONAL ECONOMIC ORGANIZATIONS (74%); RESEARCH INSTITUTES (73%); EUROPEAN UNION (68%); - (%); SVY Surveys, polls & research studies (%); TDS Trade Shows (%); PDT New Products and Services (%)
Company: SenseTime
Ticker: 0020 (HongKong)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SOFTWARE MAKERS (90%); SOFTWARE SERVICES & APPLICATIONS (90%); COMPUTER SOFTWARE (89%); SUSTAINABLE DEVELOPMENT (78%); INFORMATION SECURITY & PRIVACY (70%); PUB Publishing; Information Services (%)
Geographic: SHANGHAI, CHINA (79%); EAST CHINA (79%); CHINA (92%); ASIA (91%); UNITED STATES (79%); HONG KONG (74%); SINGAPORE (58%); EUROPEAN UNION MEMBER STATES (56%); China
Load-Date: September 5, 2022","PR Newswire
SenseTime, a leading global artificial intelligence (AI) software company, released its latest white paper ""AI Governance for Balanced Development"" at the 2022 World Artificial Intelligence Conference(WAIC). The white paper expounds SenseTime's insights, goals and achievements in promoting AI governance.
Tian Feng, Dean of SenseTime's Intelligence Industry Research Institute, was invited to attend the 2022 WAIC and share key massages in the white paper.  During the speech, Mr. Tian stated that AI governance has entered the ""Stage of Implementation"" in which companies and their stakeholders should promote transparency through technical verification.
As more companies around the world use AI in their products and services, cultivating public trust in AI technologies remains a key step in unleashing the potential of AI. This year, regulators and organizations in Singapore, the European Union, the United States, China and other countries released several AI governance toolkits and sandboxes to promote the implementation of AI governance.
""As the world's leading AI software company, SenseTime actively promotes the importance of AI ethics and governance based on its three core ethical principles of responsible AI: sustainability, applying a human-centric approach, and controllable technology. As AI governance enters the next stage, developing responsible and verifiable AI is SenseTime's next goal to help the industry improve the trustworthiness of their AI products and services,"" said Tian Feng.
Four levels of AI governance to develop responsible and verifiable AI
Establishing a comprehensive AI governance system is the first step to developing responsible and verifiable AI, which is a core component of ethical AI to build trust in the technology. Over the years, AI governance has moved from discussion on principles (Stage 1.0) and discussion on policies (Stage 2.0) into technical verification for industry applications (Stage 3.0).  To accelerate the implementation of AI ethics governance, in this white paper, SenseTime shares thought-provoking ideas on how to  best administer AI governance noting that it is a dynamic process driven by value, supported by technical tools, implemented with collaboration and achieved through hierarchical progression.SenseTime also presents the hierarchy of AI governance, which is divided into four levels: Functional, Reliable, Controllable and Trustworthy, covering the functionality, security and robustness, controllability and ethical requirements of AI governance.
By Implementing AI governance throughout the whole life cycle of product design, research and development, release and operation, companies will build a greater public trust towards the use of AI.
Robust internal initiatives to reinforce AI ethics efforts
SenseTime not only attaches a high level of importance to the innovation and R&D of AI, but also places AI ethics and governance as a top priority. In January 2020, the company established the Committee of AI Ethics and Governance to promote the construction of an AI ethical governance system, and ensure AI governance is applied throughout all aspects of operations.
Information security and data privacy protection are always among the top priorities for SenseTime. Accordingly, the company established a dedicated Data Security and Personal Information Protection Committee, which is responsible for the strict implementation and promotion of data security control measures.
SenseTime has also established a strict ethical risk control system and ethical review mechanism to devise ethical review and risk control standards and set up AI ethical review procedures.
In order to promote responsible and verifiable AI, SenseTime continuously improves its AI ethics governance system.  The company has established a comprehensive product review process covering the product design, development and deployment. Trainings on ethical risk control and review mechanism are also provided for employees to safeguard the smooth operation of ethical risk control and review.
To ensure the implementation of the AI governance system, SenseTime introduced mechanisms to effectively manage ethical risks includingEthics Risk Management Goal-setting, Ethics Incidents Reporting and Mitigation Mechanism, Ethics Governance Review Mechanism. A series of internal process tools and technology platforms covering data governance, algorithm evaluation, model examination, and ethical review have also been developed and deployed.
At 2022 WAIC, Gong Chao, Head of Technology Policy and Ethics Research at SenseTime's Intelligence Industry Research Institute also participated in a panel discussion titled ""Embracing technology governance systems to empower a path to sustainable development"". Mr. Gong shared SenseTime's views on AI governance along with various industry applications.
Promoting the need of responsible and verifiable AI is a never-ending goal, and it will always be a fundamental strategy for SenseTime as it expands and diversifies its technology offerings. SenseTime will continue to work to promote fair, responsible, and legally complaint applications of AI technology, and strive to improve the quality of its products and services.
About SenseTime
SenseTime is a leading AI software company founded in Hong Kong in 2014, focused on creating a better AI-empowered future through innovation. Upholding a vision of advancing the interconnection of the physical and digital worlds with AI, driving sustainable productivity growth and seamless interactive experiences, SenseTime is committed to advancing the state of the art in AI research, developing scalable and affordable AI software platforms that benefit businesses, people and society, and attracting and nurturing top talents, shaping the future together.
With our roots in the academic world, we invest in our original and cutting-edge research that allows us to offer and continuously improve industry-leading, full-stack AI capabilities, covering key fields across perception intelligence, decision intelligence, AI-enabled content generation and AI-enabled content enhancement, as well as key capabilities in AI chips, sensors and computing infrastructure. Our proprietary AI infrastructure, SenseCore, allows us to develop powerful and efficient AI software platforms that are scalable and adaptable for a wide range of applications.
Today, our technologies are trusted by customers and partners in many industry verticals including Smart Business, Smart City, Smart Life and Smart Auto.
SenseTime Group Inc. (stock code: 0020.HK) has successfully listed on the Main Board of the Stock Exchange of Hong Kong Limited (HKEX). We have offices in markets including Hong Kong, Mainland China, Taiwan, Macau, Japan, Singapore, Saudi Arabia, the United Arab Emirates, Malaysia and South Korea, etc., as well as presences in Thailand, Indonesia and the Philippines. For more information, please visit SenseTime'swebsiteas well as itsLinkedIn,Twitter,Facebook andYouTube pages.
SOURCE SenseTime
CONTACT: SenseTime Group Limited, Email: pr@sensetime.com  
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); PRESS RELEASES (90%); CORPORATE GOVERNANCE (89%); ASSOCIATIONS & ORGANIZATIONS (78%); PRODUCT DEVELOPMENT (78%); RESEARCH & DEVELOPMENT (78%); SUSTAINABLE DEVELOPMENT (78%); INTERNATIONAL ECONOMIC ORGANIZATIONS (74%); RESEARCH INSTITUTES (73%); EUROPEAN UNION (68%); - (%); SVY Surveys, polls & research studies (%); TDS Trade Shows (%); PDT New Products and Services (%)
Company: SenseTime
Ticker: 0020 (HongKong)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); SOFTWARE MAKERS (90%); SOFTWARE SERVICES & APPLICATIONS (90%); COMPUTER SOFTWARE (89%); SUSTAINABLE DEVELOPMENT (78%); INFORMATION SECURITY & PRIVACY (70%); PUB Publishing; Information Services (%)
Geographic: SHANGHAI, CHINA (79%); EAST CHINA (79%); CHINA (92%); ASIA (91%); UNITED STATES (79%); HONG KONG (74%); SINGAPORE (58%); EUROPEAN UNION MEMBER STATES (56%); China
Load-Date: September 5, 2022",positive,0.6192370653152466,balanced/neutral,"['privacy', 'transparency', 'security']",[],"['policy', 'governance', 'standards', 'should']",['algorithm'],3,0,4,1
2021,Unknown Title,"Byline: Express Computer
Body
Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.
Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purpose-""to make the world more sustainable by building trust in society through innovation."" To realize the vision of a sustainable world through its global business brand ""FUJITSU Uvance"" which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.
In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the ""Fujitsu Group External Advisory Committee on AI Ethics"" to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.
On February 1, Fujitsu will newly establish the ""AI Ethics and Governance Office"" (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.
This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); MACHINE LEARNING (73%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%); SAFETY (69%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%); SUSTAINABLE DEVELOPMENT (72%)
Load-Date: January 28, 2022","Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.
Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purpose-""to make the world more sustainable by building trust in society through innovation."" To realize the vision of a sustainable world through its global business brand ""FUJITSU Uvance"" which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.
In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the ""Fujitsu Group External Advisory Committee on AI Ethics"" to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.
On February 1, Fujitsu will newly establish the ""AI Ethics and Governance Office"" (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.
This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Classification
Language: ENGLISH
Publication-Type: Magazine
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); BUSINESS NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); MACHINE LEARNING (73%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%); SAFETY (69%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%); SUSTAINABLE DEVELOPMENT (72%)
Load-Date: January 28, 2022",positive,0.5923939943313599,balanced/neutral,['safety'],[],"['governance', 'framework']",['machine learning'],1,0,2,1
2021,Unknown Title,"Body
VISIUM TECHNOLOGIES INC (""VISM-0"") - Partnership With IREX AI, the Leader in Ethical AI for Video - Surveillance
Visium Technologies, Inc, (""Visium"" or the ""Company""), a provider of world-class real-time cybersecurity, context-focused analysis, and predictive visualization technologies, announced today that it has entered into an integration and partnership agreement with IREX AI, Inc., the premier provider of video-based solutions that empower city governments, public safety, organizations, transportation authorities, and service providers with an Ethical AI and Big Data platform.
Mark Lucky, CEO of Visium, commented, ""We are very pleased to be partnering with IREX, the leader in the race for Ethical AI and video analytics. They have an impressive track record of success and rapid growth, and we see our TruContextTM technology providing meaningful analytic, connected data and context focused enhancements to their current and future customers. IREX competes in the rapidly growing intelligence, surveillance, and reconnaissance market that is currently estimated at $86 billion annually. TruContextTM will provide significant enhancements to the IREX Ethical AI platform by mapping and overlaying threat detection information, People Analytics, and geolocation data onto its existing video and imaging representations to create a comprehensive dashboard to solve crime faster by considering the full context.""
Calvin Yadav, IREX CEO, added ""There is no denying that public safety is being driven by digital transformation and investment in smart cities. We are excited to team up IREX's SearchveillanceTM technology with Visium's groundbreaking TruContextTM . Co-joining Visium with the powerful Ethical AI engine of IREX makes the world's first Real-Time intelligence whiteboard with video &image validation technology called ELI (Ethical Layered Intelligence). ELI will change the game by shaving months from investigation(s) for Federal &local law enforcement or Military reconnaissance missions. Working with Visium and the enhancements that their TruContext technology provides to our Ethical Artificial Intelligence platform helps our customers to make decisions in real-time"" (figure class=""image image_resized"" style=""width:199px;"")(/figure) About IREX AI, Inc. IREX AI, Inc. is a provider of AI-powered video analytics operating in over 30 countries world-wide. IREX's mission is to mold cities of the future: safe, comfortable, and sustainable. The IREX Ethical AI and Big Data platform focuses on public safety and connects cameras and sensors to a secure private cloud, analyzing data in real-time and providing vital, proactive opportunities to prevent security and safety incidents. IREX allows cities to adapt to ever-changing threats, using Ethical AI technology to combat 21st-century problems such as pandemics, overcrowding, missing children, mass shootings, rising crime rates, and much more.
For more information, please visit www.IREX.AI (figure class=""image image_resized"" style=""width:277px;"")(/figure) About Visium Technologies, Inc Visium Technologies, Inc. (OTC PINK:VISM) is a Florida corporation based in Fairfax, Virginia, focused on providing context enabling global cybersecurity clarity, using machine learning and advanced algorithms to support enterprises in protecting their most valuable assets - their data, business applications, and IoT on their networks and in the cloud.
For more information please visit www.visiumtechnologies.com
Safe Harbor Statement: Under the Private Securities Litigation Reform Act of 1995: This release includes forward-looking statements that reflect management's current views with respect to future events and performance. These forward-looking statements are based on management's beliefs and assumptions and information currently available. The words ""believe,"" ""expect,"" ""anticipate,"" ""intend,"" ""estimate,"" ""project"" and similar expressions that do not relate solely to historical matters identify forward-looking statements. Investors should be cautious in relying on forward-looking statements because they are subject to a variety of risks, uncertainties, and other factors that could cause actual results to differ materially from those expressed in any such forward-looking statements. These factors include, but are not limited to, whether the reverse stock split will be beneficial to the Company and its shareholders, any inability to meet the NYSE American continued listing standards in the future for any reason, and those other factors described in our filings with the U.S. Securities and Exchange Commission. Any responsibility to update forward-looking statements is expressly disclaimed. IREX AI, Inc. Corporate: Calvin Yadav, Chief Executive Officer calvin@irex.ai Corporate Office: 901 N Pitt Street, Suite 170 Alexandria, VA 22314 Visium Technologies, Inc. Corporate: Mark Lucky, Chief Executive Officer mlucky@visiumtechnologies.com Follow us on Twitter and Instagram Twitter | Instagram Corporate Office: 4094 Majestic Lane Suite 360 Fairfax, VA 22033 Phone: 703-273-0383
______________________________________
_______________________________________________
____________________________________________________________
(c)2022 Market News Publishing Inc. All rights reserved. Toronto:(416)366-8881 Vancouver:(604)689-1101 Fax:(604)689-1106
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: MNP
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); SURVEILLANCE (92%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (90%); SAFETY (90%); SURVEILLANCE TECHNOLOGY (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (89%); ESPIONAGE (89%); ETHICS (89%); INVESTIGATIONS (89%); MILITARY SURVEILLANCE (89%); NEGATIVE NEWS (89%); SAFETY, ACCIDENTS & DISASTERS (89%); NEGATIVE PERSONAL NEWS (88%); CRIME RATES (87%); AGREEMENTS (78%); EXECUTIVES (78%); GEOSPATIAL DATA (78%); LAW ENFORCEMENT (78%); SMART CITIES (78%); PARTNERSHIP AGREEMENTS (73%); CITIES (70%); CITY GOVERNMENT (70%); PLATFORMS & ISSUES (70%); REGIONAL & LOCAL GOVERNMENTS (70%); TRANSPORTATION DEPARTMENTS (70%); ASSOCIATIONS & ORGANIZATIONS (55%); MASS SHOOTINGS (50%)
Company: VISIUM TECHNOLOGIES INC
Ticker: VISM; (Nasdaq Pink Sheets)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (90%); BIG DATA (89%); MILITARY SURVEILLANCE (89%); CAMERAS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GEOSPATIAL DATA (78%); INFORMATION SECURITY & PRIVACY (77%); TRANSPORTATION DEPARTMENTS (70%)
Load-Date: March 31, 2022","VISIUM TECHNOLOGIES INC (""VISM-0"") - Partnership With IREX AI, the Leader in Ethical AI for Video - Surveillance
Visium Technologies, Inc, (""Visium"" or the ""Company""), a provider of world-class real-time cybersecurity, context-focused analysis, and predictive visualization technologies, announced today that it has entered into an integration and partnership agreement with IREX AI, Inc., the premier provider of video-based solutions that empower city governments, public safety, organizations, transportation authorities, and service providers with an Ethical AI and Big Data platform.
Mark Lucky, CEO of Visium, commented, ""We are very pleased to be partnering with IREX, the leader in the race for Ethical AI and video analytics. They have an impressive track record of success and rapid growth, and we see our TruContextTM technology providing meaningful analytic, connected data and context focused enhancements to their current and future customers. IREX competes in the rapidly growing intelligence, surveillance, and reconnaissance market that is currently estimated at $86 billion annually. TruContextTM will provide significant enhancements to the IREX Ethical AI platform by mapping and overlaying threat detection information, People Analytics, and geolocation data onto its existing video and imaging representations to create a comprehensive dashboard to solve crime faster by considering the full context.""
Calvin Yadav, IREX CEO, added ""There is no denying that public safety is being driven by digital transformation and investment in smart cities. We are excited to team up IREX's SearchveillanceTM technology with Visium's groundbreaking TruContextTM . Co-joining Visium with the powerful Ethical AI engine of IREX makes the world's first Real-Time intelligence whiteboard with video &image validation technology called ELI (Ethical Layered Intelligence). ELI will change the game by shaving months from investigation(s) for Federal &local law enforcement or Military reconnaissance missions. Working with Visium and the enhancements that their TruContext technology provides to our Ethical Artificial Intelligence platform helps our customers to make decisions in real-time"" (figure class=""image image_resized"" style=""width:199px;"")(/figure) About IREX AI, Inc. IREX AI, Inc. is a provider of AI-powered video analytics operating in over 30 countries world-wide. IREX's mission is to mold cities of the future: safe, comfortable, and sustainable. The IREX Ethical AI and Big Data platform focuses on public safety and connects cameras and sensors to a secure private cloud, analyzing data in real-time and providing vital, proactive opportunities to prevent security and safety incidents. IREX allows cities to adapt to ever-changing threats, using Ethical AI technology to combat 21st-century problems such as pandemics, overcrowding, missing children, mass shootings, rising crime rates, and much more.
For more information, please visit www.IREX.AI (figure class=""image image_resized"" style=""width:277px;"")(/figure) About Visium Technologies, Inc Visium Technologies, Inc. (OTC PINK:VISM) is a Florida corporation based in Fairfax, Virginia, focused on providing context enabling global cybersecurity clarity, using machine learning and advanced algorithms to support enterprises in protecting their most valuable assets - their data, business applications, and IoT on their networks and in the cloud.
For more information please visit www.visiumtechnologies.com
Safe Harbor Statement: Under the Private Securities Litigation Reform Act of 1995: This release includes forward-looking statements that reflect management's current views with respect to future events and performance. These forward-looking statements are based on management's beliefs and assumptions and information currently available. The words ""believe,"" ""expect,"" ""anticipate,"" ""intend,"" ""estimate,"" ""project"" and similar expressions that do not relate solely to historical matters identify forward-looking statements. Investors should be cautious in relying on forward-looking statements because they are subject to a variety of risks, uncertainties, and other factors that could cause actual results to differ materially from those expressed in any such forward-looking statements. These factors include, but are not limited to, whether the reverse stock split will be beneficial to the Company and its shareholders, any inability to meet the NYSE American continued listing standards in the future for any reason, and those other factors described in our filings with the U.S. Securities and Exchange Commission. Any responsibility to update forward-looking statements is expressly disclaimed. IREX AI, Inc. Corporate: Calvin Yadav, Chief Executive Officer calvin@irex.ai Corporate Office: 901 N Pitt Street, Suite 170 Alexandria, VA 22314 Visium Technologies, Inc. Corporate: Mark Lucky, Chief Executive Officer mlucky@visiumtechnologies.com Follow us on Twitter and Instagram Twitter | Instagram Corporate Office: 4094 Majestic Lane Suite 360 Fairfax, VA 22033 Phone: 703-273-0383
______________________________________
_______________________________________________
____________________________________________________________
(c)2022 Market News Publishing Inc. All rights reserved. Toronto:(416)366-8881 Vancouver:(604)689-1101 Fax:(604)689-1106
Classification
Language: ENGLISH
Publication-Type: Newswire
Journal Code: MNP
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); SURVEILLANCE (92%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (90%); SAFETY (90%); SURVEILLANCE TECHNOLOGY (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (89%); ESPIONAGE (89%); ETHICS (89%); INVESTIGATIONS (89%); MILITARY SURVEILLANCE (89%); NEGATIVE NEWS (89%); SAFETY, ACCIDENTS & DISASTERS (89%); NEGATIVE PERSONAL NEWS (88%); CRIME RATES (87%); AGREEMENTS (78%); EXECUTIVES (78%); GEOSPATIAL DATA (78%); LAW ENFORCEMENT (78%); SMART CITIES (78%); PARTNERSHIP AGREEMENTS (73%); CITIES (70%); CITY GOVERNMENT (70%); PLATFORMS & ISSUES (70%); REGIONAL & LOCAL GOVERNMENTS (70%); TRANSPORTATION DEPARTMENTS (70%); ASSOCIATIONS & ORGANIZATIONS (55%); MASS SHOOTINGS (50%)
Company: VISIUM TECHNOLOGIES INC
Ticker: VISM; (Nasdaq Pink Sheets)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); DATA ANALYTICS (90%); BIG DATA (89%); MILITARY SURVEILLANCE (89%); CAMERAS (78%); DIGITALIZATION & DIGITAL TRANSFORMATION (78%); GEOSPATIAL DATA (78%); INFORMATION SECURITY & PRIVACY (77%); TRANSPORTATION DEPARTMENTS (70%)
Load-Date: March 31, 2022",positive,0.5751084089279175,balanced/neutral,"['privacy', 'surveillance', 'safety', 'security']",[],"['standards', 'law', 'should']",['machine learning'],4,0,3,1
2021,Unknown Title,"Byline: Crypto AM: Blockchanging the World Bit by Bit with Dr Jane Thomason
Highlight: Crypto AM's Dr Jane Thomason explores the ethics of blockchain, and how the industry must get it right.The post Why the blockchain community needs ethics appeared first on CityAM.
Body
2020 and 2021 have been exciting years for blockchain, with fortunes being made and lost at a breath-taking rate! Certik  reported that the amount of money lost in DeFi hacks more than doubled to $1.3 billion in 2021, with centralisation the most common vulnerability. 
We all chuckled when Chef Nomi  ran off with $14 m from Sushi Swap and sheepishly returned it. But was it really funny? That was someone's money. Do we pause to think about the consequences of what we are doing in this growing ecosystem?
Last year, we asked that very question in Applied Ethics in a Digital World  , and I tackled the ethical challenges of Blockchain and DeFi.  Let me highlight some of these issues. The potent mix of automation and financial technologies powering faster transactions and accumulating masses of consumer data surfaces a plethora of ethical questions and demands new approaches and frameworks to ensure that ethics are baked into the design of these new and powerful technologies.
                                            Technology stack                                        
At the tech stack level, we need to ensure proper conditions and methods of data sharing in blockchain meet expectations in terms of security, privacy, efficiency, and system integrity. The key ethical question at the technology stack level is ""how should data security, privacy, and accessibility be ensured ethically, and what ethical information management strategy should be applied in system development and use?"".
                                            Applications                                        
It is in the applications that are built on blockchains, that the biggest ethical questions emerge.
Cryptocurrency risks include consumer protection, money laundering, criminal abuses, volatility and tax evasion, among others. Bitcoin has been criticised for costly, energy-hungry and otherwise meaningless computations used in mining. Many are working on advances in the underlying mechanisms needed to make cryptocurrencies more ethical and sustainable.
DeFi presents an array of ethical challenges, many related to consumer protection. Most DAOs raise money and, in return, investors get back governance tokens, thus creating a high degree of centralisation at the start of token distribution. As Protocols started using their governance tokens as ""rewards"" for users participating in the network, many users see tokens as yield, not voting rights. 
There is usually no minimum number to initiate the governance, but in order for a system to be considered sufficiently decentralised, there needs to be a high minimum number of token holders. Thus, the economic incentives of providing liquidity in order to get rewarded with governance tokens, encourages competitive and speculative behavior  which leads to a centralised governance structure, since tokens slowly concentrate in a few hands. Excessive centralisation means parties with conflict of interest can push through proposals, and activist investors can acquire a significant number of governance tokens to help push through proposals profitable to them.
Smart contracts raise ethical questions about self-executing code that operates autonomously and raise questions of legal jurisdiction and issues of territoriality. There is no legal recognition of documents or financial instruments stored on or issued for blockchains. When a smart contract fails, under which law and in which jurisdiction can action be taken? The legal status of a DAO is also a grey area, as nobody owns the organisation, who can be sued and who sues or in the case of liquidating a tangible asset owned by the DAO, what rules are to be followed?
                                            Institutions and society                                        
Challenges for regulators include decentralising the financial system, managing economic stability, and protecting consumer interests. Cryptocurrencies are in direct conflict with the established monetary systems and inevitably create ethical challenges for monetary policy. 
Blockchain, like all technologies, can be misused, especially when there are risks of authoritarian states, persecution, and unintended consequences. There are risks of bad actors using digital identities, bank accounts, and mobile phones that allow authorities to track people's choices. Such control might allow authorities to increase surveillance over vulnerable or persecuted populations. An authoritarian state could use such data collected from refugees against refugees, or nations of the global North that have no sympathy for the movements of refugees and immigrants, to keep refugees in neighboring countries.
                                            Data ethics                                        
 Data ethics studies evaluate moral problems related to data (including generation, recording, curation, processing, dissemination, sharing, and use, for example), algorithms (artificial intelligence, artificial agents, machine learning, and robots), and corresponding practices (responsible innovation, programming, hacking, and professional codes), to form and support morally good solutions (right conducts or values). 
Key ethical issues include the re-identification of individuals through data-mining, linking, merging, and re-using large datasets, as well as risks for group privacy, when the identification of types of individuals, independently of the de-identification of each of them, may lead to serious ethical problems , from group discrimination to group-targeted forms of violence. Automation has significantly increased processing speed but also led to more ethical risks and the need to examine unintended consequences of an automated technology. Scott (2018)  raises some powerful ethical questions related to automation, including what happens when there is a mistake or vulnerability in the code?
                                            Consumer vulnerability                                        
At the heart of ethical considerations for blockchain lies consumer protection. The vast amount of personal and private data stored creates a number of points for consumer vulnerability. Sensitive, personally identifiable information for some of the most vulnerable people in the world is also being generated and made accessible across agencies, inevitably introducing a greater risk of data breaches.
                                            Decentralised autonomous organisations                                        
While DAOs have been widely promoted by blockchain proponents as providing transparency and trust, it is increasingly evident that DAOs are still in an experimental stage; there are also a large number of information asymmetries that may exist in a DAO and participant ambitions, motivations, values, or priorities are not transparent. 
When automatically executable contracts such as those that underpinned the DAO are exploited, there is little legal recourse for those affected. Goodell and Aste  argue that for Blockchain to be widely distributed in any given investment community, there must be some degree of adaptation with traditional ways of operating by introducing regulation.
                                            What does all this mean?                                        
There is certainly scope for greater ethical reflection and purposeful consideration of ethics in the design of blockchain and DeFi applications. This should include:
                                            Encourage greater ethical reflection from developers during design.                       Connect developers more closely to the ethical outcomes of their decisions and algorithms.                       Encourage community and network to take a more active and demanding stance on ethics.                       Encourage community and network to understand what is happening behind the scenes with governance and decisions.                                        
Blockchain can have ethical impacts at the technology, application, and societal levels. It is important that these are considered and built into system design with intentionality.
While the promise of automation and decentralisation is attractive, it is important to avoid the inadvertent facilitation of unethical conduct. Blockchain technology is a conditional good; it is only as beneficial and useful as the care that is taken to make it. As Simon Langstaff said  ""get the ethics right and we will be able to look back at this time of decision without regret"".
The post Why the blockchain community needs ethics  appeared first on CityAM. 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: WEBCTY
Subject: ETHICS (95%); BLOCKCHAIN (91%); CRYPTOCURRENCY (90%); DECENTRALIZED FINANCE (90%); FINANCIAL TECHNOLOGY (90%); CONSUMER PROTECTION (89%); DIGITAL CURRENCY (89%); NEGATIVE NEWS (89%); CONSUMER LAW (88%); FRAUD & FINANCIAL CRIME (69%); TAXES & TAXATION (67%); EXTORTION (64%); MONEY LAUNDERING (64%); TAX FRAUD (64%); TAX LAW (64%); JURISDICTION (50%)
Industry: BLOCKCHAIN (91%); CRYPTOCURRENCY (90%); DECENTRALIZED FINANCE (90%); FINANCIAL TECHNOLOGY (90%); CRYPTO ASSETS (89%); DIGITAL CURRENCY (89%); INFORMATION SECURITY & PRIVACY (77%); INFORMATION MANAGEMENT & TECHNOLOGY (74%); DATA SECURITY (73%); BANKING & FINANCE (69%); INFORMATION MANAGEMENT (68%)
Load-Date: March 3, 2022","2020 and 2021 have been exciting years for blockchain, with fortunes being made and lost at a breath-taking rate! Certik  reported that the amount of money lost in DeFi hacks more than doubled to $1.3 billion in 2021, with centralisation the most common vulnerability. 
We all chuckled when Chef Nomi  ran off with $14 m from Sushi Swap and sheepishly returned it. But was it really funny? That was someone's money. Do we pause to think about the consequences of what we are doing in this growing ecosystem?
Last year, we asked that very question in Applied Ethics in a Digital World  , and I tackled the ethical challenges of Blockchain and DeFi.  Let me highlight some of these issues. The potent mix of automation and financial technologies powering faster transactions and accumulating masses of consumer data surfaces a plethora of ethical questions and demands new approaches and frameworks to ensure that ethics are baked into the design of these new and powerful technologies.
                                            Technology stack                                        
At the tech stack level, we need to ensure proper conditions and methods of data sharing in blockchain meet expectations in terms of security, privacy, efficiency, and system integrity. The key ethical question at the technology stack level is ""how should data security, privacy, and accessibility be ensured ethically, and what ethical information management strategy should be applied in system development and use?"".
                                            Applications                                        
It is in the applications that are built on blockchains, that the biggest ethical questions emerge.
Cryptocurrency risks include consumer protection, money laundering, criminal abuses, volatility and tax evasion, among others. Bitcoin has been criticised for costly, energy-hungry and otherwise meaningless computations used in mining. Many are working on advances in the underlying mechanisms needed to make cryptocurrencies more ethical and sustainable.
DeFi presents an array of ethical challenges, many related to consumer protection. Most DAOs raise money and, in return, investors get back governance tokens, thus creating a high degree of centralisation at the start of token distribution. As Protocols started using their governance tokens as ""rewards"" for users participating in the network, many users see tokens as yield, not voting rights. 
There is usually no minimum number to initiate the governance, but in order for a system to be considered sufficiently decentralised, there needs to be a high minimum number of token holders. Thus, the economic incentives of providing liquidity in order to get rewarded with governance tokens, encourages competitive and speculative behavior  which leads to a centralised governance structure, since tokens slowly concentrate in a few hands. Excessive centralisation means parties with conflict of interest can push through proposals, and activist investors can acquire a significant number of governance tokens to help push through proposals profitable to them.
Smart contracts raise ethical questions about self-executing code that operates autonomously and raise questions of legal jurisdiction and issues of territoriality. There is no legal recognition of documents or financial instruments stored on or issued for blockchains. When a smart contract fails, under which law and in which jurisdiction can action be taken? The legal status of a DAO is also a grey area, as nobody owns the organisation, who can be sued and who sues or in the case of liquidating a tangible asset owned by the DAO, what rules are to be followed?
                                            Institutions and society                                        
Challenges for regulators include decentralising the financial system, managing economic stability, and protecting consumer interests. Cryptocurrencies are in direct conflict with the established monetary systems and inevitably create ethical challenges for monetary policy. 
Blockchain, like all technologies, can be misused, especially when there are risks of authoritarian states, persecution, and unintended consequences. There are risks of bad actors using digital identities, bank accounts, and mobile phones that allow authorities to track people's choices. Such control might allow authorities to increase surveillance over vulnerable or persecuted populations. An authoritarian state could use such data collected from refugees against refugees, or nations of the global North that have no sympathy for the movements of refugees and immigrants, to keep refugees in neighboring countries.
                                            Data ethics                                        
 Data ethics studies evaluate moral problems related to data (including generation, recording, curation, processing, dissemination, sharing, and use, for example), algorithms (artificial intelligence, artificial agents, machine learning, and robots), and corresponding practices (responsible innovation, programming, hacking, and professional codes), to form and support morally good solutions (right conducts or values). 
Key ethical issues include the re-identification of individuals through data-mining, linking, merging, and re-using large datasets, as well as risks for group privacy, when the identification of types of individuals, independently of the de-identification of each of them, may lead to serious ethical problems , from group discrimination to group-targeted forms of violence. Automation has significantly increased processing speed but also led to more ethical risks and the need to examine unintended consequences of an automated technology. Scott (2018)  raises some powerful ethical questions related to automation, including what happens when there is a mistake or vulnerability in the code?
                                            Consumer vulnerability                                        
At the heart of ethical considerations for blockchain lies consumer protection. The vast amount of personal and private data stored creates a number of points for consumer vulnerability. Sensitive, personally identifiable information for some of the most vulnerable people in the world is also being generated and made accessible across agencies, inevitably introducing a greater risk of data breaches.
                                            Decentralised autonomous organisations                                        
While DAOs have been widely promoted by blockchain proponents as providing transparency and trust, it is increasingly evident that DAOs are still in an experimental stage; there are also a large number of information asymmetries that may exist in a DAO and participant ambitions, motivations, values, or priorities are not transparent. 
When automatically executable contracts such as those that underpinned the DAO are exploited, there is little legal recourse for those affected. Goodell and Aste  argue that for Blockchain to be widely distributed in any given investment community, there must be some degree of adaptation with traditional ways of operating by introducing regulation.
                                            What does all this mean?                                        
There is certainly scope for greater ethical reflection and purposeful consideration of ethics in the design of blockchain and DeFi applications. This should include:
                                            Encourage greater ethical reflection from developers during design.                       Connect developers more closely to the ethical outcomes of their decisions and algorithms.                       Encourage community and network to take a more active and demanding stance on ethics.                       Encourage community and network to understand what is happening behind the scenes with governance and decisions.                                        
Blockchain can have ethical impacts at the technology, application, and societal levels. It is important that these are considered and built into system design with intentionality.
While the promise of automation and decentralisation is attractive, it is important to avoid the inadvertent facilitation of unethical conduct. Blockchain technology is a conditional good; it is only as beneficial and useful as the care that is taken to make it. As Simon Langstaff said  ""get the ethics right and we will be able to look back at this time of decision without regret"".
The post Why the blockchain community needs ethics  appeared first on CityAM. 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: WEBCTY
Subject: ETHICS (95%); BLOCKCHAIN (91%); CRYPTOCURRENCY (90%); DECENTRALIZED FINANCE (90%); FINANCIAL TECHNOLOGY (90%); CONSUMER PROTECTION (89%); DIGITAL CURRENCY (89%); NEGATIVE NEWS (89%); CONSUMER LAW (88%); FRAUD & FINANCIAL CRIME (69%); TAXES & TAXATION (67%); EXTORTION (64%); MONEY LAUNDERING (64%); TAX FRAUD (64%); TAX LAW (64%); JURISDICTION (50%)
Industry: BLOCKCHAIN (91%); CRYPTOCURRENCY (90%); DECENTRALIZED FINANCE (90%); FINANCIAL TECHNOLOGY (90%); CRYPTO ASSETS (89%); DIGITAL CURRENCY (89%); INFORMATION SECURITY & PRIVACY (77%); INFORMATION MANAGEMENT & TECHNOLOGY (74%); DATA SECURITY (73%); BANKING & FINANCE (69%); INFORMATION MANAGEMENT (68%)
Load-Date: March 3, 2022",positive,0.7445868253707886,balanced/neutral,"['privacy', 'surveillance', 'discrimination', 'transparency', 'security']",[],"['regulation', 'policy', 'governance', 'law', 'should', 'must', 'need to']",['machine learning'],5,0,7,1
2021,Unknown Title,"Body
On July 4, the Aspen Institute Mexico will organize a webinar on Ethics and Artificial Intelligence, with the participation of Gabriela Ramos, promoter of the initiative of the first global standard on the ethics of artificial intelligence, adopted by UNESCO Member States at the General Conference.
It is a fact that there is only an offline world and a digital or online world. Since the beginning of social networks and the widespread use of so-called smartphones connected to the internet, the digital world has progressively become the most important part of our lives, to the point where we are now: we can no longer imagine a world without being connected to the internet.
""In 2018, Audrey Azoulay, Director-General of UNESCO, launched an ambitious project: to give the world an ethical framework for the use of artificial intelligence. Three years later, thanks to the mobilization of hundreds of experts from around the world and intense international negotiations, UNESCO's 193 Member States have just officially adopted this ethical framework.""
UNESCO's recommendation includes these points: data protection, banning social bookmarking and mass surveillance, helping to monitor and evaluate, as well as environmental protection.
All of us who are connected, we are exposed, and in one way or another, we have been prey to some kind of abuse of our personal data, even without knowing it. The problem starts from the lack of knowledge of citizens about their rights and the obligations of companies, in terms of data protection.
In a way, we all fall prey to the ""like"" culture, which exposes us to the constant expectation of causing a reaction in the largest number of ""friends"" or ""followers"" with whom we connect. Even knowing that, to a large extent, the result of the reactions we cause is manipulated by algorithms enabled with artificial intelligence.
The best way to evaluate the outcome of implementing artificial intelligence technologies is not measured in terms of the number of tasks that can be automated, but in the impact they have on people's well-being. The mission of artificial intelligence tools should be to enable humans, not to limit them.
We are at the dawn of becoming an interplanetary race, yet the earth remains our only viable option to maintain the mass survival of our species, so one of the main missions of artificial intelligence should be to help us combat climate change and manage natural resources to keep the human race safe.
These are some of the topics we will be discussing in the webinar, so see you on July 4th.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (92%); AGREEMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); VIRTUAL EVENTS (90%); ENVIRONMENTAL TREATIES & AGREEMENTS (78%); ENVIRONMENTALISM (78%); TREATIES & AGREEMENTS (78%); INTERNET SOCIAL NETWORKING (76%); SOCIAL MEDIA (76%); INTELLIGENCE SERVICES (73%); SURVEILLANCE (73%); CLIMATE CHANGE (71%); CONSERVATION (71%); ENVIRONMENT & NATURAL RESOURCES (71%); NEGATIVE NEWS (71%); SOCIAL NETWORKING (71%); NATURAL RESOURCES (66%); NATURAL RESOURCES MANAGEMENT (66%)
Organization: ASPEN INSTITUTE (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INTERNET & WWW (90%); TELECONFERENCING (90%); ONLINE SECURITY & PRIVACY (89%); DATA SECURITY (87%); INFORMATION SECURITY & PRIVACY (87%); INTERNET SOCIAL NETWORKING (76%); SOCIAL MEDIA (76%); MOBILE & CELLULAR TELEPHONES (56%)
Load-Date: August 17, 2022","On July 4, the Aspen Institute Mexico will organize a webinar on Ethics and Artificial Intelligence, with the participation of Gabriela Ramos, promoter of the initiative of the first global standard on the ethics of artificial intelligence, adopted by UNESCO Member States at the General Conference.
It is a fact that there is only an offline world and a digital or online world. Since the beginning of social networks and the widespread use of so-called smartphones connected to the internet, the digital world has progressively become the most important part of our lives, to the point where we are now: we can no longer imagine a world without being connected to the internet.
""In 2018, Audrey Azoulay, Director-General of UNESCO, launched an ambitious project: to give the world an ethical framework for the use of artificial intelligence. Three years later, thanks to the mobilization of hundreds of experts from around the world and intense international negotiations, UNESCO's 193 Member States have just officially adopted this ethical framework.""
UNESCO's recommendation includes these points: data protection, banning social bookmarking and mass surveillance, helping to monitor and evaluate, as well as environmental protection.
All of us who are connected, we are exposed, and in one way or another, we have been prey to some kind of abuse of our personal data, even without knowing it. The problem starts from the lack of knowledge of citizens about their rights and the obligations of companies, in terms of data protection.
In a way, we all fall prey to the ""like"" culture, which exposes us to the constant expectation of causing a reaction in the largest number of ""friends"" or ""followers"" with whom we connect. Even knowing that, to a large extent, the result of the reactions we cause is manipulated by algorithms enabled with artificial intelligence.
The best way to evaluate the outcome of implementing artificial intelligence technologies is not measured in terms of the number of tasks that can be automated, but in the impact they have on people's well-being. The mission of artificial intelligence tools should be to enable humans, not to limit them.
We are at the dawn of becoming an interplanetary race, yet the earth remains our only viable option to maintain the mass survival of our species, so one of the main missions of artificial intelligence should be to help us combat climate change and manage natural resources to keep the human race safe.
These are some of the topics we will be discussing in the webinar, so see you on July 4th.
Classification
Language: ENGLISH
Publication-Type: Newspaper
Journal Code: CENFENG
Subject: ARTIFICIAL INTELLIGENCE ETHICS (93%); ETHICS (92%); AGREEMENTS (90%); ARTIFICIAL INTELLIGENCE (90%); VIRTUAL EVENTS (90%); ENVIRONMENTAL TREATIES & AGREEMENTS (78%); ENVIRONMENTALISM (78%); TREATIES & AGREEMENTS (78%); INTERNET SOCIAL NETWORKING (76%); SOCIAL MEDIA (76%); INTELLIGENCE SERVICES (73%); SURVEILLANCE (73%); CLIMATE CHANGE (71%); CONSERVATION (71%); ENVIRONMENT & NATURAL RESOURCES (71%); NEGATIVE NEWS (71%); SOCIAL NETWORKING (71%); NATURAL RESOURCES (66%); NATURAL RESOURCES MANAGEMENT (66%)
Organization: ASPEN INSTITUTE (84%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (93%); ARTIFICIAL INTELLIGENCE (90%); INTERNET & WWW (90%); TELECONFERENCING (90%); ONLINE SECURITY & PRIVACY (89%); DATA SECURITY (87%); INFORMATION SECURITY & PRIVACY (87%); INTERNET SOCIAL NETWORKING (76%); SOCIAL MEDIA (76%); MOBILE & CELLULAR TELEPHONES (56%)
Load-Date: August 17, 2022",neutral,0.8084862232208252,balanced/neutral,"['privacy', 'surveillance', 'security']",[],"['framework', 'should']",[],3,0,2,0
2021,Unknown Title,"Body
(GlobeNewswire) - The Alberta Machine Intelligence Institute (Amii) and the CIO Strategy Council (CIOSC) have launched a new Artificial Intelligence (AI) Governance course to empower startups and small and medium businesses to develop strong ethical and governance foundations for AI-enabled products. The interactive workshop, led by machine learning experts from Amii, helps companies derisk the responsible development of AI products through a focus on ethics, governance and fairness. With increasing attention being paid to the social, cultural and economic impacts of AI from all sectors of society, the course offers a tangible path forward for businesses looking to minimize drawbacks while capturing the benefits of AI systems.
Designed for business leaders and technical teams alike, the course enables participants to: Have strong foundation for understanding ethical questions in AI;Discuss the positive business impacts of a fairness-first approach to AI adoption;Identify ethical risks within an organization in terms of AI application; andPlan the next steps to continuously identify and mitigate risks in AI adoption.
As AI is embedded ever more deeply into products and services, it is essential that companies have robust governance frameworks in place, says Keith Jansa, Executive Director of CIOSC. This program will give participants a good understanding of emerging standards in this area and equip them with the tools they need to ensure they are building and operating AI systems in a responsible way.
The course offers participants a greater awareness of ethical considerations in AI, an understanding of the factors to look out for within an organization and concrete approaches companies can take to ensure the responsible development of AI systems. Rounding out the content, the course also includes case studies on the ethics of specific AI applications, a focus on AI governance structures and offers actionable strategies and frameworks that businesses can use to develop and improve their own AI standards and practices. The course also helps companies take the next steps by connecting them with resources and support to build robust AI ethics practices through the AI Ethics and Governance Registry.
Every year, more businesses turn to AI for their next competitive advantage, and with this growth comes a greater need for training and resources to guide the responsible development of the technology, says Stephanie Enders, VP of Product at Amii. As an organization committed to AI for good and for all, Amii is proud to work alongside the CIO Standards Council to lend our expertise to help companies avoid future risk by building an understanding of best practices.
The course comes at a time when increasing emphasis is being placed on AI standards by government and numerous other sectors of society. With the $443 million renewal of the Pan-Canadian AI Strategy, the Government of Canada recently-announced plans to advance the development and adoption of standards and a conformity assessment program related to AI. Through this course in AI Governance, companies can take meaningful steps toward ensuring compliance and developing their own internal frameworks to support the responsible development of AI.
About Amii
One of Canadas three centres of AI excellence as part of the Pan-Canadian AI Strategy, Amii (the Alberta Machine Intelligence Institute) is an Alberta-based non-profit institute that supports world-leading research in artificial intelligence and machine learning and translates scientific advancement into industry adoption. Amii grows AI capabilities through advancing leading-edge research, delivering exceptional educational offerings and providing business advice all with the goal of building in-house AI capabilities. For more information, visit amii.ca.
About the CIO Strategy Council
The CIO Strategy Council is Canadas national forum that brings together the countrys most forward-thinking chief information officers and executive technology leaders to collectively mobilize on common digital priorities. Cutting across major sectors of the Canadian economy public, private and not for profit the Council harnesses the collective expertise and action of Canadas CIOs to propel Canada as a digital-first nation. The CIO Strategy Council is accredited by the Standards Council of Canada and develops standards that support the data-driven economy. Learn more at ciostrategycouncil.com.
TO ARRANGE AN INTERVIEW WITH Amii, PLEASE CONTACT:
Spencer Murray
Director, Communications & Public Relations
spencer.murray@amii.ca 
TO ARRANGE AN INTERVIEW WITH THE CIOSC, PLEASE CONTACT:
Katie Gibson
Vice President, Strategy and Partnerships
katie.gibson@ciostrategycouncil.com 
Spencer Murray
Communications & Public Relations
t: 587.415.6100 ext. 109 | c: 780.991.7136
spencer.murray@amii.ca 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1788
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EXECUTIVES (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BEST PRACTICES (78%); CASE STUDIES (78%); CORPORATE GOVERNANCE (78%); PRODUCT DEVELOPMENT (78%); SMALL BUSINESS (77%); MACHINE LEARNING (73%); ECONOMICS (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%)
Geographic: ALBERTA, CANADA (58%); CANADA (92%)
Load-Date: July 22, 2022","(GlobeNewswire) - The Alberta Machine Intelligence Institute (Amii) and the CIO Strategy Council (CIOSC) have launched a new Artificial Intelligence (AI) Governance course to empower startups and small and medium businesses to develop strong ethical and governance foundations for AI-enabled products. The interactive workshop, led by machine learning experts from Amii, helps companies derisk the responsible development of AI products through a focus on ethics, governance and fairness. With increasing attention being paid to the social, cultural and economic impacts of AI from all sectors of society, the course offers a tangible path forward for businesses looking to minimize drawbacks while capturing the benefits of AI systems.
Designed for business leaders and technical teams alike, the course enables participants to: Have strong foundation for understanding ethical questions in AI;Discuss the positive business impacts of a fairness-first approach to AI adoption;Identify ethical risks within an organization in terms of AI application; andPlan the next steps to continuously identify and mitigate risks in AI adoption.
As AI is embedded ever more deeply into products and services, it is essential that companies have robust governance frameworks in place, says Keith Jansa, Executive Director of CIOSC. This program will give participants a good understanding of emerging standards in this area and equip them with the tools they need to ensure they are building and operating AI systems in a responsible way.
The course offers participants a greater awareness of ethical considerations in AI, an understanding of the factors to look out for within an organization and concrete approaches companies can take to ensure the responsible development of AI systems. Rounding out the content, the course also includes case studies on the ethics of specific AI applications, a focus on AI governance structures and offers actionable strategies and frameworks that businesses can use to develop and improve their own AI standards and practices. The course also helps companies take the next steps by connecting them with resources and support to build robust AI ethics practices through the AI Ethics and Governance Registry.
Every year, more businesses turn to AI for their next competitive advantage, and with this growth comes a greater need for training and resources to guide the responsible development of the technology, says Stephanie Enders, VP of Product at Amii. As an organization committed to AI for good and for all, Amii is proud to work alongside the CIO Standards Council to lend our expertise to help companies avoid future risk by building an understanding of best practices.
The course comes at a time when increasing emphasis is being placed on AI standards by government and numerous other sectors of society. With the $443 million renewal of the Pan-Canadian AI Strategy, the Government of Canada recently-announced plans to advance the development and adoption of standards and a conformity assessment program related to AI. Through this course in AI Governance, companies can take meaningful steps toward ensuring compliance and developing their own internal frameworks to support the responsible development of AI.
About Amii
One of Canadas three centres of AI excellence as part of the Pan-Canadian AI Strategy, Amii (the Alberta Machine Intelligence Institute) is an Alberta-based non-profit institute that supports world-leading research in artificial intelligence and machine learning and translates scientific advancement into industry adoption. Amii grows AI capabilities through advancing leading-edge research, delivering exceptional educational offerings and providing business advice all with the goal of building in-house AI capabilities. For more information, visit amii.ca.
About the CIO Strategy Council
The CIO Strategy Council is Canadas national forum that brings together the countrys most forward-thinking chief information officers and executive technology leaders to collectively mobilize on common digital priorities. Cutting across major sectors of the Canadian economy public, private and not for profit the Council harnesses the collective expertise and action of Canadas CIOs to propel Canada as a digital-first nation. The CIO Strategy Council is accredited by the Standards Council of Canada and develops standards that support the data-driven economy. Learn more at ciostrategycouncil.com.
TO ARRANGE AN INTERVIEW WITH Amii, PLEASE CONTACT:
Spencer Murray
Director, Communications & Public Relations
spencer.murray@amii.ca 
TO ARRANGE AN INTERVIEW WITH THE CIOSC, PLEASE CONTACT:
Katie Gibson
Vice President, Strategy and Partnerships
katie.gibson@ciostrategycouncil.com 
Spencer Murray
Communications & Public Relations
t: 587.415.6100 ext. 109 | c: 780.991.7136
spencer.murray@amii.ca 
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 1788
Subject: ETHICS (92%); ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); EXECUTIVES (90%); ASSOCIATIONS & ORGANIZATIONS (89%); BEST PRACTICES (78%); CASE STUDIES (78%); CORPORATE GOVERNANCE (78%); PRODUCT DEVELOPMENT (78%); SMALL BUSINESS (77%); MACHINE LEARNING (73%); ECONOMICS (70%)
Industry: ARTIFICIAL INTELLIGENCE ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (73%)
Geographic: ALBERTA, CANADA (58%); CANADA (92%)
Load-Date: July 22, 2022",neutral,0.5699630379676819,balanced/neutral,['fairness'],['fairness'],"['governance', 'standards', 'compliance', 'need to']",['machine learning'],1,1,4,1
2021,Unknown Title,"Body
Link to Story
MINNEAPOLIS, Feb. 1, 2022 /PRNewswire/ -- Society of Corporate Compliance and Ethics® (SCCE) is pleased to announce the release of a new edition of The Complete Compliance and Ethics Manual—a trusted resource written by more than 90 compliance and ethics professionals.
This manual provides detailed analyses of critical aspects of a compliance and ethics program, and includes practical tools, checklists, policies, and procedures to help compliance professionals improve program effectiveness and address a wide range of risk areas.
SCCE's The Complete Compliance and Ethics Manual, newly updated for 2022. Newly updated for 2022, The Complete Compliance and Ethics Manual contains 80 comprehensive articles and is organized to help you quickly find the information you need. New content includes:
Compliance in remote and hybrid environments
Antitrust compliance programs evaluated by the DOJ
OFAC's framework for compliance commitments
ESG leadership
Data safekeeping and the European Union
Updated content in 41 areas, including:
Creating a code of conduct
Communicating values across cultures
Board engagement, training, and reporting
Hotline and whistleblowing reporting
Employee discipline and compliance
Third-party risk management
Anti-corruption and anti-bribery
Conflicts of interest
Personal device policies and practices
Social media compliance
Artificial intelligence and corporate compliance
Purchasing options include a one-year online subscription, a softcover print book, and a money-saving print and online bundle. The online version of The Complete Compliance and Ethics Manual is provided through COSMOS®, SCCE's online content platform, which contains powerful search capabilities that allow users to easily access the information they seek.
To purchase or learn more, visit About SCCE
Society of Corporate Compliance and Ethics® (SCCE) is a nonprofit, member-based association for compliance and ethics professionals. Since 2004, SCCE has been championing ethical practices and compliance standards to promote the lasting success and integrity of organizations worldwide and across all industries. Headquartered in Minneapolis, MN, SCCE serves over 6,700 members in 100+ countries around the globe.
SCCE offers 45+ educational conferences a year, weekly webinars, publications, training resources, certification opportunities, and networking for career growth and program development.
Visit the SCCE website at or call 888.277.4977.
SOURCE Society of Corporate Compliance and Ethics (SCCE)
MENAFN01022022003732001241ID1103626319
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (87%); NEGATIVE BUSINESS NEWS (78%); REGULATORY COMPLIANCE (78%); RISK MANAGEMENT (78%); WEB BASED TRAINING (78%); WHISTLEBLOWERS (77%); ANTI-CORRUPTION (76%); CORRUPTION (72%); EUROPEAN UNION (71%); NEGATIVE NEWS (71%); VIRTUAL EVENTS (71%); ANTITRUST & TRADE LAW (68%); BRIBERY (66%); NONPROFIT ORGANIZATIONS (65%); SOCIAL MEDIA (65%); ARTIFICIAL INTELLIGENCE (50%)
Organization:  EUROPEAN UNION (55%)
Industry: RISK MANAGEMENT (78%); TELECONFERENCING (67%); SOCIAL MEDIA (65%); ARTIFICIAL INTELLIGENCE (50%)
Geographic: MINNEAPOLIS, MN, USA (73%); MINNESOTA, USA (73%); EUROPEAN UNION MEMBER STATES (75%)
Load-Date: August 31, 2022","Link to Story
MINNEAPOLIS, Feb. 1, 2022 /PRNewswire/ -- Society of Corporate Compliance and Ethics® (SCCE) is pleased to announce the release of a new edition of The Complete Compliance and Ethics Manual—a trusted resource written by more than 90 compliance and ethics professionals.
This manual provides detailed analyses of critical aspects of a compliance and ethics program, and includes practical tools, checklists, policies, and procedures to help compliance professionals improve program effectiveness and address a wide range of risk areas.
SCCE's The Complete Compliance and Ethics Manual, newly updated for 2022. Newly updated for 2022, The Complete Compliance and Ethics Manual contains 80 comprehensive articles and is organized to help you quickly find the information you need. New content includes:
Compliance in remote and hybrid environments
Antitrust compliance programs evaluated by the DOJ
OFAC's framework for compliance commitments
ESG leadership
Data safekeeping and the European Union
Updated content in 41 areas, including:
Creating a code of conduct
Communicating values across cultures
Board engagement, training, and reporting
Hotline and whistleblowing reporting
Employee discipline and compliance
Third-party risk management
Anti-corruption and anti-bribery
Conflicts of interest
Personal device policies and practices
Social media compliance
Artificial intelligence and corporate compliance
Purchasing options include a one-year online subscription, a softcover print book, and a money-saving print and online bundle. The online version of The Complete Compliance and Ethics Manual is provided through COSMOS®, SCCE's online content platform, which contains powerful search capabilities that allow users to easily access the information they seek.
To purchase or learn more, visit About SCCE
Society of Corporate Compliance and Ethics® (SCCE) is a nonprofit, member-based association for compliance and ethics professionals. Since 2004, SCCE has been championing ethical practices and compliance standards to promote the lasting success and integrity of organizations worldwide and across all industries. Headquartered in Minneapolis, MN, SCCE serves over 6,700 members in 100+ countries around the globe.
SCCE offers 45+ educational conferences a year, weekly webinars, publications, training resources, certification opportunities, and networking for career growth and program development.
Visit the SCCE website at or call 888.277.4977.
SOURCE Society of Corporate Compliance and Ethics (SCCE)
MENAFN01022022003732001241ID1103626319
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); BUSINESS ETHICS (90%); ASSOCIATIONS & ORGANIZATIONS (87%); NEGATIVE BUSINESS NEWS (78%); REGULATORY COMPLIANCE (78%); RISK MANAGEMENT (78%); WEB BASED TRAINING (78%); WHISTLEBLOWERS (77%); ANTI-CORRUPTION (76%); CORRUPTION (72%); EUROPEAN UNION (71%); NEGATIVE NEWS (71%); VIRTUAL EVENTS (71%); ANTITRUST & TRADE LAW (68%); BRIBERY (66%); NONPROFIT ORGANIZATIONS (65%); SOCIAL MEDIA (65%); ARTIFICIAL INTELLIGENCE (50%)
Organization:  EUROPEAN UNION (55%)
Industry: RISK MANAGEMENT (78%); TELECONFERENCING (67%); SOCIAL MEDIA (65%); ARTIFICIAL INTELLIGENCE (50%)
Geographic: MINNEAPOLIS, MN, USA (73%); MINNESOTA, USA (73%); EUROPEAN UNION MEMBER STATES (75%)
Load-Date: August 31, 2022",positive,0.6622520685195923,balanced/neutral,['access'],[],"['standards', 'framework', 'law', 'compliance', 'certification']",[],1,0,5,0
2021,Unknown Title,"Dateline: Japan 
Body
Japan, Jan. 28 -- Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purposea&#8364;""""to make the world more sustainable by building trust in society through innovation.a&#8364;? To realize the vision of a sustainable world through its global business brand a&#8364; FUJITSU Uvancea&#8364;?
 which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the a&#8364; Fujitsu Group External Advisory Committee on AI Ethicsa&#8364;? to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.On February 1, Fujitsu will newly establish the a&#8364; AI Ethics and Governance Officea&#8364;? (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Published by HT Digital Content Services with permission from Pivotal Sources. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SAFETY (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BUSINESS NEWS (89%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (72%); MEDIA CONTENT (61%)
Load-Date: January 29, 2022","Japan, Jan. 28 -- Fujitsu Limited announced the decision to establish a new organization to strengthen its governance of AI ethics.Building and maintaining trust remains central to all of Fujitsu's business activities, forming the basis of its Purposea&#8364;""""to make the world more sustainable by building trust in society through innovation.a&#8364;? To realize the vision of a sustainable world through its global business brand a&#8364; FUJITSU Uvancea&#8364;?
 which focuses on the solution of social issues, both services and technologies as well as trust in the Fujitsu Group will play an essential role.In March 2019, Fujitsu formulated the ""Fujitsu Group AI Commitment"" to create greater value for customers and society while honoring its promise to deliver safe, secure, and transparent AI technology. With this commitment as a point of departure, in September 2019 Fujitsu further established the a&#8364; Fujitsu Group External Advisory Committee on AI Ethicsa&#8364;? to ensure an objective evaluation of Fujitsu's AI ethics framework by an impartial third party. Since then, Fujitsu has continuously and proactively worked to enhance its corporate governance to enforce the principles of ethical AI.On February 1, Fujitsu will newly establish the a&#8364; AI Ethics and Governance Officea&#8364;? (Head: Junichi Arahori) to accelerate the safe and secure deployment of leading-edge technologies including artificial intelligence (AI) and other machine learning applications in society.This marks the next step in Fujitsu's ongoing efforts to strengthen and enforce comprehensive, company-wide measures to achieve robust AI ethics governance based on international best-practices, policies, and legal frameworks. The new office will focus on implementing measures to actively promote ethics related to the research, development, and implementation of advanced technologies.
Published by HT Digital Content Services with permission from Pivotal Sources. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ARTIFICIAL INTELLIGENCE ETHICS (94%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); COMPANY ACTIVITIES & MANAGEMENT (90%); SAFETY (90%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (90%); BUSINESS NEWS (89%); BEST PRACTICES (78%); CORPORATE GOVERNANCE (78%); RESEARCH & DEVELOPMENT (77%); SOCIETAL ISSUES (73%); SUSTAINABLE DEVELOPMENT (72%)
Company:  FUJITSU LTD (96%)
Ticker: 6702 (TSE) (96%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (96%); ARTIFICIAL INTELLIGENCE ETHICS (94%); ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (72%); MEDIA CONTENT (61%)
Load-Date: January 29, 2022",positive,0.5382727980613708,balanced/neutral,['safety'],[],"['governance', 'framework']",['machine learning'],1,0,2,1
2021,Unknown Title,"Byline: National Post, National Post
Body
Tagging a rocking chair on Instagram has landed the federal NDP leader in discussions with the ethics commissioner.
On Sunday, a photo was posted to Jagmeet Singh's Instagram account seated in a grey wing-backed chair, his newborn daughter cradled in his arms.
That same chair, a $1,895 rocker manufactured by Toronto's Monte Design Group, made an appearance in early December in a now-deleted Instagram post on the account owned by Singh's wife, Gurkiran Kaur Sidhu.
Party officials confirmed the chair was gifted to her by the company with the expectation she'd promote it on social media.
Sunday's post was originally tagged with Monte Design's Instagram account, by Wednesday the tag had been removed.
Singh and immediate members of his family are forbidden from accepting such gifts under House of Commons rules - guidelines that apply to all MPs( https://www.ourcommons.ca/About/StandingOrders/appa1-e.htm ).
Section 14 of the House conflict of interest code states MPs and their family aren't allowed to, either directly or indirectly, accept ""any gift or other benefit"" that ""may influence the member in the exercise of a duty or function of his or her office.""
On Wednesday, NDP spokesperson Melanie Richer said the tagged post was merely part of efforts by the couple to promote made-in-Canada products.
""Jagmeet and Gurkiran love finding Canadian companies to support,"" Richer said.
""From the furniture they have in their home to the clothes they wear, they're proud to support Canadian companies and Canadian workers.""
The chair, she said, was specifically gifted to Singh's wife.
""There was no expectation that Jagmeet would post about it,"" Richer said.
""That being said, while they're extremely grateful, they've realized their error and have paid for the gift.""
How I'm spending my time these days // J'ai une nouvelle partenaire pour passer le temps
???? pic.twitter.com/NI77H2TLGA( https://t.co/NI77H2TLGA )
- Jagmeet Singh (@theJagmeetSingh) January 17, 2022( https://twitter.com/theJagmeetSingh/status/1483212807386669056?ref_src=twsrc%5Etfw )
The NDP's lapse-of-judgement defence isn't sitting well with some observers.
UBC political science professor Max Cameron told National Post that following the rules should be a no-brainer for the social media-savvy NDP leader.
""It's just so basic - you get a gift over a certain amount, you have to report it to the commissioner, period,"" he said.
""All politicians should know this, and it's certainly surprising that Singh didn't comply.""
Under the rules, all gifts worth over $200 must be disclosed to the federal ethics commissioner within 60 days of receipt.
Richer said the party is working with the ethics commissioner to ""ensure that any gifts received are declared and that we are in compliance with the Act.""
Canadian politicians are no stranger to ethical dilemmas, with Prime Minister Justin Trudeau and his family finding themselves embroiled in a number of high-profile scandals.
Trudeau became the first prime minister in Canadian history to be convicted of breaking ethics laws after his infamous 2016 Christmas vacation to the Aga Khan's private island in the Bahamas.
In 2018, the prime minister found himself under scrutiny again after the ethics commissioner determined he'd breached the Conflict of Interest Act by improperly pressuring then-Justice Minister Jody Wilson-Raybould to offer SNC-Lavalin a deferred prosecution agreement as the Quebec engineering firm was on trial facing criminal bribery charges.
Ties between the Trudeaus and WE Charity founders Craig and Marc Kielburger were at issue when the organization was chosen to run a nearly billion-dollar student service grant program in summer 2020.
While Ethics Commissioner Mario Dion found the prime minister provided no preferential treatment to the Kielburgers, he ruled former Finance Minister Bill Morneau did - writing in his report that Morneau permitted his ministerial staff to ""disproportionately assist"" the organization when it came seeking federal funding.
Ethics and conflict-of-interest rules are in place for a reason, Cameron said - particularly if Singh is expected to call out other politicians for not following ethics guidelines.
""If you get a gift, particularly a gift of any value, it creates a feeling of being beholden to the giver,"" Cameron said.
""We don't want our politicians to be in that position.""
Email: bpassifiume@postmedia.com( bpassifiume@postmedia.com )
Twitter: @bryanpassifiume( http://twitter.com/bryanpassifiume ) !@COPYRIGHT=© 2022 Postmedia Network Inc. All rights reserved.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); ELECTIONS & POLITICS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); LEGISLATIVE BODIES (78%); SOCIAL MEDIA (78%); POLITICAL SCIENCE (73%); INFANTS & TODDLERS (57%); tagging,rocking,chair,instagram,landed,federal !@PERMALINK= https://nationalpost.com/news/politics/made-in-canada-rocker-lands-jagmeet-singh-in-ethical-trouble (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); SOCIAL MEDIA (78%)
Geographic: TORONTO, ON, CANADA (74%); ONTARIO, CANADA (59%); CANADA (92%)
Load-Date: January 19, 2022","Tagging a rocking chair on Instagram has landed the federal NDP leader in discussions with the ethics commissioner.
On Sunday, a photo was posted to Jagmeet Singh's Instagram account seated in a grey wing-backed chair, his newborn daughter cradled in his arms.
That same chair, a $1,895 rocker manufactured by Toronto's Monte Design Group, made an appearance in early December in a now-deleted Instagram post on the account owned by Singh's wife, Gurkiran Kaur Sidhu.
Party officials confirmed the chair was gifted to her by the company with the expectation she'd promote it on social media.
Sunday's post was originally tagged with Monte Design's Instagram account, by Wednesday the tag had been removed.
Singh and immediate members of his family are forbidden from accepting such gifts under House of Commons rules - guidelines that apply to all MPs( https://www.ourcommons.ca/About/StandingOrders/appa1-e.htm ).
Section 14 of the House conflict of interest code states MPs and their family aren't allowed to, either directly or indirectly, accept ""any gift or other benefit"" that ""may influence the member in the exercise of a duty or function of his or her office.""
On Wednesday, NDP spokesperson Melanie Richer said the tagged post was merely part of efforts by the couple to promote made-in-Canada products.
""Jagmeet and Gurkiran love finding Canadian companies to support,"" Richer said.
""From the furniture they have in their home to the clothes they wear, they're proud to support Canadian companies and Canadian workers.""
The chair, she said, was specifically gifted to Singh's wife.
""There was no expectation that Jagmeet would post about it,"" Richer said.
""That being said, while they're extremely grateful, they've realized their error and have paid for the gift.""
How I'm spending my time these days // J'ai une nouvelle partenaire pour passer le temps
???? pic.twitter.com/NI77H2TLGA( https://t.co/NI77H2TLGA )
- Jagmeet Singh (@theJagmeetSingh) January 17, 2022( https://twitter.com/theJagmeetSingh/status/1483212807386669056?ref_src=twsrc%5Etfw )
The NDP's lapse-of-judgement defence isn't sitting well with some observers.
UBC political science professor Max Cameron told National Post that following the rules should be a no-brainer for the social media-savvy NDP leader.
""It's just so basic - you get a gift over a certain amount, you have to report it to the commissioner, period,"" he said.
""All politicians should know this, and it's certainly surprising that Singh didn't comply.""
Under the rules, all gifts worth over $200 must be disclosed to the federal ethics commissioner within 60 days of receipt.
Richer said the party is working with the ethics commissioner to ""ensure that any gifts received are declared and that we are in compliance with the Act.""
Canadian politicians are no stranger to ethical dilemmas, with Prime Minister Justin Trudeau and his family finding themselves embroiled in a number of high-profile scandals.
Trudeau became the first prime minister in Canadian history to be convicted of breaking ethics laws after his infamous 2016 Christmas vacation to the Aga Khan's private island in the Bahamas.
In 2018, the prime minister found himself under scrutiny again after the ethics commissioner determined he'd breached the Conflict of Interest Act by improperly pressuring then-Justice Minister Jody Wilson-Raybould to offer SNC-Lavalin a deferred prosecution agreement as the Quebec engineering firm was on trial facing criminal bribery charges.
Ties between the Trudeaus and WE Charity founders Craig and Marc Kielburger were at issue when the organization was chosen to run a nearly billion-dollar student service grant program in summer 2020.
While Ethics Commissioner Mario Dion found the prime minister provided no preferential treatment to the Kielburgers, he ruled former Finance Minister Bill Morneau did - writing in his report that Morneau permitted his ministerial staff to ""disproportionately assist"" the organization when it came seeking federal funding.
Ethics and conflict-of-interest rules are in place for a reason, Cameron said - particularly if Singh is expected to call out other politicians for not following ethics guidelines.
""If you get a gift, particularly a gift of any value, it creates a feeling of being beholden to the giver,"" Cameron said.
""We don't want our politicians to be in that position.""
Email: bpassifiume@postmedia.com( bpassifiume@postmedia.com )
Twitter: @bryanpassifiume( http://twitter.com/bryanpassifiume ) !@COPYRIGHT=© 2022 Postmedia Network Inc. All rights reserved.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: ETHICS (91%); INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); ELECTIONS & POLITICS (78%); GOVERNMENT & PUBLIC ADMINISTRATION (78%); LEGISLATIVE BODIES (78%); SOCIAL MEDIA (78%); POLITICAL SCIENCE (73%); INFANTS & TODDLERS (57%); tagging,rocking,chair,instagram,landed,federal !@PERMALINK= https://nationalpost.com/news/politics/made-in-canada-rocker-lands-jagmeet-singh-in-ethical-trouble (%)
Industry: INTERNET SOCIAL NETWORKING (90%); PHOTO & VIDEO SHARING (89%); SOCIAL MEDIA (78%)
Geographic: TORONTO, ON, CANADA (74%); ONTARIO, CANADA (59%); CANADA (92%)
Load-Date: January 19, 2022",neutral,0.8115801811218262,balanced/neutral,[],"['justice', 'justice']","['guidelines', 'compliance', 'should', 'must']",[],0,2,4,0
2021,Unknown Title,"Byline: States News Service
Dateline: LOS ANGELES, CA 
Body
The following information was released by UCLA Health System:
Media Contact
UCLA Health News
[email protected]
September 13, 2022
UCLA is one of three sites chosen to oversee a new 'computable knowledge' program that will develop strategies, standards and tools to transform the way data is collected and prepared. The NIH Common Fund's Bridge to Artificial Intelligence (Bridge2AI) program will unlock the potential of artificial intelligence (AI) and machine learning (ML) and propel biomedical and behavioral research forward, addressing current and future challenges.
""New developments every day show the promise of artificial intelligence in biomedical research and in clinical practice. But the potential of these advances, while important and exciting, remain difficult to harness in the real world, and there many technical, social and ethical issues that need to be addressed,"" said Alex Bui, a biomedical informatics expert and David Geffen Chair in Informatics at the UCLA David Geffen School of Medicine at UCLA.
He led efforts that secured UCLA's leadership position in the Bridge2AI program, which Bui said is a ""significant shift"" in the agency's approach to AI and biomedical data science.
""Research and technology are producing mountains of data, but making use of it in a systematic way for AI and ML and then deriving new scientific insights is a huge challenge,"" Bui said. ""The Bridge Center will integrate, disseminate and evaluate activities across the Bridge2AI program and UCLA is leading key elements of this center.""
A team directed by Paul Boutros, a data scientist and professor in human genetics and urology at the David Geffen School of Medicine at UCLA, will lead the Bridge Center's Tool Optimization Core. It is charged with bringing together all the tools being developed in AI/ML efforts and optimizing them for use by the larger research community in a broad range of research purposes. The Tool Optimization Core includes collaborators from Oregon Health and Science University and Sage Bionetworks, who also will be responsible for getting the new tools into the hands of individual researchers.
""The Bridge2AI program is bringing together computational and biomedical experts, along with other interdisciplinary groups, to turn data into useful information that can enable major advances in clinical and behavioral research,"" Boutros said. ""Our responsibility is not only to create software and approaches that will address current research, but to build tools that will evolve to address future challenges.""
Dr. Karol Watson, a cardiologist and professor at the David Geffen School of Medicine at UCLA, will lead the Skills and Workforce Development Core along with Dr. Peipei Ping, a professor of physiology, medicine/cardiology, and bioinformatics at the David Geffen School of Medicine at UCLA. Their team's mission is to bridge expertise across biomedical and behavioral research domains, ethics, AI/ML data science, and team science establishing a basic understanding and skills in the use of AI/ML, and a deeper understanding of its use within the nation's biomedical and behavioral research workforce. A particular focus of their efforts is increasing diversity, equity, and inclusion in AI/ML efforts.
""Among the major challenges we currently face is the potential for bias using AI/ML with our biomedical and behavioral datasets, and the lack of diverse representation both within the data and in its application,"" Watson said. ""As directed by the NIH, our core will incorporate specific outreach, recruitment and retention plans to enhance diversity in both of these areas.""
Ping added that the Bridge2AI program will provide opportunities for people with a wide range of interests and skills.
""The interdisciplinary nature of this effort requires collaboration among people from a broad spectrum of expertise, including both technical and nontechnical backgrounds,"" she said. ""Our goals include developing and implementing educational materials, courses and activities that provide developmental opportunities for people at all career stages, with a focus on opportunity for those from underrepresented backgrounds.""
To accomplish these goals, UCLA is expected to receive over $9.9 million over the next four years.
The other two Bridge Center awardee sites include the University of California, San Diego, and the University of Colorado Anschutz Medical Campus, which provide additional expertise around ethics, standards, and team science.
According to the NIH, the Bridge2AI ""program will propel biomedical research forward by setting the stage for widespread adoption of artificial intelligence (AI) that tackles complex biomedical challenges beyond human intuition."" A key step in this process is generating new datasets and best practices for machine learning analysis. By fostering an interdisciplinary community of scientific experts, the Bridge2AI program will help bring solutions to this deficit by:
Generating new flagship biomedical and behavioral datasets that are ethically sourced, trustworthy, well-defined, and accessible.
Developing software and standards to harmonize across data representations and data types.
Creating automated tools to accelerate the creation of FAIR (Findable, Accessible, Interoperable, and Reusable) and ethically sourced datasets.
Providing resources to disseminate data, ethical principles, tools, and best practices.
Creating training materials and activities for workforce development that bridges the AI, biomedical, and behavioral research communities.
This project is supported by the National Institutes of Health award number: U54HG012517.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: BIOMEDICINE (92%); ARTIFICIAL INTELLIGENCE (90%); BIOETHICS (90%); MEDICAL RESEARCH (90%); SCIENCE & TECHNOLOGY (90%); BEHAVIOR & COGNITION (89%); DATA SCIENCE (89%); ETHICS (89%); MACHINE LEARNING (89%); HEALTH CARE INFORMATION TECHNOLOGY (88%); INFORMATION SCIENCE (88%); COLLEGE & UNIVERSITY PROFESSORS (86%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EMPLOYEE TRAINING & ASSISTANCE (77%); ANATOMY & PHYSIOLOGY (76%); BIOINFORMATICS (76%); EXPERIMENTATION & RESEARCH (76%); UROLOGY (71%); PHYSICIANS & SURGEONS (70%); SOCIETAL ISSUES (68%); CARDIOLOGY (65%); LABOR & EMPLOYMENT (50%)
Organization: UNIVERSITY OF CALIFORNIA (LOS ANGELES) (94%)
Industry: BIOMEDICINE (92%); ACADEMIC MEDICAL CENTERS (90%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (89%); MACHINE LEARNING (89%); HEALTH CARE INFORMATION TECHNOLOGY (88%); COLLEGE & UNIVERSITY PROFESSORS (86%); UROLOGY (71%); PHYSICIANS & SURGEONS (70%); CARDIOLOGY (65%)
Person: DAVID GEFFEN (58%)
Geographic: LOS ANGELES, CA, USA (74%); CALIFORNIA, USA (79%)
Load-Date: September 13, 2022","The following information was released by UCLA Health System:
Media Contact
UCLA Health News
[email protected]
September 13, 2022
UCLA is one of three sites chosen to oversee a new 'computable knowledge' program that will develop strategies, standards and tools to transform the way data is collected and prepared. The NIH Common Fund's Bridge to Artificial Intelligence (Bridge2AI) program will unlock the potential of artificial intelligence (AI) and machine learning (ML) and propel biomedical and behavioral research forward, addressing current and future challenges.
""New developments every day show the promise of artificial intelligence in biomedical research and in clinical practice. But the potential of these advances, while important and exciting, remain difficult to harness in the real world, and there many technical, social and ethical issues that need to be addressed,"" said Alex Bui, a biomedical informatics expert and David Geffen Chair in Informatics at the UCLA David Geffen School of Medicine at UCLA.
He led efforts that secured UCLA's leadership position in the Bridge2AI program, which Bui said is a ""significant shift"" in the agency's approach to AI and biomedical data science.
""Research and technology are producing mountains of data, but making use of it in a systematic way for AI and ML and then deriving new scientific insights is a huge challenge,"" Bui said. ""The Bridge Center will integrate, disseminate and evaluate activities across the Bridge2AI program and UCLA is leading key elements of this center.""
A team directed by Paul Boutros, a data scientist and professor in human genetics and urology at the David Geffen School of Medicine at UCLA, will lead the Bridge Center's Tool Optimization Core. It is charged with bringing together all the tools being developed in AI/ML efforts and optimizing them for use by the larger research community in a broad range of research purposes. The Tool Optimization Core includes collaborators from Oregon Health and Science University and Sage Bionetworks, who also will be responsible for getting the new tools into the hands of individual researchers.
""The Bridge2AI program is bringing together computational and biomedical experts, along with other interdisciplinary groups, to turn data into useful information that can enable major advances in clinical and behavioral research,"" Boutros said. ""Our responsibility is not only to create software and approaches that will address current research, but to build tools that will evolve to address future challenges.""
Dr. Karol Watson, a cardiologist and professor at the David Geffen School of Medicine at UCLA, will lead the Skills and Workforce Development Core along with Dr. Peipei Ping, a professor of physiology, medicine/cardiology, and bioinformatics at the David Geffen School of Medicine at UCLA. Their team's mission is to bridge expertise across biomedical and behavioral research domains, ethics, AI/ML data science, and team science establishing a basic understanding and skills in the use of AI/ML, and a deeper understanding of its use within the nation's biomedical and behavioral research workforce. A particular focus of their efforts is increasing diversity, equity, and inclusion in AI/ML efforts.
""Among the major challenges we currently face is the potential for bias using AI/ML with our biomedical and behavioral datasets, and the lack of diverse representation both within the data and in its application,"" Watson said. ""As directed by the NIH, our core will incorporate specific outreach, recruitment and retention plans to enhance diversity in both of these areas.""
Ping added that the Bridge2AI program will provide opportunities for people with a wide range of interests and skills.
""The interdisciplinary nature of this effort requires collaboration among people from a broad spectrum of expertise, including both technical and nontechnical backgrounds,"" she said. ""Our goals include developing and implementing educational materials, courses and activities that provide developmental opportunities for people at all career stages, with a focus on opportunity for those from underrepresented backgrounds.""
To accomplish these goals, UCLA is expected to receive over $9.9 million over the next four years.
The other two Bridge Center awardee sites include the University of California, San Diego, and the University of Colorado Anschutz Medical Campus, which provide additional expertise around ethics, standards, and team science.
According to the NIH, the Bridge2AI ""program will propel biomedical research forward by setting the stage for widespread adoption of artificial intelligence (AI) that tackles complex biomedical challenges beyond human intuition."" A key step in this process is generating new datasets and best practices for machine learning analysis. By fostering an interdisciplinary community of scientific experts, the Bridge2AI program will help bring solutions to this deficit by:
Generating new flagship biomedical and behavioral datasets that are ethically sourced, trustworthy, well-defined, and accessible.
Developing software and standards to harmonize across data representations and data types.
Creating automated tools to accelerate the creation of FAIR (Findable, Accessible, Interoperable, and Reusable) and ethically sourced datasets.
Providing resources to disseminate data, ethical principles, tools, and best practices.
Creating training materials and activities for workforce development that bridges the AI, biomedical, and behavioral research communities.
This project is supported by the National Institutes of Health award number: U54HG012517.
Classification
Language: ENGLISH
Publication-Type: Newswire
Subject: BIOMEDICINE (92%); ARTIFICIAL INTELLIGENCE (90%); BIOETHICS (90%); MEDICAL RESEARCH (90%); SCIENCE & TECHNOLOGY (90%); BEHAVIOR & COGNITION (89%); DATA SCIENCE (89%); ETHICS (89%); MACHINE LEARNING (89%); HEALTH CARE INFORMATION TECHNOLOGY (88%); INFORMATION SCIENCE (88%); COLLEGE & UNIVERSITY PROFESSORS (86%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); EMPLOYEE TRAINING & ASSISTANCE (77%); ANATOMY & PHYSIOLOGY (76%); BIOINFORMATICS (76%); EXPERIMENTATION & RESEARCH (76%); UROLOGY (71%); PHYSICIANS & SURGEONS (70%); SOCIETAL ISSUES (68%); CARDIOLOGY (65%); LABOR & EMPLOYMENT (50%)
Organization: UNIVERSITY OF CALIFORNIA (LOS ANGELES) (94%)
Industry: BIOMEDICINE (92%); ACADEMIC MEDICAL CENTERS (90%); ARTIFICIAL INTELLIGENCE (90%); DATA SCIENCE (89%); MACHINE LEARNING (89%); HEALTH CARE INFORMATION TECHNOLOGY (88%); COLLEGE & UNIVERSITY PROFESSORS (86%); UROLOGY (71%); PHYSICIANS & SURGEONS (70%); CARDIOLOGY (65%)
Person: DAVID GEFFEN (58%)
Geographic: LOS ANGELES, CA, USA (74%); CALIFORNIA, USA (79%)
Load-Date: September 13, 2022",neutral,0.8582968711853027,balanced/neutral,"['bias', 'agency']",['equity'],"['standards', 'need to']",['machine learning'],2,1,2,1
2021,Unknown Title,"Body
For as long as insurance has been around, criminals have been committing insurance fraud. With increasingly sophisticated fraud activity, insurers are turning to artificial intelligence and machine learning. However, they must develop standards to prevent unfair discrimination and remove any bias in these technologies.
The use of data or historical consumer information is key in the underwriting, pricing and risk detection process, as well as the identification and investigation of insurance fraud.
However, Alan Haskins, North America insurance business development director at Quantexa, explained that as the collection of this data increases and its use becomes more sophisticated, there needs to be a conversation to establish standards for how data is utilised throughout the process of obtaining a policy and filing a claim.
In the same way that insurance companies should have a mandated responsibility to protect consumer data, Haskins argued that they should also be required by state law and regulations to identify, investigate, and report suspected insurance fraud.
These two mandates are not mutually exclusive, he added, and the insurance industry can protect consumer information and ethically utilised data sources to prevent, identify, and fight against insurance fraud and financial crime.
Insurers are turning to the use of artificial intelligence, machine learning and algorithms for good reason. They provide better visualisation across legacy systems, as well as isolated and siloed industry data sources.
However, Haskins said that these technical capabilities come with a responsibility to protect and secure consumer data. As such, insurance companies should make data ethics a priority. They can do this by, for example, restricting unauthorised access, making sure data is secure and developing meaningful policies and procedures.
In addition, Haskins stressed that despite the benefits of these innovative technologies, they should never drive or replace human decision making processes, and instead be used to improve the efficiency and effectiveness of an activity.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 2053
Subject: INSURANCE FRAUD (94%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CONSUMER LAW (90%); CORPORATE GOVERNANCE (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (90%); FRAUD & FINANCIAL CRIME (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); NEGATIVE NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (79%); CONSUMER PROTECTION (78%); CRIMINAL INVESTIGATIONS (78%); BUSINESS NEWS (77%); DISCRIMINATION (77%); DATA BREACHES (73%)
Industry: INSURANCE (94%); ARTIFICIAL INTELLIGENCE (90%); DATA SECURITY (90%); INFORMATION SECURITY & PRIVACY (90%); MACHINE LEARNING (90%); DATA GOVERNANCE & STEWARDSHIP (79%); DATA BREACHES (73%)
Load-Date: July 27, 2022","For as long as insurance has been around, criminals have been committing insurance fraud. With increasingly sophisticated fraud activity, insurers are turning to artificial intelligence and machine learning. However, they must develop standards to prevent unfair discrimination and remove any bias in these technologies.
The use of data or historical consumer information is key in the underwriting, pricing and risk detection process, as well as the identification and investigation of insurance fraud.
However, Alan Haskins, North America insurance business development director at Quantexa, explained that as the collection of this data increases and its use becomes more sophisticated, there needs to be a conversation to establish standards for how data is utilised throughout the process of obtaining a policy and filing a claim.
In the same way that insurance companies should have a mandated responsibility to protect consumer data, Haskins argued that they should also be required by state law and regulations to identify, investigate, and report suspected insurance fraud.
These two mandates are not mutually exclusive, he added, and the insurance industry can protect consumer information and ethically utilised data sources to prevent, identify, and fight against insurance fraud and financial crime.
Insurers are turning to the use of artificial intelligence, machine learning and algorithms for good reason. They provide better visualisation across legacy systems, as well as isolated and siloed industry data sources.
However, Haskins said that these technical capabilities come with a responsibility to protect and secure consumer data. As such, insurance companies should make data ethics a priority. They can do this by, for example, restricting unauthorised access, making sure data is secure and developing meaningful policies and procedures.
In addition, Haskins stressed that despite the benefits of these innovative technologies, they should never drive or replace human decision making processes, and instead be used to improve the efficiency and effectiveness of an activity.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Journal Code: 2053
Subject: INSURANCE FRAUD (94%); ETHICS (91%); ARTIFICIAL INTELLIGENCE (90%); CONSUMER LAW (90%); CORPORATE GOVERNANCE (90%); CRIME, LAW ENFORCEMENT & CORRECTIONS (90%); FRAUD & FINANCIAL CRIME (90%); INVESTIGATIONS (90%); MACHINE LEARNING (90%); NEGATIVE NEWS (90%); COMPANY ACTIVITIES & MANAGEMENT (79%); CONSUMER PROTECTION (78%); CRIMINAL INVESTIGATIONS (78%); BUSINESS NEWS (77%); DISCRIMINATION (77%); DATA BREACHES (73%)
Industry: INSURANCE (94%); ARTIFICIAL INTELLIGENCE (90%); DATA SECURITY (90%); INFORMATION SECURITY & PRIVACY (90%); MACHINE LEARNING (90%); DATA GOVERNANCE & STEWARDSHIP (79%); DATA BREACHES (73%)
Load-Date: July 27, 2022",neutral,0.5454654097557068,balanced/neutral,"['privacy', 'bias', 'discrimination', 'security', 'access']",[],"['policy', 'governance', 'standards', 'law', 'should', 'must']",['machine learning'],5,0,6,1
2021,Unknown Title,"Dateline: India 
Body
India, Feb. 21 -- Fujitsu today announced the development of a resource toolkit offering developers guidance for evaluating the ethical impact and risks of AI systems based on international AI ethics guidelines. Fujitsu will offer these resources free of charge starting from February 21, 2022 to promote the safe and secure deployment of AI systems in society.Figure 1. Outline of AI Ethics Impact AssessmentThe toolkit consists of a variety of case studies and reference materials, including a newly developed method for clarifying ethical requirements in AI ethics guidelines written in natural language, as well as for applying ethical requirements to actual AI systems. The resources in Japanese can be downloaded here, with availability in English to follow in the near future.With this guidance, Fujitsu aims to prevent misunderstandings and potential risks caused by differences in the interpretation of descriptions in guidelines, offering AI system developers and operators new tools for thoroughly identifying and preventing possible ethical issues early in the development process in keeping with international best practices.Dr. Christoph Lutge of the Technical University of Munich, a leading authority in the research of responsible AI and business ethics, comments, ""In Europe, there is a growing debate about AI regulations, and one of the key issues is how to close the gap between principles and practices, or ""what"" and ""how."" I believe that the results of this research are very significant in that they enable us to practice based on principles. I would also like to express my deep appreciation for the decision to open up the research results and stimulate discussion worldwide.""Going forward, Fujitsu will actively work to partner with government agencies, private companies, and leading researchers to further refine and promote its newly developed methodology and aims to release an expanded version of the resource toolkit in fiscal year 2022.BackgroundIn April 2021, the European Commission issued a draft for a regulatory framework calling for a comprehensive ethical response for AI system developers, users, and stakeholders in response to increasing concerns surrounding algorithmic bias and discriminatory decision-making in AI and machine learning applications.To commit fully to the responsible use of technology and earn society's trust in AI systems and the companies and organizations involved in this space, Fujitsu has formulated its own AI Commitment in 2019, as well as a new AI Ethics and Governance Office to develop and enforce robust policies for AI ethics, promote organizational AI ethical governance to ensure their effectiveness. 
Now, Fujitsu will move from principle to practice by steadily implementing best practices in the real-world to ensure the realization of ethical, safe, and transparent AI and machine learning technologies.At present, it is common practice in AI system development to identify possible ethical risks in AI systems based on AI ethics guidelines issued by government authorities and companies. These guidelines are written in natural language, however, contributing to possible differences in interpretation and misunderstandings amongst designers and developers that can lead to inappropriate or insufficient measures. Under this method it is also difficult to judge whether the contents of the guidelines were thoroughly and appropriately reviewed.Many challenges remain, however, and possible misinterpretation of guidelines in the design phase of new technologies can potentially lead to insufficient or inappropriate measures to counter risk.New evaluation method and resources to help clarify guidelines and ethical riskIn preparing this new toolkit and guidance for developers, Fujitsu performed analyses of past AI related incidents collected in the AI Incident Database of the international consortium Partnership on AI (1). This process led to the conclusion that ethical issues related to AI systems can be contextualized with the exchange of information (""interactions"") between discreet elements within an AI system and between an AI system and its users and other stakeholders.Based on these findings, Fujitsu successfully developed an evaluation method to systematically identify relevant ethical issues related to AI systems, allowing for the creation of AI ethics models (2) that are able to clarify the interpretation of AI ethics guidelines.Fujitsu applied its new evaluation method to 15 representative cases out of the AI Incident Database (164 global cases registered as of February 21, 2022, examples included cases from areas like the financial and human resources sector). Applying the new method, all ethical issues that occurred in real world use cases were successfully identified as risks in advance during verification trials, the results of which have been published.Fujitsu will be offering the following resource toolkit consisting of a variety of resources and guidance for developers to refer to in their own work:Download site (in Japanese, English available at future date)1. Whitepaper: A general overview of methodology2. AI ethical impact assessment procedure manual: AI system diagram, preparation procedure of AI ethical model and explanation of problem correspondence method3. AI ethical model: An AI ethical model based on AI ethical guidelines published by the European Commission (created by Fujitsu) 4. AI ethics analysis case studies: Results of analysis of major AI ethics issues from the AI Incident Database of Partnership on AI (As of February 21, there were six cases, which were added sequentially.)Use Case: risk in use of AI for the evaluation of individuals for bank loans, recruitmentFigure 1 shows an example of an evaluation process of an individual typical in use case scenarios like personnel recruitment or the approval of bank loans. The correspondence table in the AI ethics model identified the ""validity of the evaluation process"" (whether the evaluation is conducted responsibly with reference to the output results from the AI system) as a check item for the interaction (relationship) between the user of the AI system and the target person to be evaluated, whereas ""overdependency on AI results,"" ""selective interpretation and evaluation of output results"" and ""ignorance of output results"" are listed as possible risks.Within this example, AI system developers can identify the risk of an ""overdependence of users on outputs from an AI system that may contain bias and lead to unfair decisions"" as a possible risk in an AI system and appropriately adjust the system to prevent this risk.(1) Partnership on AI:A non-profit organization established in 2016 that address the ethical challenges of AI, for a future where AI and humans work together.(2) AI ethics models:AI ethics models include a correspondence table of ""check items"" and ""interactions"", a tool for step-by-step evaluation of ethical requirements for AI systems. AI ethic models are manually created based on a specific guideline, but once generated, a model can be used generically to evaluate various AI systems. Using this method, developers and operators of AI systems can automatically retrieve all relevant check items from a previously created AI ethics model for a systematic and comprehensive evaluation of related possible risks based on the type of interactions within an AI system.About FujitsuFujitsu is the leading Japanese information and communication technology (ICT) company offering a full range of technology products, solutions and services. Approximately 126,000 Fujitsu people support customers in more than 100 countries. We use our experience and the power of ICT to shape the future of society with our customers. Fujitsu Limited (TSE:6702) reported consolidated revenues of 3.6 trillion yen (US$34 billion) for the fiscal year ended March 31, 2021. For more information, please see www.fujitsu.com.
Published by HT Digital Content Services with permission from Web Newswire. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (89%); BUSINESS ETHICS (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); MACHINE LEARNING (78%); SAFETY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CASE STUDIES (76%); NEGATIVE SOCIETAL NEWS (76%); GOVERNMENT & PUBLIC ADMINISTRATION (71%); PRIVATELY HELD COMPANIES (71%)
Company:  FUJITSU LTD (92%)
Ticker: 6702 (TSE) (92%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (92%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (78%)
Geographic: JAPAN (79%); EUROPE (75%)
Load-Date: February 21, 2022","India, Feb. 21 -- Fujitsu today announced the development of a resource toolkit offering developers guidance for evaluating the ethical impact and risks of AI systems based on international AI ethics guidelines. Fujitsu will offer these resources free of charge starting from February 21, 2022 to promote the safe and secure deployment of AI systems in society.Figure 1. Outline of AI Ethics Impact AssessmentThe toolkit consists of a variety of case studies and reference materials, including a newly developed method for clarifying ethical requirements in AI ethics guidelines written in natural language, as well as for applying ethical requirements to actual AI systems. The resources in Japanese can be downloaded here, with availability in English to follow in the near future.With this guidance, Fujitsu aims to prevent misunderstandings and potential risks caused by differences in the interpretation of descriptions in guidelines, offering AI system developers and operators new tools for thoroughly identifying and preventing possible ethical issues early in the development process in keeping with international best practices.Dr. Christoph Lutge of the Technical University of Munich, a leading authority in the research of responsible AI and business ethics, comments, ""In Europe, there is a growing debate about AI regulations, and one of the key issues is how to close the gap between principles and practices, or ""what"" and ""how."" I believe that the results of this research are very significant in that they enable us to practice based on principles. I would also like to express my deep appreciation for the decision to open up the research results and stimulate discussion worldwide.""Going forward, Fujitsu will actively work to partner with government agencies, private companies, and leading researchers to further refine and promote its newly developed methodology and aims to release an expanded version of the resource toolkit in fiscal year 2022.BackgroundIn April 2021, the European Commission issued a draft for a regulatory framework calling for a comprehensive ethical response for AI system developers, users, and stakeholders in response to increasing concerns surrounding algorithmic bias and discriminatory decision-making in AI and machine learning applications.To commit fully to the responsible use of technology and earn society's trust in AI systems and the companies and organizations involved in this space, Fujitsu has formulated its own AI Commitment in 2019, as well as a new AI Ethics and Governance Office to develop and enforce robust policies for AI ethics, promote organizational AI ethical governance to ensure their effectiveness. 
Now, Fujitsu will move from principle to practice by steadily implementing best practices in the real-world to ensure the realization of ethical, safe, and transparent AI and machine learning technologies.At present, it is common practice in AI system development to identify possible ethical risks in AI systems based on AI ethics guidelines issued by government authorities and companies. These guidelines are written in natural language, however, contributing to possible differences in interpretation and misunderstandings amongst designers and developers that can lead to inappropriate or insufficient measures. Under this method it is also difficult to judge whether the contents of the guidelines were thoroughly and appropriately reviewed.Many challenges remain, however, and possible misinterpretation of guidelines in the design phase of new technologies can potentially lead to insufficient or inappropriate measures to counter risk.New evaluation method and resources to help clarify guidelines and ethical riskIn preparing this new toolkit and guidance for developers, Fujitsu performed analyses of past AI related incidents collected in the AI Incident Database of the international consortium Partnership on AI (1). This process led to the conclusion that ethical issues related to AI systems can be contextualized with the exchange of information (""interactions"") between discreet elements within an AI system and between an AI system and its users and other stakeholders.Based on these findings, Fujitsu successfully developed an evaluation method to systematically identify relevant ethical issues related to AI systems, allowing for the creation of AI ethics models (2) that are able to clarify the interpretation of AI ethics guidelines.Fujitsu applied its new evaluation method to 15 representative cases out of the AI Incident Database (164 global cases registered as of February 21, 2022, examples included cases from areas like the financial and human resources sector). Applying the new method, all ethical issues that occurred in real world use cases were successfully identified as risks in advance during verification trials, the results of which have been published.Fujitsu will be offering the following resource toolkit consisting of a variety of resources and guidance for developers to refer to in their own work:Download site (in Japanese, English available at future date)1. Whitepaper: A general overview of methodology2. AI ethical impact assessment procedure manual: AI system diagram, preparation procedure of AI ethical model and explanation of problem correspondence method3. AI ethical model: An AI ethical model based on AI ethical guidelines published by the European Commission (created by Fujitsu) 4. AI ethics analysis case studies: Results of analysis of major AI ethics issues from the AI Incident Database of Partnership on AI (As of February 21, there were six cases, which were added sequentially.)Use Case: risk in use of AI for the evaluation of individuals for bank loans, recruitmentFigure 1 shows an example of an evaluation process of an individual typical in use case scenarios like personnel recruitment or the approval of bank loans. The correspondence table in the AI ethics model identified the ""validity of the evaluation process"" (whether the evaluation is conducted responsibly with reference to the output results from the AI system) as a check item for the interaction (relationship) between the user of the AI system and the target person to be evaluated, whereas ""overdependency on AI results,"" ""selective interpretation and evaluation of output results"" and ""ignorance of output results"" are listed as possible risks.Within this example, AI system developers can identify the risk of an ""overdependence of users on outputs from an AI system that may contain bias and lead to unfair decisions"" as a possible risk in an AI system and appropriately adjust the system to prevent this risk.(1) Partnership on AI:A non-profit organization established in 2016 that address the ethical challenges of AI, for a future where AI and humans work together.(2) AI ethics models:AI ethics models include a correspondence table of ""check items"" and ""interactions"", a tool for step-by-step evaluation of ethical requirements for AI systems. AI ethic models are manually created based on a specific guideline, but once generated, a model can be used generically to evaluate various AI systems. Using this method, developers and operators of AI systems can automatically retrieve all relevant check items from a previously created AI ethics model for a systematic and comprehensive evaluation of related possible risks based on the type of interactions within an AI system.About FujitsuFujitsu is the leading Japanese information and communication technology (ICT) company offering a full range of technology products, solutions and services. Approximately 126,000 Fujitsu people support customers in more than 100 countries. We use our experience and the power of ICT to shape the future of society with our customers. Fujitsu Limited (TSE:6702) reported consolidated revenues of 3.6 trillion yen (US$34 billion) for the fiscal year ended March 31, 2021. For more information, please see www.fujitsu.com.
Published by HT Digital Content Services with permission from Web Newswire. For any query with respect to this article or any other content requirement, please contact Editor at contentservices@htlive.com
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (94%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); BEST PRACTICES (89%); BUSINESS ETHICS (78%); BUSINESS ETHICS & CORPORATE CITIZENSHIP (78%); MACHINE LEARNING (78%); SAFETY (78%); SOCIETY, SOCIAL ASSISTANCE & LIFESTYLE (78%); CASE STUDIES (76%); NEGATIVE SOCIETAL NEWS (76%); GOVERNMENT & PUBLIC ADMINISTRATION (71%); PRIVATELY HELD COMPANIES (71%)
Company:  FUJITSU LTD (92%)
Ticker: 6702 (TSE) (92%)
Industry: NAICS334118 COMPUTER TERMINAL & OTHER COMPUTER PERIPHERAL EQUIPMENT MANUFACTURING (92%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); MACHINE LEARNING (78%)
Geographic: JAPAN (79%); EUROPE (75%)
Load-Date: February 21, 2022",neutral,0.6529363989830017,balanced/neutral,"['bias', 'safety']",[],"['governance', 'guidelines', 'framework']",['machine learning'],2,0,3,1
2021,Unknown Title,"Byline: McKinsey & Company
Highlight: Every company must establish its own best practices for managing its data. Here are five pitfalls to avoid based on our conversations with experts and early adopters.
Body
 Link to Image 
Now more than ever, every company is a data company. By 2025, individuals and companies around the world will produce an estimated 463 exabytes of data each day, compared with less than three exabytes a decade ago.
With that in mind, most businesses have begun to address the operational aspects of data management-for instance, determining how to build and maintain a data lake or how to integrate data scientists and other technology experts into existing teams. Fewer companies have systematically considered and started to address the ethical aspects of data management, which could have broad ramifications and responsibilities. If algorithms are trained with biased data sets or data sets are breached, sold without consent, or otherwise mishandled, for instance, companies can incur significant reputational and financial costs. Board members could even be held personally liable.
So how should companies begin to think about ethical data management? What measures can they put in place to ensure that they are using consumer, patient, HR, facilities, and other forms of data appropriately across the value chain-from collection to analytics to insights?
We began to explore these questions by speaking with about a dozen global business leaders and data ethics experts. Through these conversations, we learned about some common data management traps that leaders and organizations can fall into, despite their best intentions. These traps include thinking that data ethics does not apply to your organization, that legal and compliance have data ethics covered, and that data scientists have all the answers-to say nothing of chasing short-term ROI at all costs and looking only at the data rather than their sources.
In this article, we explore these traps and suggest some potential ways to avoid them, such as adopting new standards for data management, rethinking governance models, and collaborating across disciplines and organizations. This list of potential challenges and remedies is not exhaustive; our research base was relatively small, and leaders could face many other obstacles, beyond our discussion here, to the ethical use of data. But what's clear from our research is that data ethics needs both more and sustained attention from all members of the C-suite, including the CEO.
Potential challenges for business leaders
Sidebar
What is data ethics?
We spoke with about a dozen business leaders and data ethics experts. In their eyes, these are some characteristics of ethical data use:
It preserves data security and protects customer information. The practitioners we spoke with tend to view cybersecurity and data privacy as part and parcel of data ethics. They believe companies have an ethical responsibility (as well as legal obligations) to protect customers' data, defend against breaches, and ensure that personal data are not compromised.
It offers a clear benefit to both consumers and companies. ""The consumer's got to be getting something"" from a data-based transaction, explained an executive at a large financial-services company. ""If you're not solving a problem for a consumer, you've got to ask yourself why you're doing what you're doing."" The benefit to customers should be straightforward and easy to summarize in a single sentence: customers might, for instance, get greater speed, convenience, value, or savings.
It offers customers some measure of agency. ""We don't want consumers to be surprised,"" one executive told us. ""If a customer receives an offer and says, 'I think I got this because of how you're using my data, and that makes me uncomfortable. I don't think I ever agreed to this,' another company might say, 'On page 41, down in the footnote in the four-point font, you did actually agree to this.' We never want to be that company.""
It is in line with your company's promises. In data management, organizations must do what they say they will do-or risk losing the trust of customers and other key stakeholders. As one senior executive pointed out, keeping faith with stakeholders may mean turning down certain contracts if they contradict the organization's stated data values and commitments.
There is a dynamic body of literature on data ethics. Just as the methods companies use to collect, analyze, and access data are evolving, so will definitions of the term itself. In this article, we define data ethics as data-related practices that seek to preserve the trust of users, patients, consumers, clients, employees, and partners. Most of the business leaders we spoke to agreed broadly with that definition, but some have tailored it to the needs of their own sectors or organizations (see sidebar, ""What is data ethics?""). Our conversations with these business leaders also revealed the unintended lapses in data ethics that can happen in organizations. These include the following:
Thinking that data ethics doesn't apply to your organization
While privacy and ethical considerations are essential whenever companies use data (including artificial-intelligence and machine-learning applications), they often aren't top of mind for some executives. In our experience, business leaders are not intentionally pushing these thoughts away; it's often just easier for them to focus on things they can ""see""- the tools, technologies, and strategic objectives associated with data management-than on the seemingly invisible ways data management can go wrong.
In a 2021 McKinsey Global Survey on the state of AI, for instance, only 27 percent of some 1,000 respondents said that their data professionals actively check for skewed or biased data during data ingestion. Only 17 percent said that their companies have a dedicated data governance committee that includes risk and legal professionals. In that same survey, only 30 percent of respondents said their companies recognized equity and fairness as relevant AI risks. AI-related data risks are only a subset of broader data ethics concerns, of course, but these numbers are striking.
Thinking in silos: Legal, compliance, or data scientists have data ethics covered
Companies may believe that just by hiring a few data scientists, they've fulfilled their data management obligations. The truth is data ethics is everyone's domain, not just the province of data scientists or of legal and compliance teams. At different times, employees across the organization-from the front line to the C-suite-will need to raise, respond to, and think through various ethical issues surrounding data. Business unit leaders will need to vet their data strategies with legal and marketing teams, for example, to ensure that their strategic and commercial objectives are in line with customers' expectations and with regulatory and legal requirements for data usage.
As executives navigate usage questions, they must acknowledge that although regulatory requirements and ethical obligations are related, adherence to data ethics goes far beyond the question of what's legal. Indeed, companies must often make decisions before the passage of relevant laws. The European Union's General Data Protection Regulation (GDPR) went into effect only in May 2018, the California Consumer Privacy Act has been in effect only since January 2020, and federal privacy law is only now pending in the US Congress. Years before these and other statutes and regulations were put in place, leaders had to set the terms for their organizations' use of data-just as they currently make decisions about matters that will be regulated in years to come.
Laws can show executives what they can do. But a comprehensive data ethics framework can guide executives on whether they should, say, pursue a certain commercial strategy and, if so, how they should go about it. One senior executive we spoke with put the data management task for executives plainly: ""The bar here is not regulation. The bar here is setting an expectation with consumers and then meeting that expectation-and doing it in a way that's additive to your brand.""
Chasing short-term ROI
Prompted by economic volatility, aggressive innovation in some industries, and other disruptive business trends, executives and other employees may be tempted to make unethical data choices-for instance, inappropriately sharing confidential information because it is useful-to chase short-term profits. Boards increasingly want more standards for the use of consumer and business data, but the short-term financial pressures remain. As one tech company president explained: ""It's tempting to collect as much data as possible and to use as much data as possible. Because at the end of the day, my board cares about whether I deliver growth and EBITDA.... If my chief marketing officer can't target users to create an efficient customer acquisition channel, he will likely get fired at some point-or at least he won't make his bonus.""
Looking only at the data, not at the sources
Ethical lapses can occur when executives look only at the fidelity and utility of discrete data sets and don't consider the entire data pipeline. Where did the data come from? Can this vendor ensure that the subjects of the data gave their informed consent for use by third parties? Do any of the market data contain material nonpublic information? Such due diligence is key: one alternative data provider was charged with securities fraud for misrepresenting to trading firms how its data were derived. In that case, companies had provided confidential information about the performance of their apps to the data vendor, which did not aggregate and anonymize the data as promised. Ultimately, the vendor had to settle with the US Securities and Exchange Commission.
A few important building blocks
These data management challenges are common-and they are by no means the only ones. As organizations generate more data, adopt new tools and technologies to collect and analyze data, and find new ways to apply insights from data, new privacy and ethical challenges and complications will inevitably emerge. Organizations must experiment with ways to build fault-tolerant data management programs. These seven data-related principles, drawn from our research, may provide a helpful starting point.
Set company-specific rules for data usage
Leaders in the business units, functional areas, and legal and compliance teams must come together to create a data usage framework for employees-a framework that reflects a shared vision and mission for the company's use of data. As a start, the CEO and other C-suite leaders must also be involved in defining data rules that give employees a clear sense of the company's threshold for risk and which data-related ventures are OK to pursue and which are not.
Leaders must come together to create a data usage framework that reflects a shared vision and mission for the company's use of data.
Such rules can improve and potentially speed up individual and organizational decision making. They should be tailored to your specific industry, even to the products and services your company offers. They should be accessible to all employees, partners, and other critical stakeholders. And they should be grounded in a core principle-for example, ""We do not use data in any way that we cannot link to a better outcome for our customers."" Business leaders should plan to revisit and revise the rules periodically to account for shifts in the business and technology landscape.
Communicate your data values, both inside and outside your organization
Once you've established common data usage rules, it's important to communicate them effectively inside and outside the organization. That might mean featuring the company's data values on employees' screen savers, as the company of one of our interview subjects has done. Or it may be as simple as tailoring discussions about data ethics to various business units and functions and speaking to their employees in language they understand. The messaging to the IT group and data scientists, for instance, may be about creating ethical data algorithms or safe and robust data storage protocols. The messaging to marketing and sales teams may focus on transparency and opt-in/opt-out protocols.
Organizations also need to earn the public's trust. Posting a statement about data ethics on the corporate website worked for one financial-services organization. As an executive explained: ""When you're having a conversation with a government entity, it's really helpful to be able to say, 'Go to our website and click on Responsible Data Use, and you'll see what we think.' We're on record in a way that you can't really walk back."" Indeed, publicizing your company's data ethics framework may help increase the momentum for powerful joint action, such as the creation of industry-wide data ethics standards.
Build a diverse data-focused team
A strong data ethics program won't materialize out of the blue. Organizations large and small need people who focus on ethics issues; it cannot be a side activity. The work should be assigned to a specific team or attached to a particular role. Some larger technology and pharmaceutical companies have appointed chief ethics or chief trust officers in recent years. Others have set up interdisciplinary teams, sometimes referred to as data ethics boards, to define and uphold data ethics. Ideally, such boards would include representatives from, for example, the business units, marketing and sales, compliance and legal, audit, IT, and the C-suite. These boards should also have a range of genders, races, ethnicities, classes, and so on: an organization will be more likely to identify issues early on (in algorithm-training data, for example) when people with a range of different backgrounds and experiences sit around the table.
One multinational financial-services corporation has developed an effective structure for its data ethics deliberations and decision making. It has two main data ethics groups. The major decisions are made by a group of senior stakeholders, including the head of security and other senior technology executives, the chief privacy officer, the head of the consulting arm, the head of strategy, and the heads of brand, communications, and digital advertising. These are the people most likely to use the data.
Governance is the province of another group, which is chaired by the chief privacy officer and includes the global head of data, a senior risk executive, and the executive responsible for the company's brand. Anything new concerning data use gets referred to this council, and teams must explain how proposed products comply with the company's data use principles. As one senior company executive explains, ""It's important that both of these bodies be cross-functional because in both cases you're trying to make sure that you have a fairly holistic perspective.""
As we've noted, compliance teams and legal counsel should not be the only people thinking about a company's data ethics, but they do have an important role to play in ensuring that data ethics programs succeed. Legal experts are best positioned to advise on how your company should apply existing and emerging regulations. But teams may also want to bring in outside experts to navigate particularly difficult ethical challenges. For example, a large tech company brought in an academic expert on AI ethics to help it figure out how to navigate gray areas, such as the environmental impact of certain kinds of data use. That expert was a sitting but not voting member of the group because the team ""did not want to outsource the decision making."" But the expert participated in every meeting and led the team in the work that preceded the meetings.
Engage champions in the C-suite
Some practitioners and experts we spoke with who had convened data ethics boards pointed to the importance of keeping the CEO and the corporate board apprised of decisions and activities. A senior executive who chaired his organization's data ethics group explained that while it did not involve the CEO directly in the decision-making process, it brought all data ethics conclusions to him ""and made sure he agreed with the stance that we were taking."" All these practitioners and experts agreed that having a champion or two in the C-suite can signal the importance of data ethics to the rest of the organization, put teeth into data rules, and support the case for investment in data-related initiatives.
Indeed, corporate boards and audit committees can provide the checks needed to ensure that data ethics are being upheld, regardless of conflicting incentives. The president of one tech company told us that its board had recently begun asking for a data ethics report as part of the audit committee's agenda, which had previously focused more narrowly on privacy and security. ""You have to provide enough of an incentive-a carrot or a stick to make sure people take this seriously,"" the president said.
Consider the impact of your algorithms and overall data use
Organizations should continually assess the effects of the algorithms and data they use-and test for bias throughout the value chain. That means thinking about the problems organizations might create, even unwittingly, in building AI products. For instance, who might be disadvantaged by an algorithm or a particular use of data? One technologist we spoke with advises asking the hard questions: ""Start your meetings about AI by asking, 'Are the algorithms we are building sexist or racist?'""
Certain data applications require far greater scrutiny and consideration. Security is one such area. A tech company executive recalled the extra measures his organization took to prevent its image and video recognition products and services from being misused: ""We would insist that if you were going to use our technology for security purposes, we had to get very involved in ensuring that you debiased the data set as much as possible so that particular groups would not be unfairly singled out."" It's important to consider not only what types of data are being used but also what they are being used for-and what they could potentially be used for down the line.
Think globally
The ethical use of data requires organizations to consider the interests of people who are not in the room. Anthropologist Mary Gray, the senior principal researcher at Microsoft Research, raises questions about global reach in her 2019 book, Ghost Work. Among them: Who labeled the data? Who tagged these images? Who kept violent videos off this website? Who weighed in when the algorithm needed a steer?
Today's leaders need to ask these sorts of questions, along with others about how such tech work happens. Broadly, leaders must take a 10,000-foot view of their companies as players in the digital economy, the data ecosystem, and societies everywhere. There may be ways they can support policy initiatives or otherwise help to bridge the digital divide, support the expansion of broadband infrastructure, and create pathways for diversity in the tech industry. Ultimately, data ethics requires leaders to reckon with the ongoing rise in global inequality-and the increasing concentration of wealth and value both in geographical tech hubs and among AI-enabled organizations.
Embed your data principles in your operations
It's one thing to define what constitutes the ethical use of data and to set data usage rules; it's another to integrate those rules into operations across the organization. Data ethics boards, business unit leaders, and C-suite champions should build a common view (and a common language) about how data usage rules should link up to both the company's data and corporate strategies and to real-world use cases for data ethics, such as decisions on design processes or M&A. In some cases, there will be obvious places to operationalize data ethics-for instance, data operations teams, secure-development operations teams, and machine-learning operations teams. Trust-building frameworks for machine-learning operations can ensure that data ethics will be considered at every step in the development of AI applications.
Regardless of which part of the organization the leaders target first, they should identify KPIs that can be used to monitor and measure its performance in realizing their data ethics objectives. To ensure that the ethical use of data becomes part of everyone's daily work, the leadership team also should advocate, help to build, and facilitate formal training programs on data ethics.
Data ethics can't be put into practice overnight. As many business leaders know firsthand, building teams, establishing practices, and changing organizational culture are all easier said than done. What's more, upholding your organization's data ethics principles may mean walking away from potential partnerships and other opportunities to generate short-term revenues. But the stakes for companies could not be higher. Organizations that fail to walk the walk on data ethics risk losing their customers' trust and destroying value.
About the authors
Alex Edquist is an alumna of McKinsey's Atlanta office; Liz Grennan is an associate partner in the Stamford, Connecticut, office; Sian Griffiths is a partner in the Washington, DC, office; and Kayvaun Rowshankish is a senior partner in the New York office.
The authors wish to thank Alyssa Bryan, Kasia Chmielinski, Ilona Logvinova, Keith Otis, Marc Singer, Naomi Sosner, and Eckart Windhagen for their contributions to this article.
This article was edited by Roberta Fusaro, an editorial director in the Waltham, Massachusetts, office.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (92%); BEST PRACTICES (90%); DATA SCIENCE (90%); NEGATIVE TECHNOLOGY NEWS (89%); ASSOCIATIONS & ORGANIZATIONS (88%); BOARDS OF DIRECTORS (78%); CORPORATE GOVERNANCE (78%); DATA ANALYTICS (78%); EXECUTIVES (78%); CONSUMERS (74%); VALUE CHAIN (74%); PRIVACY RIGHTS (60%); Digital Insights (%); Big data (%); Digital (%)
Industry: DATA SCIENCE (90%); INFORMATION SECURITY & PRIVACY (89%); DATA ANALYTICS (78%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA LAKES (78%); DATA SECURITY (78%); BANKING & FINANCE (69%)
Load-Date: September 23, 2022","Link to Image 
Now more than ever, every company is a data company. By 2025, individuals and companies around the world will produce an estimated 463 exabytes of data each day, compared with less than three exabytes a decade ago.
With that in mind, most businesses have begun to address the operational aspects of data management-for instance, determining how to build and maintain a data lake or how to integrate data scientists and other technology experts into existing teams. Fewer companies have systematically considered and started to address the ethical aspects of data management, which could have broad ramifications and responsibilities. If algorithms are trained with biased data sets or data sets are breached, sold without consent, or otherwise mishandled, for instance, companies can incur significant reputational and financial costs. Board members could even be held personally liable.
So how should companies begin to think about ethical data management? What measures can they put in place to ensure that they are using consumer, patient, HR, facilities, and other forms of data appropriately across the value chain-from collection to analytics to insights?
We began to explore these questions by speaking with about a dozen global business leaders and data ethics experts. Through these conversations, we learned about some common data management traps that leaders and organizations can fall into, despite their best intentions. These traps include thinking that data ethics does not apply to your organization, that legal and compliance have data ethics covered, and that data scientists have all the answers-to say nothing of chasing short-term ROI at all costs and looking only at the data rather than their sources.
In this article, we explore these traps and suggest some potential ways to avoid them, such as adopting new standards for data management, rethinking governance models, and collaborating across disciplines and organizations. This list of potential challenges and remedies is not exhaustive; our research base was relatively small, and leaders could face many other obstacles, beyond our discussion here, to the ethical use of data. But what's clear from our research is that data ethics needs both more and sustained attention from all members of the C-suite, including the CEO.
Potential challenges for business leaders
Sidebar
What is data ethics?
We spoke with about a dozen business leaders and data ethics experts. In their eyes, these are some characteristics of ethical data use:
It preserves data security and protects customer information. The practitioners we spoke with tend to view cybersecurity and data privacy as part and parcel of data ethics. They believe companies have an ethical responsibility (as well as legal obligations) to protect customers' data, defend against breaches, and ensure that personal data are not compromised.
It offers a clear benefit to both consumers and companies. ""The consumer's got to be getting something"" from a data-based transaction, explained an executive at a large financial-services company. ""If you're not solving a problem for a consumer, you've got to ask yourself why you're doing what you're doing."" The benefit to customers should be straightforward and easy to summarize in a single sentence: customers might, for instance, get greater speed, convenience, value, or savings.
It offers customers some measure of agency. ""We don't want consumers to be surprised,"" one executive told us. ""If a customer receives an offer and says, 'I think I got this because of how you're using my data, and that makes me uncomfortable. I don't think I ever agreed to this,' another company might say, 'On page 41, down in the footnote in the four-point font, you did actually agree to this.' We never want to be that company.""
It is in line with your company's promises. In data management, organizations must do what they say they will do-or risk losing the trust of customers and other key stakeholders. As one senior executive pointed out, keeping faith with stakeholders may mean turning down certain contracts if they contradict the organization's stated data values and commitments.
There is a dynamic body of literature on data ethics. Just as the methods companies use to collect, analyze, and access data are evolving, so will definitions of the term itself. In this article, we define data ethics as data-related practices that seek to preserve the trust of users, patients, consumers, clients, employees, and partners. Most of the business leaders we spoke to agreed broadly with that definition, but some have tailored it to the needs of their own sectors or organizations (see sidebar, ""What is data ethics?""). Our conversations with these business leaders also revealed the unintended lapses in data ethics that can happen in organizations. These include the following:
Thinking that data ethics doesn't apply to your organization
While privacy and ethical considerations are essential whenever companies use data (including artificial-intelligence and machine-learning applications), they often aren't top of mind for some executives. In our experience, business leaders are not intentionally pushing these thoughts away; it's often just easier for them to focus on things they can ""see""- the tools, technologies, and strategic objectives associated with data management-than on the seemingly invisible ways data management can go wrong.
In a 2021 McKinsey Global Survey on the state of AI, for instance, only 27 percent of some 1,000 respondents said that their data professionals actively check for skewed or biased data during data ingestion. Only 17 percent said that their companies have a dedicated data governance committee that includes risk and legal professionals. In that same survey, only 30 percent of respondents said their companies recognized equity and fairness as relevant AI risks. AI-related data risks are only a subset of broader data ethics concerns, of course, but these numbers are striking.
Thinking in silos: Legal, compliance, or data scientists have data ethics covered
Companies may believe that just by hiring a few data scientists, they've fulfilled their data management obligations. The truth is data ethics is everyone's domain, not just the province of data scientists or of legal and compliance teams. At different times, employees across the organization-from the front line to the C-suite-will need to raise, respond to, and think through various ethical issues surrounding data. Business unit leaders will need to vet their data strategies with legal and marketing teams, for example, to ensure that their strategic and commercial objectives are in line with customers' expectations and with regulatory and legal requirements for data usage.
As executives navigate usage questions, they must acknowledge that although regulatory requirements and ethical obligations are related, adherence to data ethics goes far beyond the question of what's legal. Indeed, companies must often make decisions before the passage of relevant laws. The European Union's General Data Protection Regulation (GDPR) went into effect only in May 2018, the California Consumer Privacy Act has been in effect only since January 2020, and federal privacy law is only now pending in the US Congress. Years before these and other statutes and regulations were put in place, leaders had to set the terms for their organizations' use of data-just as they currently make decisions about matters that will be regulated in years to come.
Laws can show executives what they can do. But a comprehensive data ethics framework can guide executives on whether they should, say, pursue a certain commercial strategy and, if so, how they should go about it. One senior executive we spoke with put the data management task for executives plainly: ""The bar here is not regulation. The bar here is setting an expectation with consumers and then meeting that expectation-and doing it in a way that's additive to your brand.""
Chasing short-term ROI
Prompted by economic volatility, aggressive innovation in some industries, and other disruptive business trends, executives and other employees may be tempted to make unethical data choices-for instance, inappropriately sharing confidential information because it is useful-to chase short-term profits. Boards increasingly want more standards for the use of consumer and business data, but the short-term financial pressures remain. As one tech company president explained: ""It's tempting to collect as much data as possible and to use as much data as possible. Because at the end of the day, my board cares about whether I deliver growth and EBITDA.... If my chief marketing officer can't target users to create an efficient customer acquisition channel, he will likely get fired at some point-or at least he won't make his bonus.""
Looking only at the data, not at the sources
Ethical lapses can occur when executives look only at the fidelity and utility of discrete data sets and don't consider the entire data pipeline. Where did the data come from? Can this vendor ensure that the subjects of the data gave their informed consent for use by third parties? Do any of the market data contain material nonpublic information? Such due diligence is key: one alternative data provider was charged with securities fraud for misrepresenting to trading firms how its data were derived. In that case, companies had provided confidential information about the performance of their apps to the data vendor, which did not aggregate and anonymize the data as promised. Ultimately, the vendor had to settle with the US Securities and Exchange Commission.
A few important building blocks
These data management challenges are common-and they are by no means the only ones. As organizations generate more data, adopt new tools and technologies to collect and analyze data, and find new ways to apply insights from data, new privacy and ethical challenges and complications will inevitably emerge. Organizations must experiment with ways to build fault-tolerant data management programs. These seven data-related principles, drawn from our research, may provide a helpful starting point.
Set company-specific rules for data usage
Leaders in the business units, functional areas, and legal and compliance teams must come together to create a data usage framework for employees-a framework that reflects a shared vision and mission for the company's use of data. As a start, the CEO and other C-suite leaders must also be involved in defining data rules that give employees a clear sense of the company's threshold for risk and which data-related ventures are OK to pursue and which are not.
Leaders must come together to create a data usage framework that reflects a shared vision and mission for the company's use of data.
Such rules can improve and potentially speed up individual and organizational decision making. They should be tailored to your specific industry, even to the products and services your company offers. They should be accessible to all employees, partners, and other critical stakeholders. And they should be grounded in a core principle-for example, ""We do not use data in any way that we cannot link to a better outcome for our customers."" Business leaders should plan to revisit and revise the rules periodically to account for shifts in the business and technology landscape.
Communicate your data values, both inside and outside your organization
Once you've established common data usage rules, it's important to communicate them effectively inside and outside the organization. That might mean featuring the company's data values on employees' screen savers, as the company of one of our interview subjects has done. Or it may be as simple as tailoring discussions about data ethics to various business units and functions and speaking to their employees in language they understand. The messaging to the IT group and data scientists, for instance, may be about creating ethical data algorithms or safe and robust data storage protocols. The messaging to marketing and sales teams may focus on transparency and opt-in/opt-out protocols.
Organizations also need to earn the public's trust. Posting a statement about data ethics on the corporate website worked for one financial-services organization. As an executive explained: ""When you're having a conversation with a government entity, it's really helpful to be able to say, 'Go to our website and click on Responsible Data Use, and you'll see what we think.' We're on record in a way that you can't really walk back."" Indeed, publicizing your company's data ethics framework may help increase the momentum for powerful joint action, such as the creation of industry-wide data ethics standards.
Build a diverse data-focused team
A strong data ethics program won't materialize out of the blue. Organizations large and small need people who focus on ethics issues; it cannot be a side activity. The work should be assigned to a specific team or attached to a particular role. Some larger technology and pharmaceutical companies have appointed chief ethics or chief trust officers in recent years. Others have set up interdisciplinary teams, sometimes referred to as data ethics boards, to define and uphold data ethics. Ideally, such boards would include representatives from, for example, the business units, marketing and sales, compliance and legal, audit, IT, and the C-suite. These boards should also have a range of genders, races, ethnicities, classes, and so on: an organization will be more likely to identify issues early on (in algorithm-training data, for example) when people with a range of different backgrounds and experiences sit around the table.
One multinational financial-services corporation has developed an effective structure for its data ethics deliberations and decision making. It has two main data ethics groups. The major decisions are made by a group of senior stakeholders, including the head of security and other senior technology executives, the chief privacy officer, the head of the consulting arm, the head of strategy, and the heads of brand, communications, and digital advertising. These are the people most likely to use the data.
Governance is the province of another group, which is chaired by the chief privacy officer and includes the global head of data, a senior risk executive, and the executive responsible for the company's brand. Anything new concerning data use gets referred to this council, and teams must explain how proposed products comply with the company's data use principles. As one senior company executive explains, ""It's important that both of these bodies be cross-functional because in both cases you're trying to make sure that you have a fairly holistic perspective.""
As we've noted, compliance teams and legal counsel should not be the only people thinking about a company's data ethics, but they do have an important role to play in ensuring that data ethics programs succeed. Legal experts are best positioned to advise on how your company should apply existing and emerging regulations. But teams may also want to bring in outside experts to navigate particularly difficult ethical challenges. For example, a large tech company brought in an academic expert on AI ethics to help it figure out how to navigate gray areas, such as the environmental impact of certain kinds of data use. That expert was a sitting but not voting member of the group because the team ""did not want to outsource the decision making."" But the expert participated in every meeting and led the team in the work that preceded the meetings.
Engage champions in the C-suite
Some practitioners and experts we spoke with who had convened data ethics boards pointed to the importance of keeping the CEO and the corporate board apprised of decisions and activities. A senior executive who chaired his organization's data ethics group explained that while it did not involve the CEO directly in the decision-making process, it brought all data ethics conclusions to him ""and made sure he agreed with the stance that we were taking."" All these practitioners and experts agreed that having a champion or two in the C-suite can signal the importance of data ethics to the rest of the organization, put teeth into data rules, and support the case for investment in data-related initiatives.
Indeed, corporate boards and audit committees can provide the checks needed to ensure that data ethics are being upheld, regardless of conflicting incentives. The president of one tech company told us that its board had recently begun asking for a data ethics report as part of the audit committee's agenda, which had previously focused more narrowly on privacy and security. ""You have to provide enough of an incentive-a carrot or a stick to make sure people take this seriously,"" the president said.
Consider the impact of your algorithms and overall data use
Organizations should continually assess the effects of the algorithms and data they use-and test for bias throughout the value chain. That means thinking about the problems organizations might create, even unwittingly, in building AI products. For instance, who might be disadvantaged by an algorithm or a particular use of data? One technologist we spoke with advises asking the hard questions: ""Start your meetings about AI by asking, 'Are the algorithms we are building sexist or racist?'""
Certain data applications require far greater scrutiny and consideration. Security is one such area. A tech company executive recalled the extra measures his organization took to prevent its image and video recognition products and services from being misused: ""We would insist that if you were going to use our technology for security purposes, we had to get very involved in ensuring that you debiased the data set as much as possible so that particular groups would not be unfairly singled out."" It's important to consider not only what types of data are being used but also what they are being used for-and what they could potentially be used for down the line.
Think globally
The ethical use of data requires organizations to consider the interests of people who are not in the room. Anthropologist Mary Gray, the senior principal researcher at Microsoft Research, raises questions about global reach in her 2019 book, Ghost Work. Among them: Who labeled the data? Who tagged these images? Who kept violent videos off this website? Who weighed in when the algorithm needed a steer?
Today's leaders need to ask these sorts of questions, along with others about how such tech work happens. Broadly, leaders must take a 10,000-foot view of their companies as players in the digital economy, the data ecosystem, and societies everywhere. There may be ways they can support policy initiatives or otherwise help to bridge the digital divide, support the expansion of broadband infrastructure, and create pathways for diversity in the tech industry. Ultimately, data ethics requires leaders to reckon with the ongoing rise in global inequality-and the increasing concentration of wealth and value both in geographical tech hubs and among AI-enabled organizations.
Embed your data principles in your operations
It's one thing to define what constitutes the ethical use of data and to set data usage rules; it's another to integrate those rules into operations across the organization. Data ethics boards, business unit leaders, and C-suite champions should build a common view (and a common language) about how data usage rules should link up to both the company's data and corporate strategies and to real-world use cases for data ethics, such as decisions on design processes or M&A. In some cases, there will be obvious places to operationalize data ethics-for instance, data operations teams, secure-development operations teams, and machine-learning operations teams. Trust-building frameworks for machine-learning operations can ensure that data ethics will be considered at every step in the development of AI applications.
Regardless of which part of the organization the leaders target first, they should identify KPIs that can be used to monitor and measure its performance in realizing their data ethics objectives. To ensure that the ethical use of data becomes part of everyone's daily work, the leadership team also should advocate, help to build, and facilitate formal training programs on data ethics.
Data ethics can't be put into practice overnight. As many business leaders know firsthand, building teams, establishing practices, and changing organizational culture are all easier said than done. What's more, upholding your organization's data ethics principles may mean walking away from potential partnerships and other opportunities to generate short-term revenues. But the stakes for companies could not be higher. Organizations that fail to walk the walk on data ethics risk losing their customers' trust and destroying value.
About the authors
Alex Edquist is an alumna of McKinsey's Atlanta office; Liz Grennan is an associate partner in the Stamford, Connecticut, office; Sian Griffiths is a partner in the Washington, DC, office; and Kayvaun Rowshankish is a senior partner in the New York office.
The authors wish to thank Alyssa Bryan, Kasia Chmielinski, Ilona Logvinova, Keith Otis, Marc Singer, Naomi Sosner, and Eckart Windhagen for their contributions to this article.
This article was edited by Roberta Fusaro, an editorial director in the Waltham, Massachusetts, office.
Classification
Language: ENGLISH
Publication-Type: Web Publication
Subject: ETHICS (92%); BEST PRACTICES (90%); DATA SCIENCE (90%); NEGATIVE TECHNOLOGY NEWS (89%); ASSOCIATIONS & ORGANIZATIONS (88%); BOARDS OF DIRECTORS (78%); CORPORATE GOVERNANCE (78%); DATA ANALYTICS (78%); EXECUTIVES (78%); CONSUMERS (74%); VALUE CHAIN (74%); PRIVACY RIGHTS (60%); Digital Insights (%); Big data (%); Digital (%)
Industry: DATA SCIENCE (90%); INFORMATION SECURITY & PRIVACY (89%); DATA ANALYTICS (78%); DATA GOVERNANCE & STEWARDSHIP (78%); DATA LAKES (78%); DATA SECURITY (78%); BANKING & FINANCE (69%)
Load-Date: September 23, 2022",neutral,0.750009298324585,balanced/neutral,"['privacy', 'bias', 'fairness', 'transparency', 'security', 'agency', 'consent', 'digital divide', 'access', 'inequality', 'environmental impact']","['fairness', 'equity']","['regulation', 'policy', 'governance', 'standards', 'framework', 'law', 'compliance', 'audit', 'should', 'must', 'need to', 'suggest', 'advocate']",['algorithm'],11,2,13,1
2021,Unknown Title,"Byline: WANG QINGYUN
Body
China has shared its positions on the supervision, development and use of artificial intelligence, as well as on related international cooperation, in a paper that calls for strengthened ethical governance of AI, Foreign Ministry spokeswoman Mao Ning said on Thursday.
The position paper, submitted to the Meeting of the High Contracting Parties to the Convention on Certain Conventional Weapons on Wednesday, emphasized that China has always committed to building a community with a shared future for mankind in the field of AI, Mao said at a daily news conference.
The paper also stressed that China has advocated the people-oriented principle and the principle of using AI for good purposes to make sure that AI is safe, reliable and controllable, thus to better empower sustainable world development and promote the well-being of all humanity, Mao said.
AI technology, which continually develops and is being widely used, is beginning to impose a complicated influence on the politics, economy, military affairs and society of all countries, the spokeswoman said.
Countries have come to realize that once abused, the technology may impact their ethical norms and legal systems, causing serious ethical problems, Mao said, adding that it's an important issue for all countries to strengthen the ethical governance of AI.
China attaches great importance to preventing and controlling AI-related risks, and hopes to work together with the world to form a widely approved solution for the international governance of AI, the spokeswoman said.
It will also continue to implement the principle of extensive consultation, joint contribution and shared benefits and work with the international community to carry out the Global Development Initiative and the Global Security Initiative to deal with challenges arising from the use of AI, Mao said.
The Meeting of the High Contracting Parties to the Convention on Certain Conventional Weapons for 2022 is being held in Geneva, Switzerland from Wednesday to Friday.
Parties to the convention gather at the meeting annually, and meet every five years at the review conference.
At the Sixth Review Conference of the convention held in Geneva in December last year, China submitted another position paper, which focused on regulating military applications of AI.
wangqingyun@chinadaily.com.cn
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: INTERNATIONAL RELATIONS & NATIONAL SECURITY (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INTERNATIONAL RELATIONS (90%); STATE DEPARTMENTS & FOREIGN SERVICES (90%); CONFERENCES & CONVENTIONS (89%); TALKS & MEETINGS (89%); SUSTAINABLE DEVELOPMENT (78%); ARMS CONTROL & DISARMAMENT (76%); MILITARY WEAPONS (76%); NEGATIVE NEWS (76%); PRESS CONFERENCES (70%); LAW & LEGAL SYSTEM (66%); CHINA (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (78%); MILITARY WEAPONS (76%)
Geographic: GENEVA, SWITZERLAND (87%); SWITZERLAND (91%)
Load-Date: November 17, 2022","China has shared its positions on the supervision, development and use of artificial intelligence, as well as on related international cooperation, in a paper that calls for strengthened ethical governance of AI, Foreign Ministry spokeswoman Mao Ning said on Thursday.
The position paper, submitted to the Meeting of the High Contracting Parties to the Convention on Certain Conventional Weapons on Wednesday, emphasized that China has always committed to building a community with a shared future for mankind in the field of AI, Mao said at a daily news conference.
The paper also stressed that China has advocated the people-oriented principle and the principle of using AI for good purposes to make sure that AI is safe, reliable and controllable, thus to better empower sustainable world development and promote the well-being of all humanity, Mao said.
AI technology, which continually develops and is being widely used, is beginning to impose a complicated influence on the politics, economy, military affairs and society of all countries, the spokeswoman said.
Countries have come to realize that once abused, the technology may impact their ethical norms and legal systems, causing serious ethical problems, Mao said, adding that it's an important issue for all countries to strengthen the ethical governance of AI.
China attaches great importance to preventing and controlling AI-related risks, and hopes to work together with the world to form a widely approved solution for the international governance of AI, the spokeswoman said.
It will also continue to implement the principle of extensive consultation, joint contribution and shared benefits and work with the international community to carry out the Global Development Initiative and the Global Security Initiative to deal with challenges arising from the use of AI, Mao said.
The Meeting of the High Contracting Parties to the Convention on Certain Conventional Weapons for 2022 is being held in Geneva, Switzerland from Wednesday to Friday.
Parties to the convention gather at the meeting annually, and meet every five years at the review conference.
At the Sixth Review Conference of the convention held in Geneva in December last year, China submitted another position paper, which focused on regulating military applications of AI.
wangqingyun@chinadaily.com.cn
Classification
Language: ENGLISH
Publication-Type: Newspaper
Subject: INTERNATIONAL RELATIONS & NATIONAL SECURITY (91%); ARTIFICIAL INTELLIGENCE (90%); ETHICS (90%); INTERNATIONAL RELATIONS (90%); STATE DEPARTMENTS & FOREIGN SERVICES (90%); CONFERENCES & CONVENTIONS (89%); TALKS & MEETINGS (89%); SUSTAINABLE DEVELOPMENT (78%); ARMS CONTROL & DISARMAMENT (76%); MILITARY WEAPONS (76%); NEGATIVE NEWS (76%); PRESS CONFERENCES (70%); LAW & LEGAL SYSTEM (66%); CHINA (%)
Industry: ARTIFICIAL INTELLIGENCE (90%); SUSTAINABLE DEVELOPMENT (78%); MILITARY WEAPONS (76%)
Geographic: GENEVA, SWITZERLAND (87%); SWITZERLAND (91%)
Load-Date: November 17, 2022",neutral,0.6607328653335571,balanced/neutral,['security'],[],"['governance', 'law', 'calls for']",[],1,0,3,0
2021,Unknown Title,"Body
2022 JUN 03 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News -- New research on Machine Learning is the subject of a report. According to news reporting from Macerata, Italy, by NewsRx journalists, research stated, ""The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored.""
 The news correspondents obtained a quote from the research from the University of Macerata, ""Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals.""
 According to the news reporters, the research concluded: ""Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.""
 This research has been peer-reviewed.
 For more information on this research see: Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms. AI & SOCIETY, 2022:1-15.
 Our news journalists report that additional information may be obtained by contacting Simona Tiribelli, Dept. of Political Sciences, Communication and International Relations, University of Macerata, Macerata, 62100 Italy.
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s00146-022-01455-6. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation.
 Keywords for this news article include: Macerata, Italy, Europe, Algorithms, Cyborgs, Emerging Technologies, Machine Learning.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: MACHINE LEARNING (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DISCRIMINATION (90%); EDUCATION RESEARCH (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); ROBOTICS (90%); INVESTIGATIONS (89%); NEGATIVE SOCIETAL NEWS (89%); NEWS REPORTING (78%); PHILOSOPHY (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); Macerata;Italy;Europe;Algorithms;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%)
Geographic: EUROPE (58%)
Load-Date: July 28, 2022","2022 JUN 03 (NewsRx) -- By a News Reporter-Staff News Editor at Robotics & Machine Learning Daily News -- New research on Machine Learning is the subject of a report. According to news reporting from Macerata, Italy, by NewsRx journalists, research stated, ""The increasing implementation of and reliance on machine-learning (ML) algorithms to perform tasks, deliver services and make decisions in health and healthcare have made the need for fairness in ML, and more specifically in healthcare ML algorithms (HMLA), a very important and urgent task. However, while the debate on fairness in the ethics of artificial intelligence (AI) and in HMLA has grown significantly over the last decade, the very concept of fairness as an ethical value has not yet been sufficiently explored.""
 The news correspondents obtained a quote from the research from the University of Macerata, ""Our paper aims to fill this gap and address the AI ethics principle of fairness from a conceptual standpoint, drawing insights from accounts of fairness elaborated in moral philosophy and using them to conceptualise fairness as an ethical value and to redefine fairness in HMLA accordingly. To achieve our goal, following a first section aimed at clarifying the background, methodology and structure of the paper, in the second section, we provide an overview of the discussion of the AI ethics principle of fairness in HMLA and show that the concept of fairness underlying this debate is framed in purely distributive terms and overlaps with non-discrimination, which is defined in turn as the absence of biases. After showing that this framing is inadequate, in the third section, we pursue an ethical inquiry into the concept of fairness and argue that fairness ought to be conceived of as an ethical value. Following a clarification of the relationship between fairness and non-discrimination, we show that the two do not overlap and that fairness requires much more than just non-discrimination. Moreover, we highlight that fairness not only has a distributive but also a socio-relational dimension. Finally, we pinpoint the constitutive components of fairness. In doing so, we base our arguments on a renewed reflection on the concept of respect, which goes beyond the idea of equal respect to include respect for individual persons. In the fourth section, we analyse the implications of our conceptual redefinition of fairness as an ethical value in the discussion of fairness in HMLA. Here, we claim that fairness requires more than non-discrimination and the absence of biases as well as more than just distribution; it needs to ensure that HMLA respects persons both as persons and as particular individuals.""
 According to the news reporters, the research concluded: ""Finally, in the fifth section, we sketch some broader implications and show how our inquiry can contribute to making HMLA and, more generally, AI promote the social good and a fairer society.""
 This research has been peer-reviewed.
 For more information on this research see: Beyond bias and discrimination: redefining the AI ethics principle of fairness in healthcare machine-learning algorithms. AI & SOCIETY, 2022:1-15.
 Our news journalists report that additional information may be obtained by contacting Simona Tiribelli, Dept. of Political Sciences, Communication and International Relations, University of Macerata, Macerata, 62100 Italy.
 The direct object identifier (DOI) for that additional information is: https://doi.org/10.1007/s00146-022-01455-6. This DOI is a link to an online electronic document that is either free or for purchase, and can be your direct source for a journal article and its citation.
 Keywords for this news article include: Macerata, Italy, Europe, Algorithms, Cyborgs, Emerging Technologies, Machine Learning.
 Our reports deliver fact-based news of research and discoveries from around the world. Copyright 2022, NewsRx LLC
Classification
Language: ENGLISH
Document-Type: Expanded Reporting
Publication-Type: Newsletter
Subject: MACHINE LEARNING (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); DISCRIMINATION (90%); EDUCATION RESEARCH (90%); EXPERIMENTATION & RESEARCH (90%); JOURNALISM (90%); ROBOTICS (90%); INVESTIGATIONS (89%); NEGATIVE SOCIETAL NEWS (89%); NEWS REPORTING (78%); PHILOSOPHY (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%); Macerata;Italy;Europe;Algorithms;Cyborgs;Emerging Technologies;Machine Learning (%)
Industry: MACHINE LEARNING (93%); ARTIFICIAL INTELLIGENCE ETHICS (92%); ARTIFICIAL INTELLIGENCE (90%); ROBOTICS (90%); NEWS REPORTING (78%); WRITERS (73%); COLLEGES & UNIVERSITIES (71%)
Geographic: EUROPE (58%)
Load-Date: July 28, 2022",neutral,0.8748106360435486,balanced/neutral,"['bias', 'discrimination', 'fairness']",['fairness'],[],"['machine learning', 'robotics']",3,1,0,2
